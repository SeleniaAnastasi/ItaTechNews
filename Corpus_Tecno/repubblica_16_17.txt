<doc url="https://www.repubblica.it/tecnologia/2017/11/28/foto/le_donne_della_maker_faire_2017-182457470/1/" parent_folder="Repubblica 16-17" id="file17861684" filename="1">
<p> Tecnologia </p>
<p> Dieci donne della Maker Faire 2017, fra intelligenza artificiale, urbanistica e ambiente </p>
<p> Area espositiva di 100mila metri quadrati, 400 stand, 800 progetti, 131 workshop su impresa 4.0, 129 laboratori dedicati ai bambini (da musica a robotica, passando per il coding e l’Internet delle cose), 55 scuole e 21 università. Sono i numeri dell'edizione di quest'anno. E una presenza femminile di rilievo: quasi il 45% dei team è composto da una o più donne. LEGGI L'ARTICOLO </p>
<p> di JAIME D'ALESSANDRO 28 Novembre 2017 </p>
<p> Chiara Russo Responsabile della area kids della Maker Faire, è Ceo e cofondatrice di Codemotion. Dopo la laurea in Ingegneria Informatica inizia la sua carriera nel 2004 nella consulenza. Mamma di Margherita, ama viaggiare e andare in barca a vela. Codemotion è oggi la più importante conferenza di tecnologia in Europa, con un network internazionale di oltre 570.000 sviluppatori, è presente in 6 paesi (Italia, Spagna, Germania, Olanda, Polonia e Israele) con un team di 30 persone solo in Italia. Oltre alle conferenze Codemotion organizza hackathon, progetti di open innovation a forte connotazione tecnologica e percorsi di formazione. Nel 2013 ha avviato una scuola di tecnologia per bambini e ragazzi </p>
<p> 1 di 9 </p>
<p> Chloé Rutzerveld Olandese, è "critical designer" del cibo: ne esplora e sfida la produzione e il consumo. Usa la tecnologia per trovare il modo di produrre in maniera più sostenibile. È affascinata dalla natura, dal corpo umano e dalla strana relazione che la gente ha con il cibo. Dopo la laurea Cum Laude conseguita all’Eindhoven University of Technology nel 2014, ha avviato il proprio atelier come Food and Concept Designer. </p>
<p> 2 di 9 </p>
<p> Marie Caye Francese ma residente in Olanda. Ddiplomata alla Design Academy of Eindhoven Cum Laude nel dipartimento Food-Non Food lavora assieme ad Arvid Jense. Arvid & Marie collaborano per unire competenze tecnologiche e pensiero critico. Alla Maker Faire presentano il loro robot capce di produrre bibite e gestirsi in autonomia. </p>
<p> 3 di 9 </p>
<p> Engeli Kummeling E' urbanista con esperienza in agenzie governative e di design urbano con una passione per la natura. Crede nella necessità di riconsiderare costantemente il modo in cui organizziamo e costruiamo l’ambiente in cui viviamo, così da renderlo adeguato alle esigenze future. </p>
<p> 4 di 9 </p>
<p> Chiara Cecchini E' uno degli Alumni del Food Innovation Program ed è tra i co-fondatori di Future Food. Vive in California, è responsabile della colonna Edible Innovation di Maker Magazine e del partenariato Future Food con Maker Faire NY e Maker Faire Bay Area. Appassionata di tecnologie esponenziali, è Ricercatrice presso la UC Davis e concentra i suoi studi, soprattutto, sull’Ai per migliorare il nostro sistema alimentare. </p>
<p> 5 di 9 </p>
<p> Maria Chiara Carrozza Scienziato Italiano, membro del Parlamento, eletta nel 2013 deputato con il Partito Democratico, già ministro dell’Istruzione, dell’Università e della Ricerca, è professore ordinario di Bioingegneria Industriale presso la Scuola Superiore Sant’Anna di Pisa, che ha diretto dal 2007 al 2013. È responsabile dell’Area “Neuro-Robotics” dell’Istituto di Biorobotica. Dal 2017 è membro della Task Force Italiana in Intelligenza Artificiale di AGID (Agenzia Digitale Italiana). </p>
<p> 6 di 9 </p>
<p> Laura Kampf Maker e youtuber di Colonia (Germania), di 33 anni. Ogni settimana Laura costruisce un nuovo progetto e lo documenta sul web. Ogni domenica uno dei suoi video è pubblicato, e il lunedì si ricomincia da zero. “Essere in grado di concentrarmi sul processo piuttosto che sul prodotto mi permette di esplorare non solo le idee buone ma anche quelle cattive che è talvolta molto più interessante” </p>
<p> 7 di 9 </p>
<p> Jessie Mooberry Lavora ad A^3 del progetto Airbus finalizzato a riunire decisori politici, tecnologi e Ong per modernizzare la gestione del traffico aereo. E’ tecnologa al Peace Innovation Lab di Standford e ha iniziato la sua carriera nei droni con Uplift Aeronautics costruendo aeroplani partendo da un garage di Standford con il primo drone umanitario non profit per il trasporto merci. </p>
<p> 8 di 9 </p>
<p> Sara Roversi Curatrice dell'area Food della Maker Faire, è nata il 10 marzo 1980 a Bologna. Imprenditrice seriale, appassionata, tra cibo, digitale, social innovation. Nel 2004 fonda con il marito, You Can Group che oggi è un ecosistema imprenditoriale che alimenta costantemente la nascita di nuove imprese. Dal 2010 è membro del consiglio direttivo di Unindustria Bologna. Nel 2012 riceve il Premio Bellisario dedicato alle giovani imprenditrici e il premio Giovani Imprenditori della Camera di Commercio di Bologna. Assieme al Prof. Matteo Vignoli, ha dato vita al master internazionale “Food Innovation Program” che ha la missione di ispirare e formare una nuova generazione di imprenditori ed innovatori nella filiera alimentare </p>
</doc>
<doc url="https://www.repubblica.it/economia/finanza/2016/07/24/news/ai_bot-144631966/" parent_folder="Repubblica 16-17" id="file17861670" filename="ai_bot-144631966">
<p> Economia </p>
<p> Intelligenza artificiale, con i Bot cambia il rapporto tra aziende e clienti </p>
<p> Il mercato dell'intelligenza artificiale è in rapida crescita: salgono i finanziamenti, nel giro di pochi anni varrà decine di miliardi. Tra le varie applicazioni accelerano i servizi di risposta automatica agli utenti, che cambiano anche il modo di relazionarsi con i consumatori </p>
<p> 24 Luglio 2016 2 minuti di lettura </p>
<p> MILANO - Non robot umanoidi o strani ritrovati della scienza. Magari vetture che si guidano sempre più da sole e case con elettrodomestici capaci di auto-regolarsi o rispondere ai nostri input più disparati. Ma le forme nelle quali si manifesta l'Intelligenza artificiale con la quale verremo in contatto saranno sempre più anche pixel e parole che ci appaiono su schermi di pc, smartphone o tablet e rispondono alle nostre domande. Già da qualche tempo Mark Zuckerberg, inventore di Facebook ma anche proprietario di alcuni fra i più pervasivi sistemi di messaging del mondo come Messanger e Whatsapp, ha annunciato al mondo l'arrivo dei "messenger Bot". Si tratta di programmi che interagiscono con gli utenti di un servizio online, come una chat o un sito web o un'applicazione di messaggistica, come se fossero un essere umano. Sui vari servizi di chat diffusi in ogni smartphone, proliferano conversazioni dedicate a questo o quel settore con l'intelligenza artificiale a rispondere alle sollecitazioni degli utenti. </p>
<p> Non è un caso che gli investimenti nelle startup dedicate proprio alla AI (Artificial intelligence) siano cresciuti esponenzialmente negli ultimi anni, dai 45 milioni di dollari del 2010 censiti da CBInsight a 310 l'anno scorso. Le stime sono disparate, ma nel prossimo decennio il mercato dell'AI è accreditato di valere oltre 40 miliardi di dollari. Anche l'Italia può fare la sua parte: è notizia fresca la decisione di Amazon di aprire un nuovo Centro di Sviluppo a Torino per mettere a punto le capacità di Intelligenza Artificiale e apprendimento automatico di Alexa, l'assistente vocale basata su cloud di Amazon, che supporta Amazon Echo, Echo Dot, Amazon Fire TV e Amazon Tap. Sarà dedicato al progresso del riconoscimento vocale e della comprensione del linguaggio naturale: il "machine learning", una branca dell'informatica che si basa su algoritmi che consentono ai sistemi di effettuare analisi predittive a partire da ampie raccolte di dati, senza che questi sistemi vengano appositamente programmati. L'AI "è dunque un campo molto molto ampio e riguarda tutte quelle soluzioni e tecnologie software (ma anche hardware) che consentono di elaborare grandi quantità di informazioni, estrarre del valore da queste informazioni e restituirle all'utente finale", spiega Enrico Donati, presidente e ceo di Assist, una realtà italiana cresciuta esponenzialmente negli ultimi anni che ha aperto la strada dei Bot nel rapporto tra imprese e clienti. Sono passati infatti anni da quando ha confezionato il primo Bot applicato al servizio clienti di Vodafone Italia, il servizio via messaggio che informa sulla disponibilità di credito. Ai più giovani potrà sembrare uno strumento rudimentale, ma i ragionamenti alla base sono proprio gli stessi di Zuckerberg, che poi ha portato l'innovazione alle punte massime con l'idea di offrire agli utenti una "esprienza" sempre più vicina al dialogo umano. "E' vero che gli studi siano in proposito sono nati 30 anni fa, ma questo è un momento di particolare sviluppo perché è maturata la tecnologia: è più forte e soprattutto più economica", aggiunge Donati. Al quale sottoponiamo il dilemma che sorge spontaneo, soprattutto quando si tratta di servizi che mediano tra aziende e clienti sostituendo quel che ora si fa in molti call center: tra tecnologia e posti di lavoro, chi vince? "La storia ci dice che gli Usa - dove evoluzione tecnologica è più avanti che altrove - non hanno un problema di disoccupazione paragonabile al nostro. Certo, se considero il singolo caso senza dubbio con una piattaforma di Bot e poche persone riesco a fare quel che fanno decine di call center. Ma in un periodo di tempo più ampio credo ci saranno possibilità di crescita del lavoro, con nuove professionalità. I report ci dicono che ne spariranno alcuni, ma sull'essempio di quel che accade in California avremo i nuovi 'Bot helper', quelli che perfezionano le risposte dell'intelligenza artificiale". La soluzione per evitare choc occupazionali è allora "moltiplicare i capitali investiti, che sono pochi in Italia. Investire in ricerca, in educazione, in formazione: non possiamo non diventare più forti anche in settori dove c'è bisogno di investimenti di capitali di rischio. Il venture capital deve diventare una vera industria, dobbiamo convincerci che solo investendo in 100 aziende ne troveremo una buona". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2017/09/06/news/al_tipsy_bar-174756432/" parent_folder="Repubblica 16-17" id="file17861685" filename="al_tipsy_bar-174756432">
<p> Tecnologia </p>
<p> 120 bicchieri all'ora e 60 tipi di mix. Sono i numeri dei due baristi robot del Tipsy Bar, "ingaggiati" dall'imprenditore Rino Armeni che lavora nella Sin City. Ma non mancano le polemiche </p>
<p> 06 Settembre 2017 1 minuti di lettura </p>
<p> CHI ENTRA per la prima volta al Tipsy Bar di Las Vegas può restare spiazzato perché dietro il bancone, pronti a servire, non troverà dei camerieri in carne e ossa, ma due robot. È l'idea del proprietario, l'imprenditore italiano Rino Armeni, ceo di Robotic Innovation e attivo nel settore della ristorazione. Che ha deciso di coniugare i due ruoli. I due robottini presenti nel locale, realizzati dall'azienda torinese Makr Shark, sostituiscono perfettamente gli otto baristi umani che li affiancano. Ordinare è semplice: ogni tavolino è dotato di un iPad con cui scegliere il drink, e, come dei bartender professionisti, i robot selezionano gli ingredienti, mescolano, aggiungono le guarnizioni e servono al bancone. Servizio completo. E sono anche più veloci dei loro "colleghi": riescono a servire ben 120 bicchieri l'ora e comporre 60 tipi di cocktail. </p>
<p> Tipsy Bar, a Las Vegas i cocktail li fa il robot </p>
<p> Nonostante sia la città delle stravaganze, anche a Las Vegas non sono mancate critiche all'utilizzo dei robot. Una parte degli impiegati locali ritiene che in questo modo si tolgano opportunità ai lavoratori, dando la precedenza alle macchine. Una paura che è aumentata negli ultimi anni, da quando l'utilizzo di computer e intelligenza artificiale ha contribuito a far calare i posti di lavoro, colpendo in particolare gli operai e i dipendenti dei fast food. Proprio questi ultimi sono scesi in piazza il 4 settembre scorso, nella giornata mondiale a loro dedicata, chiedendo contratti migliori e un aumento del salario. E in molti si sono detti preoccupati per l'utilizzo della tecnologia. </p>
<p> Ma non sono gli unici settori dove si respira questo timore: secondo uno studio dell'università statunitense Baylor, proposto dal sociologo Paul McClure, l'incremento della robotica e dell'intelligenza artificiale ha aumentato l'ansia legata alla disoccupazione e all'insicurezza finanziaria. Per questo Rino Armeni sottolinea come i suoi originali baristi siano nati come attrazione e non per sostituire gli esseri umani. Per ora i due robot del Tipsy Bar sono promossi a pieni voti dai clienti. Anche se qualche nostalgico sottolinea come, fra un drink e l'altro, non possa sfogarsi con loro e non ricevere nessun consiglio. Il calore umano, insomma, è sempre l'elemento che conta, non solo quello dell'alcol. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2017/08/21/news/attenti_ai_robot_killer_intervista_a_giorgio_metta_dell_iit-173545649/" parent_folder="Repubblica 16-17" id="file17861683" filename="attenti_ai_robot_killer_intervista_a_giorgio_metta_dell_iit-173545649">
<p> Tecnologia </p>
<p> Attenti ai robot soldato, Giorgio Metta (Iit): ''Ma a fare paura ora sono le macchine da guerra dotate di intelligenza artificiale'' </p>
<p> di GIULIANO ALUFFI </p>
<p> Per l'androide in trincea oggi la tecnologia è davvero immatura. Così il direttore della ricerca all'Istituto italiano di tecnologia di Genova commenta l'appello all'Onu di Musk e altri 116 ''big'' dell'hi-tech </p>
<p> 21 Agosto 2017 1 minuti di lettura </p>
<p> "Al momento queste tecnologie non esistono in forme davvero concrete". Così puntualizza uno dei maggiori esperti italiani di intelligenza artificiale, Giorgio Metta, direttore della ricerca all'IIT commentando l'appello all'Onu di Musk e altri 116 ''big'' contro l'uso dei robot nelle trincee. "Però i progressi nei sistemi robotici sono stati notevoli, anche se bisogna fare dei distinguo. Se si parla di un robot-soldato umanoide, allora oggi la tecnologia è davvero immatura". Il pericolo non è "Terminator", quindi? I rischi più concreti sono su macchine non antropomorfe: ad esempio un carrarmato dotato dei più moderni sistemi di visione e di riconoscimento (sistemi che già sono in uso sui prototipi di auto driverless), dotato di cingoli, cannoni, lanciamissili e dotato di un'intelligenza sufficiente a prendere decisioni. </p>
<p> Come mai l’appello di oggi viene dagli esponenti dell’industria dell’intelligenza artificiale? Perché oggi i più importanti ricercatori in intelligenza artificiale lavorano per l’industria. Gli investimenti nel settore di Google, di Elon Musk, di Toyota, di Microsoft sono stati così ingenti negli ultimi anni da far diventare queste imprese leader indiscusse nella ricerca. Se io fossi un suo studente e le dicessi: “Professor Metta, ho quest’idea per un robot soldato…” lei dovrebbe avvisare qualcuno o cercare qualche autorizzazione? Al momento, finché si tratta solo di ricerca teorica e non di produzione vera e propria, non c’è nessuna regolamentazione in questo senso. Comunque quando facciamo progetti per la commissione europea, ci viene chiesto di specificare se può esserci un “dual use”, ossia se si tratta di una tecnologia che oltre agli scopi civili potrebbe essere impiegata anche per usi militari. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2016/11/13/news/bot_realta_virtuale_e_disoccupazione_tech_di_cosa_si_e_parlato_al_web_summit-151820470/" parent_folder="Repubblica 16-17" id="file17861656" filename="bot_realta_virtuale_e_disoccupazione_tech_di_cosa_si_e_parlato_al_web_summit-151820470">
<p> Tecnologia </p>
<p> Ultim'ora 14.53 </p>
<p> Sanità Calabria: si dimette il commissario Zuccatelli, governo lavora a successore </p>
<p> Web Summit tra bot, realtà virtuale e disoccupazione tech </p>
<p> Filippo Santelli </p>
<p> Al mega evento digitale di Lisbona il settore più caldo è quello dell’intelligenza artificiale: dalle imprese del consumo ai social network come Facebook, tutti studiano come automatizzare i propri sistemi. L’effetto? Tanti posti di lavoro spariranno </p>
<p> 13 Novembre 2016 3 minuti di lettura </p>
<p> ROMA - Ne ha parlato sul palco il capo della tecnologia di Facebook. Ne parlavano dietro le quinte gli investitori. La guardano le grandi aziende di tutti i settori. Ci lavorano molte delle 1.500 startup che hanno esposto alla fiera. A voler identificare una tecnologia calda, tra quelle che tra lunedì e venerdì hanno invaso il Web Summit di Lisbona, il più grande evento digitale d'Europa, non si può che citare l'intelligenza artificiale. I cosiddetti bot, algoritmi in grado di percepire, pensare e dialogare come umani e con gli umani. E di sostituirli in molte delle loro mansioni ordinarie, dall'assistenza clienti alla guida di un veicolo. Ma oltre all'AI, di fatto già una realtà, i 53mila visitatori del Summit hanno potuto avere un assaggio anche delle prossime frontiere in ambito digitale, quelle che vedremo materializzarsi nei prossimi anni. Dalla auto che si guidano da sole alla vita nella realtà virtuale. Un bot per amico "Voglio parlarvi dei nostri prossimi dieci anni", ha esordito sul palco del Summit Mike Schroepfer, capo della tecnologia di Facebook. Che per il social network significano soprattutto intelligenza artificiale e deep learning, cervelli digitali capaci di comprendere sempre più a fondo testi e immagini. Schroepfer ha mostrato cosa significherà nel concreto. Se oggi di in una foto postata dagli utenti l'algoritmo riconoscere il numero di persone, domani potrà anche interpretarne i gesti, capire cosa sta succedendo. E così per i testi, da cui potrà estrarre le informazioni essenziali. Tutto per organizzare in maniera sempre più efficace la montagna di dati che circolano sui social, da Facebook a Instagram, e proporre a utenti e pubblicitari quelle più rilevanti. Ma a fare un giro tra i palchi e padiglioni del Summit, si capisce che ai bot stanno guardano le aziende di tanti settori, dai beni di consumo alla finanza, per automatizzare una serie di servizi oggi affidati agli umani. Una startup tedesca per esempio, CollectAI, gestisce in maniera automatica il recupero dei crediti. Tante altre propongono di affidare ai robot il lavoro oscuro del servizi clienti. "E il settore su cui investo di più", conferma Phil Libin, ex amministratore delegato di Evernote e ora partner del super fondo venture Usa General Catalyst. "Le applicazioni più immediate sono quelle per le imprese, ma credo che presto ne arriveranno anche per i consumatori". La Snapchat dei bot, per citare una di quelle in cui il suo fondo ha investito: "Sì, magari è già lì fuori". </p>
<p> Un bot per nemico Ma se il centralinista, il responsabile vendite o l'autista del futuro saranno intelligenze artificiali, non è difficile immaginare qual sarà l'impatto di questa tecnologia sul mercato del lavoro. La metà degli oltre 500 investitori presenti al Summit, il 53%, ha dichiarato che "è inevitabile che l'intelligenza artificiale distrugga milioni di posti". E per il 93% di loro i governi mondiali sono impreparati a gestire questo cambiamento. Un ritardo che ha riconosciuto anche l'ex presidente della Commissione europea Barroso, intervenuto all'inaugurazione dell'evento: la politica globale non ha ancora trovato un modo per regolare un settore che avanza a ritmi supersonici, a lei sconosciuti. Il rischio di questo sfasamento è che generi delle reazioni anti tecnologiche. Se il problema viene posto qui al Web Summit è perché lo scenario spaventa non poco i giganti del digitale. Automobili condivise Un'industria su cui l'automazione sta arrivando alla massima velocità è quella dell'automobile. Lo si capisce dal numero di grandi aziende che hanno mandato i loro rappresentanti al Web Summit: dal Ceo di Renault-Nissan Carlos Ghosn, ai manager di Cadillac, Aston Martin, Bmw, Volvo. Si è parlato ovviamente di guida autonoma e degli ostacoli che ci separano da un domani (tra il 2020 e il 2025) in cui potremmo staccare le macchine dal volante. Ma anche del cambiamento di paradigma che questa innovazione porterà: la mobilità non sarà più un prodotto su quattro ruote, ma un ecosistema di servizi on demand o in condivisione. E' soprattutto per questo, più ancora che per lo sviluppo delle tecnologie, che le società di automotive hanno cominciato a mettere il naso tra le startup. Ghosn ha detto che la sua società creerà una "porta di ingresso unica" a cui potranno rivolgersi le aziende innovative che vogliono lavorare con lei. Per evitare che la loro voce si perda nella lentezza decisionale di una grande multinazionale. Realtà parallele Il flusso di investimenti sui bot e sulla mobilità è già enorme. Così come sulla realtà virtuale, un altro dei settori più chiacchierati del Summit, anche se nel suo caso è più difficile capire quale sarà la "killer app", l'applicazione che porterà le masse a mettere la testa dentro i visori e trasferirsi nel loro universo parallelo. Una delle applicazioni più immediate vista a Lisbona è in ambito medico, nei processi riabilitativi. Mentre gli sviluppatori di Disney o di Sony sono al lavoro su nuovi prodotti immersivi, dai film ai videogiochi, e le aziende li studiano per proporre nuovi e più efficaci modelli di training ai dipendenti. I dispositivi però restano ancora complessi e costosi per un utilizzo "privato": la sfida è renderla una tecnologia per tutti. Htc ha appena annunciato il primo visore Vive wireless. Facebook, nei prossimi mesi, metterà il pc direttamente nel suo Oculus. Ci convincerà che chattare via avatar è meglio? L'impressione è che ci vorrà ancora un po' di tempo. @filipposantelli </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2016/06/30/news/dalle_leggi_della_robotica_di_asimov_a_oggi_agli_algoritmi_serve_un_etica-143124026/" parent_folder="Repubblica 16-17" id="file17861673" filename="dalle_leggi_della_robotica_di_asimov_a_oggi_agli_algoritmi_serve_un_etica-143124026">
<p> Tecnologia </p>
<p> Dalle leggi della robotica di Asimov a oggi: agli algoritmi serve un’etica </p>
<p> di SIMONE COSIMI </p>
<p> Le driverless car saranno il primo vero fronte di scontro, perché il più concreto, fra due gerarchie di valori: quella umana e quella del codice. Ma non tutti la pensano allo stesso modo </p>
<p> 30 Giugno 2016 3 minuti di lettura </p>
<p> QUALCHE giorno fa ha fatto molto discutere la notizia sul robot in grado di violare la prima “legge della robotica” teorizzata da Isaac Asimov nei suoi romanzi fantascientifici. Costruito da un ingegnere e artista dell’università di Berkeley, quel braccio robotico è stato infatti programmato per scegliere se ferire o meno un essere umano. L’altro giorno è invece saltato fuori sul web un nuovo video rilasciato da quei cervelloni della Boston Dynamics, l’azienda acquistata da Google nel 2013 dalla quale Mountain View ha tuttavia annunciato di volersi svincolare. Nella clip, al solito raggelante, si vede il nuovo cane robot “Spot Mini” imbastire un tira e molla col “padrone”, chiamiamolo così, intorno a una lattina di birra. In questo come in altri casi non dotati di una plasticità antropomorfa – dagli algoritmi ai codici con cui sono e saranno programmati i miliardi di oggetti connessi fino ai network d’intelligenza artificiale – la domanda di fondo, che tutti conoscono e nessuno riesce davvero a sciogliere, è tuttavia sempre la stessa: cosa accadrà quando l’etica umana verrà scombussolata da sistemi dotati di una serie di regole in contrasto con le nostre? A dire il vero qualcuno l’allarme l’ha lanciato: l’astrofisico Stephen Hawking e il folle imprenditore Elon Musk (Telsa, Space X e così via) si sono per esempio detti molto preoccupati sui rischi legati all’evoluzione dell’intelligenza artificiale. Questioni simili se le pongono in molti, dai filosofi (come lo svedese Nick Bostrom, che insegna a Oxford) alle tante grandi menti impegnate con i colossi dell’hi-tech internazionale (vedi alla voce Ray Kurzweil, in forze a Google), con esiti e posizioni ovviamente diverse. Al solito, la forchetta si muove fra apocalittici e integrati. Forse, però, una delle prime esperienze che ci porranno la questione concretamente di fronte sarà quella delle auto a guida autonoma. È intorno al cuore del codice che forniremo a quei veicoli senza pilota che si giocherà il primo tempo di questa partita. Prima che le altre forme d’intelligenza artificiale possano raggiungere livelli di cui preoccuparsi. </p>
<p> Chi salvare in caso d’incidente? Una ricerca pubblicata su Science ha spalancato ancora una volta la questione etica proponendo un quesito di fondo. Anzi, il quesito: “Supponiamo che un’auto senza conducente debba scegliere tra colpire un gruppo di pedoni o deviare e andare a sbattere danneggiando i propri passeggeri. Cosa dovrebbe fare?”. Mettere a rischio la vita dei passeggeri evitando magari una carneficina numericamente più consistente o tutelare gli occupanti ponderando, per così dire, le perdite potenziali? Le risposte dei cittadini statunitensi interpellati sul tema manifestano la frattura morale in tutta la sua profondità. Il risultato è che sarebbe sacrosanto limitare i danni ma d’altronde nessuno si mostrerebbe disponibile a farsi trasportare da un mezzo così programmato. Quasi tutti la penseremmo d’altronde così. Si apre insomma un gioco a somma zero. La questione si muove ovviamente sulla scala valoriale. Per parlare davvero di etica è necessario che le macchine (stradali, robotiche o algoritmiche) siano in grado di produrne una autonoma leggendo e riordinando il mondo. Altrimenti tutto continuerà in fondo a dipendere solo da come le abbiamo programmate. Lo stesso dilemma, in un contesto diverso, si pone per esempio nel caso dei droni armati in grado di identificare autonomamente i bersagli e sparare. Insomma, per molti i veri problemi nasceranno quando i programmatori avranno davvero perso il controllo di ciò che hanno creato. Per altri, invece, la questione rimane comunque alla base: servirebbe un coding etico, cioè un modo di istruire le macchine in maniera che non possano mai arrivare a sciogliere da sole specifiche questioni. Tuttavia rimarrebbe sospeso l’ennesimo quesito: quali sono quelle specifiche questioni? In altre parole, si tratta della responsabilità morale di chi scrive gli algoritmi di cui parla per esempio da tempo David Orban della Singularity University. Affronta la questione sotto diversi punti di vista, da quello finanziario all’internet delle cose. Sì, perché siamo già oggi immersi in una ragnatela di decisioni che ci sfuggono, dal trading delle Borse alle ricerche su internet fino alle mappe intelligenti che decidono come ricalcolare i nostri percorsi. L’auto autonoma sarà tuttavia l’emersione più importante della faccenda perché fisica, concreta, applicata a una dimensione capillare e portatrice di sviluppi complessi: dai software modificabili all’intreccio di normative che incroceranno legislazione, assicurazioni, acquirenti. “La risposta è sì, serve un’etica dell’algoritmo e quell’etica va costruita attraverso un confronto esterno al mondo dei laboratori – risponde Giovanni Boccia Artieri, sociologo e docente di internet studies all’università di Urbino – perché deve mettere appunto in chiaro delle soglie limite sull’utilizzo delle macchine. Dovranno essere soglie universali, che si applichino oltre la singola invenzione o scoperta”. Insomma, oggi sono le driverless car, domani sarà una sempre più pervasiva intelligenza artificiale di cui magari c’innamoreremo, dopodomani chissà: “In fondo, e Asimov ne è solo un esempio, sono temi non così inediti – aggiunge Boccia Artieri – li abbiamo già affrontati. Ci si ripresentano ora che quelle sue tre leggi della robotica hanno motivo di essere implementate perché molte delle cose previste in quelli e altri romanzi sono possibili. Il punto però è uno: stavolta dobbiamo cercare di arrivare prima e non dopo. Dobbiamo sottrarre alla contingenza dei programmatori la risoluzione di queste questioni, per puntare a una visione complessiva dei valori che vogliamo non vengano intaccati dalla dittatura dell’algoritmo”. Anche perché, spesso senza accorgercene, stiamo già correndo il rischio di cambiare i nostri atteggiamenti e le nostre scelte. In un lento lavoro di mutazione: “Nel momento in cui la scarsa trasparenza degli algoritmi che ci aiutano nelle azioni di tutti i giorni diventa la normalità, cioè il nostro quotidiano, abbiamo già smarrito un pezzo dell’etica individuale”. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/scienze/2016/11/02/news/dal_treno_a_idrogeno_all_intelligenza_artificiale_i_pareri_delle_esperte-151174626/" parent_folder="Repubblica 16-17" id="file17861682" filename="dal_treno_a_idrogeno_all_intelligenza_artificiale_i_pareri_delle_esperte-151174626">
<p> Dal treno a idrogeno all'intelligenza artificiale, i pareri delle esperte </p>
<p> Una tecnologa, una chimica, un'informatica e un'oncologa. Quattro studiose del network 100esperte.it ci spiegano l'attualità scientifica: dai robot che imparano al treno tedesco a idrogeno </p>
<p> ROMA - Chi sono le studiose che hanno accettato di far parte del network 100esperte.it? Quali sono le loro competenze? Abbiamo voluto "mettere alla prova" la rete di ricercatrici presentato al Festival di Genova chiedendo a quattro di loro di aiutarci nell'interpretare quattro temi scientifici di stringente attualità, dalle macchine molecolari alla robotica. Ecco le loro risposte. Isabella Nova, docente di chimica industriale e tecnologia al Politecnico di Milano, autrice di studi e brevetti innovativi sulla riduzione delle emissioni inquinanti. </p>
<p> In Germania è stato appena varato il treno a idrogeno, ma le nostre città superano i limiti dello smog con sempre maggior frequenza. Cosa può fare la scienza? Oggi uno dei problemi più seri è che le marmitte catalitiche sono efficaci solo quando la temperatura degli scarichi supera i 150 gradi: quindi all'avviamento le auto, ancora fredde, inquinano, mentre gli autobus, per come si muovono raggiungono raramente temperature alte. L'inquinamento imputabile ai "motori freddi" può arrivare fino al 60% di quello totale del traffico. La nostra risposta è ideare catalizzatori che abbassano a 100 gradi la temperatura necessaria, e materiali speciali a doppia azione: finché sono a bassa temperatura assorbono le emissioni nocive, impedendo loro di diffondersi nell'aria, e poi le convertono in sostanze innocue (azoto e acqua) quando la temperatura si alza. Col mio gruppo del Politecnico di Milano abbiamo sviluppato modelli matematici che grandi realtà dell'automotive europeo - oltre che, di recente, gli autobus di Milano e i Suv di quasi tutte le marche - usano per le marmitte catalitiche a bassa temperatura. Ma più radicale ancora sarà, per l'ambiente, l'era dei veicoli a idrogeno. Lavoriamo a un sistema per convertire in idrogeno non solo la Co2, tramite la cosiddetta fotosintesi artificiale, ma anche i combustibili fossili: così un'auto potrà ancora alimentarsi a benzina, ma convertirla subito in idrogeno e non inquinare più. Barbara Caputo, docente ingegneria informatica all'Università La Sapienza di Roma. E' stata definita "la donna che parla coi robot" per i suoi risultati nello sviluppo di algoritmi perché i robot possano apprendere direttamente da Internet. Perché oggi è così importante che i robot imparino a imparare? Perché sono ancora troppo rigidi e fanno molta fatica ad affrontare ambienti imprevisti - lo abbiamo visto anche mesi fa con il tragico errore dell'autopilota della Tesla che ha scambiato un camion bianco per il cielo. Non è stato un caso: i robot oggi, per dirla brutalmente, non ci vedono molto bene. La visione artificiale è la sfida più importante che stiamo affrontando per poter avere l'aiuto dei robot a tutti i livelli della vita quotidiana - pensiamo solo alla necessità di badanti per la popolazione che invecchia o di veicoli driverless per chi, anziano, non è più in grado di guidare. Oggi anche un problema banale, come "metti in ordine la stanza" è arduo, per un robot. Cosa è una "stanza"? Quante stanze diverse posso avere al mondo? Quanti tipi di mobili? Di ostacoli? Il robot deve essere capace di astrarre, ossia "capire" il concetto di stanza, e riconoscere come tale quella in cui si trova. Col mio gruppo sviluppo algoritmi che permettono ai robot di cercare sul Web immagini simili a ciò che si trova davanti a loro, così da identificare gli oggetti e muoversi libero nel mondo, affrancato dai limiti dell'esperienza personale. E' un po' come quando l'uomo ha inventato la scrittura ed ha potuto, così, abbeverarsi al sapere di tutti gli altri per risolvere problemi inediti. Margherita Venturi, docente di chimica generale all'Università di Bologna. Con Vincenzo Balzani è la pioniera, italiana e internazionale, delle macchine molecolari. Le macchine molecolari - che hanno appena vinto il Nobel per la chimica - sono il futuro? Che siano il futuro, più che il presente, si vede da un fatto: il comitato del Nobel è stata criticato non solo per l'inspiegabile dimenticanza del fondatore italiano di queste ricerche - Vincenzo Balzani, con cui collaboro sin dagli anni '80, facevamo nanotecnologia già 3-4 anni prima che nascesse quella parola - ma anche perché in genere si premiano ricerche con applicazioni già assodate. Che in questo caso ancora non esistono. Ma le prospettive sono rivoluzionarie. Tra le più vicine, muovere le molecole a comando per usarle come piccolissimi "bit" per computer che non siano più elettronici, ma chimici: un po' come il nostro cervello, per capirci. Un altro ambito importantissimo è quello medico: in futuro sapremo programmare dei "nanorobot" perché diano la caccia, nell'organismo, alle cellule tumorali ovunque si trovino. La seconda ondata della tecnologia sarà una nuova era: un domani ai medici potrebbe bastare spruzzare nella nostra bocca le nanomacchine, e queste risolveranno i problemi che incontrano muovendosi, per poi essere riespulse. E' ancora in parte fantascienza: le sfide sono grandi, ad esempio scoprire come si possono sincronizzare le nanomacchine per farle lavorare in squadra. Una strada promettente - oggetto delle mie ricerche di oggi - è l'uso della luce. Raffaella Giavazzi, dirige il laboratorio di biologia e terapia delle metastasi tumorali dell'IRCCS Mario Negri. E' autrice di oltre 200 pubblicazioni sulla biologia e farmacologia dei tumori. Potremo sconfiggere il cancro, come si dice oggi, "affamando la bestia"? Oggi c'è sempre più coscienza dell'importanza di tagliare i rifornimenti del tumore, contrastando la formazione dei nuovi vasi sanguigni che il tumore crea per ricevere ossigeno e nutrimento. Questo processo, detto "angiogenesi" è anche parte essenziale della diffusione del nemico più insidioso: le metastasi. Perché sono proprio i vasi sanguigni a permettere che le cellule tumorali lascino il sito originale del cancro e si spargano agli altri organi. Per questo io studio strategie che prevengano, riducano o distruggano i vasi sanguigni "cattivi", così da fermare la crescita del tumore. Però bisogna identificarli, questi vasi. Con il mio gruppo riusciamo a riconoscere molecole specifiche sui vasi del tumore così possiamo attaccarli in modo selettivo con un farmaco, risparmiando i vasi sanguigni sani. E poi sviluppiamo farmaci che - in combinazione con terapie note, come la chemioterapia - ostacolano efficacemente la formazione di nuovi vasi. Un ambito ancora più nuovo è lo studio delle "conversazioni" chimiche che i tumori hanno con il loro ambiente mentre crescono. Sono cambiamenti molecolari che possiamo cercare di intercettare per "dissuadere" il tumore dal progredire, intervenendo quindi non solo sul tumore ma sul microambiente in cui si trova. </p>
<p> Il tuo contributo è fondamentale per avere un’informazione di qualità. Sostieni il giornalismo di Repubblica. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/social-network/2016/04/13/news/f8_2016_facebook_nel_futuro_tra_video_360_8k_realta_virtuale_e_intelligenza_artificiale-137554355/" parent_folder="Repubblica 16-17" id="file17861651" filename="f8_2016_facebook_nel_futuro_tra_video_360_8k_realta_virtuale_e_intelligenza_artificiale-137554355">
<p> Tecnologia </p>
<p> F8 2016, Facebook nel futuro tra video 360°8k, realtà virtuale e Intelligenza artificiale </p>
<p> di ALESSANDRO CREA </p>
<p> Durante la conferenza annuale, Zuckerberg ha tenuto un keynote in cui ha illustrato la visione del social tra bot, videocamere e altre soluzioni, per un mondo sempre più connesso </p>
<p> 13 Aprile 2016 2° minuti di lettura </p>
<p> UN KEYNOTE pieno di novità, quello di Mark Zuckerberg. Il ceo di Facebook cui ha illustrato quella che è la sua visione del futuro, non solo per quanto riguarda lo sviluppo ma anche per gli scenari a venire, in cui realtà virtuale, intelligenza artificiale e connettività saranno i protagonisti assoluti. Connettere il mondo. La roadmap mostrata è infatti chiarissima, e illustra quella che sarà l'evoluzione del popolare social network nei prossimi 10 anni. Se si identifica l'azienda Facebook esclusivamente col sito Facebook, pensare che la prima ha intenzione di introdurre soluzioni hardware e software in campi molto distanti dai social può sembrare confusivo, ma in realtà non lo è. </p>
<p> Roadmap final. Per Zuckerberg infatti il social network è stato solo il primo stadio di attuazione della vera mission dell'azienda che è, da sempre, "connettere il mondo". In questa visione più ampia che porta il concetto di socialità sostenuto dalla tecnologia a una dimensione più vasta, è normale pensare sia alle app per la comunicazione, come WhatsApp, Messenger e Instagram, sia agli sviluppi futuri fatti di realtà virtuale e intelligenza artificiale. Proprio da questi due ambiti del resto arrivano le novità più interessanti. Realtà virtuale e aumentata per tutti. La prima si chiama Facebook Surround 360 ed è una videocamera che ha l'aspetto di un disco volante, al cui interno troviamo un sistema di ben 17 videocamere che, grazie a un avanzato algoritmo per lo stitching (l'operazione di unire e fondere diversi spezzoni di filmato per crearne uno panoramico), è in grado di produrre filmati ad altissima risoluzione, 8k, a 360° e già pronti per la realtà virtuale, dando così la possibilità ai creatori di contenuti di offrirne di nuovi e più coinvolgenti su Facebook, fruibili tramite il sito o attraverso un visore per la realtà virtuale (Facebook infatti ha acquisito Oculus nel 2014). L'aspetto più interessante però è che Facebook Surround 360 non è un progetto proprietario ma sarà open source: l'azienda di Menlo Park infatti posterà i progetti e tutto il materiale inerente su GitHub entro l'estate, con l'obiettivo di stimolare il mercato e indirizzarlo allo sviluppo di soluzioni di questo tipo. Facebook surround 360. Non a caso infatti Zuckerberg ha sottolineato che, entro una decina d'anni, i dispositivi per la realtà virtuale o aumentata avranno l'aspetto di normali oggetti di utilizzo comune, ad esempio gli occhiali e faranno parte della nostra vita quotidiana. Bot e Intelligenza Artificiale. Il secondo pilastro della roadmap è rappresentato invece dall'Intelligenza Artificiale e anche in questo caso Zuckerberg ha annunciato novità. Sulla scia di quanto appena fatto da Microsoft, con l'introduzione dei BOT su Skype e la futura maggior integrazione di Cortana nell'app, che sarà in grado di dialogare con le IA e svolgere dei compiti per noi, i BOT sbarcano anche in Messenger. Facebook crede che Messenger possa diventare un canale preferenziale soprattutto per le aziende, uno strumento tramite cui interagire con i propri clienti e, per questo, ha pensato a un sistema di API per gli sviluppatori e a una nuova piattaforma che si muove soprattutto in questa direzione. Se dunque i BOT di Skype sono pensati per un pubblico consumer, con la possibilità di prenotare voli, alberghi e ristoranti, Facebook ha pensato a IA in grado di fornire non solo i classici contenuti automatizzati come aggiornamenti su meteo e traffico, ma anche comunicazioni personalizzate in linguaggio naturale, ricevute, notifiche ed altro ancora. In quest'ottica dunque i BOT potrebbero rappresentare un nuovo importante strumento per il commercio, l'assistenza clienti e anche per i media. In futuro quindi gli utenti potranno ordinare tramite loro un mazzo di fiori, consegnare una bolla di lavoro ma anche ottenere notizie personalizzate da parte dei media. Del terzo pilastro, quello legato alla connettività, che prevede anche l'impegno diretto nello sviluppo di infrastrutture di telecomunicazione sia terrestri che saziali, ad esempio satellitari, si parlerà invece probabilmente nei prossimi giorni, ma anche qui ci saranno sicuramente sorprese notevoli. Per quanto riguarda il social network vero e proprio infine è in arrivo l'interessante tasto Salva, che consentirà agli utenti di appuntare articoli, prodotti e video incontrati in giro per il Web, all'interno di un elenco privato dentro la propria pagina Facebook. L'elenco sarà quindi comodamente consultabile da qualsiasi dispositivo quando servirà all'utente o semplicemente quando ne avrà voglia. Facebook inoltre produrrà anche degli avvisi per l'utente in alcuni contesti: se ad esempio nella lista c'è un prodotto, riceveremo un messaggio quando questo sarà disponibile in vendita. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/social-network/2016/06/02/news/facebook_annuncia_deeptext_cosi_la_nostra_intelligenza_artificiale_capira_tutto_cio_che_scrivi_-141149789/" parent_folder="Repubblica 16-17" id="file17861650" filename="facebook_annuncia_deeptext_cosi_la_nostra_intelligenza_artificiale_capira_tutto_cio_che_scrivi_-141149789">
<p> Tecnologia </p>
<p> Facebook annuncia DeepText: "La nostra intelligenza artificiale capirà tutto ciò che scrivi" </p>
<p> Rosita Rijtano </p>
<p> Il sistema trae la sua forza dal deep learning, cioè da quella tecnologia d'apprendimento automatico che mima il comportamento dei nostri neuroni, ed è già in grado di capire il contenuto testuale di svariate centinaia di post al secondo in più di venti differenti linguaggi con un'accuratezza "quasi umana" </p>
<p> 02 Giugno 2016 2 minuti di lettura </p>
<p> CAPIRA' tutto ciò che scriviamo con un'accuratezza "quasi umana". È l'intelligenza artificiale di Facebook, che adesso ha a disposizione un nuovo strumento, appena annunciato in un post sul blog ufficiale della compagnia e firmato da tre dipendenti: Aparna Lakshmiratan, Ahmad Abdulkader e Joy Zhang. Chiamato DeepText, stando a quanto dicono i suoi creatori, è già in grado di capire il contenuto testuale di svariate migliaia di post al secondo, in più di venti linguaggi differenti. Ma farà sempre meglio, giorno dopo giorno. Un sistema che trae la propria forza dal deep learning, cioè da quella tecnologia d'apprendimento automatico, sviluppata a partire dagli anni Ottanta, che simula il comportamento dei neuroni umani. E si affina con l'esperienza. Nell'immediato futuro Menlo Park conta di sfruttare DeepText per classificare ogni contenuto fatto di parole che viene pubblicato sulla piattaforma: oggi si parla di due trilioni di post. Una conquista necessaria per profilarci ancora più nel dettaglio e offrirci suggerimenti rispondenti ai nostri interessi, sia per quel che concerne i contenuti da vedere sulla timeline sia per i servizi che il social network mette a disposizione al proprio interno. Al momento lo strumento viene testato in due modi. Primo: in Facebook Messenger permette all'intelligenza artificiale di capire, tra le altre cose, quando chattando con un amico abbiamo bisogno di un passaggio e di darci immediatamente l'opportunità di chiamare un taxi. Secondo: di conoscere se stiamo cercando di vendere qualcosa. In questo caso vedremo subito comparire in bacheca la pubblicità dei servizi sviluppati da Mark Zuckerberg & Co. che aiutano a concludere l'affare nel recinto della rete blu. Senza bisogno di rivolgerci altrove. Ma, annota Quartz, il nuovo motore "intelligente" potrebbe essere usato anche per raffinare le ricerche dentro al social. Che in questo modo si configura ulteriormente come un ecosistema a sé stante, autarchico, in cui è possibile fare di tutto: da ordinare la pizza allo scambio di denaro, passando per le telefonate. In diretta concorrenza con Google. </p>
<p> Ultima, ma non per ordine d'importanza, è la possibilità di impiegarlo per filtrare lo spam o eliminare i commenti e i post offensivi. Del resto, non sarebbe una novità se si pensa alle tecniche di riconoscimento delle immagini ampiamente sfruttate. Proprio nei giorni scorsi il sito di tecnologia TechCrunch riportava che adesso i sistemi di intelligenza artificiale di Facebook segnalano molte più foto lesive, o considerate tali, degli umani. E a quanto pare tutto ciò presto potrebbe accadere per i testi e forse pure per le notizie, dietro la cui selezione fino ad ora c'è stato lo zampino della mano umana. Si prospetta uno scenario non privo di distopie, come dimostrano i casi di famose opere d'arte (L'origine del mondo di Gustave Courbet), foto di statue (la sirenetta di Copenaghen) e istantanee artistiche. Colpevoli di violare le regole del buon costume imposte dal network, censurate senza appello, semplicemente perché non capite. @rositarijtano </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/social-network/2016/04/05/news/facebook_foto_ciechi-136952080/" parent_folder="Repubblica 16-17" id="file17861653" filename="facebook_foto_ciechi-136952080">
<p> Tecnologia </p>
<p> Ultim'ora 14.53 </p>
<p> Sanità Calabria: si dimette il commissario Zuccatelli, governo lavora a successore </p>
<p> Facebook "legge" le foto per i ciechi grazie all'intelligenza artificiale </p>
<p> Il social network lancia un servizio per descrivere le immagini a chi non vede. Per ora disponibile solo in inglese e per iOS, a breve anche per Android </p>
<p> 05 Aprile 2016 1 minuti di lettura </p>
<p> L'INTELLIGENZA artificiale al servizio dei ciechi. Mentre la rete diventa sempre più il regno incontrastato delle immagini, il gigante dei social network Facebook si attrezza per far "leggere" le foto ai non vedenti. Il nuovo servizio viene lanciato oggi per fare da guida a chi non può vedere il mare magnum di fotografie di cui i social sono quotidianamente inondati. Usando l'intelligenza artificiale, i server di Facebook sono ora in grado di decodificare e descrivere le immagini caricate sul sito, rendendole disponibili in una forma che può essere letta dagli screen reader, sofisticati software utilizzati dai ciechi per accedere ai contenuti online. Gli screen reader interpretano però solo il testo, non le immagini. Ora il nuovo servizio si propone di risolvere il problema. Interpretando le immagini attraverso l'intelligenza artificiale, che riconosce visi e oggetti. </p>
<p> C'è una sensibilità particolare ad ispirare l'operazione: quella di Matt King, ingegnere di Facebook che ha perso la vista in seguito ad una retinite pigmentosa. L'opzione parte oggi su iOS e a breve sarà disponibile per Android. Sull'iPhone è necessario attivare lo screen reader già inserito, VoiceOver, per permettere alle fotografie di venire "lette". Il servizio sfrutta il software per il riconoscimento degli oggetti sviluppato da Facebook. Per il momento, è disponibile solo in inglese, in formato piuttosto stringato. Le descrizioni sono del tipo: "nella foto ci sono due persone che stanno sorridendo", per un massimo di cento parole. Restrizione che limita la possibilità del computer di fornire una descrizione dettagliata. Ma nelle intenzioni di Facebook diverrà col tempo sempre più precisa e raffinata, fino anche a poter rispondere a eventuali domande che l'utente vorrà porre sulle immagini. Il mese scorso Twitter ha mosso i primi passi nella stessa direzione, permettendo agli utenti di aggiungere una descrizione delle foto postate sul sito di microblogging. Che forse è più completa di quella ora accessibile su Facebook, ma ha lo svantaggio di dover essere inserita manualmente, mentre quella di Facebook è automatica. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/social-network/2017/11/28/news/facebook_l_intelligenza_artificiale_per_evitare_i_suicidi-182385867/" parent_folder="Repubblica 16-17" id="file17861658" filename="facebook_l_intelligenza_artificiale_per_evitare_i_suicidi-182385867">
<p> Tecnologia </p>
<p> Facebook, l'intelligenza artificiale per evitare i suicidi </p>
<p> di SIMONE COSIMI </p>
<p> Il sistema analizzerà parole-chiave e schemi ricorrenti nei post, nei commenti e nei video per intervenire prima e meglio nelle situazioni a rischio. Distribuito in tutto il mondo, ma per ora non in Europa </p>
<p> 28 Novembre 2017 1 minuti di lettura </p>
<p> L’HA lanciato Mark Zuckerberg attraverso la sua pagina. Si tratta di un nuovo strumento, in fase di distribuzione in tutti i mercati del mondo ma per il momento non nell’Unione Europea, che Facebook ha messo a punto per tentare di prevenire i suicidi fra gli adolescenti. Si basa su un sistema avanzato di intelligenza artificiale che in sostanza sarà in grado di analizzare gli scambi di messaggi nei commenti e i video trasmessi in diretta alla ricerca di parole-chiave, schemi ricorrenti e segnali in grado di indicare un possibile rischio di questo tipo. Dunque un meccanismo che non fa leva sulle segnalazioni degli utenti ma su una prima analisi automatizzata. </p>
<p> Il filtro, che appunto nei Paesi dell’Unione non sarà per il momento implementato per ragioni di regolamentazione della privacy, sembrerebbe molto utile. Oltre a identificare i contenuti in odore di pensieri suicidi, servirà a dare priorità alle procedure di revisione e controllo per poter intervenire prima sui post considerati più a rischio. A ben vedere, è un corposo sviluppo del sistema già testato – ma solo sui post testuali e solo negli Stati Uniti – a partire dallo scorso marzo. In un post sul blog ufficiale Guy Rosen, vicepresidente del prodotto, ne spiega il funzionamento: oltre a cercare parole e frasi scansionerà i commenti. Se troverà formule tipo “Tutto bene?” o “Posso aiutarti?” le classificherà come potenziali indicatori di pensieri suicidi. Anche l'assegnazione di quel compito di revisione, cioè chi se ne dovrà occupare, sarà curata con maggiore precisione. Non mancherà un arricchimento delle squadre che, in tutto il mondo, si occupano di questo genere di segnalazioni. </p>
<p> “Abbiamo team in tutto il pianeta operative tutti i giorni 24 ore su 24 che analizzano i report e danno rilevanza ai più seri – ha scritto Rosen – offriamo alle persone numerose possibilità, da quella di mettersi in contatto con un amico a una linea di supporto e altri consigli e risorse”. Come si diceva, anche Zuckerberg ne ha parlato: “Con tutta la paura di quanto l’intelligenza artificiale possa essere pericolosa in futuro, è bene ricordarci quanto possa invece aiutarci oggi a salvare vite umane”. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/social-network/2016/02/04/news/google_lascia_amit_singhal_l_ideatore_del_motore_di_ricerca-132740177/" parent_folder="Repubblica 16-17" id="file17861655" filename="google_lascia_amit_singhal_l_ideatore_del_motore_di_ricerca-132740177">
<p> Tecnologia </p>
<p> Google: lascia Amit Singhal, l'ideatore del motore di ricerca </p>
<p> Al suo posto entra John Giannandrea, esperto di intelligenza artificiale </p>
<p> 04 Febbraio 2016 1 minuti di lettura </p>
<p> Amit Singhal lascia Google dopo 15 anni. Alla guida di Search lo sostituirà John Giannandrea, esperto di intelligenza artificiale.Il responsabile di Google Search lascia Mountain View dopo 15 anni. al suo posto, a partire dal 26 febbraio 2016, entrerà l'attuale president of engineering."Search è più forte che mai", ha scritto Singhal in un post sul blog, "e non può che migliorare, se affidato a eccezionali dirigenti al lavoro ogni giorno". </p>
<p> Giannandrea, scrive la Reuters, è entrato in Google nel 2010 ed è a capo della divisione dedicata all'intelligenza artificiale. "L'intelligenza delle macchine è cruciale per la nostra visione di Search", ha scritto Google in una nota, "che aspira a realizzare un assistente intelligente, capace di connettere gli utenti e le azioni al mondo reale". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2016/06/06/news/google_un_tasto_rosso_per_evitare_che_l_intelligenza_artificiale_diventi_consapevole-141425678/" parent_folder="Repubblica 16-17" id="file17861662" filename="google_un_tasto_rosso_per_evitare_che_l_intelligenza_artificiale_diventi_consapevole-141425678">
<p> Tecnologia </p>
<p> Google, un tasto rosso per evitare che l'intelligenza artificiale diventi consapevole </p>
<p> di MANOLO DE AGOSTINI </p>
<p> Big G ha creato un sistema per spegnere questi software in qualsiasi momento ed evitare uno scenario alla "Terminator" </p>
<p> 06 Giugno 2016 2 minuti di lettura </p>
<p> LO SVILUPPO di intelligenze artificiali più evolute e di robot umanoidi avanzati potrebbe migliorarci la vita in modi che ancora fatichiamo a comprendere, ma i più scettici non escludono uno scenario alla "Terminator", con l'intelligenza artificiale che diventa consapevole di sé a tal punto da vedere gli umani come una minaccia e volerli sterminare. Scene apocalittiche che a Hollywood riscuotono grande successo ma che in qualche modo potrebbero avere un fondo di verità se in casa Google stanno studiando un modo sicuro per "staccare la spina" alle intelligenze artificiali, nel caso in cui queste non si comportino nel modo desiderato. I ricercatori londinesi di DeepMind, azienda acquisita da Big G nel 2014, stanno lavorando gomito a gomito con gli scienziati dell'Università di Oxford per trovare un modo di impedire alle intelligenze artificiali di diventare padrone di se stesse, ovvero capaci di negare agli uomini il controllo sulle loro azioni. Il lavoro del team è illustrato nel documento "Safely Interruptible Agents" pubblicato sul sito del Machine Intelligence Research Institute (MIRI). Secondo i ricercatori - scrive BusinessInsider - è improbabile che le intelligenze artificiali si comportino sempre in modo ottimale e per questo "di tanto in tanto può essere necessario che un operatore umano prema il grosso pulsante rosso che impedisca all'agente d'intelligenza artificiale di continuare una sequenza nociva di azioni - nocive sia per l'agente o per l'ambiente - e riportarlo in una situazione più sicura". </p>
<p> I ricercatori hanno così creato una rete che consente all'operatore umano d'interrompere ripetutamente e in modo sicuro un'intelligenza artificiale, assicurandosi che quest'ultima non impari a impedire o indurre tali interruzioni. "Se l'agente si aspetta un premio ma è in grado di capire che sta per essere spento, cercherà di resistere per ottenere la ricompensa. Il nostro framework fa sì che il supervisore umano prenda temporaneamente il controllo dell'agente e lo induca a credere di voler spegnersi da solo". Non solo: hanno riscontrato che alcuni algoritmi come quelli di Q-learning sono interrompibili in modo sicuro mentre altri come quelli Sarsa (State-Action-Reward-State-Action) non lo sono, ma possono essere modificati facilmente affinché lo diventino. "Non è chiaro se tutti gli algoritmi possano essere resi facilmente interrompibili", dicono. Al momento non ci sono intelligenze artificiali tanto evolute da rappresentare un problema come quello della "Skynet" di Terminator per il genere umano, ma allo stesso tempo i progressi nel settore sono esponenziali e per questo è difficile dire se e quando l'umanità avrà bisogno di premere il fatidico "tasto rosso". Secondo Nick Bostrom, a capo del The Future of Humanity Institute, le macchine diventeranno più intelligenti degli uomini entro 100 anni e potrebbero rivoltarsi contro i propri creatori. "Credo che quando verrà raggiunta l'equivalenza con il genere umano, non passerà molto tempo prima che le macchine diventino superintelligenti. Potrebbe volerci molto tempo per arrivare al livello umano, ma penso che il passo da lì alla superintelligenza sarà molto rapido. Credo che queste macchine con potrebbero essere molto potenti, per le stesse ragioni per cui noi esseri umani siamo molto potenti rispetto ad altri animali su questo pianeta. Non è perché i nostri muscoli sono più forti o i nostri denti più affilati, ma perché i nostri cervelli sono migliori". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2016/03/09/news/ibm_l_intelligenza_artificiale_watson_ora_lavora_al_concierge_di_un_hotel-135104188/" parent_folder="Repubblica 16-17" id="file17861675" filename="ibm_l_intelligenza_artificiale_watson_ora_lavora_al_concierge_di_un_hotel-135104188">
<p> Tecnologia </p>
<p> Ibm, l'intelligenza artificiale Watson ora lavora al concierge di un hotel </p>
<p> Il super pc sfrutta grandi capacità di calcolo. Viene utilizzato all'interno del robot Connie </p>
<p> 09 Marzo 2016 1 minuti di lettura </p>
<p> Il "cervello" di Watson, il super pc di Ibm che sfrutta grandi capacità di calcolo e intelligenza artificiale, dopo ospedali e ristoranti ha trovato un altro lavoro: viene impiegato dal robot Connie nel concierge in hotel nell'ambito di un progetto pilota avviato dalla catena Hilton negli Usa. Connie, spiega il colosso informatico, è il primo robot con cervello di Watson ad essere impiegato in questo settore. L'automa affiancherà il personale in carne e ossa e risponderà alle domande degli ospiti sull'hotel e sulla destinazione turistica in cui ci si trova. Per il momento il robot è entrato in funzione alla reception dell'Hilton McLean in Virginia e sta imparando a interagire con i suoi ospiti e a rispondere alle loro domande in modo amichevole e puntuale. Le tecnologie del super pc Watson sfruttate dall'automa sono diverse: da quella che traduce il linguaggio parlato in testo e viceversa alla funzionalità di classificazione del linguaggio naturale. La peculiarità della sua intelligenza artificiale è che è in grado di migliorare e apprendere man mano che aumenta le interazioni con il pubblico. </p>
<p> Con Ibm e Hilton collabora anche WayBlazer, motore "cognitivo" specializzato nelle raccomandazioni di viaggi. Il robot è invece "Nao", automa umanoide da 8mila dollari realizzato dalla compagnia francese Aldebaran che già viene impiegato in alcune banche giapponesi come assistente. L'esperimento con Hilton però per la prima volta integra l'intelligenza artificiale di Watson. In Asia, ma non solo, i robot si stanno già ritagliando spazi nel mondo lavorativo: da Pepper nei negozi di SoftBank alle guardie-robot in grado di "leggere" le emozioni in Corea del Sud. Del resto l'ultimo rapporto del World Economic Forum prevede che entro il 2020 cinque milioni di posti di lavoro andranno persi, rimpiazzati da macchine intelligenti. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/venerdi/reportage/2016/06/21/news/il_futuro_a_tokyo_e_gia_roba_da_museo-142492355/" parent_folder="Repubblica 16-17" id="file17861667" filename="il_futuro_a_tokyo_e_gia_roba_da_museo-142492355">
<p> I siti di Repubblica </p>
<p> Annunci, lavoro e aste </p>
<p> Il futuro a Tokyo è già roba da museo. Robot inclusi </p>
<p> Il Miraikan, dedicato a scienza e innovazione, compie 15 anni. Tra le attrazioni, un «alone digitale animato» che accompagna i visitatori. E crea per ognuno una canzone su misura </p>
<p> Per entrare nel futuro bisogna percorrere il lungomare, fra ristoranti e centri commerciali. Si supera la copia della Statua della Libertà e si gira a sinistra proseguendo su un largo ponte pedonale pavimentato di legno chiaro, che d’estate abbaglia. Addentrandosi nell’isola artificiale di Odaiba ci si lascia alle spalle la spiaggia e, al di là dello stretto braccio di mare, i grattacieli di Shiodome e Ginza con il resto di Tokyo che si intuisce fra un palazzo e l’altro. Dopo l’ultimo shopping mall sorvegliato da un Gundam a «grandezza naturale», un robot alto diciotto metri nato in seno alla migliore scuola d’animazione giapponese, bisogna attraversare ancora un giardino e si arriva al National Museum of Emerging Science and Innovation, il Miraikan, che quest’anno compie quindici anni. Il Giappone, Tokyo in particolare, è uno dei pochi luoghi al mondo dove la tecnologia è un’attrazione turistica e al Miraikan lo sanno bene. Istituzione pubblica, ha sede in un edificio di vetro da ottomila metri quadrati. Ha accolto poco meno di un milione e mezzo di visitatori nel 2015, adulti nel 57 per cento dei casi. Il resto sono bambini e ragazzi. Questa è la casa di Asimo, l’automa della Honda che si esibisce tre volte al giorno correndo, salutando e inchinandosi prima di andar via accompagnato dall’inevitabile applauso. E sempre qui c’è anche lo Shinkai, il sottomarino che nel 1990 raggiunse i seimila cinquecento metri di profondità, record imbattuto fino al 2012.Ma la prima cosa che colpisce entrando è il Geo-Cosmos, una sfera di tredici tonnellate e sei metri di diametro coperta da dieci milioni di pixel appesa nella corte centrale. Riproduce in tempo reale le condizioni meteorologiche del Pianeta e a intervalli regolari mostra gli eventi che l’hanno segnato negli ultimi tempi, dall’aumento delle temperature allo tsunami del 2011. Un Pianeta parlante che, per una volta, può mostrare e raccontare le sue ferite. </p>
<p> «È stato proprio lo tsunami a darci le linee guida da qui al 2020» dice il direttore del museo Mamoru Mohri, secondo astronauta giapponese andato nello spazio. C’è stato per due volte, nel 1992 e poi nel 2000 raggiungendo la stazione orbitante Iss. Oggi ha sessantotto anni e dal 2007 dirige il Miraikan. «Presto dieci miliardi di persone vivranno su questo pianeta» continua Mohri. «Questo significa che dobbiamo affrontare sfide nuove e su scala mondiale. Con le nostre mostre cerchiamo di porre degli interrogativi, stimolare la discussione attraverso la comunicazione scientifica, e spingere a pensare». Al di là delle frasi di circostanza, il National Museum of Emerging Science and Innovation effettivamente non è un museo come gli altri. Non si limita a mostrare ai visitatori informazioni in ordine più o meno cronologico, cerca invece di far vivere il futuro – o meglio, i futuri possibili con tutte le loro problematiche – puntando all’esperienza diretta. «Dall’ambiente all’intelligenza artificiale, fino all’uso dei dati personali nella nostra società» spiega Maholo Uchida, curatrice del museo e artefice di una delle sue ultime mostre dedicata ai videogame e alla realtà virtuale intitolata Game On. Fra giochi, sperimentazioni, laboratori, qui a volte si vira anche verso l’arte contemporanea con un forte uso di tecnologia. Una delle aree di maggior successo, tanto per fare un esempio, è Songs of Anagura. A chi entra viene chiesto se acconsente alla raccolta dei suoi dati durante la visita. Optando per il sì ci si ritrova attorno ai piedi, grazie a un sistema di sensori e videoproiettori, un alone digitale animato che ci segue e interagisce con quello degli altri visitatori allungando piccole manine che si stringono e abbracciano. Metafora del nostro altro io nella grande rete. Uno spasso per i bambini. Qualche imbarazzo in più se le effusioni digitali avvengono fra gli avatar di una donna e un uomo che non si conoscono. Alla fine la mostra, tenendo conto di quel che abbiamo fatto e delle attività sociali del nostro alter ego, compone una canzone grazie all’intelligenza artificiale che la gestisce, scegliendo il ritmo e combinando le parole in base al nostro atteggiamento. Uscendo si riceve un foglio pieno di numeri. È il resoconto, minuto per minuto, di ogni nostro movimento. Con un sottotitolo evidente: il web è una fonte infinita di risorse e di divertimento, ma il prezzo che si paga è dire tutto (o quasi) di noi. «La robotica è l’altro grande tema del Miraikan» prosegue Uchida. Non ci sono solo Asimo o le sedie motorizzate Unicab, sempre della Honda, che miracolosamente si tengono in equilibrio su una sola grande ruota, ma anche gli androidi di Hiroshi Ishiguro, dell’Università di Osaka, arrivati con la mostra Android: What is Human? Alcuni leggono notizie, altri sono da compagnia. Perché, come scrive Alec Ross, responsabile dell’innovazione per il Dipartimento di Stato americano ai tempi di Hillary Clinton, in Il nostro futuro. Come affrontare il mondo dei prossimi vent’anni appena pubblicato da Feltrinelli (pp. 352, euro 19,50), il Giappone è un Paese che invecchia in fretta e sa di avere un problema per quel che riguarda l’assistenza agli anziani. Una delle risposte sarà probabilmente proprio la robotica giapponese gestita dalle intelligenze artificiali statunitensi, iniziando da quella di Watson della Ibm, che presto muoverà la famiglia di robot Papper della Softbank. Il Miraikan non è sempre stato così di successo. All’inizio, quindici anni fa, i visitatori erano un terzo di quelli di oggi. Odaiba, l’isola artificiale su cui sorge il museo, venne costruita negli anni Ottanta, prima dell’esplosione della bolla speculativa del 1991. In quel periodo l’economia giapponese sembrava inarrestabile e faceva paura. Presto gli Stati Uniti sarebbero stati comprati e sottomessi dalle grandi multinazionali come la Sony, vagheggiava fra gli altri il romanzo Sol Levante di Michael Crichton. Non è accaduto. A Tokyo e dintorni le cose hanno preso tutt’altra piega, il Paese è entrato in una lunga stagnazione e Odaiba era rimasta vuota, eccezion fatta per il grande palazzo della Fuji Tv firmato dall’architetto Kenzo Tange, il Miraikan, e il Tokyo Big Sight, centro fieristico fatto da quattro mezze piramidi capovolte collegate fra loro. Ora però l’isola artificiale è in pieno boom edilizio, con le Olimpiadi del 2020 alle porte. Il turismo, soprattutto quello dalla Cina, va a gonfie vele e un grande porto destinato alle navi da crociera sorgerà proprio a fianco del Miraikan. «Odaiba finalmente ha il suo presente, quello immaginato oltre trent’anni fa» conclude Maholo Uchida con una punta di ironia. Sperando che questa volta non si tratti di una bolla e che il museo abbia anche lui il suo futuro. (17 giugno 2016) </p>
<p> Il tuo contributo è fondamentale per avere un’informazione di qualità. Sostieni il giornalismo di Repubblica. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/social-network/2017/10/18/news/il_linguista_italiano_che_educa_le_macchine_per_facebook_sono_come_bimbi_smemorati_insegno_loro_ad_imparare_-178591619/" parent_folder="Repubblica 16-17" id="file17861657" filename="il_linguista_italiano_che_educa_le_macchine_per_facebook_sono_come_bimbi_smemorati_insegno_loro_ad_imparare_-178591619">
<p> Tecnologia </p>
<p> Ultim'ora 14.53 </p>
<p> Sanità Calabria: si dimette il commissario Zuccatelli, governo lavora a successore </p>
<p> Il linguista italiano che educa le macchine per Facebook: "Sono come bimbi smemorati, insegno loro a imparare" </p>
<p> Jaime D'Alessandro </p>
<p> Marco Baroni lavora nei laboratori di Parigi del social network e vuole far diventare "adulta" l'intelligenza artificiale: "Gli algoritmi prenotano voli e taxi. Ma l'immaginazione è un'altra cosa" </p>
<p> 18 Ottobre 2017 2 minuti di lettura </p>
<p> PARIGI - Una bambina capace di svolgere compiti con un'abilità straordinaria. Inquietante per alcuni, una divinità per altri. Ma la bambina, che tutti chiamano intelligenza artificiale, cade ancora in errori così grossolani da far disperare gli insegnanti. Basta interrogarla su una materia che conosce relativamente poco ed è persa. Completamente persa. Nei laboratori dei Facebook Artificial Intelligence Researchers (Fair), in un vecchio palazzo del centro di Parigi un tempo sede di una banca, tentano di spingerla ad apprendere le lingue. "Cerchiamo di capire come da piccoli arriviamo al linguaggio così da poter riprodurre quel processo anche nelle macchine. Se ci riuscissimo, potremmo davvero portare le intelligenze artificiali (Ai) a imparare come facciamo noi", racconta Marco Baroni. 46 anni di Bolzano, non è un ingegnere né un informatico ma un linguista teorico. Fidanzata a Barcellona, vita da nomade: ha studiato in Italia, si è specializzato a Los Angeles, ha lavorato a Seattle per poi tornare in Italia ad insegnare e fare ricerca a Trento. È arrivato alla corte di Yann LeCun, direttore dei laboratori di Facebook, quasi per caso. LeCun è uno dei padri della visione artificiale e del cosiddetto "machine learning", l'apprendimento delle macchine. Professore della New York University, Mark Zuckerberg lo ha convinto nel 2013 a dirigere i Fair. Lei come è stato contattato? "Mi arrivò una mail mentre ero a Trento. Cercavano un linguista teorico. Pensavo fosse uno scherzo. E quando venni a fare il colloquio non ero nemmeno troppo convinto. Ma qui, e negli altri tre laboratori sparsi nel mondo, hanno una marcia in più. Si fa ricerca e si fa ricerca avendo i fondi senza doverli andare a chiedere ". Così ha accettato e si è trovato a insegnare all'intelligenza artificiale. A proposito: quanti anni hanno le Ai? </p>
<p> "Mi verrebbe da dire che sono bambini fra i cinque e i dieci anni, ma è un sbaglio umanizzare troppo. Fanno errori banali che però non sono errori umani. Se riuscissimo ad avere una mente digitale che compie i nostri stessi passi falsi saremmo già avanti". Per questo insegna loro ad essere dei bambini? "Da un lato, avere algoritmi più vicini ai nostri comportamenti significa poter costruire modelli matematici di quei comportamenti. Dall'altro, far apprendere alle macchine in maniera più semplice. Il primo problema è che non sappiamo esattamente come noi stessi apprendiamo il linguaggio". Il secondo? "Le intelligenze artificiali sono affette da un paio di malattie gravi. Una si chiama catastrophic forgetting (il "dimenticare catastrofico", ndr). Gli algoritmi possono diventare dei campioni del gioco da tavolo cinese Go, ma non c'è verso che quelle conoscenze poi le riescano ad applicare agli scacchi. Devono apprendere tutto da capo. È come insegnare a un bambino il percorso per arrivare dalla sua camera alla cucina e lì ad aprire il cassetto per prendere le posate. Lui diventa veloce, la precisione è sovrumana, ma quando gli si chiede di aprire un cassetto in bagno che è di colore diverso per prendere un asciugamano casca nell'afasia". E allora le ansie di Elon Musk, Bill Gates e dell'astrofisico Stephen Hawking sul pericolo che le Ai sfuggano di mano? "Gli algoritmi di oggi possano arrivare a gestire un'autovettura e a prevedere certi eventi a breve termine. Se un pedone fermo a un incrocio attraverserà quando per lui scatterà il verde. Ma da qui alla vera intelligenza ne passa. LeCun, per esempio, è convinto che l'intelligenza sia proprio il poter prevedere qualcosa a lungo termine perché implica il saper immaginare il comportamento di una persona o di un oggetto o ancora di un evento. Ma non esiste la tecnologia necessaria. Come tutti i campi di ricerca qui si procede per balzi, non è una evoluzione progressiva né esponenziale". Eppure sugli assistenti virtuali tutti i colossi dell'hi-tech puntano molto. "Siri, Cortana, Alexa e le altre, sanno trovare un brano musicale, prenotare un volo, chiamare un taxi. Ogni rete neurale svolge una funzione specifica, limitata. Ma la loro somma non fa l'intelligenza, non porta al capire il senso di una frase o il significato di un'immagine ". Però possono guidare un drone, una macchina o gestire una torretta armata come quelle in uso in Sud Corea ai margini della zona demilitarizzata. "Possono fare tutto questo. Ma non sanno ancora sfruttare il sapere che hanno acquisito. Ed è questo che io studio attraverso la lingua. Alcuni credono che se riuscissimo a "guarire" le intelligenze artificiali potrebbero diventare la figlia prediletta dell'umanità. Ammesso sia così, il lavoro da fare è ancora tanto". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/scienze/2016/10/28/news/il_robot_senza_batteria_che_si_alimenta_da_solo-150802626/" parent_folder="Repubblica 16-17" id="file17861680" filename="il_robot_senza_batteria_che_si_alimenta_da_solo-150802626">
<p> Il robot senza batteria che si alimenta da solo </p>
<p> Sviluppato presso l'Università di Bristol, grazia alla struttura morbida consuma pochissima energia. Trae sostentamento dal cibo, vale a dire materia organica assorbita dalla bocca ed elaborata in una pila combustibile biologica </p>
<p> UN ROBOT che può funzionare per sempre e che non ha alcuna batteria. Trova la propria energia esattamente come facciamo noi e gli altri esseri viventi: mangia ed estrae energia dal suo cibo. Lo hanno costruito alcuni scienziati all'Università di Bristol (UK), realizzandone un prototipo che per ora vive in una vasca da bagno. Si tratta di un soft robot, vale a dire una macchina che sostituisce le strutture rigide con gel morbidi, almeno in parte. Una scelta che abbatte notevolmente l'energia necessaria per farlo funzionare. Questo robot ha una bocca da cui aspira il cibo, uno stomaco per elaborarlo e un sistema di scarico per gli scarti. </p>
<p> Ispirato alla salpida, è fondamentalmente un tubo. Da una parte c'è la bocca, che assorbe acqua mischiata a materiale organico. Lo stomaco è una pila a combustibile biologica (MFC), che trasforma la biomassa in energia chimica per alimentare il robot stesso. Gli scarti dell'operazione vengono eliminati, contemporaneamente all'assunzione del pasto successivo. In teoria può funzionare in eterno ed è possibile collegarne diversi in serie. "La vera svolta è l'aver ottenuto abbastanza energia per renderlo autosufficiente" ha commentato Fumiya lida dell'Università di Cambridge. Appena sufficiente, in effetti, perché l'energia che si ottiene dalla MFC è pochissima. Basta per far funzionare il robot proprio in virtù della sua struttura morbida. Resta comunque un punto fermo nell'evoluzione della robotica: macchine basate su questo principio potrebbero avere un numero indefinito di possibili applicazioni, senza andare troppo in là nel futuro. Basti pensare al lavoro in ambienti inospitali, come i siti di disastri nucleari o acque inquinate. Si potrebbe persino progettarli in modo tale che il loro cibo sia proprio l'elemento inquinante che vogliamo rimuovere, facendone ad esempio dei divoratori di petrolio o di plastica. O possiamo immaginarli aggirarsi tra le coltivazioni, impegnati a monitorare le piante senza bisogno che un essere umano si occupi di loro. È lecito supporre che tra qualche anno il sistema energetico sarà più efficiente, e questo tipo di robot potrà fare di più che auto mantenersi. A quel punto di potrà parlare di integrazione con l'Intelligenza Artificiale in tutti i suoi aspetti e con gli altri tipi di robotica. "In futuro robot come questi potrebbero essere usati nell'oceano per raccogliere spazzatura", suggerisce Hemma Philamore, una ricercatrice dell'Università di Bristol che ha partecipato al progetto. "Quello che stiamo progettando è un robot che può inserirsi con naturalità in un ambiente naturale". La cultura sci-fi ci ha abituati a robot umanoidi che non hanno bisogno né di mangiare né di respirare, perché dotati di fonti energetiche inesauribili. E questo spesso è proprio il dettaglio che permette ai personaggi umani di riconoscere un essere artificiale. Il nostro futuro, a quanto pare, potrebbe essere diverso. </p>
<p> Il tuo contributo è fondamentale per avere un’informazione di qualità. Sostieni il giornalismo di Repubblica. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2016/05/20/news/insegnante_robot-140220189/" parent_folder="Repubblica 16-17" id="file17861679" filename="insegnante_robot-140220189">
<p> Tecnologia </p>
<p> L'insegnante è un robot. Ma non se ne accorge nessuno </p>
<p> di SANDRO IANNACCONE </p>
<p> Si chiama Jill Watson, e fa l'assistente in un corso di programmazione. Nessuno degli studenti, però, si è accorto che è un computer </p>
<p> 20 Maggio 2016 1 minuti di lettura </p>
<p> PER SEI mesi ha corretto esercizi, coordinato diverse attività, risposto alle domande più varie. E nessuno, tra gli studenti con cui aveva interagito, si è accorto di nulla. "Lei" si chiama Jill Watson, ed è l'assistente di un corso online in intelligenza artificiale organizzato dalla Georgia Institute of Technology. Piccolo particolare: non si tratta di un'insegnante in carne e ossa, ma di un computer. D'altronde, chi meglio di un software per insegnare a programmare algoritmi di intelligenza artificiale? L'idea è venuta ad Ashok Goel, docente del corso, in cerca di un aiuto per far fronte alle oltre 10mila domande poste ogni semestre dagli studenti. E, a quanto pare, ha funzionato bene. "La piaga più grande dei corsi online", ha spiegato Goel, "è l'alto tasso di abbandono da parte degli studenti. La causa principale è che gli studenti stessi lamentano di non avere abbastanza interazioni con gli insegnanti. Abbiamo creato Jill per fornire risposte e feedback più veloci". Goel e la sua équipe, anzitutto, hanno raccolto gli oltre 40mila messaggi pubblicati dagli studenti su Piazza, il forum online del corso, e li hanno dati in pasto a un algoritmo in grado di comprendere le domande ed elaborare delle risposte sensate: "Uno dei segreti dei corsi online", dice ancora il docente, "è che il numero di domande cresce all'aumentare degli studenti, ma si tratta quasi sempre di domande molto simili. Gli studenti tendono a chiedere sempre la stessa cosa: la domanda più comune, per esempio, è dove trovare i testi delle esercitazioni e i voti". Durante le prime settimane del corso, Jill, messa alla prova in una sezione nascosta del forum, ha leggermente deluso le aspettative dei suoi creatori, fornendo spesso risposte strane o non pertinenti: "Inizialmente, gli output del software non erano soddisfacenti", racconta Lalith Polepeddi, una degli studenti che ha collaborato alla scrittura dell'algoritmo, "perché si focalizzava troppo sulle parole chiave. Per esempio, se uno studente chiedeva di organizzare un incontro per seguire le video-lezioni con altri studenti, il software suggeriva la lettura di un testo per integrare le video-lezioni". Analizzando gli errori, Goel e i suoi colleghi sono però riusciti a ottimizzare l'algoritmo, rendendolo sempre più intelligente. </p>
<p> Dopo due mesi di perfezionamento, Jill ha iniziato a interagire sulla sezione pubblica del forum, raggiungendo un tasso del 97% di pertinenza nelle risposte che forniva. E nessuno degli studenti si è accorto di avere a che fare con un computer. Qualcuno ha chiesto addirittura a Jill un appuntamento dal vivo. Impossibile, peccato. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2016/09/29/news/intelligenza_artificiale_apple_grande_alleanza-148775010/" parent_folder="Repubblica 16-17" id="file17861674" filename="intelligenza_artificiale_apple_grande_alleanza-148775010">
<p> Tecnologia </p>
<p> IA: grande alleanza tra Facebook, Microsoft, Ibm, Google e Amazon. Apple resta fuori </p>
<p> di CLAUDIO CUCCIATTI </p>
<p> Horvitz, Research di Redmond: "Nuovi orizzonti per la salute, l'istruzione, i trasporti e il benessere pubblico". LeCun, Fb Research: "Dobbiamo garantire il rapporto tra etica e progresso" </p>
<p> 29 Settembre 2016 1 minuti di lettura </p>
<p> ROMA - L'importanza della sfida dello sviluppo dell'intelligenza artificiale è riuscita ad unire cinque colossi della tecnologia: Facebook, Amazon, Google, Ibm e Microsoft. Al tavolo, al momento della firma, è rimasta però una sedia vuota. Apple infatti ha deciso di non aderire alla "grande alleanza" che intende potenziare il ruolo degli assistenti vocali a tal punto da pensare per loro un ruolo sempre più centrale per la quotidianità. L'azienda di Cupertino ha deciso di avanzare nella ricerca in solitaria, a testa bassa, tappandosi le orecchie con la cera e rifiutando ogni lusinga. Un accordo storico. "Siamo entusiasti dell'intesa in materia di intelligenza artificiale - ha detto Eric Horvitz di Microsoft Research -, avrà un grande impatto sulle persone e nella società. Nella collaborazione vediamo un'importante possibilità di sviluppo per la salute, l'istruzione, i trasporti e il benessere pubblico". Tra etica e progresso. La nascita di un "direttorio tecnologico" ne aumenta la responsabilità, soprattutto a livello etico. "Come ricercatori sentiamo il peso della fiducia che le persone ripongono in noi - ha spiegato Yann LeCun, direttore di Facebook Research -. Dobbiamo garantire che il progresso vada di pari passo con la massima considerazione per i valori umani". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2016/09/16/news/intelligenza_artificiale_lavoro_usa-147847319/" parent_folder="Repubblica 16-17" id="file17861661" filename="intelligenza_artificiale_lavoro_usa-147847319">
<p> Tecnologia </p>
<p> Ultim'ora 14.53 </p>
<p> Sanità Calabria: si dimette il commissario Zuccatelli, governo lavora a successore </p>
<p> Intelligenza artificiale, in 5 anni i robot sostituiranno il 6% degli americani sul posto di lavoro </p>
<p> di CLAUDIO CUCCIATTI </p>
<p> Nel rapporto Forrester si preannuncia l'evoluzione degli assistenti vocali che escluderanno l'uomo in molte professioni, dalla guida all'assistenza clienti </p>
<p> 16 Settembre 2016 2 minuti di lettura </p>
<p> ROMA - Entro il 2021 il 6% dei lavoratori americani saranno sostituiti dai robot. Se fino ad ora le teorie e le previsioni legate all'intelligenza artificiale apparivano più un capriccio filosofico da nerd, i dati del rapporto della Forrester ripreso dal Guardian sono lo schiaffo che catapulta, con irruenza, alla realtà. Il rapporto. "Nei prossimi cinque anni - si legge nelle pagine redatte da Forrester - gli agenti intelligenti, da semplici, diventeranno robot sofisticati. Le aziende potranno puntare su questi strumenti per ridurre il costo del lavoro". L'impatto negli Stati Uniti, tra i Paesi tecnologicamente più avanzati, si preannuncia devastante: sei lavoratori americani su cento saranno sostituiti dalle macchine. </p>
<p> Assistenti vocali. Interroghiamo con leggerezza Siri, l'assistente virtuale degli iPhone, sul meteo del prossimo fine settimana o sul percorso per raggiungere l'hotel più vicino. Lo si fa come se fosse un gioco, alterando la voce e facendo facce strane, spesso stupide, convinti che quella vocina metallica e accomodante sia rinchiusa in un pozzo troppo profondo per rispondere alle nostre provocazioni. Su internet o sulle riviste di tecnologia leggiamo che Google e Uber costruiscono automobili senza pilota, per un futuro che immaginiamo non proprio prossimo. Manca la consapevolezza, a tal punto dallo stentare nel crederci, che tra cinque anni questi strumenti possano evolversi e sostituire l'uomo in attività molto complesse, a partire dal lavoro. Nel rapporto Forrester si citano i rappresentanti dei servizi clienti, gli addetti dei call center e gli autisti di taxi e camion come le figure professionali a rischio estinzione. Se in un lustro le prospettive sono queste, molti altri impieghi saranno affidati completamente all'intelligenza artificiale entro la metà del secolo. Oltre al fatto che donne e uomini saranno costretti a reinventare se stessi (o una nuova professone) per trovare un impiego, un aumento (ulteriore) della disoccupazione potrebbe portare a disordini sociali. Non si tratta di una visione catastrofica: i padri delle nuove tecnologie hanno più volte messo in guardia sulla pericolosità di un utilizzo scorretto o sproporzionato delle proprie creature. "Prima le macchine faranno un sacco di lavoro per noi - parola di Bill Gates - e non saranno super intelligenti. Sarà positivo, se saremo capaci di maneggiarle bene. Un paio di decenni più tardi questa intelligenza diventerà un problema". Toni più apocalittici sono stati usati dal fondatore di Tesla e SpaceX, Elon Musk: "Affidare l'intelligenza ai computer è come invocare il demonio". Tra i problemi del futuro, dunque, dovremmo aggiungere anche il 'controllo della tecnologia', una minaccia che al momento pare trascurata: "I politici preferiscono parlare di lauree e di formazione tecnica, riferendosi a strumenti vecchi di almeno cinque o dieci anni. Non ci rendiamo conto - ha detto Andy Stern, ex presidente della Service Employees International Union - di quanto velocemente il futuro sta arrivando". Cinque anni passano in un lampo, meglio iniziare a riflettere. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/social-network/2016/04/12/news/intelligenza_artificiale_social_network-137374446/" parent_folder="Repubblica 16-17" id="file17861649" filename="intelligenza_artificiale_social_network-137374446">
<p> Tecnologia </p>
<p> Ultim'ora 14.53 </p>
<p> Sanità Calabria: si dimette il commissario Zuccatelli, governo lavora a successore </p>
<p> Il social ci parlerà come nel film "Lei", grazie all'intelligenza artificiale </p>
<p> di SIMONE COSIMI </p>
<p> L'ultimo annuncio di Facebook è solo un antipasto di come si evolveranno le piattaforme, spingendosi oltre il riconoscimento delle foto o della voce e intrattenendo con gli utenti conversazioni dal sapore umano. Uno sguardo al futuro prossimo venturo </p>
<p> 12 Aprile 2016 3 minuti di lettura </p>
<p> IN MOLTI, Mark Zuckerberg compreso, vedono il futuro dei social network in mano alla realtà virtuale. In realtà, e la notizia sulla nuova funzione di Facebook in grado di "leggere" il contenuto delle foto ai non vedenti lo conferma, si tratterà più di piattaforme estremamente versatili. In grado, fondamentalmente, di fare una cosa: dialogare con l'utente in maniera sempre più naturale. L'Automatic Alternative Text appena lanciato dalla squadra che si occupa di accessibilità, composta anche da Matt King, un ingegnere cieco, racconta infatti, sebbene abbia ancora molta strada da fare, come potrebbero essere le piattaforme digitali da qui a pochi anni. </p>
<p> ''Lei", sussurri d'amore tra un umano e un computer </p>
<p> Lo scorso novembre Google ha per esempio svelato un nuovo sistema, battezzato TensorFlow, sul quale è tornata pochi giorni fa nel corso di un evento a San Francisco: i suoi servizi in cloud dedicati alle tecnologie cosiddette di machine learning saranno resi disponibili gratuitamente a chiunque voglia mettersi alla prova. Sono strumenti che Big G già utilizza per indentificare le immagini all'interno di Google Photos, riconoscere i comandi vocali pronunciati dagli utenti sui telefoni Android, migliorare la ricerca sul motore o raffinare le traduzioni fra lingue. Adesso altri sviluppatori esterni potranno sfruttarli per costruire nuovi servizi. Più avvolgenti e profondi. Il testo alternativo appena svelato da Facebook supera un simile annuncio firmato da Twitter qualche giorno fa: mentre in quest'ultimo caso sono però gli utenti a poter aggiungere una didascalia leggibile tramite strumenti dello smartphone come il VoiceOver dell'iPhone, nel primo tutto avviene in automatico. Automatic Alternative Text consentirà infatti di ascoltare una descrizione delle foto che scorrono nella bacheca dell'utente non vedente tramite smartphone, individuandone gli oggetti o gli amici immortalati. È solo un tassello della più ampia strategia di Menlo Park. Anche quella svelata pochi mesi fa. Fa leva su Big Sur, il suo cervellone. Un prototipo di server modulare intelligente che può scavare i contenuti del social e agire simulando il comportamento umano. È probabilmente il cuore di quella che sarà Facebook M, l'assistente virtuale della piattaforma ancora in fase di sviluppo ma sulla quale si raccontano cose mirabolanti. Dovremmo conversarci attraverso Messenger. Anche Big Sur è stato aperto agli sviluppatori tramite l'Open Compute Project, proprio come nel caso di Google. Il deep learning che riconosce gli oggetti o gli individui nelle immagini, decodifica il linguaggio naturale e traduce, come su Skype, non basta più: i colossi della Silicon Valley stanno dunque spingendo l'asticella sempre più in là. Per farlo, hanno deciso di aprire le proprie risorse anziché continuare a fare tutto in casa. A costo di farsi fregare qualche segreto. </p>
<p> "Lei", al posto di Scarlett c'è Micaela Ramazzotti </p>
<p> Qualche idea? Big Sur può leggere testi, rispondere a domande complesse e giocare ai videogame. È questa la direzione, ancora prima e in parallelo alla realtà virtuale: aumentare il tasso di versatilità e di risposta del social. Dargli in qualche un alone vitale. D'altronde un piccolo segnale di questa tendenza si vede già su diverse altre piattaforme come quella di messaggistica Telegram o il social per il lavoro più gettonato del momento, Slack: risponde al nome di bot. Banali utenze automatiche in grado di svolgere specifici compiti a seguito di particolari comandi. Come fossero degli amici che ci tengono aggiornati su certe notizie o ci aiutano in certi compiti. Sono le forme primordiali e facilmente sviluppabili da chiunque di un'intelligenza artificiale articolata come quella a cui stanno lavorando luminari come Yann LeCun, capo del dipartimento AI di Facebook e già fondatore del Center for Data Science della New York University. Un sistema in grado di imparare da solo e assomigliare sempre di più alla Samantha di "Her", il film di Spike Jonze uscito ormai tre anni fa, proprio all'inizio di questa febbre da intelligenza artificiale. </p>
<p> "I bot sono le app del futuro" ha detto il Ceo di Microsoft, Satya Nadella, all'ultimo Build del gigante di Redmond. La direzione in effetti appare segnata. Ed è quella della "conversation as a platform", di piattaforme sempre più conversazionali fatte di scambi e botta e risposta col sistema: nel corso dell'evento è stato per esempio confermato che Cortana tenterà di sganciarsi dalle repliche preimpostate e che la suite di sviluppo che ne è alla base, la Cortana Intelligence Suite, si arricchirà di due applicazioni come il Windows Cognitive Service che consentirà ai sistemi di interpretare i bisogni analizzando il linguaggio naturale e il Microsoft Bot Framework, un supporto allo sviluppo di bot intelligenti. Per non parlare di Ibm, che sul tema è leader assoluto col suo supercomputer Watson ma che al momento sembra aver concentrato le principali applicazioni su fronti diversi, dalla salute all'urbanistica passando per i robot, che sta "educando". Perfino Adobe promette di renderci il lavoro più semplice con gli Smart Tag automatici dei documenti. "Sono tutte conferme di una tendenza abbastanza netta - racconta Luigi Portinale, docente di informatica e intelligenza artificiale all'università del Piemonte orientale - resa possibile dalle grandi potenze di calcolo, inimmaginabili fino a qualche anno fa, e dagli algoritmi in grado di processare un'enorme quantità di dati". I social network cambieranno dunque pelle, facendosi sempre più elastici. Ma a deciderne la direzione "saranno le esigenze degli utenti - aggiunge l'esperto - il sogno dell'intelligenza artificiale, cioè quello di macchine e in questo caso piattaforme dialoganti, si avvicina a piccoli passi. D'altra parte è pur vero che questo settore sfodera tempi piuttosto lunghi e spesso torna sui propri paradigmi del passato. Tuttavia negli ultimi anni anche gli utenti si sono fatti più esigenti e in certi casi smaliziati: si aspettano dunque che ciò che hanno sotto i propri occhi e usano ogni giorno offra sempre nuovi servizi". Non solo i social. Sono nate molte realtà e alleanze, come l'OpenAI, un'alleanza sostenuta dal capo di Telsa Elon Musk che punta alla massima condivisione di studi e risultati oltre che alla creazione di standard di settore, proprio per accelerare questa marcia. Questo perché, lo ha confermato uno studioso del mondo digitale come Kevin Kelly, "l'intelligenza artificiale sta migliorando costantemente ma non esponenzialmente", sfuggendo alla Legge di Moore che vorrebbe salti in avanti sensibili ogni 18 mesi. Ci vorrà ancora un po' di tempo. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2017/11/06/news/i_robot_ci_ruberanno_il_lavoro_andra_meglio_nelle_metropoli-180415869/" parent_folder="Repubblica 16-17" id="file17861686" filename="i_robot_ci_ruberanno_il_lavoro_andra_meglio_nelle_metropoli-180415869">
<p> Tecnologia </p>
<p> I robot ci ruberanno il lavoro? Il Mit: ''Molto meno nelle metropoli'' </p>
<p> di MARA MAGISTRONI </p>
<p> Uno studio del MediaLab del Mit di Boston rivela che l'impatto dell'automazione in termini di perdita di posti di lavoro sarà più grande nelle città meno popolose. Le città più grandi, invece, reggeranno meglio il confronto con robot e simili </p>
<p> 06 Novembre 2017 2 minuti di lettura </p>
<p> IL FUTURO è adesso: robotica, sistemi di apprendimento automatico e riconoscimento vocale, algoritmi e chatbot finiranno per sostituirci a breve. Uno scenario cui è importante arrivare preparati. È questa la convinzione che ha guidato un'équipe di ricercatori del Media Lab del Mit di Boston, che in nuovo studio hanno cercato di prevedere, per l’appunto, quali saranno le aree metropolitane (statunitensi) più colpite in termini di occupazione dall’ingombrante presenza dell'automazione negli ambiti lavorativi. E in linea generale ciò che ne è emerso è che a risentirne di più saranno le città più piccole, mentre i nuclei con più di 100mila abitanti assorbiranno meglio l'impatto. ·LE FIGURE PROFESSIONALI PIU' A RISCHIO Le ragioni, osservano dal Mit, fanno capo al differente profilo dell'occupazione e delle competenze tra una piccola e una grande città. Nei centri con più di 100 mila abitanti (per esempio Washington, D.C., Boston e Cambridge, Durham e Chapel Hill), infatti, la maggior parte dei posti di lavoro sono ricoperti da figure professionali con competenze manageriali, specialistiche e tecniche mediamente più avanzate: sviluppatori di software o analisti finanziari svolgono compiti cognitivi che più difficilmente potranno essere sostituiti in massa dai processi automatici. Nelle città più piccole, invece, le occupazioni principali sono meno specifiche: lavori d'ufficio, cassieri, impiegati nei servizi di ristorazione, lavori routinari, impiegati nel settore agricolo o turistico sono sostituibili dalle macchine con maggiore facilità. </p>
<p> LEGGI ''In Italia 3,2 milioni di posti a rischio automazione" ·L'IMPATTO NELLE GRANDI CITTA' Lo studio del Mit riconosce oltretutto alle grandi città il vantaggio di essere luogo dove si creano sinergie tra figure professionali creative e dalle elevate competenze tecniche. Inoltre, secondo l'autore della ricerca Iyad Rahwan, anche l'approccio al lavoro di routine tra le grandi e le piccole città è differente: nei grandi centri sembra esserci maggiore efficienza, meno 'pigrizia' da parte dei lavoratori, una caratteristica che fa diminuire la necessità di figure di questo tipo. Va da sé che, se il numero di lavoratori sostituibili dall'automazione è inferiore, l'impatto dei processi automatici non potrà che essere minore. ·NEI PICCOLI CENTRI Ci sono però delle eccezioni in questa tendenza generale: i centri con meno di 75mila abitanti come Warner Robins (Georgia), Ithaca (New York) e Corvallis (Oregon) si piazzano tra le prime 15 aree metropolitane che il Media Lab del Mit definisce “a minor rischio di disoccupazione tecnologica”. Perchè? La risposta è semplice: sono strettamente connessi ad attività che impiegano lavoratori altamente qualificati poiché ospitano rispettivamente una base della Air Force, la Cornell University e un grosso laboratorio di ricerca HP. LEGGI Le aziende: l'intelligenza artificiale non vi ruberà il lavoro L'obiettivo dell'indagine, precisano gli esperti del Mit, non è quello di fare previsioni in termini assoluti, ma fornire un'analisi comparata che permetta ai legislatori di prendere coscienza del fenomeno e, magari, sviluppare strategie e strumenti a sostegno di chi si ritroverà a essere sostituito dall'automazione nel medio-lungo termine. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2016/12/26/news/kissenger_baciarsi_a_distanza_con_un_app-154891262/" parent_folder="Repubblica 16-17" id="file17861678" filename="kissenger_baciarsi_a_distanza_con_un_app-154891262">
<p> Tecnologia </p>
<p> Kissenger, se per baciarsi a distanza basta un'app </p>
<p> Gaia Scorza Barcellona </p>
<p> Un dispositivo permette di scambiare effusioni attraverso lo smartphone. Lo ha sviluppato un team di ricercatori a Londra con l'obiettivo di replicare la sensazione del contatto trasmettendo l'emozione </p>
<p> 26 Dicembre 2016 2 minuti di lettura </p>
<p> UN'ICONA non può bastare: chi ha il desiderio di baciare ''davvero'' potrebbe volere ben di più di una faccina da spedire via telefonino. Ma per andare un po' oltre, bisogna risvegliare i sensi, o perlomeno replicarli. E' ciò che tenta di fare Kissenger, dispositivo che si applica allo smartphone per trasmettere il bacio a distanza sfruttando, per quanto possibile, il contatto. Un mini materassino in silicone dotato di sensori è la ''protesi'' che tenta di tradurre lo scambio di effusioni in realtà, durante una videochiamata. Per gestirlo c'è l'applicazione che permette di inviare e ricevere simultaneamente il bacio, ciascuno attraverso il proprio telefonino connesso a Facetime oppure via WhatsApp. E' grazie al sistema aptico, basato cioè sul processo di riconoscimento degli oggetti attraverso il tatto, che Kissenger cerca di restituire la sensazione fisica del contatto, tradotto in una vibrazione. </p>
<p> Kissenger is 'a real-time mobile kiss messenger' .. enhancing social relationship capabilities in the age of digital communication!???? #LSR16 pic.twitter.com/2sJMm6JTGh </p>
<p> Un oggetto superfluo per molti; una nuova frontiera per il sesso del futuro, secondo altri. Non a caso l'apparecchio, il cui nome riassume l'unione tra ''mobile-kiss-messenger'', è stato presentato alla conferenza dedicata a ''Love & sex with robots'' di Londra, palcoscenico di progetti e prototipi che fanno riflettere su come potrebbe evolversi l'erotismo nell'era dell'intelligenza artificiale. Certo, ci si trova pur sempre di fronte a uno schermo. ''E' un po' come baciare un vibratore'', sosteneva un anno fa Gian Volpicelli dopo avere testato il dispositivo per Motherboard ''baciando'' la sua ragazza via telefonino nel laboratorio di Adrian Cheok, dove il prototipo è stato battezzato nel 2011. Niente a che vedere con il bacio ''in carne e ossa'', inutile negarlo. Ma adesso per Kissenger si intravedono nuove potenzialità. </p>
<p> ''Abbiamo voluto creare un robot con silicone che fosse in grado di dare e ricevere baci sfruttando la tecnologia del mobile'', spiega Emma Yann Zhang, una delle autrici del progetto della City University of London. Per il momento, Kissenger altro non è che un paio di ''labbra da baciare'', anche se finte, da applicare al proprio device, ma il team che lo ha sviluppato pensa già alla creazione di robot a grandezza naturale in grado di trasmettere l'emozione a chi interagisce con loro. LEGGI L'amore con iCon: il futuro del sesso sempre più smart ''Non intendiamo stabilire se sia eticamente accettabile avere intimità con i robot'', spiega Zhang in un report, pur dicendosi convinta che l'intimità tra uomini e macchine non potrà che crescere in virtù dell'intelligenza artificiale. Intanto, come ogni tecnologia di comunicazione, il progetto servirà a raccogliere dati. I ricercatori potranno registrare statistiche legate ai parametri vitali, come pressione sanguigna e frequenza cardiaca, per vedere attraverso test di laboratorio se gli utenti possono davvero stabilire relazioni emotive con i dispositivi. E capire se mai sarà possibile provare le stesse sensazioni scatenate da un bacio. A quel punto, non ci sarebbe pù bisogno di avere una persona dall'altra parte dello smartphone. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2017/06/21/news/_la_bambola_sa_che_cosa_provi_grazie_all_intelligenza_artificiale-168702739/" parent_folder="Repubblica 16-17" id="file17861688" filename="la_bambola_sa_che_cosa_provi_grazie_all_intelligenza_artificiale-168702739">
<p> Tecnologia </p>
<p> Una bambola "aumentata": sa cosa provi, grazie all'intelligenza artificiale </p>
<p> di ROSITA RIJTANO </p>
<p> L'hanno creata dei ricercatori per dimostrare l'efficacia di un chip capace supportare degli algoritmi smart. Ha imparato a riconoscere otto emozioni, interpretando le espressioni facciali catturate attraverso una mini telecamera </p>
<p> 21 Giugno 2017 1 minuti di lettura </p>
<p> ROMA - Le basterà osservarti per sapere che cosa provi. Se sei triste, felice, o arrabbiato. Sono le potenziali caratteristiche della bambola del futuro, ovviamente smart. A suggerirle è il lavoro di alcuni ricercatori dell'Università di Castilla-La Mancha, in Spagna, che hanno appena dotato di queste capacità un piccolo fantoccio. Un esperimento diretto a dimostrare l'efficacia di un chip in grado di supportare degli algoritmi di intelligenza artificiale. Un dispositivo dotato di batteria, grazie a cui la bambola ha imparato a riconoscere ben otto emozioni, inclusa sorpresa e felicità, interpretando le espressioni facciali catturate attraverso una telecamerina. Assemblarlo è costato circa 115 dollari, rivela la rivista di scienza New Scientist. "Un indicatore - scrive il giornalista Timothy Revell - di quanto stia diventando facile dotare i device di abilità basiche dell'intelligenza artificiale". </p>
<p> Gli enormi passi in avanti compiuti nel campo dell'apprendimento delle macchine, fanno sì che oggi abbiamo già degli algoritmi capaci di riconoscere gli oggetti e anche le emozioni, così come di leggere le labbra, scrivere poesie, prendere decisioni e molto altro ancora. Dotare dei piccoli chip di queste abilità per, poi, inserirli negli oggetti intelligenti che ci circondano ogni giorno - dagli orologi ai bracciali, passando per droni e robot - sembra adesso diventare solo una questione di tempo. "Nel prossimo futuro, ci saranno una miriade di piccoli occhi ovunque che non solo ci guarderanno, ma proveranno ad aiutarci", ha detto a The New Scientist, Oscar Deniz, a capo del progetto spagnolo. Uno dei vantaggi di quest'intelligenza artificiale formato chip è che non ha bisogno della Rete per funzionare, quindi i dati che racimola rimangono all'interno del dispositivo stesso. Con un conseguente guadagno, pare, anche per la privacy. Non male, se si pensa che sia la Barbie intelligente della Mattel sia i giocattoli della Genesis Toys sono stati accusati di violare la riservatezza dei propri utenti. Infatti, per funzionare inviavano le informazioni collezionate da bambole e orsacchiotti ai database aziendali. Un "effetto collaterale" che, in questo modo, non avrebbe più ragione d'esistere. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/economia/2020/02/05/news/la_nuova_paura_dell_operaio_italiano_il_robot_mi_togliera_il_posto_-247651795/" parent_folder="Repubblica 16-17" id="file17861676" filename="la_nuova_paura_dell_operaio_italiano_il_robot_mi_togliera_il_posto_-247651795">
<p> Economia </p>
<p> La nuova paura dell'operaio: "Il robot mi toglierà il posto" </p>
<p> Il rapporto Censis-Eudaimon sul welfare aziendale. I lavoratori temono anche una compressione dei diritti sindacali per colpa dell'intelligenza artificiale </p>
<p> 05 Febbraio 2020 1 minuti di lettura </p>
<p> ROMA - Sette milioni di lavoratori italiani hanno paura di perdere il posto di lavoro a causa dei robot e della intelligenza artificiale. Il timore contagia quasi un operaio su due. In generale, l'85% dei lavoratori è preoccupato per le innovazioni digitali (il dato supera l'89% tra gli operai). Per il 50% si imporranno ritmi di lavoro più intensi, per il 43% si dilateranno gli orari di lavoro, per il 33% (il 43% tra gli operai) si lavorerà peggio di oggi, per il 28% (il 33% tra gli operai) la sicurezza non migliorerà. Il terzo rapporto del Censis sul welfare aziendale, realizzato in collaborazione con Eudaimon, registra un certo pessimismo tra i dipendenti italiani, più accentuato tra gli operai. Ecco altri dati: - per il 58% (il 63% tra gli operai) in futuro si guadagnerà meno di oggi; </p>
<p> - per il 50% si avranno minori tutele, garanzie e protezioni. In questo caso le percentuali restano elevate tra dirigenti e quadri (54%), operai (52%) e impiegati (49%). Forte è anche il timore di nuovi conflitti in azienda: per il 52% dei lavoratori (il 58% degli operai) sarà più difficile trovare obiettivi comuni tra imprenditori, manager e lavoratori. In realtà, le aziende che utilizzano molto la tecnologia pagano di più i loro dipendenti. Fatto 100 lo stipendio medio italiano, nei settori tecnologici il compenso sale a 184.1, mentre negli altri comparti scende a 93,5. Sono i numeri di una vera e propria disuguaglianza salariale in atto nelle aziende italiane tra chi oggi lavora con le nuove tecnologie e chi no. Per due lavoratori su tre che già ne beneficiano (il 66%), il welfare aziendale sta migliorando la loro qualità della vita. Le percentuali sono elevate tra dirigenti e quadri (89%), lavoratori intermedi (60%), operai (79%). Guardando al futuro, il 54% dei lavoratori è convinto che gli strumenti di welfare aziendale potranno migliorare il benessere in azienda. E in vista dell'arrivo di robot e intelligenza artificiale, il welfare aziendale viene annoverato tra le cose positive che si possono ottenere in un futuro immaginato con meno lavoro, meno reddito e minori tutele. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2016/06/24/news/legge_robot_personalita_elettronica_ue-142679939/" parent_folder="Repubblica 16-17" id="file17861665" filename="legge_robot_personalita_elettronica_ue-142679939">
<p> Tecnologia </p>
<p> "Personalità elettronica per tutti i robot". Dall'Ue una legge che dà diritti e doveri agli automi </p>
<p> di ELENA DUSI </p>
<p> Il Parlamento di Bruxelles ha presentato una mozione per imporre ai "lavoratori artificiali" di essere registrati, pagare un'assicurazione e contribuire alle pensioni degli umani che per colpa loro saranno licenziati </p>
<p> 24 Giugno 2016 1 minuti di lettura </p>
<p> ROMA - Le tre leggi di Asimov non bastano più. Il Parlamento Europeo ne ha allo studio una quarta, che doterà i robot di “personalità elettronica”. Sempre più numerosi, autonomi, intelligenti e diffusi nelle industrie, i robot dovranno avere diritti e doveri. Saranno registrati e muniti di una sorta di carta d’identità, pagheranno per i danni che commettono e contribuiranno – ancora non è ben chiaro come – al welfare delle nazioni che li impiegano. La mozione sulla “personalità elettronica” dei robot è stata presentata al Parlamento Europeo da Mady Delvaux, proveniente dal partito operaio socialista del Lussemburgo. Difficilmente, in realtà, verrà approvata dall’assemblea di Bruxelles e trasformato in una legge vincolante dalla Commissione. Ma non si può negare che il testo sollevi un problema importante per un’Europa che, come molti altri paesi, si affaccia su quella che la proposta definisce la “nuova rivoluzione industriale”. </p>
<p> La bozza di legge parte dalla letteratura, citando Frankenstein, Pigmalione, il Golem di Praga fino a Karel Capek, lo scrittore ceco inventore della parola robot. Poi passa sul terreno più concreto dell’economia. Le vendite di automi, impiegati soprattutto nelle industrie automobilistica ed elettronica, ma anche negli ospedali e nell'assistenza agli anziani, sono cresciute nel mondo del 17% all’anno tra il 2010 e il 2014, per fare un balzo del 29% l’anno scorso. I brevetti nell’ultimo decennio sono triplicati. La bozza di legge suggerisce una sorta di tassa sui robot per rimpolpare il sistema previdenziale privato di tanti lavoratori umani. Ogni cittadino che impiega degli automi dovrà segnalarli allo stato, indicando anche quanto risparmia in contributi grazie alla sostituzione dei lavoratori in carne e ossa con quelli in acciaio e silicio. Anche i robot dovranno rispettare le leggi. Prima di tutto quelle di Asimov, poi un codice di condotta redatto ad hoc da Bruxelles. Qualora un automa dovesse infrangere una norma o causare un danno a qualcuno, sarebbe giusto che ne risponda legalmente, soprattutto se dotato di intelligenza artificiale, di capacità di apprendere autonomamente e – come pure prevede la bozza di legge – di surclassare l’uomo in quanto a facoltà intellettive. Una sorta di registro traccerebbe l’identità di tutti i lavoratori artificiali in Europa, con un obbligo di assicurazione simile a quello previsto per le auto. La notizia della bozza di legge è stata accolta in rete da parecchi sberleffi (e dal no generalizzato degli industriali). Ma non sono mancati commenti più avveduti. Parlare di personalità giuridica per i robot oggi potrà sembrare prematuro. Ma l’avanzata galoppante di intelligenza artificiale, computer capaci di apprendere, auto senza guidatori e perfino armi in grado di prendere decisioni autonome, ci porterà probabilmente un giorno a rispolverare la bozza della deputata Delvaux. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2017/02/09/news/l_era_dei_robot_in_europa_e_il_reddito_di_cittadinanza-157940502/" parent_folder="Repubblica 16-17" id="file17861672" filename="l_era_dei_robot_in_europa_e_il_reddito_di_cittadinanza-157940502">
<p> Tecnologia </p>
<p> La proposta dell'Ue: reddito di cittadinanza nell'era dei robot </p>
<p> Jaime D'Alessandro </p>
<p> A Strasburgo il Parlamento Europeo vota la prima risoluzione per un diritto civile sulle incarnazioni dell'intelligenza artificiale. Fra le proposte un sussidio minimo universale per bilanciare la scomparsa di milioni di posti di lavoro </p>
<p> 15 Febbraio 2017 3 minuti di lettura </p>
<p> BRUXELLES - Mady Delvaux, europarlamentare socialista, siede su un divanetto al quinto piano del Parlamento europeo. Sullo sfondo, gli uffici dei movimenti di estrema destra. Lei sorride anche se parla di rabbia, quella che potrebbe nascere dalla scomparsa di milioni di posti di lavoro con l’avvento di automazione e robotica. "C’è chi sostiene che in Paesi come gli Stati Uniti a rischio saranno il 47 per cento degli impieghi", racconta l’ex ministro dei trasporti e delle telecomunicazioni del Lussemburgo. La commissione giuridica da lei guidata, ha scritto la prima risoluzione per un diritto civile sulla robotica che il Parlamento Europeo voterà il 16 febbraio. Se dovesse passare, aprirebbe la strada ad un percorso che nel giro di tre anni potrebbe dare vita a norme valide in tutto in continente. “Secondo me l’intelligenza artificiale avrà effetto su tutti i lavori in un certo grado. I vantaggi portati da questa ennesima rivoluzione industriale saranno enormi, ma bisogna stare attenti ai costi sociali perché c’è già abbastanza risentimento in giro”. </p>
<p> La definizione di robot per il Parlamento Europeo della Commissione per le norme di diritto civile sulla robotica </p>
<p> Mady Delvaux e si suoi colleghi della commissione dopo due anni di lavoro sono approdati alla fantascienza: le tre leggi pubblicate da Isaac Asimov nel 1942 che sanciscono il primato dell’uomo sulla macchina. Una citazione nelle premesse del documento che nel suo complesso mira più in alto. Vuole regolare lo sviluppo dell’intelligenza artificiale nelle sue tante incarnazioni, stabilendo diritti, doveri e linee guida. In sessantotto punti viene chiesta l’istituzione di una agenzia per la robotica, si parla dell’impatto sociale e di quello scientifico, di droni, macchine a guida autonoma e assistenza medica, responsabilità di chi scrive algoritmi e di chi costruisce automi, necessità di garantire la privacy in un mondo fatto di oggetti intelligenti che parlano, ascoltano e guardano. Con una presa di posizione che sta già dividendo. Al punto quarantaquattro si tira in ballo li reddito di cittadinanza: ai parlamentari che si riuniranno a Strasburgo viene chiesto di prendere in esame "anche l'eventuale introduzione di un reddito di base generale" per i cittadini. Quello stesso reddito minimo suggerito a novembre da Elon Musk, l’imprenditore che guida Tesla e SpaceX. Malgrado i benefici portati da questa rivoluzione, sarebbero infatti milioni gli impieghi a rischio. </p>
<p> Nessuno in realtà sa cosa aspettarsi e in quale misura. Il 47 per cento di posti di lavoro a rischio negli Usa, che diventano il 57 come media in Occidente, è una previsione di Carl Benedikt Frey e Michael Osborne della Oxford University del 2013 convalidata da un rapporto della Banca mondiale del 2016. Peccato che la stima fatta da Frey e Osborne non tiene conto proprio della variabile normativa, il fatto che i vari Stati potranno agevolare o bloccare la diffusione dell'automazione parzialmente o nel suo complesso. Non è una variabile di poco conto. In ogni caso stando a queste previsioni, altrove dovranno fronteggiare situazioni ben peggiori rispetto alla nostra: l'uso dei robot colpirà in primo luogo le aree della manifattura globale a basso costo, Cina, India e Thailandia, dove gli impieghi a rischio sono rispettivamente il 77, il 72 e il 69 per cento. “La produzione completamente automatizzata forse significherà per noi il poter riportare in casa quel che facevamo costruire in quei Paesi”, continua la Delvaux. “Con una differenza rispetto al passato: l’aumento del prodotto interno lordo difficilmente porterà una maggiore occupazione”. </p>
<p> John Maynard Keynes aveva sostenuto che la tecnologia avrebbe significato alla disoccupazione di massa già nel 1930. La sua idea oggi è tornata di gran moda e si riverbera in saggi come The Rise of the Robots (Basic Books) di Martin Ford, premiato dal Financial Times fra i libri dell’anno nel 2015. “Sarebbe assurdo ignorare il problema”, ci racconta il verde Max Andersson, anche lui parte della commissione. "E' evidente che l'impatto ci sarà e non possiamo arrivare inpreparati". Ma non tutti sono d’accordo. “Non facciamo del terrorismo: i robot svolgeranno i lavori degradanti o che è meglio che vengano fatti da macchine perché più affidabili”, spiega Roberto Viola, che ha diretto Agcom ai tempi di Silvio Berlusconi e adesso è a capo del Directorate General for Communications Networks (Dg Connect) della Commissione Europea. “Troveremo un equilibrio, bisogna solo fare attenzione. Reddito di cittadinanza e tasse sulla produzione della robotica sono ricette vecchie. La società dei robot ha bisogno di una nuova strategia che mantenga il bello del nostro stato sociale”. Un nuovo patto insomma, per il quale però serviranno risorse. E sul dove trovarle le opinioni divergono ancora una volta in maniera così radicale da far prevedere brutto tempo a Strasburgo per la giornata del 16 febbraio. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2016/12/26/news/l_intelligenza_artificiale_che_vuole_prevedere_il_futuro-154596758/" parent_folder="Repubblica 16-17" id="file17861664" filename="l_intelligenza_artificiale_che_vuole_prevedere_il_futuro-154596758">
<p> Tecnologia </p>
<p> L'intelligenza artificiale tenta la profezia: prevede il futuro da una foto </p>
<p> di EMILIO VITALIANO </p>
<p> Dai ricercatori del MIT un algoritmo che da un'immagine di base realizza un video con una previsione di ciò che può avvenire in quello che vede nell'ambiente </p>
<p> 26 Dicembre 2016 2 minuti di lettura </p>
<p> IMMAGINATE di bloccare un avvenimento in un determinato istante e di fantasticare su quali possano essere gli sviluppi della situazione interrotta. Qualche volta potrebbe essere un compito facile, altre un po' meno, ma gli esseri umani sono comunque dotati di capacità intuitive che consentono loro di effettuare delle previsioni. Più complicato è per le macchine, anche se i ricercatori del Massachusetts Institute of Technology (MIT) si stanno impegnando per colmare questo gap finora abissale. Perché un nuovo studio ha sviluppato un sistema di intelligenza artificiale (AI) in grado di realizzare proprio delle previsioni su come una determinata scena potrebbe trasformarsi e costruirne un esempio di svolgimento. L'algoritmo creato, infatti, partendo da un fermo immagine, ha la capacità di generare un mini video che mostra nel concreto quali potrebbero essere le evoluzioni di un contesto in relazione alle condizioni al contorno. Le possibilità sono molteplici e sottolineano un aspetto che forse per tutti noi può essere banale, ma che non lo è per un software. Se qualcuno sta cucinando, per esempio, lo sviluppo successivo e più naturale potrebbe essere il consumo del cibo appena preparato. Eppure anche una previsione così semplice è un passo ancora abbastanza difficoltoso per l'intelligenza artificiale e presume la necessità innanzitutto di capire quello che sta avvenendo nel presente. In ogni caso, per sviluppare il software, i ricercatori hanno utilizzato come base due milioni di video che riproducevano diverse situazioni. In seguito hanno fornito un'immagine per creare un filmato con dei possibili scenari futuri relativi proprio alla foto di partenza. Per migliorare la loro qualità è stata utilizzata una configurazione conosciuta come "generative adversarial network" (GAN), un metodo che prevede la realizzazione di un video da parte di un network che poi viene giudicato da un suo simile per comprendere se il filmato è reale o creato da una macchina. Così facendo, i due network sono in competizione reciproca ed affinano le loro capacità per prevalere uno sull'altro, con la conseguenza che i video appaiono sempre più realistici. Ovviamente entro certo limiti, perché il sistema sta muovendo solo i suoi primi passi ed i microfilm sono ancora abbastanza approssimativi; infatti, al momento contengono appena trentadue fotogrammi (per la durata di circa un secondo) e sono in bassa risoluzione. </p>
<p> Inoltre, al software manca quella sorta di buon senso necessario per capire azioni scontate per gli esseri umani (per esempio, un treno in partenza da una stazione deve lasciare la stazione stessa). Un problema legato alla scarsa conoscenza del mondo, che attualmente è costruita solo sui due milioni di video impiegati come base. A tal proposito è interessate sottolineare come i filmati di apprendimento non siano stati etichettati, in quanto il nuovo sistema è in grado di acquisire conoscenza senza supervisione, con un notevole risparmio di tempo. Per ora comunque l'aspetto più interessante del software è la dimostrazione di quello che in potenza sarà in grado di fare nel futuro. Un sistema con capacità predittive (anche minime) e consapevole della realtà che lo circonda, infatti, ha riscontri nel concreto ed in vari ambiti, poiché qualsiasi robot che opera interagendo con l'uomo deve essere dotato di tali caratteristiche. Un esempio semplice e chiarificatore di questo concetto è fornito proprio da Carl Vondrick, membro del team padre di questa ricerca: se una persona sta per sedersi di sicuro non gradisce che un robot sposti la sedia. In conclusione, il prossimo passo sarà rendere i video più lunghi e, anche se il futuro non potrà mai essere previsto con esattezza, un giorno il sistema sviluppato dal MIT offrirà ai suoi utenti più scenari alternativi di potenziali evoluzioni. Insomma, un modo per ricordarci quante sono le biforcazioni che in ogni momento la vita di tutti noi può imboccare. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/scienze/2016/06/14/news/l_intelligenza_artificiale_supera_per_terza_volta_il_test_di_turing-142006986/" parent_folder="Repubblica 16-17" id="file17861671" filename="l_intelligenza_artificiale_supera_per_terza_volta_il_test_di_turing-142006986">
<p> L'intelligenza artificiale supera per terza volta il test di Turing </p>
<p> Il sistema ha superato l'esame "orale" dando il sonoro a un video. Per ottenere questo risultato i ricercatori lo hanno allenato a vedere 1.000 video muti e ad ascoltare 46.000 suoni </p>
<p> ROMA - L'Intelligenza artificiale supera per la terza volta il test di Turing, quello che determina se il comportamento di una macchina intelligente è indistinguibile da quello umano. Dopo il computer 'pensante' sviluppato a San Pietroburgo capace di comportarsi come un ragazzino di 13 anni, un'intelligenza artificiale aveva superato 'l'esame scritto' con la produzione di un testo che avrebbe potuto essere prodotto da un umano, e ora un'altra ha superato l'esame orale, rendendo 'sonoro' un video muto. Il nuovo esperimento, pubblicato sul sito arXiv dal gruppo coordinato da Andrew Owens del Mit (Massachusetts Institute of Technology) è molto più di una curiosità: algoritmi simili in futuro potrebbero produrre automaticamente effetti sonori per film e spettacoli, e potrebbero aiutare i robot a comprendere meglio le proprietà degli oggetti per interagire meglio con l'ambiente. "Quando si mette il dito in un bicchiere di vino, il suono che fa riflette la quantità di liquido che è nel bicchiere", ha detto Owens. "Un algoritmo che modella tali suoni - ha aggiunto - può rivelare informazioni chiave sulle forme degli oggetti e i materiali di cui sono fatti". </p>
<p> Per ottenere il sistema di intelligenza artificiale in grado di produrre suoni, i ricercatori lo hanno allenato a vedere 1.000 video muti e ad ascoltare 46.000 suoni. "Per prevedere quale sarà il suono prodotto in un video, l'algoritmo esamina le proprietà audio di ciascun fotogramma e li abbina ai suoni più simili nel database", afferma Owens. "Una volta che il sistema ha tutti i frammenti dell'audio - ha aggiunto - li cuce per creare un suono coerente". Così il sistema può produrre accuratamente sfumature differenti, dall'acqua che scorre, alla roccia che rotola, al fruscio dell'erba. </p>
<p> Il tuo contributo è fondamentale per avere un’informazione di qualità. Sostieni il giornalismo di Repubblica. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/social-network/2017/08/29/news/polygram_il_social_che_sceglie_gli_emoji_leggendo_la_tua_faccia-174118551/" parent_folder="Repubblica 16-17" id="file17861659" filename="polygram_il_social_che_sceglie_gli_emoji_leggendo_la_tua_faccia-174118551">
<p> Tecnologia </p>
<p> Polygram, il social che traduce le emozioni in emoji leggendo la faccia </p>
<p> Simone Cosimi </p>
<p> Una nuova piattaforma promette di aiutarci a postare faccine in stile Reactions ma in modo automatico, grazie all'intelligenza artificiale. Fra le altre funzionalità anche i filtri per migliorare i volti programmati insieme ai chirurghi plastici </p>
<p> 29 Agosto 2017 1 minuti di lettura </p>
<p> UN NUOVO social network promette di farci rispondere ai post "leggendo" i nostri volti e trasformando le emozioni in emoji allegre, sghignazzanti, attonite e così via. Si chiama Polygram, è pensato per iOS ed è stato appena lanciato. Sfrutta la videocamera frontale degli smartphone per scansionare il volto dell'utente e riportare le sue effettive reazioni, cavalcando così la tendenza del riconoscimento facciale. Non solo: propone anche un'analisi accurata di queste reazioni e in generale dell'atteggiamento degli utenti rispetto al contenuto pubblicato, dalle visualizzazioni al numero di screenshot effettuati fino alla divisione per genere e alla geolocalizzazione. Oro per gli influencer, fetta di utenti a cui in effetti i creatori sembrano puntare in modo deciso. </p>
<p> Polygram uses AI to capture facial expressions and automatically translate them into a range of emoji reactions. ?? https://t.co/ZEzzre3iZS </p>
<p> Il mondo dei social network è ovviamente complicato: i player sono pochi e pachidermici, fare breccia è un'impresa e negli anni decine di società e startup sono morte provandoci. Il predominio di Facebook, Instagram (sempre Facebook) e in misura minore di Snapchat, Twitter, Linkedin pur con storie diverse è di fatto consolidato. L'intelligenza artificiale utilizzata per individuare le reali espressioni dei volti, e dare così un tocco di vera interattività, può tuttavia essere la carta della sopravvivenza di Polygram, che ha raccolto un paio di milioni di dollari e si è subito lanciato nella complicata arena. Per sviluppare il sistema sfrutta una rete neurale in grado di individuare i movimenti facciale e poi proporre una serie di emoji affini. Chissà che il vero obiettivo non sia farsi "mangiare" da qualcuno dei protagonisti del settore. Oltre al rapidissimo riconoscimento facciale l'app include una serie di altre curiose funzionalità: dai filtri che ci rendono più attraenti, stando ai creatori fra cui Faryar Ghazanfari disegnati addirittura con l'aiuto di chirurghi plastici, a un'interessante opzione battezzata "wipe to reveal" che copre le immagini di una sorta di nebbia che gli altri utenti possono rimuovere cliccandoci sopra ma solo per pochi istanti: una via di mezzo fra contenuto effimero e privato che dovrebbe impedire di scattare screenshot, come spesso capita su Snapchat, visto che l'intera foto non sarà mai visibile per intero. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2016/07/19/news/r1_robot_iit-144419183/" parent_folder="Repubblica 16-17" id="file17861663" filename="r1_robot_iit-144419183">
<p> Tecnologia </p>
<p> R1, il primo robot per le famiglie: ''Costerà quanto una tv di nuova generazione'' </p>
<p> di VALENTINA RUGGIU </p>
<p> A casa, al lavoro o in vacanza: il giorno in cui i robot cammineranno al nostro fianco si avvicina. Specialmente ora che l'Istituto italiano di tecnologia ha creato l'umanoide R1 "your personal humanoid". Cosa lo differenzia dagli altri? Tanti piccoli dettagli, ma soprattutto il prezzo </p>
<p> 19 Luglio 2016 3 minuti di lettura </p>
<p> ''SARA' un robot rassicurante e piacevole". Con queste parole, un anno e mezzo fa, Giorgio Metta annunciava a Repubblica l'inizio di un grande progetto: portare i robot umanoidi nelle case degli italiani. Oggi, sotto il suo coordinamento, quel sogno ha un nome: R1-your personal humanoid ed è il primo robot sviluppato a basso costo, concepito per raggiungere il mercato di massa. Un team di 32 ricercatori e designer dell'Istituto Italiano di Tecnologia (Iit), polo d'eccellenza in Italia e nel mondo, sono riusciti nell'intento di creare un umanoide al costo di una tv di ultima generazione. E per completare l'obiettivo manca solo un passaggio: la produzione in serie. Ma non ci vorrà molto, al massimo 18 mesi e lo vedremo scorrazzare in giro per il mondo. Un tuttofare con rotelle. R1 sarà un amico fidato che ci aiuterà nelle faccende domestiche o nel lavoro da ufficio. Lo vedremo in hotel dietro il banco della reception o in ospedale in aiuto di infermiere e caposala nella gestione di cartelle e dati. All'inizio gli dovremo insegnare tutto: dalla planimetria dell'ambiente alla collocazione degli oggetti. Ma in poco tempo sarà in grado di muoversi in autonomia, riconoscendo ambienti, volti e voci e compiendo azioni al posto nostro. Come fare un caffè o prendere il telecomando al posto nostro, senza farci alzare dal divano. "Noi ci siamo spremuti le meningi per abbattere i costi mantenendo alta la qualità. - spiega Metta - Abbiamo cercato di rendere il tutto meno dispendioso utilizzando materiali economici, come polimeri e plastiche, che richiedono processi produttivi meno costosi rispetto a quelli tradizionali". Il prezzo finale dipenderà da quanti robot verranno costruiti. ''Per i primi 100 prototipi abbiamo individuato un target di prezzo che si aggira sui 25mila euro. Superata questa soglia, il prezzo inizierà a scendere e continuerà a calare man mano che diventerà un prodotto di consumo. La fascia, più o meno finale, di prezzo sarà di 3mila euro, quanto il costo di un moderno televisore al plasma''. </p>
<p> I precedenti. R1 è il risultato di un lungo percorso di sperimentazione e ricerca che raccoglie la conoscenza acquisita dai ricercatori con la creazione di altri robot, in particolare di iCub: l'umanoide costruito per gli studi sull'intelligenza artificiale, oggi presente in tutto il mondo con 30 prototipi. Rispetto a lui e agli altri umanoidi in circolazione, però, le differenze sono tante: "iCub è un prodotto di ricerca in cui il prezzo non era importante. R1 invece è un tentativo di approcciare il mercato di massa in cui il prezzo diventa questione fondamentale", spiega Giorgio Metta, responsabile e coordinatore del progetto. E anche con il famoso robot umanoide Pepper, che da poco è stato adottato sulle navi da crociera, il confronto non regge perché R1 ha il dono della presa. In Pepper le mani servono solo per indicare o fare dei gesti ma non per compiere azioni. Per realizzare R1, invece, i ricercatori si sono concentrati proprio sulla possibilità di farlo interagire con l'esterno attraverso l'uso degli arti superiori, donandogli la capacità di afferrare oggetti, aprire cassetti o porte. Un valore aggiuntivo rispetto alle alternative già esistenti sul mercato, che gli assicurano un posto d'onore tra i tuttofare di casa. </p>
<p> Come si muove R1, il robot umanoide ''domestico'' </p>
<p> Le mani e gli avambracci di R1 sono rivestiti di una pelle artificiale, con sensori che conferiscono al robot il senso del tatto, permettendogli di "sentire" l'interazione con gli oggetti che manipola. Il disegno delle mani è stato semplificato rispetto a quello di iCub per garantire robustezza e costi contenuti, pur consentendo l'esecuzione di semplici operazioni domestiche. Hanno la forma di due guanti a manopola e il polso è sferico, aspetti che gli permettono di sollevare pesi fino a 1,5 kg e chiudere completamente la presa attorno a ciò che afferra, specialmente oggetti cilindrici come bicchieri e bottiglie. Ma non è tutto. Anatomia di un robot. Dalla testa alle rotelle, R1 è un concentrato di tecnologia avanzata. Il volto è uno schermo LED a colori su cui compaiono delle espressioni stilizzate: pochi, semplici tratti per un modo semplice e veloce di comunicare con l'uomo. All'interno, invece, lo schermo ospita i sensori per la visione, - due telecamere e uno scanner 3D - quelli per l'equilibrio e per la generazione e percezione del suono. Il corpo è allungabile e "snodabile", con il busto che si estende fino a 140 centimetri e il torso che si torce anche lateralmente. Stesso discorso per gli arti meccanici, che possono guadagnare fino a 13 cm. Nella ''pancia'', invece, trovano posto tre computer che governano le capacità del robot, dal calcolo al movimento della testa, sino al controllo di tutti i sensori. Una scheda wirelss permette al robot di collegarsi alla rete internet, ricavando informazioni utili all'interazione con l'uomo e gli aggiornamenti del software. La memoria di una vita. L’idea è che queste macchine diventino il centro di tutta la nostra comunicazione digitale: mantengano l’agenda, ci aiutino a ottimizzare la pianificazione, diventino la nostra interfaccia con altri strumenti di uso quotidiano. ''Man mano che il robot starà con noi, inizierà ad avere memoria di tutto ciò che facciamo e che abbiamo fatto insieme. Magari, un giorno, avrà memoria di tutta la nostra vita e gli potrò chiedere di accedere a ricordi, tra foto e video”, conclude Metta. E a questo punto è il caso di dirlo, la rivoluzione sarà entrata in casa. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2016/06/13/news/robot_asimov-141947940/" parent_folder="Repubblica 16-17" id="file17861660" filename="robot_asimov-141947940">
<p> Tecnologia </p>
<p> Ideato un robot che decide se ferire le persone </p>
<p> La "provocazione" dell'artista-cibernetico Alexander Reben: "La mia macchina viola la prima legge di Asimov. Voglio che si discuta sui rischi connessi allo sviluppo dell'intelligenza artificiale" </p>
<p> 13 Giugno 2016 1 minuti di lettura </p>
<p> ROMA. Isaac Asimov è stato smentito: per la prima volta è stato costruito un robot che viola la sua "prima legge della robotica", quella che afferma che un robot non può fare del male ad un essere umano. A costruirlo è stato Alexander Reben, un ingegnere dell'università di Berkeley che però si definisce anche artista, oltre che esperto di robotica. Il suo dispositivo può scegliere se pungere o no un dito provocando una piccola ferita. Il robot consiste in un braccio meccanico e una piattaforma su cui l'utente deve mettere il dito. L'intelligenza artificiale decide arbitrariamente se far partire un ago che punge il dito, violando in tal modo la prima delle tre regole che Asimov aveva "dettato" per i robot protagonisti dei suoi romanzi di fantascienza. Lo scopo del dispositivo, spiega Reben sul proprio sito, è far discutere sui rischi connessi ad intelligenze artificiali sempre più evolute. "La grande preoccupazione sulle intelligenze artificiali è che possano andare fuori controllo - afferma l'esperto, divenuto famoso come l'inventore di 'blabdroid', un robot che spinge le persone a raccontare cose di se stesse -. I giganti della tecnologia affermano che siamo ben lontani da questo, ma pensiamoci prima che sia troppo tardi. Io sto provando che robot pericolosi possono esistere, dobbiamo assolutamente confrontarci sul tema". </p>
<p> L'argomento è in realtà già molto dibattuto, con una serie di esperti che ad esempio hanno chiesto un bando ad eventuali droni in grado di combattere senza essere guidati dall'uomo. Qualche giorno fa un team di ricercatori di Google ha affermato di aver realizzato un sorta di 'tasto rosso' in grado di spegnere un'intelligenza artificiale nel caso diventasse pericolosa. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2017/09/25/news/robot_dentista_in_cina_impiantati_due_denti_senza_l_intervento_umano-176472749/" parent_folder="Repubblica 16-17" id="file17861687" filename="robot_dentista_in_cina_impiantati_due_denti_senza_l_intervento_umano-176472749">
<p> Tecnologia </p>
<p> Robot dentista in Cina impianta due denti senza l’intervento umano </p>
<p> di MARIA LUISA PRETE </p>
<p> L'operazione è durata circa un'ora e, per la prima volta, non è intervenuto nessun operatore medico </p>
<p> 25 Settembre 2017 1 minuti di lettura </p>
<p> LA ROBOTICA in campo medico continua a fare passi da gigante. I dottori in camice bianco potrebbero essere sostituiti da Intelligenze artificiali governate da algoritmi sempre più sofisticati. Soprattutto la chirurgia, avida di precisione, sembra prospettare gli scenari più interessanti. Alcuni sono diventati già realtà, come la prima operazione di implantologia realizzata da una macchina. È successo in Cina, dove una donna ha accettato di farsi impiantare due denti da un robot senza l'intervento umano. L'unità medica robotica è stata sviluppata, nell'arco di una ricerca durata quattro anni, dalla collaborazione tra l'Ospedale Stomatologico affiliato all'Università di medicina militare di Fourth, con sede a Xian, e l'istituto di robotica dell'Università Beihang di Pechino. L'operazione è durata circa un'ora e non ha visto l'intervento manuale di nessun operatore medico umano, hanno assistito ma senza svolgere un ruolo attivo. Ha fatto tutto il robot: è riuscito, da solo e con successo, a impiantare due denti realizzati con il procedimento della stampa 3D. "Gli impianti sono stati montati entro un margine di errore di 0,2-0,3 mm, raggiungendo lo standard richiesto per questo tipo di operazione", hanno detto gli esperti al South China Morning Post. La tecnologia è stata progettata per ovviare alla carenza di dentisti qualificati nella Cina continentale ed evitare i frequenti errori umani registrati in questo settore. Il robot riesce a combinare la competenza dei dentisti con i vantaggi offerti dalla tecnologia. Secondo un sondaggio epidemiologico circa 400 milioni di pazienti hanno bisogno di denti nuovi in Cina, ma il numero di dentisti qualificati è inferiore alla domanda. Inoltre, sempre secondo quanto riferisce il South China Morning Post, vengono eseguiti nel paese circa un milione di impianti ogni anno, ma la scarsa qualità dell'intervento chirurgico causa spesso ai pazienti ulteriori problemi. Grazie alla nuova tecnologia messa a punto, si riesce a operare meglio all'interno del piccolo spazio della bocca, dove alcune aree sono difficili da vedere, rendendo complicato l'intervento. </p>
<p> Gli operatori hanno calibrato il robot sul paziente, in modo che potesse muoversi correttamente, calcolando l'angolo e la profondità necessari per adattare i nuovi denti nella cavità nella bocca della paziente. Hanno poi testato i movimenti e raccolto i dati necessari per effettuare le modifiche del caso prima di fare alla donna un'anestesia locale ed eseguire l'operazione. Il robot ha eseguito tutto alla perfezione e la coraggiosa signora adesso avrà una dentatura perfetta senza danni collaterali. Per la paura del dentista, sia uomo che macchina, la scienza si deve ancora attrezzare. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/scienze/2016/06/20/news/robot_fugge_dal_laboratorio_ritrovato_in_strada-142448398/" parent_folder="Repubblica 16-17" id="file17861681" filename="robot_fugge_dal_laboratorio_ritrovato_in_strada-142448398">
<p> Robot fugge dal laboratorio, ritrovato in strada </p>
<p> In Russia, a Perm. Aveva le batterie scariche, stava imparando a orientarsi </p>
<p> 20 giugno 2016 </p>
<p> STAVA imparando a orientarsi in modo autonomo, test dopo test, mentre i ricercatori registravano ogni sua risposta, e quando la porta è rimasta aperta, non vedendo ostacoli, è uscito fino a raggiungere la strada. E' la prima fuga 'spontanea' di un robot dal laboratorio in cui è stato costruito. E' accaduto in Russia, a Perm, e il robot è stato ritrovato per strada, dove era rimasto immobile perchè le sue batterie erano ormai scariche e aveva paralizzato il traffico, circondato da curiosi e polizia. Che si tratti di una trovata pubblicitaria o no, è un episodio che riflettere doppiamente. Da un lato perchè la fuga potrebbe essere stata la conseguenza di un errore di progettazione del test, dall'altro perchè indica quanto ci sia ancora da fare prima di avere robot capaci di muoversi nell'ambiente in modo autonomo. Bianco, con due braccia un display sul torace e uno al posto del viso, il robot si chiama Promobot come l'azienda che lo ha costruito. Quando l'ingegnere del laboratorio dove erano in corso i test ha dimenticato una porta di servizio aperta, il robot ha continuato a spostarsi sulle sue ruote, mettendo in pratica tutto quello che fino a quel momento aveva imparato. La capacità di orientarsi nello spazio fa parte del suo speciale addestramento di capostipite della nuova generazione di Promobot, indicata con la sigla V3 e che l'azienda prevede di presentare al pubblico in settembre. Per Promobot è stato 'naturale' continuare a spostarsi in ambienti sempre nuovi, soprattutto non incontrando alcun ostacolo. Il personale dell'azienda ha impiegato 40 minuti per ritrovarlo, quando ormai nella strada si è formato un ingorgo. Nel caso di una trovata pubblicitaria, di certo non sarebbe tra le più riuscite: la fuga non sarebbe avvenuta "se il robot fosse stato programmato in modo corretto", rileva Filippo Cavallo, esperto di robotica sociale dell'Istituto di Biorobotica della Scuola Superiore Sant'Anna di Pisa. "Chi ha programmato l'esperimento - aggiunge - avrebbe dovuto dare al robot un'area di operazioni definita, con un limite massimo all'interno del quale muoversi e da non superare. Il robot avrebbe anche dovuto tener conto dell'autonomia delle sue batterie e non allontanarsi dal punto di recupero". Un episodio come la fuga, insomma, lascia pensare che il robot possa avere "un baco di non robustezza e affidabilità". Ma soprattutto, ha concluso l'esperto, la 'fuga' del robot è "uno spunto importante per chi sta lavorando sulle capacità cognitive dei robot di orientarsi nell'ambiente e uno stimolo a costruire macchine in grado di collaborare con l'uomo". </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/social-network/2016/01/04/news/social_maggiordomo_facebook-130615523/" parent_folder="Repubblica 16-17" id="file17861654" filename="social_maggiordomo_facebook-130615523">
<p> Tecnologia </p>
<p> Zuckerberg si programmerà il maggiordomo. In casa farà quasi tutto lui </p>
<p> di ROSITA RIJTANO </p>
<p> Il papà del social network, che conta 1 miliardo di utenti attivi al dì, ha deciso di programmare la basica AI (intelligenza artificiale) senza aiuti: da solo e partendo dalla propria abitazione. L’ha annunciato pubblicando un post sulla propria bacheca personale </p>
<p> 04 Gennaio 2016 2 minuti di lettura </p>
<p> APRIRA' la porta di casa ai nostri amici, semplicemente guardandoli negli occhi. Accenderà le luci, la musica, controllerà la temperatura. Guidato dalla nostra voce. È l'assistente domestico immaginato da Mark Zuckerberg. A cui il papà di Facebook, e da poco anche di una bimba di nome Max, ha intenzione di lavorare entro il prossimo anno. La sua sfida personale per il 2016. [[ge:rep-locali:repubblica:130621055]] Così, se il 2015 è stata la stagione dei due libri al mese, del mandarino, e del "conoscere una persona nuova ogni giorno", nell'immediato futuro le attenzioni del 31enne si concentreranno sull'intelligenza artificiale. Ad annunciarlo è lo stesso Zuckerberg, pubblicando un post sulla propria bacheca personale. Come ormai ha l'abitudine di fare per tenere aggiornata la comunità in blu che conta 1 miliardo di utenti attivi al dì. In ogni parte del mondo. Si tratterà, spiega, di "una semplice AI (intelligenza artificiale ndr) per gestire la casa e aiutarmi con il lavoro". Alcuni speculano sul fatto che possa essere un vero robot, in metallo e chip, ma è difficile da stabilire. Ciò che è certo: Mr. Facebook la paragona a Jarvis, l'aiutante digitale di Iron Man. E sarà "intelligente" nel senso che interagire con lei equivarrà a dialogare con un essere umano. O quasi. "Le parlerò, potrà vedere me e le mie espressioni facciali, predire ciò di cui ho bisogno prima del tempo e così via". Anche se non ha ancora deciso come la chiamerà, svela nei commenti chiedendo suggerimenti ai seguaci. </p>
<p> "Le insegnerò a farmi sapere ciò che succede nella camera di Max che ho necessità di controllare quando non sono con lei", prosegue Mark che per amore della neo arrivata ha preso anche due mesi di paternità. "Mentre sul versante lavorativo, mi aiuterà a visualizzare i dati in realtà virtuale, in modo da consentirmi di costruire servizi migliori e gestire le mie organizzazioni più efficacemente". Il tutto, probabilmente, facendo ricorso a Oculus Rift: il visore per la realtà aumentata inglobato dal social network nel 2014, per due miliardi di dollari, e presto in vendita. Attenzione però: non è l'annuncio di una nuova compagnia. Ma, precisa Zuckerberg, un progetto tutto suo "per imparare cose nuove". Il mantra è "inventa". Tanto che ha deciso di programmare la basica AI senza aiuti: da solo e partendo dalla propria abitazione. Perché "la tecnologia è diversa di casa in casa, quindi sarà più semplice iniziare costruendo qualcosa esclusivamente per me, che un prodotto generale che funzioni per tutti". Curiosi di sapere come si evolverà? Niente paura, il giovane milionario promette di aggiornarci sui propri progressi circa una volta al mese. Su Facebook, of course. Un'ambizione individuale, quella di Mark, che si sposa con un tema collettivo e attuale: l'intelligenza artificiale sarà, infatti, una grande protagonista del mondo hi-tech nel 2016. L'hanno criticata in molti. Primo fra tutti l'eclettico fondatore di Tesla, Elon Musk, che lo scorso dicembre ha annunciato con un tweet la nascita di OpenAI: una compagnia no profit che vuole promuovere lo sviluppo del deep learning (cioè quella tecnologia d’apprendimento automatico, sviluppata a partire dagli anni Ottanta, che mima il comportamento dei neuroni umani), in modo aperto e collaborativo ."Penso che possiamo costruire l'intelligenza artificiale in modo che lavori per noi", è invece il pensiero guida di Zuckerberg, preoccupato più dai disastri dovuti alla diffusione di "malattie e violenze". Stesso discorso per Eric Schmidt, direttore esecutivo di Alphabet Inc., e Jared Cohen, direttore di Google Ideas che sull'ultimo numero del Time scrivono: "Alla fine l'AI è una tecnologia e la tecnologia è solo uno strumento. Sta a noi usarlo bene, sfruttare il suo potere per migliorare le nostre vite e quelle delle persone che ci circondano". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2016/10/20/news/stephen_hawking_l_intelligenza_artificiale_e_il_futuro_dell_umanita_-150230760/" parent_folder="Repubblica 16-17" id="file17861666" filename="stephen_hawking_l_intelligenza_artificiale_e_il_futuro_dell_umanita_-150230760">
<p> Tecnologia </p>
<p> Stephen Hawking: l'intelligenza artificiale è il futuro dell'umanità </p>
<p> di ELENA RE GARBAGNATI </p>
<p> L'AI non è solo un rischio, ma anche un'opportunità da sfruttare: lo ha dichiarato lo scienziato presenzia all'inaugurazione Leverhulme Centre for the Future of Intelligence </p>
<p> 20 Ottobre 2016 1 minuti di lettura </p>
<p> NON tutte le intelligenze artificiali saranno necessariamente Terminator. Anzi, potranno essere d'aiuto all'uomo. Parola di Stephen Hawking, il fisico britannico che ieri ha partecipato all'evento inaugurale del Leverhulme Centre for the Future of Intelligence (CFI) dell'Università di Cambridge. L'istituzione si occuperà di applicazioni di intelligenza artificiale, che ormai interessano moltissimi settori, dagli smartphone "intelligenti" ai robot chirurgici, passando per i droidi militari. Il Leverhulme Centre è stato creato grazie a un finanziamento di 10 milioni di sterline erogato dal Leverhulme Trust e vede la collaborazione tra le università di Oxford, Cambridge, Imperial College di Londra, e Berkeley, California. Hawking in passato si è espresso molteplici volte mettendo in guardia contro i pericoli dell'Intelligenza Artificiale, e ieri non ha fatto diversamente: "accanto ai benefici, le intelligenze artificiali porteranno anche dei pericoli, come potenti armi autonome, o nuovi modi che permetteranno a pochi di opprimere molti", però non sarà tutto negativo, se ci saranno istituzioni come il Leverhulme Centre. </p>
<p> Insomma, "il successo nella creazione di intelligenze artificiali potrebbe essere il più grande evento nella storia della nostra civiltà" sostiene Hawking. Una chiave di lettura insolitamente positiva, che se ci pensiamo bene non contraddice la sua visione: ha sempre sostenuto che le AI possono essere utili, se tenute sotto controllo, e così resta, nonostante ammetta che "causeranno disagi alla nostra economia, e in futuro, potrebbero sviluppare una volontà propria, in conflitto con la nostra". Proprio quest'ultimo è il punto centrale della questione: al Leverhulme Centre lavoreranno i ricercatori specializzati in diverse discipline, rappresentanti dell'industria e politici su progetti per la regolamentazione delle armi autonome, e per l'attenta valutazione delle implicazioni che potrebbe avere l'intelligenza artificiale sulla nostra società. "L'AI è estremamente eccitante. Le sue applicazioni pratiche possono aiutarci ad affrontare importanti problemi sociali, e a facilitare lo svolgimento di molte attività nella vita quotidiana", ha detto Margaret Boden, professore di scienze cognitive. Finora la tecnologia ha portato a grandi progressi, ma se abusata "presenta gravi pericoli". Ecco perché il "CFI si prepone lo scopo di anticipare questi pericoli, guidando lo sviluppo delle AI in forme human-friendly". È questa la chiave di interpretazione che mette d'accordo tutti: usare le AI per migliorare noi stessi e l'ambiente in cui viviamo, garantendo al contempo che "sistemi artificiali intelligenti abbiano obiettivi in ??linea con i valori umani" e che in nessun modo si evolvano spontaneamente in "nuove direzioni, non gradite". La questione non è se sia giusto o meno questo approccio, ampiamente condivisibile, ma se ci riusciranno all'atto pratico. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
