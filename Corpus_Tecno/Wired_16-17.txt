Elenco degli H2 di https://www.wired.it/internet/web/2020/10/13/crittografia-end-to-end-five-eyes/I Five Eyes, alleanza per la condivisione d’intelligence tra Stati Uniti, Canada, Regno Unito, Australia e Nuova Zelanda, hanno indirizzato alle aziende tecnologiche una richiesta, sottoscritta anche da Giappone e India, per consentire alle forze dell’ordine di accedere alle comunicazioni protette da crittografia end-to-end. Ormai con cadenza annuale, dal 2018, i Five Eyes insistono per ottenere una backdoor nei sistemi di crittografia di applicazioni di messaggistica, perché permetterebbe a criminali e terroristi di agire indisturbati. In primis i sette governi spingono perché le app siano progettate tenendo conto della sicurezza pubblica. Detto altrimenti, condividendo con le agenzie d’intelligence chiavi e strumenti di accesso per perseguire contenuti e attività illegali, facilitare le indagini e individuare i colpevoli. Le aziende tecnologiche, perciç, dovrebbero fornire alle forze dell’ordine i contenuti crittografati in un formato leggibile e utilizzabile. I nuovi servizi, inoltre, dovrebbero essere pensati tenendo conto anche delle posizioni dei governi. I sette firmatari sostengono che “particolari implementazioni della tecnologia di crittografia” pongono grossi ostacoli alle indagini delle forze dell’ordine, in particolar modo dal fatto che le stesse piattaforme tecnologiche non possono accedere alle comunicazioni ospitate sui loro canali di comunicazione e, di conseguenza, non sono in grado di fornire i dati necessari agli investigatori. “Chiediamo alle aziende tecnologiche di collaborare con i governi per intraprendere i passi suggeriti, concentrandosi su soluzioni ragionevoli e tecnicamente fattibili”, spiegano i sette governi nel comunicato stampa. La partita è aperta.Elenco degli H2 di https://www.wired.it/economia/finanza/2020/09/09/tesla-titoli-tecnologici-wall-street/Sono tra quelli che hanno superato meglio la crisi finanziaria ed economica dell’emergenza Covid-19, ma ora i titoli tecnologici stanno attraversando uno dei loro periodi peggiori degli ultimi tempi sulla piazza di New York. L’indice Nasdaq di Wall Street, dove sono quotate le principali aziende del settore, ha infatti perso quasi il 4% nell’ultima seduta a causa soprattutto di una serie di vendite da parte degli investitori, e nel complesso ha riportato un calo di oltre il 10% nelle ultime tre sessioni. Complessivamente, i grandi colossi come Facebook, Amazon, Apple, Tesla, Microsoft, Alphabet e Netflix hanno bruciato in una settimana oltre mille miliardi di dollari capitalizzazione. In particolare, alla riapertura di Wall Street dopo la chiusura per il Labour Day, le azioni Apple hanno subito perdite per oltre il 6%, facendo scendere la capitalizzazione al di sotto del traguardo dei 2mila miliardi conquistato il mese scorso, mentre Facebook e Amazon hanno lasciato sul terreno rispettivamente il 4% e il 3,5%. A riportare però la situazione peggiore è il gigante dell’auto elettrica Tesla, che dopo la crescita esponenziale registrata nell’ultimo periodo, ha visto il titolo crollare di oltre 20 punti percentuali nella sola giornata di martedì 8 settembre. A pesare su questa performance negativa è soprattutto l’esclusione del titolo Tesla dal paniere delle aziende dello Standard & Poor’s 500, che raccoglie le 500 società statunitensi con capitalizzazione maggiore. A sua volta, inoltre, questo indice ha perso circa 2,4% del suo valore, nella sua peggiore seduta degli ultimi mesi. E a far vacillare Tesla ha contribuito anche l’annuncio da parte del gigante automobilistico General Motors dell’acquisto di una quota dell’11% del produttore di camion elettrici Nikola, tra i principali concorrenti proprio dell’azienda creata da Elon Musk. La notizia ha fatto guadagnare al titolo di Nikola oltre il 39% e a General Motors il 7,93%. Inoltre, anche il patrimonio personale dello stesso Musk ha subito una perdita di 16,3 miliardi di dollari in seguito al tonfo delle azioni Tesla, facendo scendere il miliardario americano dalla quarta alla sesta posizione del Bloomberg Billionaires Index, come riporta La Repubblica. Secondo gli analisti, ad aver scatenato la pioggia di vendite che ha fatto calare così drasticamente i principali titoli di Wall Street avrebbero contribuito da una parte il nuovo crollo del petrolio, che registra un -8,2% sul costo del barile a causa del calo della domanda, e dall’altra le incertezze sulla ripresa economica. Infine, secondo quanto si legge su Business Insider, a complicare ulteriormente la situazione e a evidenziare i contorni di una bolla speculativa rispetto i titoli dell’indice Nasdaq è possibile che abbiano giocato un ruolo anche le imponenti compravendite di azioni da parte della giapponese SoftBank, che possiede partecipazioni in tutte le principali aziende tecnologiche americane.Elenco degli H2 di https://www.wired.it/economia/business/2016/02/09/manifesto-governo/L’hanno chiamato summit dei Numeri uno d’Italia. È andato in scena lunedì 8 febbraio all’Hangar Bicocca di Milano e ha raccolto oltre 85 fra imprenditori e top manager di successo. Oltre ad alcuni contributi dall’esterno, come quello di Sergio Marchionne, amministratore delegato di Fca. I numeri uno, appunto, quelli che spingono il made in Italy nel mondo. Una sorta di vertice a cavallo fra futuro e imprenditoria, cultura e innovazione, per i 35 anni della testata Capital del gruppo Class. Dall’incontro – e dalla lavagna digitale lunga 32 metri che caratterizzava la scenografia – sono uscite decine di contributi raccolti in un manifesto di 10 punti. Dieci messaggi indirizzati al governo che spaziano dal paesaggio alla manifattura, dalla scuola alle tasse. Come sarà l’Italia del futuro? Quale sarà il suo ruolo nello scacchiere dell’economia mondiale, mai tanto in movimento come in questa fase storica? E ancora, quali settori assumeranno rilevanza? Queste alcune delle domande a cui i principi dell’impresa italiana hanno tentato di dare una risposta fra le architetture pensate da Italo Rota e le opere di Anselm Kiefer. Fino al 14 febbraio l’installazione multimediale che riassume molti dei punti discussi l’8 febbraio rimarrà a disposizione dei cittadini per poi imbarcarsi alla volta della Cina e degli Stati Uniti. Cosa occorre, dunque, per produrre il futuro dell’Italia? Anzitutto la tutela del paesaggio, “unico al mondo per bellezza, profondità, coraggio, creatività, generosità, umanità” si legge nel documento finale. Così come lo stile di vita, fatto di creatività, moda, design ma anche di natura e arte. Poi cavalcare la rivoluzione digitale in tutte le sue anime, dai big data all’intelligenza artificiale: “Occorre quindi che questa nuova cultura, unita all’umanesimo di cui il Paese è impregnato, venga diffusa a tutti i livelli, cominciando dalla scuola elementare. Occorre che il primato di secondo paese manifatturiero d’Europa sia difeso e sviluppato proprio grazie alla valorizzazione dei primati, finora conosciuti, nella tecnologia rivoluzionaria del digitale, di cui fa parte anche il primato nelle stampanti 3D”. Ancora, i numeri uno hanno messo in evidenza il ribaltamento del mercato del lavoro, che avrà bisogno di nuove professionalità, lo sviluppo di innovazione nella manifattura puntando su robotica e automazione per “creare mercati che non esistono”, e altri settori su cui scommettere: scienze della vita, food e agritecnologie per la scienza della nutrizione, packaging innovativo, tecnologie per il ciclo dell’acqua e per quello dei rifiuti, modelli predittivi e supercomputazione applicati a diversi settori, compreso l’ambiente e il sociale, trasporti, automotive e motocicli, tecnologie per i beni culturali e digital humanities. La seconda parte del manifesto vira più sull’aspetto sociale. Attenzione agli “eccessi della finanza”, raccomandano i top manager, occorre un “nuovo contratto sociale” a partire dai doveri sociali degli imprenditori. Oppure al modello d’Europa che verrà, che i numeri uno vogliono come un “vero stato federale” in grado di contrastare il rigorismo esasperato della Germania e dei Paesi che la seguono. Il punto centrale per sfilarsi dall’egoismo tedesco è affrontare il debito pubblico: “Un debito esorbitante come quello attuale non si riduce solo con la crescita perché esso stesso frena lo sviluppo, drena risorse, espone ad attacchi selvaggi della speculazione alla ricerca di nuovi profitti, magari per la perdita di potere a causa della caduta del prezzo delle materie prime e in particolare del petrolio o per il rallentamento della crescita economica globale che riduce i margini”. Il programma indirizzato a Matteo Renzi si chiude con una stoccata sulle tasse – meno burocrazia, meno costi sul lavoro e sulle aziende – e una sulla scuola e l’università, che devono rivedere la propria offerta sulla base delle “necessità della nuova economia e della data science”.Elenco degli H2 di https://www.wired.it/internet/web/2016/10/24/ernest-bot-che-ti-fa-parlare-con-conto-in-banca/Tenere sotto controllo le spese, sapere dove e come si impiega il proprio denaro, approntare un piano di risparmio per un investimento futuro, un’automobile oppure una casa. Ernest è una starup italiana nata da un’idea Niall Bellabarba, Lorenzo Sicilia e Cristoforo Mione. “Ernest è più evoluto di un’app bancaria, perché suddivide le spese in 14 categorie ed è già in grado di imparare quali spese fa chi lo usa”, dice Bellabarba. Co-fondatore di Ernest e managing director, è migrato nel Regno Unito una ventina di anni fa e ha lavorato 4 anni per BlackRock, importante società di investimento, un’esperienza che lo ha portato a comprendere come finanza e tecnologia non siano più scindibili e che, senza la giusta cultura finanziaria, la pianificazione è complicata e spesso vana. Ernest è in grado di sviluppare piani di risparmio personalizzati per gli investimenti futuri: dotato di Intelligenza Artificiale, è in grado di rispondere a diversi tipi di domande. Ad esempio, sa quanto è stato speso solo in acquisti online, oppure in un determinato ristorante. “Ernest diventa un coach che aiuta ogni giorno nella gestione delle finanze”. Il modello di business è di tipo Freemium, gratuito nella versione base e a pagamento per godere delle funzioni più evolute, tra cui il monitor costante del mercato, alla ricerca di tariffe più vantaggiose per le spese correnti quali luce, gas, telefonia e assicurazioni. È anche in grado di collegarsi a più servizi ebanking intestati alla stessa persona, assumendo quindi più informazioni sullo stato finanziario di chi ne fa uso, funzionalità comoda per i nuclei familiari. Le tariffe per chi dovesse scegliere la modalità a pagamento non sono ancora note ma, dice Niall Bellabarba, saranno importi piccoli. Al momento Ernest è su Facebook Messenger ed è gratuito, in futuro sarà disponibile su altre piattaforme e servizi. A fine ottobre sarà anche online, sul sito ernest.ai. È disponibile anche per le banche, per diventare uno strumento B2B e raggiungere così un numero maggiore di utenti. Sembra una missione ambiziosa ma, in realtà, ha una sua attendibilità. Nel contesto bancario attuale, dove imperano tassi decisamente bassi, diminuire i costi diventa cruciale. Ernest è in grado di svolgere molti dei compiti normalmente erogati dai customer service delle banche. “Diverse banche hanno già mostrato interesse per Ernest: abbiamo contatti in Europa, in Italia e in Africa, ma ne vorremmo di più”, continua Niall Bellabarba. Per il momento il bot parla solo in inglese e renderlo poliglotta è uno dei motivi per cui la startup intende lanciare un round di finanziamento di 2,5 milioni di sterline (2,75 milioni di euro circa), denaro utile anche all’espansione in Europa e lo sviluppo del bot stesso. Questo round si aggiunge al primo, di 300mila dollari erogati da business angel londinesi, chiuso a maggio e necessario per le prime spese. “Una parte dei soldi servirà ad assumere sviluppatori e a implementare il servizio clienti e le strategie di marketing”, conclude Bellabarba. Gestire le spese quotidiane e il risparmio è il presente di Ernest, in futuro potrà anche consigliare quali investimenti fare per combattere o lenire gli effetti dell’inflazione. Che la finanza stia diventano sempre più materia tecnologica lo dimostrano i numeri raccolti da Accenture che ha registrato, nel primo trimestre del 2016, investimenti globali nel FinTech per 5,3 miliardi di dollari, in crescita del 67% rispetto allo stesso periodo del 2015. A guidare la crescita Europa e Asia.Elenco degli H2 di https://www.wired.it/economia/lavoro/2016/03/18/robot-lavoro/La scorsa estate, un nuovo straordinario tipo di hotel ha aperto a Nagasaki, in Giappone: l’Henn-na Hotel, uno albergo composto per lo più da robot. Robot con un’intelligenza artificiale (compreso un dinosauro meccanico) lavorano alla reception e accolgono gli ospiti. Altri sono addetti alle pulizie e al facchinaggio. Anche se una cosa del genere può sembrare un tantino futuristica ora, la realtà è che sempre più androidi si prenderanno i nostri posti di lavoro, negli anni a venire. Dopotutto, siamo alle soglie di una “Seconda era delle macchine”, alimentata dall’automazione, dall’intelligenza artificiale e dalla robotica. Già oggi, i cassieri sono stati sostituiti da una tecnologia automatica all’uscita, e il check-in elettronico è una norma negli aeroporti. Siri sembra stia diventando sempre più intelligente, e si sta evolvendo in un’assistente digitale a tutti gli effetti. E con poche centinaia di dollari su Best Buy, chiunque può prendere un robot che passi l’aspirapolvere per casa.  Ancora non siete convinti che i robot siano davvero tra noi? Su 1.896 tra scienziati, analisti e ingegneri di spicco interpellati nell’ambito di un rapporto del Pew Research Center sul futuro dei posti di lavoro, il 48% già “immagina un futuro nel quale robot e agenti digitali rimpiazzeranno un numero considerevole di operai e di impiegati”. Tra le categorie più a rischio ci sono gli autisti professionisti, come i camionisti e i tassisti. Entro il 2020, General Motors, Mercedes, Audi, Nissan, BMW, Renault, Tesla e Google hanno in programma la vendita di veicoli guidati in qualche modo autonomamente. L’amministratore delegato di Uber, Travis Kalanick, ha già parlato di un piano per sostituire tutti gli autisti aziendali con automobili che si guidano da sole. Ma non finisce qui. Potrebbero essere presi di mira anche tutti quei lavori da impiegato che si è sempre pensato fossero esclusiva degli esseri umani. I primi a “bruciare”, secondo gli esperti interpellati, saranno i paralegali, i contabili, gli addetti alle trascrizioni e le segreterie mediche. L’uso sempre più diffuso dei software di finanza fai da te e di strumenti di sbobinatura automatica rappresentano solo l’inizio del cambiamento che investirà questi settori. E la cosa importante da sottolineare è che molti di questi lavori non sono solo ripetitivi e meccanici. Necessitano anche una certa abilità nell’apprendere e nell’adattarsi a nuove informazioni. Ed è proprio per questo che la rivoluzione dell’intelligenza artificiale è così spaventosa. Ho visto in prima persona quanto un nuovo lavoro possa apparire (e scomparire) velocemente, anche nel mio campo, quello dei social media. Solo qualche anno fa, il “social media manager” era uno dei profili più ricercati, sul sito Indeed.com. Poi, gli strumenti di social media management – compreso Hootsuite, creato dalla mia azienda – sono diventati sempre più diffusi e semplici da utilizzare. Per molte aziende, questa tecnologia ha trasformato i social media in qualcosa che può essere gestita anche dall’interno. Dovremmo quindi farci prendere dal panico e lasciare che i robot prendano il sopravvento? Quello che sembra evidente è che un tipo di lavoro che oggi mantiene milioni di persone, potrebbe sparire tra 10 o 20 anni. La cosa più sensata da fare sarebbe quella di iniziare a prendere le giuste contromisure e prepararsi a questo cambiamento. Sì, ma come? La risposta classica che si dà è quella di investire nello sviluppo delle competenze che una macchina non può garantire, come la creatività, il problem-solving, l’ingegno e altre capacità di “ordine superiore”. Reinventare il nostro sistema scolastico attuale. Coltivare l’eccezionalità e tutte quelle abilità tipicamente umane. Ma il punto è che potrebbe non essere abbastanza.  Promuovere la creatività e incoraggiare un modo di pensare differente potrebbe aiutarci a fronteggiare il problema della perdita dei posti di lavoro solo nel breve periodo. Ma nel lungo, robot ancora più avanzati potrebbero svolgere tutte queste funzioni tipicamente umane molto meglio rispetto a noi. Come potremo sostenere l’economia se i lavori che sappiamo fare diventeranno obsoleti? Come faranno le persone a mantenersi? La portata di questo problema potrebbe in effetti richiedere alcune soluzioni sorprendenti e radicali, come quella di dar via i soldi. Un numero sempre più ampio di guru della tecnologia, dall’informatico Marc Andreessen a Jim Pugh, esperto di dati che ha lavorato anche per Obama, ha proposto il “reddito a vita”. Non si tratta di una manovra di welfare o di carità: il reddito a vita è una sorta di assegno destinato ad ogni adulto, occupato o disoccupato, per permettere a tutti di andare avanti. Negli Stati Uniti, parleremmo di una cifra tra i 15mila e i 20mila dollari a persona, ogni anno. Andiamo oltre quelle che potrebbero essere le reazioni più ovvie: quella di buttare via tutti questi soldi è un’idea da pazzi, è una cosa che distruggerebbe l’intera economia, eccetera. Ma come questa soluzione potrebbe avere effettivamente un senso? Per cominciare, in un mondo nel quale le intelligenze artificiali e i robot renderebbero la disoccupazione la norma e non l’eccezione, le persone avrebbero comunque bisogno di mangiare. Avrebbero comunque bisogno di mantenere la propria famiglia. E, andando più a fondo nella questione, ci sarebbe la necessità di fare in modo che si sentano ancora coinvolti in un’idea di società e collettività. Lasciare le masse in balia della tecnologia, senza un impiego e in stato di povertà, non è la ricetta per un futuro roseo. Il reddito a vita continuerebbe a far girare la ruota dell’economia e dell’innovazione. Nel nuovo millennio, la tecnologia ha generato enorme ricchezza per gli innovatori e gli imprenditori del settore. Questo ha alimentato un ciclo virtuoso, con sempre nuovi investimenti per lo sviluppo di tecnologie nuove e migliori. (Questo processo virtuoso, va detto, ha anche creato quel circolo vizioso per il quale la ricchezza è andata concentrandosi nelle mani di sempre meno persone). Ma l’intero processo si bloccherebbe in assenza di denaro da spendere. Il progresso dipende, in maniera tutt’altro che marginale, dai consumatori. Il che significa che la gente deve avere soldi da spendere. È interessante notare come l’idea del reddito a vita abbia raccolto seguaci ad ogni latitudine politica. Tempo fa, quest’idea, seppure con qualche variazione, era supportata sia da Martin Luther King Jr che da Richard Nixon. Non sarà una cosa semplice da realizzare, ad ogni modo, ma il reddito a vita non è del tutto senza precedenti. Durante gli anni Settanta, un programma quinquennale portato avanti dalla provincia canadese di Manitoba, chiamato Mincome, portò a risultanti piuttosto incoraggianti. Le madri passavano più tempo a crescere i figli. Gli studenti registravano punteggi più alti e i tassi di abbandono erano più bassi. Era calato il numero dei casi di malattie mentali, di incidenti stradali e di abusi domestici. E alla fine, le ore lavorative totali erano calate complessivamente di appena qualche punto percentuale. In altre parole, percepire un reddito a vita non portò a pigrizia e indolenza. Ma permise alle persone di spendere il proprio tempo sulle cose che contavano: famiglia, educazione, salute, realizzazione personale. Se i robot un giorno ci rubassero il lavoro – dandoci però alcune di queste cose in cambio – potrebbe non essere un così brutto affare, dopotutto. Traduzione di Fabio ManfredaElenco degli H2 di https://www.wired.it/attualita/media/2016/07/14/giffoni-2016/Dal 15 al 24 luglio a Giffoni andrà in scena la Giffoni Experience, l’appuntamento con la creatività e il cinema di alto livello per i più giovani. Ma all’interno della Giffoni Experience ci sarà spazio anche per la cultura digitale, la sharing economy, le idee per le startup innovative, all’interno della rassegna di innovazione per ragazzi Next Generation, curata nello scenario dell’Antica Ramiera di Giffoni Valle Piana dalla creative agency Giffoni Innovation Hub. Wired è media partner dell’evento. Il Giffoni Innovation Hub ha reclutato, con una call internazionale, un vero e proprio dream team che annovera giovani creativi tra i 18 e i 26 anni. Sotto la guida di tutor esperti di innovazione digitale e new media, proveranno in dieci giorni, a sviluppare idee e progetti in grado di cambiare volto al mercato delle delle industrie creative e culturali, con un forte e prioritario aggancio al marchio Giffoni, per ideare nuovi servizi e prodotti innovativi da inserire nella Giffoni Multimedia Valley, un’area di creatività focalizzata sul Sud. Al Giffoni Village, nei giorni della manifestazione, andranno anche in scena i Digital Labs, dei veri e propri workshop per avvicinare bambini e ragazzi dai 6 ai 13 alla cultura digitale, dal coding alla robotica. E poi, un progetto curato dal Giffoni Innovation Hub, Giffoni Big Data, per raccogliere e studiare i dati sulla comunità di partecipanti al festival. Non mancheranno nemmeno le tavole rotonde su pubblica amministrazione, sharing economy, industrie creative, con ospiti ed esperti di settore, mentre il 23 luglio sarà il giorno del Crowdfunding Day, un appuntamento dedicato alle nuove opportunità di produzione e finanziamento per artisti, startup creative e mercati culturali. A Giffoni, il 20 luglio, andrà in scena anche la finale nazionale del tour “TechGarage 2016 – A scuola di startup 2016″, la competizione pensata per ragazzi tra 16 e 20 anni con un focus sulla cultura di impresa e sullo sviluppo di idee vincenti ma dal solido appeal imprenditoriale.Elenco degli H2 di https://www.wired.it/economia/lavoro/2016/01/26/non-vero-entro-2020-i-robot-rimpiazzeranno-5-milioni-lavoratori/* le professioni del settore amministrativo (tutte le attività burocratiche, di segreteria per intenderci)
*  le competenze di operai e artigiani per il settore edile e manifatturiero
*  le competenze di chi oggi lavora nel settore bancario, finanziario
*  le professioni sanitarie (specie di management)
*  le professioni ingegneristiche (ebbene sì, non sono al sicuro)Elenco degli H2 di https://www.wired.it/economia/business/2016/11/18/tecnologie-segrete-alibaba/Se Alibaba è diventata la più imponente realtà globale dell’ecommerce, con numeri che lasciano Amazon a distanza siderale nel confronto, non è soltanto perché opera sul mercato più ampio e in crescita, ossia quello cinese, ma soprattutto perché sta puntando in modo deciso su ciò che consente il salto di qualità: le nuove tecnologie. Dopo avervi raccontato i pazzeschi record della serata speciale del Festival dei Single 11.11 2016 con l’evento mondano di Shenzhen, è arrivato il momento di andare dietro le quinte e scoprire cosa si nasconde dietro un marchio in così spaventosa crescita. Come offrire ai consumatori cinesi la possibilità di ordinare un prodotto pagandolo con lo smartphone (se non addirittura con il riconoscimento facciale, vedi sotto) reggendo decine di migliaia di transazioni ogni secondo e gestendo un volume quotidiano di 52 milioni di spedizioni (contro le 6 di Amazon in tutto il mondo)? Un piccolo spoiler: supporto pieno del cloud computing, uso già importante di automi e robot e realtà aumentata e virtuale. Date un’occhiata alla foto qui sopra, è stata scattata nella sala stampa dello Shenzhen Universiade Sports Center e rappresenta un immenso schermo in grado di illustrare in tempo reale tutto il volume di informazioni che era processato durante la folle 24 ore di acquisti scontati della festa dello shopping. Cosa mostrava? Il globo terrestre con scenografiche animazioni simili a raggi di luce con traiettoria parabolica che andava da ogni singola città dove un utente aveva piazzato un ordine alla città del fornitore del prodotto. Naturalmente, la Cina era protagonista con un fitto interscambio interno, ma i fasci luminosi collegavano soprattutto anche gli USA, il Giappone, la Corea del Sud così come l’Europa (Germania e UK in testa). Su un lato e l’altro scorrevano senza sosta una serie impressionanti di informazioni e analitiche come: marchi più popolari, categorie di prodotto più popolari, prodotti stessi più popolari, fasce d’età, sesso, brand più cliccati in Cina o all’estero, percentuale di pagamenti da mobile e tantissimo altro ancora. Al centro, monumentale, l’implacabile rullo del conteggio del volume di affari generato, che cresceva a colpi di più di un milione di dollari ogni due secondi. Tutto qui? No, perché questa tana del Bianconiglio poteva offrire molto di più. Durante la diretta, bastava richiedere il nome di una regione che, puf!, lo schermo si concentrava proprio in quella porzione della Cina e tutte le informazioni si adattavano al territorio. Si voleva di più? Ecco una singola città. Ancora più in profondità? Si poteva analizzare un quartiere. E qui, la rappresentazione diventava ancora più pazzesca e, per certi versi, inquietante: ogni palazzo si colorava andando a mostrare dove, cosa, chi e quanto si stava ordinando online. La seconda domanda che veniva in mente (la prima riguardava la privacy) era: “È reale tutto ciò che stiamo osservando? Oppure è solo una rappresentazione un po’ a effetto e a scena confezionata ad hoc, un filmato preconfezionato?”. Visitando l’apposito show-room di tutte le tecnologie sviluppate da Alibaba abbiamo compreso che, sì, era proprio tutto reale. Come è possibile gestire queste milioni di informazioni in tempo reale con un tale livello di precisione e di profondità? La risposta è il fiore all’occhiello del colosso, Alibaba Cloud (AliCloud) che è un po’ come le fondamenta di questa realtà così straripante, che rende possibile il collegamento tra utenti e venditori, che garantisce i pagamenti sicuri e immediati, che velocizza e rende più pratica la logistica e che consente una serie di applicazioni da rimanere a bocca aperta dalla domotica all’Internet delle cose, passando per le intelligenze artificiali e alla realtà virtuale e aumentata. Che cos’è Alibaba Cloud? Non è semplicemente una piattaforma per l’accesso a server remoti, come tanti altri servizi simili. È una sorta di grande network in grado di vedere, contare e prevedere tutte le informazioni che scorrono nella sua rete, così da connettere e proteggere chi cerca, chi compra e chi vende. Verrebbe quasi da immaginarlo come un essere senziente, se non si cadesse in un paragone un po’ troppo metafisico. L’esperienza utente di ognuno dei suoi 423 milioni di compratori attivi viene analizzata con la feature “Mille persone, mille facce” nel dettaglio per offrire ai venditori consigli e raccomandazioni su cosa offrire in un determinato territorio, su quali quali prodotti e in che modo. Di conseguenza, i brand possono modificare le proprie strategie di marketing e sviluppo seguendo report dettagliati e sempre in real time. Ma AliCloud non si ferma al supporto dell’ecommerce, perché trova altre applicazioni utilizzando anche le informazioni che vengono raccolte dagli strumenti governativi  e privati sparsi per il territorio. Può per esempio prevedere le maree e le condizioni meteo complicate aiutando i pescatori a programmare le uscite; con i software in dotazione agli enti dei beni culturali aiuta a monitorare e preservare le opere d’arte; in campo medico facilita la raccolta, la condivisione e l’archiviazione delle anamnesi e storia clinica personale. Senza dimenticare i dati raccolti dall’immenso telescopio Five-hundred-meter Aperture Spherical Telescope (FAST) grande quanto 30 campi da calcio. Ma l’esempio più clamoroso delle sue potenzialità è nel progetto governativo Hangzhou City Brain. Alibaba Cloud mette a disposizione la propria intelligenza artificiale e capacità di analisi big data per previsioni del traffico in tempo reale così da aggiustare – sempre in real time – i tempi di attesa ai semafori. Ci riesce “osservando” le auto tramite le videocamere di sorveglianza agli incroci e accedendo ai vari sensori. In tutto questo c’è anche spazio all’ecologia: nei quartieri generali, tutto il sistema di raffreddamento dei server usa energia eolica o acqua prelevata e re-imessa senza inquinamento nel lago adiacente. Legato a AliCloud c’è il sistema operativo sviluppato nel 2011 e chiamato YunOS, che governa dispositivi, auto, gadget e – ora – anche la domotica e l’Internet delle Cose: collegherà e farà comunicare il robottino-maggiodormo, gli elettrodomestici, i sistemi di videosorveglianza e di intrattenimento. C’è solo il cloud nelle tecnologie di Alibaba? Affatto. Come vi abbiamo già raccontato, è possibile accedere a negozi digitali tramite realtà virtuale: si indossano i visori, si sceglie categorie e stile e si cammina tra scaffali e prodotti, si leggono schede e caratteristiche e si ordina. Il pagamento avviene tramite la piattaforma proprietaria AliPay, attraverso lo smartphone. Il passo successivo sarà il riconoscimento facciale per i micropagamenti. A stretto giro di posta, migliaia di esercizi commerciali riceveranno un computer con grande touchscreen e webcam in alta risoluzione. Registrando la propria utenza con la foto sul documento di identità, che sarà opportunamente salvata nei database, basterà una scansione del volto al posto di Pin, impronte digitali o strisciate di carta. La seconda grande tecnologia è quella legata alla logistica e in questo ambito rientra la divisione Cainiao. Come gestire 52 milioni di pacchi quotidiani? Non solo con AliCloud, ma anche e soprattutto con sistemi sempre più automatizzati e le nuove tecnologie. Ecco come sarà il lavoro all’interno dei centri di smistamento dei prodotti: – L’addetto indossa occhiali in realtà aumentata che mostrano in sovraimpressione la direzione verso il settore, lo scaffale e il singolo prodotto da recuperare. – Viene scansionato il codice QR identificativo, gli occhiali ora indicheranno in quale scaffale mobile riporlo. – Riempiti tutti i settori, un muletto piatto e automatizzato arriverà, si piazzerà sotto lo scaffale e lo trasporterà nella successiva fase, l’inscatolamento. – Il secondo addetto, sempre tramite gli occhiali, vedrà quale misura di scatolone usare e come disporre i pacchetti all’interno (come se avesse subito la soluzione al puzzle/tetris) per ottimizzare tempi e ridurre gli sprechi. Come ultimo passaggio, c’è un servizio già attivo, il simpatico robottino-corriere Little G, che per ora funziona nel quartiere della sede centrale di Alibaba. Caricato di scatole, si reca personalmente a casa, l’utente apre lo scafandro tramite l’app e recupera il prodotto. Può muoversi in ambienti cittadini evitando ostacoli e danneggiamenti; il propulsore elettrico garantisce un’autonomia di 20 ore. Insomma, c’è tantissima tecnologia dietro al successo di Alibaba, che grazie a tutto questo ora è pronto al passo successivo, quello più complesso ossia mettere le radici anche nel resto del mondo e nei paesi dove è quasi sconosciuta. O, peggio ancora, ha una reputazione che non le rende onore: “Ah sì Alibaba, quel sito dove compri cose in stock e la roba ti arriva dopo un mese. Se ti arriva”. E in questo senso, una poderosa comunicazione avrà la stessa importanza strategica di tutte le possibili innovazioni tecnologiche.Elenco degli H2 di https://www.wired.it/scienza/lab/2016/02/26/atlas-robot-umanoide-google/È solo un robot. Cioè, in definitiva, un ammasso di ferraglia. Eppure, fa una certa impressione vederlo così maltrattato. Si chiama Atlas, ed è l’ultima versione del robot umanoide sviluppato da Boston Dynamics, azienda specializzata in robotica recentemente acquistata da Google. Il video appena pubblicato da Big G mostra, per l’appunto, il robot Atlas che apre porte, raccoglie scatole e passeggia in un bosco. Ma mostra anche i dipendenti di Boston Dynamics mobbizzare il robot, ostacolando il suo lavoro e colpendolo ripetutamente con un bastone. “Atlas è un robot umanoide dall’alta mobilità, progettato per muoversi e operare all’aperto, in condizioni di terreno sconnesso”, scrivono a Boston Dynamics. “È in grado di camminare su due piedi, lasciando gli arti superiori liberi di sollevare e trasportare oggetti e interagire con l’ambiente. In terreni estremamente sconnessi, Atlas può usare entrambi gli arti per arrampicarsi o farsi spazio in ambienti molto trafficati”. Atlas ha la corporatura pari a quella di un uomo adulto (1 metro e 75 per 82 chili), è alimentato da corrente elettrica e dotato, naturalmente, di una serie di sensori per l’equilibrio e la navigazione.Elenco degli H2 di https://www.wired.it/economia/lavoro/2016/05/03/fabbrica-4-0/La digitalizzazione e l’automazione favoriscono il lavoro umano nella fabbrica 4.0. “Negli anni settanta l’automazione significava sostituire i robot all’uomo, quindi veniva vista come il “nemico” dei posti di lavoro. Noi risentiamo ancora di questo trascorso storico, ma in realtà oggi la digitalizzazione passa dall’automazione industriale all’automazione cognitiva. Avendo maggiori dati in tempo reale, rendiamo più efficiente il lavoro degli operatori. L’operatore diventa l’augmented operator, ancora più efficiente e competitivo di prima. Il gap di competitività che potrebbe esserci tra un robot e un operatore si riduce. Si sposta quindi l’equilibrio a favore del fattore umano”. A parlare è Marco Taisch, professore ordinario del Dipartimento di Ingegneria industriale del Politecnico di Milano e fondatore del World Manufacturing Forum. Il tema della digitalizzazione del manifatturiero è protagonista al World Manufacturing Forum 2016, evento che si svolge oggi e domani a Barcellona. La quarta rivoluzione industriale disegna sistemi informativi sempre più pervasivi nell’ambito della fabbrica: questo grazie alla maturazione di alcune tecnologie come l’Internet of things, i big data, il cloud computing e  la sensoristica. Tutte queste innovazioni rendono possibile la raccolta di dati in tempo reale, favorendo la presa di decisioni necessarie per gestire il processo produttivo. “Oggi siamo in grado di progettare un prodotto totalmente in virtuale, senza la necessità di realizzare un prototipo fisico, come invece avveniva una volta. Riusciamo a pianificare la costruzione della fabbrica usando programmi di modellazione e programmazione virtuale, senza ricorrere a modellini”, racconta Taisch. All’evento sono presenti il Ministero Italiano dello Sviluppo economico e i ministeri economici di Germania, Francia, Spagna e Carolina del Sud. In Europa, la prima grande intuizione nell’ambito della fabbrica digitalizzata è stata quella tedesca col programma “Digital industry 4.0”, risalente al 2011, che ha fatto poi da traino per tutti i Paesi che si sono mossi su questa scia. “I Governi hanno rimesso al centro delle proprie politiche industriali il manifatturiero. Dopo gli scorsi anni, in cui tutti erano convinti che i servizi fossero il settore giusto su cui puntare, il manifatturiero torna al centro della scena. Anche l’Italia ha una politica su questi temi, ma non l’abbiamo ancora tirata fuori dal cassetto”, commenta Taisch. L’Italia è quarta al mondo per la produzione delle macchine utensili e vanta un ruolo di prestigio tra i player mondiali del settore.  “Solo in Lombardia, il manifatturiero pesa per il 29% del Pil regionale, quando la media nazionale è circa del 16%. Per ogni euro di Pil prodotto dall’industria manifatturiera ce ne sono 2-2,5 prodotti dai servizi correlati alla manifattura, come la logistica. Arriviamo così intorno al 60%-65% del Pil regionale. La Lombardia è la terza regione manifatturiera in Europa dopo Stoccarda e Monaco di Baviera. Inoltre, tra le prime 10 regioni d’Europa per il manifatturiero ne figurano quattro italiane: Veneto, Piemonte, Lombardia ed Emilia Romagna”, spiega Taisch. L’Unione Europea ha mosso i primi passi in tal senso un paio di anni fa e, proprio lo scorso 19 aprile, Günther Oettinger, commissario europeo per l’economia e la società digitale, ha presentato la comunicazione sulle industrie digitali a Bruxelles. Si tratta quindi di un ritorno di attenzione sul manifatturiero anche da parte dell’Unione Europea, che diventa naturale traino di politiche industriali e investimenti. Gli Stati Uniti, invece, hanno seguito un approccio diverso: per tradizione le politiche industriali rimangono esterne all’ambito governativo, le industrie hanno costituito l’Industrial Internet Consortium che gestisce questo tipo di tematiche. “L’esperienza della Carolina del Sud, che sarà presente all’evento, è molto interessante: lo Stato sta infatti promuovendo il reshoring, ovvero il ritorno delle fabbriche al Paese di origine. Da anni assistiamo all’offshoring, per cui le fabbriche vengono portate in paesi come al Romania, la Polonia e la Cina, perché la manodopera costa meno. Questo funziona finché il costo della manodopera si mantiene basso, ma quando aumenta e il livello di automazione cresce tutto si rimette in discussione. Gli Stati Uniti stanno lavorando benissimo in questo senso, incentivando il ritorno delle imprese con agevolazioni fiscali molto forti”, spiega Taisch.Elenco degli H2 di https://www.wired.it/gadget/computer/2017/11/15/intelligenza-salvera-mondo/      Queste, sono le tre Leggi della robotica stilate dallo scrittore Isaac Asimov. Proprio nel 2017, compiono la bellezza di 75 anni. All’epoca erano fantascienza pura, mentre oggi, di fronte a un’auto che sfreccia per strada, senza conducente ma con un pilota governato da un computer, ritornano più attuali che mai. E il merito va tutto all’intelligenza artificiale. Per la fine del 2017, il mercato della AI sforerà i 2,4 miliardi di dollari, ma entro il 2025 toccherà quota 59 miliardi. Il motivo di questo successo? Le applicazioni, infinite, dove i cervelli digitali possono essere utilizzati. Che si tratti di un chat-bot, quindi un sistema di assistenza automatica, o di un videogame; di un veicolo a guida autonoma o di un software per la ricerca scientifica; passando per strumenti di analisi finanziaria, robotica o processi industriali; l’intelligenza artificiale sta toccando ogni aspetto della nostra vita. E la velocità con cui lo fa dipende dalla capacità di calcolo dei processori, sempre più potenti ed efficienti. I processori hanno un ruolo importante nel rendere possibili le soluzioni di intelligenza artificiale, e dunque Intel, leader mondiale in questo settore, ha una posizione di primo piano. Difatti, l’azienda di Santa Clara, giusto per fare un esempio, fornisce i processori a più del 97% dei server su cui lavora il machine learning, importante branca dell’intelligenza artificiale. Questa posizione di rilievo nel settore ha spinto Intel a coltivare il suo vantaggio con investimenti strategici. La scorsa estate, infatti, l’azienda ha portato a termine l’acquisizione di Nervana Systems, una delle società leader, a livello mondiale, nel campo del deep learning. Intel aveva dichiarato di voler portare l’intelligenza artificiale ad essere 100 volte più veloce entro il 2020, e sembrerebbe oggi muoversi con il passo giusto per raggiungere questo traguardo, con il primo processore per network neurale del settore, Intel® Nervana™ Neural Network Processor (NNP), disponibile entro la fine di quest’anno e una roadmap di prodotti già delineata. Intel, inoltre, ha deciso di penetrare ancor più questo mercato, annunciando un investimento di un miliardo di dollari, proprio nel Settembre 2017, su ricerca e sviluppo nel ramo del deep learning. Così, a far compagnia a Nervana Systems, ecco altre startup come Mighty AI, Data Robot e Lumiata, acquisite tramite Intel Capital. Tutte realtà leader nel campo dell’intelligenza artificiale, che il colosso americano ha deciso di abbracciare a tutto tondo, in particolare nelle applicazioni sulla ricerca sul cancro, morbo di Parkinson e disturbi mentali; ricerca di bambini scomparsi attraverso l’analisi di foto; esplorazione spaziale e studi sui cambiamenti climatici. “Mi piacerebbe molto vedere l’intelligenza artificiale diffondersi ovunque ed essere a disposizione di tutti. Simile all’impatto che ha avuto Internet nelle vite della maggioranza delle persone, vorrei che l’AI avesse una pari diffusione, servendo le persone perché possano migliorare la propria vita, svolgere meglio il proprio lavoro, prendere decisioni migliori. L’AI deve essere qualcosa che agisca insieme a noi, ci aiuti a rispondere alle domande e a risolvere I problemi” – racconta Chris Feltham, Industry Technical Specialist di Intel. “Rendere possibile l’impossibile” è il mantra di Intel quando parla delle sue strategie nel campo dell’AI, che possono essere riassunte in una singola, curiosa, immagine. Quella di una strada tedesca. Auto ferme al semaforo, qualche persona che osserva l’incrocio, una comune foto di città. Tutto normale, se non fosse che si tratta di un’immagine di sintesi generata completamente da un’intelligenza artificiale, sulla base di 3000 immagini analizzate e “imparate” da un sofisticato sistema di reti neurali. È stata presentata in questi giorni all’International Conference on Computer Vision a Lido di Venezia, da un gruppo di ricercatori della Stanford University e di Intel. Ai tempi di Asimov era l’impossibile, oggi il possibile. E siamo solo all’inizio.Elenco degli H2 di https://www.wired.it/attualita/tech/2017/06/21/robot-lavoro-maturita-gif/Le macchine sostituiranno gli uomini nel mondo del lavoro? Questa la domanda attorno a cui ruota uno dei quesiti di maturità scelto dal ministero dell’Istruzione per l’ambito socio-economico. Abbiamo provato a svolgerlo in gif. Si tratta di una questione con cui l’umanità è costretta a fare i conti fin dalla rivoluzione industriale dell’800, e che, legata al tema dell’intelligenza artificiale, è tornata oggi di grande attualità.  Gli apocalittici non hanno dubbi: man mano che l’Ai progredirà, meno persone avranno accesso al mondo del lavoro. Ma la questione non è così semplice.  Se è pur vero che una rivoluzione è in atto, abbiamo tutti i mezzi sin d’ora per compensare chi perderà il proprio lavoro: una tassa sui robot, per esempio, non è un’idea così distante dalle prospettive future.  I più ottimisti sono persino convinti che saranno i robot a salvare il mondo del lavoro, cosa che in parte sta già accadendo in alcuni paesi del Sol levante come il Giappone, in cui le medie imprese hanno pianificato l’acquisizione di robot a tutto spiano per sostituire gli operai che non trovano più.  Il Giappone – come l’Italia, la Corea del sud e tanti paesi occidentali – sta diventando una nazione sempre più vecchia, in cui il numero di lavoratori è destinato, secondo i dati di un rapporto di Mc Kinsey, a diminuire sensibilmente entro il 2040. Di fronte a questo scenario, l’entrata dei robot in azienda è una soluzione tutt’altro che tragica.  Certo, ci sono ancora alcune criticità da risolvere.  Ma la questione primaria, a questo punto, è fare in modo che l’umanità tragga dall’intelligenza artificiale i maggiori benefici possibili.  Prima di tutto, come ricorda Enrico Marro in un articolo pubblicato sul Sole24ore riportato tra i documenti nella traccia di maturità, basterebbe seguire i consigli dell’Onu, che ha suggerito di abbracciare la rivoluzione digitale a partire dai banchi di scuola: c’è bisogno di creare le competenze necessarie per lavorare con le nuove tecnologie.  Della stessa idee erano già i 400 scienziati – tra cui Stephen Hawking – che nel 2015 firmarono un importante documento in cui venivano stillati punto per punto i benefici che l’umanità potrebbe trarre da queste tecnologie.  Ed è innegabile come già oggi i robot vengano utilizzati in condizioni di lavoro pericolose, per piccole pulizie domestiche o come esoscheletri e dispositivi di riabilitazione.  Insomma, l’intelligenza artificiale rappresenta una risorsa e non un rischio. Un discorso più approfondito può e deve essere invece affrontato sulla questione del libero arbitrio.  Le macchine oggi sono in grado di vedere, sentire e leggere dando un senso a informazioni con un’efficienza che la maggior parte delle volte un umano non potrebbe eguagliare: regolare questo strumento per fare in modo che non si dimostri un’arma a doppio taglio, proprio riguardo la loro libertà d’azione, è una delle vere sfide del nostro tempo. Elenco degli H2 di https://www.wired.it/attualita/tech/2016/12/12/sicurezza-privacy-trend-2017/Se nei paesi sviluppati il crimine negli ultimi 20 anni è globalmente diminuito si deve in buona parte a nuovi strumenti tecnologici che sono stati in grado di prevenirne logiche e dinamiche. Anzi, di rendere più complesso commettere un reato. Basti pensare a certi tipi di fenomeni: dai furti d’auto alle frodi legate alle carte di credito (scese in proporzione fra ammontare sottratto e denaro di plastica in circolazione). Si aprono scenari inediti e scivolosi, è vero: gli strumenti tecnologici sfoderano sempre dei lati oscuri che vanno governati. Ma i fronti su cui amministrazioni e forze dell’ordine di tutto il pianeta lavorano sono molti, dai droni per il pattugliamento a distanza all’analisi dei big data per organizzare il controllo e costruire una sorta di rete di polizia predittiva fino ai robot in grado di presidiare luoghi sensibili e dunque di liberare gli agenti in carne e ossa, destinandoli a operazioni più delicate. D’altronde è anche assodato che la linea disegnata fra riservatezza e sicurezza è sempre più sottile e fluttuante. Non c’è bisogno di arrivare alla psicopolizia di George Orwell e del suo 1984 per rendersi conto che molti di quei concetti di fondo sono, almeno potenzialmente, prossimi alla messa in pratica se non già disponibili. È la ragione per cui all’aumentare delle tecnologie sviluppate per la sicurezza devono crescere le garanzie per i cittadini. Già nel 2017, ma poi negli anni seguenti, vedremo perfezionarsi quella che gli esperti chiamano “community policing”, la computerizzazione e l’analisi del Dna. Intanto, la “vecchia” videosorveglianza è cresciuta in modo esponenziale. Nel 2014, secondo Ihs, le videocamere installate nel mondo erano 245 milioni, in salita costante. C’è da scommettere che l’anno prossimo farà segnare un nuovo record. Perché quegli occhi sono sempre più ovunque, dagli strumenti tradizionali agli smartphone passando per i droni fino alle body camera degli agenti di polizia, come negli Stati Uniti e altrove, che dovrebbero servire a sedare gli animi e garantire la tutela delle parti nell’ambito delle operazioni di arresto e fermo. Una videobulimia, insomma, sebbene gli studi sulla loro utilità in termini di prevenzione scarseggino. Anche se ovviamente, dal controllo nei parcheggi all’identificazione dei responsabili di reati, rimangono talvolta e nonostante tutto gli strumenti più utili. Le applicazioni future dei droni, invece, sono moltissime. Negli Stati Uniti molti dipartimenti di polizia, da quello di Little Rock, in Arkansas, a quello di Arlington, in Texas, stanno sperimentando piccoli velivoli telecomandati per diverse ragioni, dal controllo degli incidenti stradali alla sorveglianza generale. Sono in fondo l’evoluzione di quell’universo della videoregistrazione, che ora si sgancia dal muro per prendere il volo. Non a caso molti Stati a stelle e strisce hanno introdotto la necessità di ottenere un mandato prima di far decollare questi mezzi. Per il riconoscimento facciale da immagini aeree o videoregistrate, invece, ci vorrà ancora del tempo: quei 30 milioni di scatti già custoditi nel database dell’Fbi sono spesso poco efficaci, perché poco nitidi, quando per esempio incrociati per le foto delle patenti. In termini di thinkpol, come la chiamerebbe Winston Smith, se a Singapore esiste già da anni una rete di telecamere installate in particolare nei grandi condomini costruiti dallo Stato e sfruttate negli anni per raccogliere i numeri e capire dove si verifichi il maggior numero di reati, il mercato dei tool a disposizione è già florido. Il digitale è divenuto una piattaforma sensazionale per un nuovo genere di crimini, tuttavia fornisce alle forze dell’ordine dati e strumenti in quantità enormi e come mai prima d’ora. Con software in grado di disegnare schemi criminali e distribuire le risorse di conseguenza. Sono programmi che rispondono ai nomi di PredPol, CommandCentral Predictive di Motorola o alle soluzioni di Spillman Technologies e Wynyard Group. Il primo, tanto per fare un esempio, è un software in cloud che sfrutta complessi algoritmi per analizzare i dati memorizzati in base a specifici criteri come tempo, genere e luogo dei crimini nell’ultimo decennio. Come risultato sforna una serie di aree rosse su una mappa: sono le zone in cui è molto probabile che si riverifichino certi tipi di reati. La mappa è aggiornata in tempo reale e in base a quella lo sceriffo di Orange County, fra gli altri, decide come pattugliare il territorio. E se proprio non riusciamo a fare a meno della presenza fisica, dovremo abituarci a poliziotti dalle fattezze molto diverse da quelle di un bobby londinese. L’anno prossimo a pattugliare le strade dell’emirato arabo di Dubai potrebbero infatti esserci pattuglie di robot poliziotti in grado di fotografare e identificare i passanti, così come di facilitare denunce e pagamenti di multe. Saranno il frutto della collaborazione fra il dipartimento locale, Google e il team di Watson, l’intelligenza artificiale di Ibm. Ma le macchine vengono da tempo utilizzate per questioni di sicurezza: non solo in caso di disinnesco di ordigni ma anche per tallonare intrusi (come il nuovo drone della giapponese Secom) o appunto presidiare aree specifiche, come Knightscope K5, il robot vigilante servizio allo Stanford Shopping Center di Palo Alto, in California. Equipaggiato com una telecamera termica che riprende a 360 gradi e un ricco set di sensori, K5 legge fino a 300 targhe al minuto, riconosce persone e volti, ascolta attraverso i microfoni e allerta le persone in caso di allarme. E dura 8 ore, proprio come un turno di lavoro umano.Elenco degli H2 di https://www.wired.it/attualita/2017/07/05/arriva-in-italia-hebocon-la-competizione-per-robot-che-fanno-schifo/Ricordate quel programma televisivo in cui micidiali robot combattenti si contendevano il titolo di robot più distruttivo del mondo? Un HEBOCON è più o meno la stessa cosa, ma i robot che vi partecipano sono meno micidiali, meno distruttivi e decisamente meno tecnologici. Spesso sono realizzati con materiali di recupero e vecchi giocattoli assemblati in modo creativo con nastro adesivo, spago e colla a caldo.
A dirla tutta sono robot “heboi”, robot che fanno – letteralmente – schifo. Le sfide tra queste tipologie di robot sono però persino più avvincenti di quelle della televisione, e con regole molto semplici: il primo robot che perde l’equilibrio o che esce dall’arena è sconfitto.
 L’idea di una competizione tra robot che fanno schifo risale al 2014 ed è di Daiju Ishikawa, scrittore ed editor di un magazine umoristico online. Nata per gioco, la manifestazione si sta diffondendo rapidamente in tutto il mondo. Sono stati organizzati HEBOCON in Giappone, Stati Uniti, Nuova Zelanda, Regno Unito, Grecia, Germania e molti altri paesi.  “Heboi” è una parola giapponese, un aggettivo che significa “scarsamente dotato” e “tecnicamente carente”, “che fa schifo” appunto. Per realizzare un robot di questo tipo non servono particolari competenze tecniche e, anzi, chi dota di tecnologie troppo sofisticate il proprio robot rischia di incorrere in penalità. Il prossimo 14 luglio si terrà a Milano la prima grande competizione HEBOCON in Italia, organizzata da The FabLab e inserita nella cornice di TAG Party 2017, la festa della tecnologia di Talent Garden. TheFabLab è uno centro di progettazione e produzione digitale che si impegna, tra le tante attività, anche a favorire la diffusione di nuove competenze nei campi della robotica, dell’elettronica programmabile e della fabbricazione digitale attraverso workshop, conferenze e manifestazioni pubbliche. 
Il successo di questo tipo di manifestazione risiede principalmente in due aspetti fondamentali:  da una parte la natura fallace e assolutamente non tecnologica dei robot aiuta ad abbattere il timore di cimentarsi con una disciplina complessa e sofisticata; dall’altra l’approccio proposto per la costruzione dei robot rappresenta anche un ottimo modello formativo che ricalca per molti aspetti quello del Tinkering, un metodo di sperimentare la scienza e la tecnologia attraverso della attività che valorizzino e stimolino la creatività, la capacità di problem-solving e di indagine di ciascun individuo, sviluppato dall’Exploratorium di San Francisco e che rappresenta oggi la frontiera dell’apprendimento informale, anche per gli adulti. Sbarca quindi anche in Italia la competizione di robot più brutti di sempre, e siamo sicuri che sarà incredibilmente folle e divertente. Elenco degli H2 di https://www.wired.it/scienza/lab/2017/12/27/invenzioni-2017/La fine dell’anno è alle porte, e com’è tradizione si tirano le somme. Riviste blasonate come Nature e Science stilano le loro liste di personalità scientifiche e scoperte che hanno caratterizzato l’anno che va a concludersi. E anche noi, nel nostro piccolo, abbiamo preparato una classifica. Occupandoci di innovazione parliamo di gadget, dispositivi, veicoli innovativi: invenzioni insomma, che ogni anno rendono la nostra vita un po’ più facile, divertente, comoda, o quanto meno un po’ più più interessante. Vediamo allora quali sono state le 10 migliori invenzioni di questo 2017. Mano robotica   Il mondo delle protesi continua a fare passi da gigante. E non a caso, ce ne saranno parecchie anche nella nostra lista. Per iniziare, la mano robotica realizzata dai ricercatori della Cornell University, capace di muoversi, impugnare, sfiorare e allo stesso tempo percepire la temperatura e la consistenza degli oggetti, con una precisione impressionante. È infatti in grado di riconoscere al tatto il più maturo in un gruppo di pomodori, e a misurare facilmente la ruvidezza di una superficie.  Casco al grafene Quando pensiamo al grafene vengono alla mente applicazioni per lo sviluppo di superconduttori, transistor, e altri futuristici apparati elettronici. Ma trattandosi di di un materiale leggerissimo, super resistente e flessibile, le possibilità che offre sono innumerevoli. Un esempio, meno nobile ma non meno utile, è ad esempio quello realizzato dall’Iit in collaborazione con Momo design: il primo casco in grafene per moto e motorini. Un elmetto che promette altissima resistenza all’impatto, unita a un innovativo comfort termico. Braccio robotico extra Serve una mano? Al Mit hanno fatto anche di più, realizzando un intero braccio aggiuntivo che si monta sulle spalle e può fornire un aiuto nei lavori più disparati. È realizzato con un mix di carbonio e alluminio, e termina con una camera d’aria che può aderire saldamente a diverse superfici, e al contempo afferrare una vasta gamma di oggetti. C’è ancora da lavorare, ovviamente, per renderlo più economico e semplice da realizzare, ma potrebbe essere il primo passo verso un futuro in cui i lavoratori edili saranno equipaggiati con una serie di braccia extra, un po’ come dei tecnologici Visnu.  Pillola digitale  Altro che grande fratello: il medico in futuro saprà in tempo reale se, e quando, abbiamo preso la medicina. In barba alla privacy – forse – ma a tutto beneficio della nostra salute. E il primo passo lo abbiamo già fatto, con l’invenzione della prima pillola smart: Abilify MyCite, un antipsicotico che abbina al principio attivo anche un sensore biocompatibile, che consente al medico e ai familiari del paziente di monitorare la regolare assunzione del farmaco. Il tutto grazie a un cerotto con batteria che registra i segnali inviati dal medicinale, che possono essere controllati facilmente da una app dedicata.  Retina artificiale Ridare la vista a chi l’ha perduta, sfruttando una retina artificiale biocompatibile. È lo scopo di un progetto tutto italiano, che vede la collaborazione dell’Iit di Genova, del dipartimento di Oftalmologia dell’ospedale Sacro Cuore Don Calabria di Negrar (Verona), dell’Innovhub-Ssi Milano e dell’Università dell’Aquila. L’obbiettivo è quello di sfornare un dispositivo in grado di rimpiazzare i fotorecettori della retina umana in caso di danni, e di farlo utilizzando materiali organici e biocompatibili, che darebbero molti meno problemi di durabilità e tollerabilità rispetto a quelli attualmente disponibili, basati sul silicio. Il prototipo è stato sperimentato su modelli animali, e ha dato risultati estremamente incoraggianti. Tanto che i primi risultati di una sperimentazione sull’uomo dovrebbero arrivare già nei primi mesi del prossimo anno. Robot postino Your Autonomous Pony Express. Per gli amici, Yape. La risposta italiana ai droni postino di Amazon. I suoi creatori sono i ricercatori dell’azienda Milanese e-Novia, che hanno sviluppato un autentico robot autonomo per le consegne urbane. Un robot-postino, insomma, capace di interpretare i segnali stradali e semaforici, evitare il traffico, riconosce pedoni e ostacoli, senza bisogno di aiuto da parte di un operatore umano. E di consegnare il pacco una volta a destinazione, individuando il destinatario attraverso il riconoscimento facciale. Proprio nelle scorse settimane una piccola flotta di Yape è entrata in funzione a Cremona, e se si rivelerà un successo, come sperato, potrebbe presto diffondersi anche in altre città italiane. Occhiali elettronici per non vedenti Alcune persone hanno problemi di vista tanto accentuati da essere considerati legalmente ciechi: impossibilitati ad esempio alla guida, e per questo catalogati come disabili. Per loro la soluzione potrebbe risiedere nella realtà aumentata: è la scommessa di eSight, visori di ultima generazione che sfruttano microtelecamere e schermi oled integrati in un paio di occhiali, per elaborare immagini che compensano il difetto visivo di uno specifico paziente, e lo aiutano a recuperare almeno un certo margine di indipendenza. Ascensore da fantascienza Non solo in alto e in basso, come un ascensore tradizionale, ma anche in orizzontale, per un sistema di trasporto circolare più simile (almeno come concetto) a una piccola metropolitana. Si tratta dell’avveniristico ascensore orizzontale realizzato dalla Thyssenkrupp, una delle principali aziende di ascensoristica del globo. Un progetto che si basa su un sistema di levitazione magnetica (come quella dei treni a monorotaia) e giunti snodabili che permettono di modificare la direzione di marcia in orizzontale e in verticale. E che potrebbe rendere ancor più avveniristici grattacieli e altri grandi edifici del futuro. Oculus go Economico (costa meno di 200 euro), leggero, e totalmente autonomo. È la realtà virtuale democratica di Oculus Go, il nuovo visore di Facebook che permetterà di immergersi in ambienti tridimensionali senza bisogno di collegarsi a uno smartphone o a un pc. Il dispositivo è stato presentato quest’anno, anche se il lancio sul mercato è previsto per i primi mesi del 2018. Esoscheletro anti-cadute  Si indossa e si calibra in 3 minuti. E una volta pronto, è in grado di impedire agli anziani di cadere, prevedendo il rischio e intervenendo per controbilanciare la perdita di equilibrio. Questa in estrema sintesi la funzione di Active Pelvis Orthosis, o Apo, la protesi intelligente anti-cadute realizzata dai ricercatori della Scuola Superiore Sant’Anna di Pisa e dell’École polytechnique fédérale de Lausanne. Elenco degli H2 di https://www.wired.it/economia/business/2017/11/24/intelligenza-artificiale-business-2/
Organizzazione interna, marketing, vendita, relazione con i clienti: sono settori nevralgici per la vita di ogni azienda, dalle piccole e medie imprese ai grandi colossi, e sono anche quelli su cui impatta la spinta dell’intelligenza artificiale. Esempi importanti dell’utilizzo dell’Ai esistono già in molte realtà ma un cambio di passo più forte, in termini di cultura e strategia di adozione, potrebbe contribuire a generare quella svolta economica e di competitività di cui il sistema Paese ha bisogno. Temi al centro del convegno Il Futuro Digitale del Business tra Aziende, andato in scena lo scorso 14 novembre e organizzato dalla Casaleggio Associati, per una platea business che ha bisogno di capire meglio come gestire la transizione digitale per ricavarne vantaggio, embeddando l’Ai. Mezzo, quest’ultima, per analizzare dati o automatizzare processi, per ideare nuovi prodotti, per negoziare con i partner, per analizzare clausole e contratti, per anticipare il contatto da parte del cliente e l’elenco potrebbe continuare. In generale, come suggerisce la ricerca “Artificial Intelligence Business Evolution: l’intelligenza artificiale come acceleratore della digital transformation”, realizzata dalla Casaleggio Associati e presentata all’evento, il grande discrimine è tra un uso dell’Ai per migliorare l’efficienza produttiva e basta o un impiego utile a “un’apertura verso nuove strade di generazione di valore”. Automazione, interpretazione e previsione sono i livelli di complessità dell’impiego dell’Ai che la ricerca indaga, declinandoli per ambiti di applicazione in azienda e fornendo un excursus di esempi, che testimoniano il miglioramento per chi li adotta. Si va dalla catena alberghiera di lusso che utilizza il robot per parlare con i clienti al fashion retailer globale che usa la chatbot come ausilio per lo shopping. Per ogni ambito esistono quindi risposte perseguibili da tecnologie che apportano intelligenza aumentata, coadiuvando o sostituendo il contributo umano: chatbot e robot umanoidi nella relazione con il cliente, supporto al decision making nell’organizzazione interna, analisi automatizzate in ambito marketing. I tool non mancano e nemmeno gli esempi da seguire; meno semplice resta individuare a monte quale obiettivo generale si vuole raggiungere scegliendo di applicare l’intelligenza artificiale. Successivamente bisogna creare anche un contesto di formazione perché il cambiamento apportato sia assorbito in azienda. Un team che si dedica completamente all’Ai non può essere un aspetto facoltativo, ma rappresenta, secondo la ricerca, lo step ultimo di un processo graduale con cui si procede (il primo è migliorare i processi già automatizzati). Bisogna andare a inserire l’Ai in un complesso strutturato per accoglierla; inoltre, spesso letta come il mezzo che riduce personale, l’artificial intelligence può essere specularmente vista come lo strumento che rende possibile ottenere risultati laddove manca personale. Teoria e prassi non mancano ma come sottolinea la ricerca stessa, in genere le aziende che adottano l’intelligenza artificiale di base sono già digitalizzate, medio grandi, dotate di tecnologie multiple che spesso combinano con la stessa Ai. All’incontro B2B-Il futuro digitale del business la platea ha potuto ascoltare i contribuiti di esperti come Ettore Murciano di Loop AI, Mattia De Rosa di Microsoft Italia, Luca Scagliarini di Expert System e molti. Come ribadito, la centralità delle macchine intelligenti nasce dalla capacità di strutturare miliardi di dati in un tempo decisamente più basso di quello umano e dalla capacità dei software di apprendere dall’uomo per aiutarlo. Tuttavia anche sui dati bisogna riflettere perché, lo sottolinea la ricerca citando un mantra dei chief data officer, “se entra spazzatura esce spazzatura”: il problema quindi sono i dati all’ingresso, poi arriva il robot o l’algoritmo a fare lo sporco lavoro.  Elenco degli H2 di https://www.wired.it/attualita/tech/2017/01/09/innovazione-accessibile/L’innovazione non è tale se non diventa accessibile a un pubblico quanto più vasto possibile. L’assunto vale in ogni campo, anche per quanto riguarda le tecnologie più avanzate. Ne è convinta Comau, società che fa parte del gruppo FCA, da sempre impegnata a guidare l’evoluzione tecnologica nei processi produttivi industriali, fino ai più recenti sviluppi della “quarta rivoluzione industriale”, l’ Industry 4.0. Per l’azienda torinese progettare il futuro è la sfida di tutti i giorni. Un impegno che viene affrontato partendo da una costante riflessione sugli scenari del presente e dall’attitudine ad anticipare il cambiamento, in modo da poterlo guidare. Per questo motivo Comau ha sviluppato un piano di innovazione che si fonda su una nuova visione dell’automazione industriale. Comau immagina infatti una nuova era dell’automazione, destinata finalmente a divenire aperta. Ogni soluzione tecnologica, anche se molto complessa da progettare, dovrà essere intuitiva e semplice da apprendere e da utilizzare. Un’automazione che tende al miglioramento continuo e garantisce una maggiore efficienza dei processi produttivi, basandosi sulla collaborazione Uomo-Robot. Con l’avvento di Internet e delle tecnologie digitali, d’altra parte, anche l’industria manifatturiera sta affrontando una vera e propria rivoluzione: collaborare con le macchine industriali in assoluta sicurezza è ormai una priorità. Fondamentale per ottenere questi ambiziosi obiettivi è la formazione, indispensabile per sviluppare la Cultura dell’Automazione. Da anni Comau si propone come partner di attività educative nel campo dell’automazione industriale. Con questo scopo ha anche dato vita alla Comau Academy, che lavora per diffondere questo tipo di impostazione all’interno e all’esterno dell’azienda. Tra i diversi programmi di formazione della ‘learning factory’ di Comau si segnala il nuovo Executive Master in Manufacturing Automation & Digital Transformation, che partirà nel mese di marzo del 2017. Si tratta di un programma di studi unico, volto ad acquisire le competenze tecniche e manageriali necessarie per sviluppare e gestire soluzioni di automazione industriale nell’era della trasformazione digitale. Senza mai dimenticare che la Cultura dell’Automazione significa anche etica, sostenibilità ecologica e sociale, capacità di trovare soluzioni per il mondo di oggi e domani e condividerle con gli altri. L’approccio non è nuovo per Comau, azienda leader a livello globale nel suo settore, che sfrutta l’esperienza garantita da oltre 40 anni di attività e di costante ricerca delle soluzioni tecnologiche più semplici e al contempo innovative per rispondere alle esigenze del mercato. Con la consapevolezza che solo chi ha il coraggio di osare, di pensare a idee apparentemente irrealizzabili e chi sa imparare dai propri errori, può davvero fare la differenza.Elenco degli H2 di https://www.wired.it/economia/business/2017/09/07/italiani-auto-guida-autonoma-coop/Sarà che dal lunedì al venerdì gli italiani trascorrono 10 ore e 40 minuti al volante, un’ora in più della media europea, come ha rilevato di recente Boston Consulting Group, ma gli automobilisti del Belpaese, più di altri in Europa, sono fiduciosi nell’avvento sulle strade delle macchine a guida autonoma. Il 49% degli italiani si dichiara disposto a viaggiare una quattroruote che va da sola, contro il 34% dei tedeschi e dei francesi, il 32% degli inglesi e il 28% degli spagnoli. E più dei loro vicini di casa in Europa gli italiani hanno fiducia nei robot e nell’intelligenza artificiale. Per il 61% sono “una cosa buona”, contro il 60% del Regno Unito, il 57% delle Germania e il 55% della Spagna. L’ultimo rapporto Coop sulle abitudini degli italiani registra la fiducia dei consumatori per le nuove tecnologie. L’ingresso dei robot in fabbrica, ad esempio, spaventa i lavoratori del Belpaese meno di quanto faccia con i colleghi di Francia, Spagna e Germania. E il 70% degli operai dello Stivale, ad esempio, è ottimista rispetto agli effetti dell’industria 4.0 e al lavoro uomo-macchina. In generale gli italiani si dimostrano pronti a raccogliere i vantaggi che la tecnologia può offrire sul lavoro. Due intervistati su tre sarebbero disposti a lavorare da casa, sfruttando le opportunità del telelavoro: il 29% a parità di busta paga, mentre il 12% accetterebbe anche un taglio del 10% del salario, pur di operare da casa. Gestire liberamente il proprio tempo è, d’altronde, una delle ambizioni più care agli italiani. Telelavoro o meno, ad esempio, il 14% degli italiani che lavorano a tempo piano rinuncerebbe a un margine del proprio stipendio pur di avere più libertà per se stessi. Non solo per andare in palestra, ma anche per guadagnare più soldi facendo un altro mestiere. Coop ha ingaggiato l’istituto di ricerche Ref per dare un volto alle reclute italiane della gig economy, l’economia dei lavoretti. Come gli autisti di Uber o i fattorini di Foodora o Deliveroo. Lo studio ha somministrato 500 questionari ad altrettanti utenti di Be my eye, una piattaforma che mette in contatto persone disposte a fare un lavoretto con negozi in cerca. È emerso che il 26% di questi lavoratori ha un impiego a tempo pieno , il 15% ha una propria attività e il 14% un contratto part time. Il 45% di loro svolge un lavoretto almeno una volta alla settimana, il 35% una volta al mese. Nel 46% dei casi, però, la collaborazione è una sola. E il 65% guadagna al massimo 50 euro al mese. L’interesse e la dipendenza degli italiani dal digitale sono aumentati. Lo dimostra, ad esempio, il rapporto con i social network. Gli italiani sono più attivi degli altri europei. Il 67% della popolazione tra i 16 e i 74 anni ha un profilo social, contro il 60% della Spagna, il 56% della Germani e il 47% della Francia. Facebook domina su tutti. Il 91% di chi è pratico delle comunità virtuali, è iscritto al colosso fondato da Mark Zuckerberg. Tuttavia il rapporto non è idilliaco e gli italiani collocano Facebook tra i temi controversi dell’attualità, insieme alla democrazia digitale, per quanto concerne la tecnologia. Nelle abitudini delle famiglie italiane cresce la spesa elettronica e pesa ormai per il 41% degli acquisti di cibo e verdura. In media lo scontrino finale è di 100 euro. Il 70% degli italiani tra 40 e 54 anni si dichiara inoltre “a proprio agio” all’idea di ricevere la spesa da un drone. In un contesto di generale crescita di internet e del digitale, l’unico segmento in calo è quello della pornografia. Le ricerche settimanali si sono dimezzate rispetto al 2012 e l’Italia ha perso una posizione nella classifica mondiale dei download di film a luci rosse.Elenco degli H2 di https://www.wired.it/gadget/computer/2017/05/25/codemotion-kids-insegna-la-robotica-ai-bambini/Seduti o in piedi, radunati in gruppetti, distribuiti intorno a un grande tavolo. Impegnati con le mani e con la testa nel costruire, assemblare, far funzionare, i bambini mostrano di essere soprattutto una cosa: felici. Li osservo attraverso il vetro che separa la sala in cui fanno lezione i tutor di Codemotion Kids dal lungo corridoio del Luiss Enlabs, dove l’organizzazione ha sede. Sto attento a non farmi vedere, perché tra loro ci sono anche i miei figli, e non voglio interferire con il loro comportamento, influenzarne le reazioni. Posso vedere chiaramente che si divertono, si appassionano, socializzano. A fine lezione il loro racconto emozionato mi confermerà anche che imparano con gioia e facilità. È il primo “Sabato Tech” dei quattro che li aspettano a maggio. Un ciclo di lezioni da due ore ciascuna che introduce i bambini dagli otto anni in su al mondo della robotica, della programmazione, dei sensori e degli oggetti intelligenti. Ci troviamo a Roma, che insieme a Milano ospita una delle due sedi principali di Codemotion Kids: queste due si distinguono dalle altre presenti a Torino, Modena, Trento, Genova e Verona, perché ad esempio rendono disponibili anche percorsi formativi annuali, da seguire in cicli da 24 appuntamenti infrasettimanali. Mentre prosegue la lezione, resto a parlare con Massimo Avvisati, docente di programmazione e arti digitali e responsabile didattico di Codemotion Kids. “Robotica, elettronica, IoT, coding: gli argomenti trattati oggi dai corsi per bimbi sono ovunque più o meno gli stessi”, spiega: “Quello che ci distingue è il lavoro costante di ricerca e sviluppo del metodo educativo”. E di costruzione del team di educatori. Al momento in Italia ad operare sotto il cappello “Codemotion Kids” ci sono ben 40 coach, cui si sommano le tre persone del team di ricerca che, per esempio, si occupa di scovare e studiare gli strumenti didattici più indicati. Selezionare la squadra non è stato semplice: “È difficile trovare insegnanti che siano competenti su ciò che insegniamo e qui e, allo stesso tempo, capaci di insegnare in modo non tradizionale”. Quando chiedo come si costruisce il programma di corsi come Sabato Tech, Massimo mi guarda sorridendo, quasi comprensivo: “La domanda sul programma è quella che di solito ci viene rivolta per prima dai genitori, perché giustamente vogliono capire meglio in cosa stanno investendo i loro soldi e il tempo dei loro figli. Paradossalmente, per noi è difficile rispondere”. Già, perché il concetto stesso di programma rappresenta una concezione rigida dell’insegnamento, tipicamente scolastica, basata su step obbligatori che devono essere imposti dall’alto agli studenti. Diversamente, i workshop organizzati da Codemotion Kids si articolano per macrotemi: “Ogni lezione è project based, ovvero segue un canovaccio che poi si adatta in tempo reale sulle necessità degli studenti, prende forma in base alle loro reazioni e desideri, asseconda e stimola la loro curiosità”, chiarisce Massimo. Lo osservo con attenzione mentre parla: mi colpiscono la passione con cui definisce il senso di quanto viene fatti nei corsi, ma — da padre — anche la profonda comprensione di come i bimbi debbano essere accompagnati nell’apprendimento. Torniamo in aula per fare qualche foto. I miei bimbi, così come i loro compagni, mi ignorano per la maggior parte del tempo, tanto sono presi in ciò che fanno. Quando poi mi rivolgono la parola, lo fanno per spiegarmi con un certo orgoglio cosa stanno facendo, quindi mi mostrano una demo. Se non fossi di parte, direi che mi hanno fatto un “pitch” piuttosto convincente. Un inizio incoraggiante. Creano un piccolo robot programmabile usando il kit mBot, hanno la possibilità di utilizzare strumenti come Micro:bit, il microcomputer programmabile con 25 LED realizzato dalla BBC e pensato espressamente per la didattica digitale, imparano a comprendere il funzionamento dei circuiti con il sistema Little Bits, a programmare con il mai troppo celebrato Scratch creato dal Mit. “Siamo qui dal 2013, quando è nato Codemotion Kids, e da allora ci stiamo evolvendo rapidamente. Grazie alla ricerca, ma anche e soprattutto grazie all’interazione con i ragazzi”, conclude Avvisati. Lo saluto e vado incontro a Mattia e Dario che, finita la lezione, mi vengono incontro saltellando. Gli chiedo se si sono divertiti: “Ci torniamo anche domani?”, rispondono in coro.Elenco degli H2 di https://www.wired.it/play/televisione/2017/09/14/serie-tv-predetto-tecnologia/Perché guardiamo le serie tv? Per cercare momenti di evasione, certo, ma anche per farci affascinare da storie che non sono le nostre, personaggi particolari, scenari esotici, trame a volte perfino improbabili. Capita anche con generi che di solito più marcatamente sono lontani dalla realtà, come l’animazione, la fantascienza o il fantasy. Eppure a volte queste serie di genere finiscono per raccontare del mondo che ci circonda più di quanto non facciano i titoli più realistici. Anzi, spesso le serie tv abituate a utilizzare appieno l’immaginazione, finiscono con l’anticipare cose che avverranno realmente. È il caso recente, ad esempio, di Black Mirror, oggi al centro delle cronache per aver anticipato le animoji lanciate da Apple, ma accade anche in tante altre serie. Vediamo alcuni casi in cui le produzioni televisive hanno anticipato la tecnologia che usiamo ogni giorno. 1. Black Mirror e le animoji  Durante la sua ultima attesissima presentazione a Cupertino, la Apple ha lanciato i suoi nuovi modelli di iPhone e tutte le caratteristiche all’avanguardia che li contraddistingueranno. Fra le altre, la più divertente è forse rappresentata dalle animoji, ovvero un’evoluzione animata delle emoji che riproducono l’espressione facciale dell’utente. Appena dopo l’annuncio, l’account Twitter di Black Mirror ha fatto notare un piccolo particolare: fra le animoji, infatti, andrebbe anche inserito Waldo (come si vede nella seconda fila in terza posizione nell’immagine qui sopra). Nell’episodio The Waldo Movement, infatti, la serie di Charlie Brooker aveva anticipato l’idea di avatar animati comandati attraverso lo scanning delle espressioni del viso (una specie di filtro di Snapchat o Instagram avanzato). E in qualche modo quella di Black Mirror non fu solo una previsione tecnologica, perché nell’episodio s’immaginava che un candidato senza scrupoli utilizzasse l’animazione per celare il suo volto e vincere le elezioni tramite una campagna anti-sistemica e populista (citofonare Trump). 2. Star Trek: The Next Generation e i tablet Quasi dieci anni prima del lancio degli iPad e degli altri tablet oggi diffusissimi in commercio, ci aveva già pensato Star Trek: The Next Generation a immaginare le tavolette elettroniche. Negli episodi soprattutto della sesta stagione (andata in onda fra 1992 e 1993) si vedono infatti il comandante Picard e altri membri dell’equipaggio utilizzare dei dispositivi del tutto simili ai tablet. Ancora più sorprendente è che nella serie in inglese questi marchingegni vengono chiamati Personal Access Display Devices, ovvero: PADDs! Ma l’intera saga di Star Trek è nota ai fan per aver anticipato, o perlomeno immaginato, molte altre tecnologie introdotte decenni dopo: dall’auricolare di Uhura che sembra in tutto e per tutto un dispositivo bluetooth ai computer che interagiscono vocalmente come una Siri qualunque, c’è solo l’imbarazzo della scelta in questa serie tv. 3. I Simpson e gli smartwatch
 Un’altra serie molto nota per aver anticipato il futuro in tanti modi diversi, dai brogli elettorali al controllo governativo sulle conversazioni, dallo strapotere dei giganti del web ai selfie involontari, è proprio I Simpson. Ma in particolare in un episodio, volutamente futuristico e ambientato quando ormai i figli di casa Simpson sono adulti, introduce un’innovazione tecnologica di questi anni. Molto prima che la Samsung lanciasse i primi modelli di smartwatch nel 2013, infatti, vediamo che nell’episodio Il matrimonio di Lisa, andato in onda nel 1995, il pretendente della ragazza utilizza un computerino portato al polso per comunicare con lei, con tanto di schermo e videocamera. 4. I Jetsons e i lettini abbronzanti
 Rimanendo ancora nell’ambito dell’animazione televisiva ma andando ancora più indietro nel tempo, non si può parlare di previsioni futuristiche senza menzionare I Jetsons, la serie animata ambientata in un futuro spaziale e ipertecnologico. Oltre a introdurre nelle case degli americani concetti come le sveglie parlanti, le videochiamate e i robot domestici, questa famiglia del futuro era solita utilizzare schermi tv piatti e auto senza pilota (nel loro caso volanti). Ma una delle invenzioni più curiose anticipate da I Jetsons è sicuramente il lettino abbronzante: in uno degli episodi si vedono i personaggi abbronzarsi grazie a grosse lampade appositamente fissate sopra il loro letto. Questo accadeva alla fine degli anni Sessanta, mentre il primo lettino abbronzante individuale fu introdotto in America solo nel 1979. 5. Minority Report e i cookie Quando uscì nel 2002, il film di Steven Spielberg con Tom Cruise tratto dal racconto di Philip K. Dick Minority Report (Rapporto di minoranza) ci mostrò un futuro non troppo lontano in cui la tecnologia pervade e controlla ogni ambito della società; lo stesso fece la serie tv che ne seguì, durata una sola stagione nel 2015. In un mondo in cui degli esseri dalle capacità sovraumane riescono a predire i crimini, i cittadini sono sorvegliati e presi di mira in diversi modi (oggi bastano forse i big data). Per esempio uno degli elementi immaginati da Minority Report è il metodo in cui, grazie al riconoscimento facciale (altro aggancio alla recente presentazione Apple), monitor e display possano mostrare pubblicità personalizzate a seconda dei gusti dell’individuo: non molto lontano da ciò che accade oggi con i cookie e il targeted advertising. Inoltre vengono introdotti schermi olografici con cui è possibile interagire con il semplice movimento di braccia e mani: dalla Wii in poi anche questa innovazione non è poi così irreale.Elenco degli H2 di https://www.wired.it/play/cultura/2017/01/09/flyai-scultura-robot-mosche/FlyAi è una scultura in cui lo stato di salute e la vita di una colonia di mosche sono decisi da un software di intelligenza artificiale. Creata dallo scultore di opere cinetiche, robotiche, interattive David Bowen, FlyAi utilizza tecnologia TensorFlow, che registra i movimenti delle mosche e li classifica in una scala da 1 a 5. Il punteggio, aggiornato in tempo reale, aziona una pompa che immette nell’ecosistema acqua e nutrienti. Il sistema è progettato per durare all’infinito. Ti è piaciuto? Guarda anche Owen Wilson spiega l’artista Ed Ruscha.Elenco degli H2 di https://www.wired.it/lifestyle/design/2017/02/24/robotto-automi-da-compagnia/Un robot può essere un giocattolo dalle forme più o meno vagamente antropomorfe. Ma anche un traguardo di sofisticata tecnologia, o ancora un prezioso strumento domestico per svolgere in modo più efficiente le faccende di casa. Il ruolo ricoperto da quelli che possono essere definiti automi da compagnia è in continua evoluzione, ed è al centro della mostra Io, Robotto in programma dal 25 febbraio al 27 agosto presso il Palazzo Alberti Poja di Rovereto, in provincia di Trento. Un progetto che nasce dalla collaborazione tra il giornalista Massimo Triulzi e il Direttore della Fondazione Museo Civico di Rovereto, Franco Finotti: in esposizione oltre 90 automi che nel corso degli ultimi decenni sono entrati nell’immaginario collettivo, di cui è possibile vedere in anteprima nella nostra gallery alcuni scatti artistici realizzati dal milanese Valentino Candiani. I modelli spazieranno dal Karakuri Tea Serving Robot, il robottino con meccanismo a molla in grado di trasportare una tazza di tè sino al commensale prescelto e di tornare in cucina una volta svolto il proprio compito, all’Aibo ERS 111 di Sony (Artificial Intelligence roBOt) disegnato dal maestro Hajime Sorayama, i cui 3 mila pezzi destinati al solo mercato giapponese si esaurirono in 17 secondi, passando per il Robocco Pouring Beer Robot di Asahi, una delle più grandi aziende giapponesi produttrici di bibite, capace di fungere da frigorifero, aprire una lattina di birra e versarla lentamente in un boccale. Non solo: la mostra sarà anche l’occasione per incontri a tema, presentazioni di libri, demo di robotica e laboratori didattici per adulti e ragazzi. Il calendario degli eventi in programma sarà presto disponibile sul sito ufficiale dell’iniziativa.Elenco degli H2 di https://www.wired.it/attualita/tech/2017/06/12/giusto-dotare-lintelligenza-artificiale-libero-arbitrio/di Giulio Coraggio, partner dello studio legale DLA Piper e fondatore di IoTItaly I sistemi di intelligenza artificiale stanno raggiungendo livelli di ragionamento pari a quelli degli esseri umani. Non si limitano a calcolare le probabilità di successo di una soluzione, ma apprendono e pensano come gli esseri umani. Ciò è certamente affascinante, ma lo sfruttamento di queste tecnologie comporta rischi che non sono stati ad oggi sufficientemente valutati.
L’intelligenza artificiale che “pensa” come un essere umano Lo scorso 30 maggio 2017, IoTItaly, l’associazione italiana per la crescita dell’Internet of Things in Italia di cui sono uno dei fondatori, ha organizzato un evento con STMicroelectronics intitolato Creatività e tecnologia al tempo dell’industria 4.0.
Ci sono stati una serie di panel durante l’evento, ma la discussione a cui ho partecipato come speaker ha toccato, tra gli altri, le criticità dei sistemi di intelligenza artificiale. Non c’è dubbio che l’intelligenza artificiale possa essere un supporto enorme in qualsiasi campo, ma deve semplicemente accumulare informazioni e sulla base di queste informazioni definire la soluzione più probabile tramite un calcolo delle probabilità? Oppure deve andare oltre questa tipologia di ragionamento e aggiungere caratteristiche che sono più umane come la capacità di apprendimento e l’intuito? Penso che il video di seguito che cerca di illustrare il funzionamento del sistema di intelligenza di Google denominato DeepMind sia affascinante. https://www.youtube.com/watch?v=5J5bDQHQR1 Come accennato nel video, l’evento che viene considerato “storico” nell’evoluzione dei sistemi di intelligenza artificiale è la vittoria del sistema di intelligenza artificiale AlphaGo contro un maestro dell’antico gioco cinese Go. Il gioco del Go ha molte più varianti degli scacchi e non è quindi possibile considerare tutte le possibili alternative e il sistema deve sviluppare una sorta di “intuito” per definire la strategia migliore.
DeepMind è l’evoluzione di AlphaGo. Infatti, è definito sul suo sito web come “leader mondiale nella ricerca dell’intelligenza artificiale e nella sua applicazione per un impatto positivo. Siamo in una missione scientifica per spingere i confini dell’intelligenza artificiale, sviluppando programmi che possono imparare a risolvere qualsiasi problema complesso senza bisogno che gli venga insegnato come fare“. Il sistema di intelligenza artificiale non riceve istruzioni, ma “impara” come fare le cose e comincia a pensare come gli esseri umani. Questo è davvero impressionante poiché il livello di comprensione delle situazioni raggiungibili dai sistemi di intelligenza artificiale è illimitato e ciò vuol dire che il divario tra gli esseri umani e le macchine sta scomparendo.
Quali problemi legali possono derivare dalle “libere” decisioni dell’intelligenza artificiale? Se i sistemi di intelligenza artificiale sono lasciati liberi a prendere le proprie decisioni, vengono presentati alcuni problemi giuridici “inattesi”: 1. Chi è responsabile per i sistemi di intelligenza artificiale?
Il Comitato per gli affari legali del Parlamento europeo ha approvato un report che invita la Commissione europea a introdurre una serie di regole sulla robotica. Il Comitato richiede l’introduzione di regole di responsabilità oggettiva (e.g. del produttore o del proprietario) per i danni causati da sistemi di robotica a causa della difficolta di determinare il legale tra il comportamento dannoso del robot e il danno subito dal danneggiato.
Ma cosa succede in caso di sistemi come Google DeepMind a cui non vengono date indicazioni su cosa fare, ma la macchina semplicemente “impara” a compiere delle attività ed è quindi incontrollabile? I sistemi assicurativi obbligatori possono essere la soluzione, ma questo aggiungerà un ulteriore livello di costi che potrebbe limitare la crescita di queste tecnologie. 2. L’intelligenza artificiale agisce eticamente?
Questo è un altro argomento toccato durante l’evento di IoTItaly. La scelta che la macchina considera migliore potrebbe non essere la scelta più etica. Ma questo significa che l’intelligenza artificiale non può essere lasciata “libera” di prendere le proprie decisioni?
Alcune aziende stanno già istituendo comitati etici per definire i principi etici da imporre alle macchine. Ciò potrebbe significare che i sistemi di intelligenza artificiale potrebbero: •    “imparare” ad agire anche eticamente;
•    avere le proprie decisioni riesaminate da un essere umano come avviene nel settore medico; o
•    essere utilizzate in maniera completamente libera solo in contesti in cui non è possibile causare danni all’uomo. 3. È possibile giustificare la decisione dell’intelligenza artificiale?
Ai sensi del regolamento europeo sulla protezione dei dati personali, gli individui devono essere in grado di opporsi alle decisioni adottate da sistemi automatizzati che – in caso di dati relativi alla salute – possono essere utilizzati solo con il loro consenso.
Cosa succede se la revisione manuale di una situazione non è in grado di ottenere una piena comprensione del ragionamento eseguito dalla macchina? I ragionamenti che i sistemi di intelligenza artificiale saranno in grado di compiere diventeranno sempre più complessi e questo è un rischio concreto. Questi sono solo alcune delle implicazioni legali dell’intelligenza artificiale che è certamente un campo estremamente affascinante che porterà senza dubbio a possibili contenziosi.Elenco degli H2 di https://www.wired.it/economia/finanza/2017/12/11/future-bitcoin-cboe/ Quella di Chicago passerà alla storia per essere la Borsa in cui sono stati lanciati i primi future sul bitcoin. Le contrattazioni sul Chicago Board Options Exchange (Cboe) sono iniziate il 10 dicembre alle 17 locali (mezzanotte in Italia) con un prezzo di 15mila dollari (12.720 euro). Alle 7 di mattina in Italia aveva già superato i 17.900 dollari (15.187 euro) con un balzo verso l’alto del 24,4%. Al momento in cui scriviamo il bitcoin è scambiato per 16.725 dollari (14.190) euro, con un rialzo netto del 23,3%.  I future
Sono l’impegno con cui si acquista o si vende una quantità di merce o di un’attività finanziaria a un prezzo prefissato. In questo caso chi ha scelto i future sul bitcoin sta scommettendo sul valore della criptovaluta al 17 gennaio 2018, quando il future scadrà. Cosa è successo
Le contrattazioni dei future creano prezzi ufficiali e, a causa del forte incremento, sono state interrotte per due volte (alle 19:30 e alle 21:00 – orario di Chicago) applicando regole create proprio per limitare la preventivata volatilità, ovvero una sospensione di 2 minuti a fronte di un aumento del 10% e di 5 minuti se l’aumento repentino (in gergo “fiammata”) è almeno del 20%. La piattaforma del Cboe è risultata irraggiungibile per diversi minuti, messa in difficoltà dal forte traffico web. Cosa ci si aspetta ora
Le variabili sono diverse e, per il momento, tengono banco i numeri e la fiducia. Il bitcoin è esploso negli ultimi 12 mesi, facendo registrare un aumento del loro valore di circa il 1.500% arrivando a un valore di mercato di 300 miliardi di dollari. Tuttavia alcune grandi banche non nutrono troppa fiducia, sostenendo che un crollo del bitcoin può minacciare il sistema finanziario. In America i principali istituti di credito hanno chiesto alle autorità di intervenire con regolamenti ad hoc. Da sottolineare che questi istituti hanno assunto una posizione ufficiale contro i future sul bitcoin, ritenendo rischiosa un’operazione finanziaria non controllata da una banca centrale. Più morbida invece la linea della Deutsche Bank che rimane però pessimista nel caso in cui scoppiasse la bolla, con conseguenze a cascata sulla stabilità economica.Elenco degli H2 di https://www.wired.it/economia/finanza/2017/11/27/bitcoin-sale-analisti/Nel momento in cui scriviamo un bitcoin è scambiato per 9.568 dollari, circa 8.017 euro. Un risultato che fa gola a molti se si considera che un anno fa la criptovaluta era quotata 700 dollari (585 euro) e che durante il mese di ottobre ha superato la soglia dei 6mila dollari (5 mila euro circa). Domenica 26 novembre gli scambi sul mercato delle 1.300 monete digitali hanno toccato i 12 miliardi di dollari; 5,6 miliardi a carico del solo bitcoin la cui capitalizzazione è di 150 miliardi di dollari, più del 50% del valore dell’interno mercato, circa 294 miliardi di dollari. Euforia pericolosa?
L’aumento della domanda di bitcoin sta galvanizzando l’ambiente, dando a chi ci mercanteggia la sensazione di avere in mano una carta imbattibile. Il rischio che il sogno si infranga non è però assente; oltre ai pareri discordanti (e soggettivi) di imprenditori e economisti, resta il fatto che quello delle criptovalute è un mercato come molti altri e, per definizione, suscettibile a cambiamenti repentini e non per forza immune dal rischio bolla. Ciò nonostante gli analisti guardano al rialzo. Secondo le strategie di portafoglio consigliate dalla società di ricerca e analisi Fundstrat Global Advisors, il bitcoin può raggiungere gli 11.500 dollari entro il mese di giugno del 2018. Una sostanziale retromarcia perché la stessa azienda si diceva certa che per la stessa data il bitcoin avrebbe sfondato il tetto dei 6mila dollari. La sensazione diffusa è che i bitcoin potranno superare la soglia dei 10mila dollari (8.379 euro) prima che chi li possiede apra il panettone.Elenco degli H2 di https://www.wired.it/economia/finanza/2017/01/25/bitcoin-dove-acquistarli-italia/Un po’ sale, un po’ scende. Chi dice che questo sarà l’anno del suo boom, con quotazioni superiori ai 2000 dollari e chi ne vaticina la fine. Che il Bitcoin sia quanto di più volatile esista nell’universo delle valute, lo sapevamo già. Ma che sia anche fonte di soddisfazioni per chi ci ha creduto dal primo istante è un’altra certezza: ieri la quotazione media della moneta virtuale si attestava poco sotto gli 850 euro, che per una moneta che 7 anni fa era valutata mezzo dollaro non è poco. Qui però più che inoltrarci nella selva delle quotazioni delle criptovalute, vogliamo rispondere a una domanda più semplice: ma come si acquistano i bitcoin in Italia, senza rischiare di essere truffati? ATM. Non vanno intesi proprio come dei bancomat, ma come distributori in cui introdurre gli euro in contanti per ottenere in cambio l’accredito di bitcoin sul portafogli elettronico. In Italia, al momento della pubblicazione di quest’articolo, ce ne sono 6 o 7, pochi rispetto ad altri paesi. Il sito Coinatmradar negli Usa, tanto per dire, ne conta più di 500, 47 in Gran Bretagna, 27 in Spagna 27. Gli Atm bitcoin italiani si trovano a Torino all’interno del Sella Lab (via Maria Vittoria 38), a Milano presso il TAG (Talent Garden, via Merano 16), a Firenze in un negozio in pieno centro a quattro passi dal duomo, a Rovereto (Tn), nel bar Mani al cielo. Alcuni li ha installati Robokiosk, e permettono di cambiare gli euro in bitcoin e viceversa. La procedura per acquistare i bitcoin non è immediata: “La prima volta prevede 4 fattori di autenticazione, perché ci atteniamo alle leggi contro il riciclaggio di denaro. Ma un solo account funziona su tutte le macchine”, spiega Federico Pecoraro, CEO di Robocoin Italia. L’app Qui Bitcoin (Android) e il sito Coinatmradar segnalano altri ATM nel Computer Shop di Pisa e da Gavrilobtc a Udine, il primo ad aprire in Italia (e terzo in Europa). E a sud? Per ora ben poco. Ma presto potrebbe riaprire un distributore di bitcoin a Roma. Via internet. Attraverso siti come Bitboat si possono acquistare bitcoin pagando l’importo in una ricevitoria o alle poste. Si tratta in pratica di una semplice ricarica ai gestori del sito, che in seguito inviano i bitcoin al nostro wallet. Il sito vanta 15.000 transazioni all’attivo. Gli exchange. Ma (forse) il metodo più sicuro per acquistare bitcoin è attraverso un agente di cambio. “Bisogna fare attenzione a rivolgersi a un exchange affidabile”, spiega Marco Amadori, CEO di Inbitcoin e ricercatore blockchain lab, che segnala come exchange Bitstamp, Kraken e Therocktrading (l’unico che parla italiano). Due su tre li approva anche Pecoraro, che a Bitstamp e Therocktrading aggiunge l’americano Coinbase. “Il processo di acquisto è semplice e sicuro sugli exchange”, spiega. Di persona. Sono le transazioni che si svolgono attraverso il sito Local Bitcoin e obbediscono alle stesse regole degli acquisti tra persone che si sono conosciute in Rete. “Vedere cammello, pagare moneta” è sempre la filosofia migliore: il venditore di bitcoin va pagato solo una volta ricevuto l’accredito di bitcoin sul proprio wallet. “Personalmente diffido degli spacciatori di bitcoin, che non offrono le garanzie di un exchange e spesso alzano i prezzi”, commenta Pecoraro. Mentre Marco Amadori lo ritiene un metodo abbastanza sicuro, “anche se vanno prese le cautele degli acquisti tra privati che non si conoscono”.Elenco degli H2 di https://www.wired.it/economia/finanza/2017/12/12/tutto-sapere-bitcoin/Il lancio dei futures sui Bitcoin deciso dalla US Commodities and Futures Trading Commission ha acceso l’attenzione dei grandi media sulla moneta elettronica creata ormai sette anni fa dal misterioso Satoshi Nakamoto (la cui enigmatica identità è stata più volte individuata e smentita con altrettanta rilevanza). Si tratta di titoli che scommettono sul valore futuro della criptovaluta e che, per la prima volta, vengono scambiati su un mercato ufficiale e regolamentato, la Chicago Board Options Exchange. Di solito si usano per le materie prime – se ne sente parlare in particolare per il petrolio – ma in teoria potrebbero essere emessi per qualsiasi cosa. A leggere le fonti che si occupano di Bitcoin, pare che la svolta ci sia stata (è ovviamente una divertente provocazione) negli Stati Uniti di fronte al tacchino del Ringraziamento. La gente ha iniziato a parlare di questa valuta digitale anche come forma di investimento, oltre che di speculazione, e non a caso i conti sulle piattaforme di trading specializzate come Coinbase sono esplosi nel giro di pochi giorni. A tal punto da mettere in crisi le infrastrutture di questi servizi (e invitarli perfino a fare una ramanzina agli utenti). La quotazione si muove ora oltre i 16mila euro ma, come noto, il valore del Bitcoin rispetto a euro e dollaro fluttua di continuo e non è raro poter perdere ampie percentuali dei propri investimenti per poi recuperarne nel giro di poche ore o giorni. Dipende da numerosi fattori: l’assenza di elementi concreti alla base di quel mercato e l’ampiezza stessa del mercato, in fondo ancora piccolo nonostante le notizie di questi giorni ne stiano dando un’immagine pachidermica, dove dunque pochi massicci movimenti o previsioni (tipo l’interesse di certi fondi speculativi, tanto per fare un esempio) può comportare scossoni clamorosi. Basta osservare i grafici che pure, sul lungo periodo, assumono un andamento inequivocabile: se a gennaio un Bitcoin valeva 730 euro, oggi, appunto, ne vale oltre 14mila. Tirandosi dietro, fra l’altro, le altre due principali criptovalute come Ether (passata dai 7 euro dello scorso gennaio agli oltre 400 attuali) e Litecoin (da 4 a 164 euro). Ma oltre alle più note (alle già citate vanno aggiunte almeno Ripple, Dash, Monero, ZetaCash) se ne contano oltre un migliaio, molte di esse legate al fenomeno delle Ico, le Initial Coin Offering, modi per finanziare le startup emettendo monete digitali ma inizialmente nati proprio per dare vita a nuove criptomonete (è il caso di Ethereum o Mastercoin). Cosa sia e come funzioni il Bitcoin è ormai patrimonio comune. Anche se alla stragrande maggioranza rimane comunque un alone di mistero, tanto che diverse grandi testate rinunciano perfino a tentare di spiegarlo. Di fatto la valuta “nasce” con il “mining” informatico, cioè con la risoluzione di complesse equazioni (spesso condividendo potenza di calcolo di molte macchine nelle “Bitcoin farm” o affidandosi al “cloud mining”, affittando cioè potenza di calcolo). Quel dispendio energetico viene ricompensato dall’emissione di alcune unità. Al momento ne sarebbero prodotte circa 3.600 al giorno per un totale circolante intorno ai 17 milioni e una capitalizzazione di 300 miliardi di dollari. I bitcoin hanno un tetto: il sistema è architettato per fare in modo che non possano esserne prodotti più di 21 milioni. Da questa futura limitazione nasce la duplice faccia dello strumento: speculazione immediata e investimento-risparmio futuri. La natura di metodo di pagamento, limitata agli store del deep web, ad alcune realtà commerciali specie online e ad alcuni casi pensati per farsi pubblicità appare oggettivamente residuale. In ogni caso, se volete sapere dove poterlo così basta andare su QuiBitcoin (ho scoperto di poterci saldare il taxi ma solo da web). Estranea a ogni ente terzo di controllo, il Bitcoin certifica le transazioni attraverso la tecnologia della blockchain, una catena dei blocchi, sorta di registro aperto (trasparente per quello che riguarda la certezza dello scambio, non per i soggetti coinvolti) che valida acquisti e vendite di Bitcoin trasformando quella specifica operazione in un blocco della rete cristallizzato e, appunto, certificato dall’intero network. Nessuno può modificarne valore ed estremi o prendere il controllo dell’intera rete, perché l’investimento necessario (ammesso che sia virtualmente possibile) supererebbe i benefici acquisiti. Ragione per cui questa stessa logica informatica alla base può essere utilizzata – come in fondo fa Ethereum, mai sentito parlare dei gattini digitali collezionabili CryptoKitties? – per registrare e certificare qualsiasi genere di transazione. Per molti, specie dopo lo scandalo Mt. Gox, la piattaforma all’epoca di riferimento (vi si scambiava l’80% delle monete) per un valore dell’epoca di 450 milioni di dollari, è ben più interessante della vicenda sui bitcoin. La cooperativa aerea Sita vorrebbe identificarci i passeggeri e molte istituzioni pubbliche locali la usano per mille ragioni diverse: già dalla fine del 2015 gli investimenti dei venture capitalist sulla blockchain non riguardano più, in maggioranza, gli strumenti di pagamento ma altri ambiti e un consorzio di 30 banche internazionali (fra cui JP Morgan, BNP Paribas e Wells Fargo) ne indaga da tempo gli sviluppi. Affidabilità, solidità, assenza di sale dei bottoni, irrevocabilità: la Finlandia la usa perfino per gestire, grazie alla startup Moni, l’accoglienza (e l’identità) dei rifugiati. In Italia Helperbit la usa per tracciare i finanziamenti a iniziative di ricerca, donazioni e interventi d’emergeza. Crowdfunding in Bitcoin. E così via. Non tutti gli esperti condividono gli entusiasmi per la fiammata dei Bitcoin (che tuttavia, lo ripetiamo, è tale solo per chi non abbia mai seguito il settore, la crescita era evidente da mesi). Bolla o non bolla? Strumento per cracker e criminali intenti al riciclaggio o emblema delle magnifiche sorti e progressive del futuro senza contante? Investimento valido o follia? Se per Bill Gates e Richard Branson è meglio della moneta e per Eric Schmidt di Google è un successo anzitutto per il sistema crittografico che consente appunto l’univocità delle transazioni, per il Nobel per l’economia Robert Schiller il parere è più sfumato, nel senso che anche il Bitcoin starebbe godendo di una narrazione fascinosa, tipica dell’origine delle bolle speculative. E se Bankitalia sconsiglia l’investimento curiosamente per le stesse ragioni che al contrario sembrano decretarne l’apprezzamento (assenza di vigilanza centrale, poche informazioni, accettazione scarsamente diffusa, quotazione volatile per poi ricordare incertezza sulla tassazione e riciclaggio e il fatto che non ci sono Atm, anche se in realtà una manciata se ne trova) anche Jamie Dimon, grande capo di Jp Morgan, non ha esitato a chiamarla una “truffa” (ma il suo istituto li compra). James Gorman, ad di Morgan Stanley, ha invece spiegato che il fenomeno sta raccogliendo più attenzione di quanta ne meriti ma che “non passerà come se nulla fosse”. Una posizione sfumata, quest’ultima, che tuttavia corrisponde probabilmente a quella più azzeccata. Non tanto per le possibilità concrete di utilizzo (per ora ridotte a notizie pittoresche ma interessanti, come la Svizzera, Paese più Bitcoin-friendly del mondo, i Bitcoin di Stato estoni) ma per il potenziale di riserva di valore. C’è perfino un fondo comune, il primo in Europa, che investe in Bitcoin lanciato a una società parigina di asset management, Tobam, che gestisce circa 10 miliardi di euro. Dopo la fase degli smanettoni, la crisi del 2014 e la lenta risalita, il Bitcoin ha appena messo il piedino nel mercato buono della finanza. Senza cambiarsi le scarpe.Elenco degli H2 di https://www.wired.it/economia/finanza/2017/06/28/bitcoin-esperti/Bitcoin sì o Bitcoin no? Gli ultimi 6 mesi della cryptovaluta sono stati contraddistinti da quotazioni record e flessioni che neppure le montagne russe: da 700 a 2600 euro (fino a stabilizzarsi sui 2400 al momento della pubblicazione di quest’articolo). Niente male per una valuta nata al di fuori di banche e mercati, che solo 8 anni fa, quando è nata, era quotata pochi centesimi di euro. Ma se allora comprarla poteva voler dire dare fiducia all’idea di un’altra economia, oggi a qualcuno comprare bitcoin potrebbe sembrare un azzardo alla Gordon Gekko. Non a caso qualche giorno fa l’Economist si è chiesto cosa succederebbe se il Bitcoin finisse in bolla. E anche se le conclusioni dell’articolo non sono poi così catastrofiche, chi credeva nella cryptovaluta come regolatore di scambi al di fuori dei mercati finanziari tradizionali, qualche dubbio sulla sua funzione attuale, viste le quotazioni “monstre”, potrebbe avercelo. Dunque, è ancora conveniente pensare al Bitcoin come moneta di scambio fuori e dentro la Rete? O è venuto il momento di puntare su altre cryptovalute, meno famose ma più stabili e meno costose? Lo abbiamo chiesto a tre imprenditori italiani, che hanno scelto di lavorare con il Bitcoin e di diffonderne l’uso e la conoscenza. Giacomo Zucco, CEO di BHB Network (Blockchainlab)
«Dopo anni di studio approfondito e sperimentazione su diverse soluzioni e alternative, ritengo che non esistano altre “cryptovalute”, come si diceva nei primi anni di diffusione del fenomeno, o altre “blockchain”, come si tende a dire di recente, interessanti e promettenti come Bitcoin.
Questo per due ragioni.  La ragione generale è che, anche in presenza di un’ipotetica alternativa superiore a Bitcoin, di fatto sarebbero improbabili un turnover o una coesistenza. Bitcoin è uno strumento potente perché conta su un enorme effetto network energetico e di sicurezza legato al meccanismo del cosiddetto “mining”; un enorme effetto network monetario legato al valore dell’asset; importanti effetti network legati alla liquiditá; alla profonditá di mercato e all’accettazione da parte del mercato, un importantissimo effetto network di “mindshare”, ovvero di attenzione da parte dei più grandi esperti al mondo di crittografia, sistemi distribuiti, teoria dei giochi e sviluppo open source. E queste sono tutte caratteristiche difficilissime da raggiungere e superare. La ragione specifica é che di alternative superiori al momento non ne esistono: tutte le “altcoin”  sono rigorosamente inferiori sul piano tecnico. Ethereum, per esempio, sta vivendo un momento di gloria dovuto principalmente a un ottimo marketing, ad un proliferare di vendite di securities non regolamentate e ad aspettative insensate. Ma è un clone di Bitcoin inferiore all’originale sotto ogni aspetto: pessima scalabilità, pessima privacy, pessima sicurezza. Ripple é anche peggio. Ci sono altre alternative che, a differenza di Ethereum, sono interessanti sotto alcuni specifici aspetti tecnologici, anche se l’architettura globale non è all’altezza, e in favore di specifici vantaggi sacrificano molto su alri fronti. Per esempio, Monero é un bel progetto, che sperimenta su sistemi di privacy molto piú avanzati di Bitcoin, sacrificando peró quasi del tutto la scalabilitá. Iota, per fare un altro esempio, trova una soluzione potenzialmente interessante alla scalabilitá, ma sacrifica molto di sicurezza. E Litecoin é sostanzialmente una cavia per funzioni che sono state studiate per Bitcoin e che finiranno in Bitcoin. Ma in sostanza, la risposta breve é “No”, non ci sono altre valute interessanti e promettenti come il Bitcoin». Marco Amadori, CEO di inbitcoin
«Se conviene continuare a credere nel Bitcoin e comprarli? Sì: sul lungo periodo l’ecosistema del Bitcoin crescerà. Ma attenzione: questo non ha nulla a che fare col trading sul breve periodo, che richiede conoscenze e esperienze di trading e sul quale non mi pronuncio. Sul lungo periodo però il Bitcoin ha ancora grosse potenzialità. E con inbitcoin abbiamo puntato sulla diffusione della tecnologia del Bitcoin perché crediamo che il sistema sia meno fragile di quanto alcuni credano. In quanto al prezzo, è vero che oggi vale molto di più di quanto valeva un  anno fa o quando fu creato. Ma come diceva Confucio: “il momento migliore per piantare un albero è vent’anni fa. Il secondo momento migliore è adesso”.
Le altre cryptovalute? Non le ritengo interessanti sul lungo periodo. Capisco che possano incuriosire i trader come succede con Ethereum, che sconsiglio decisamente sul lungo periodo e a chi vuole dormire sereno. Se qualcuno pensa che puntare su una nuova cryptovaluta sia come prendere il treno che parte ora, beh… non funziona così. Meglio puntare sul Bitcoin». Federico Pecoraro, CEO di Robocoin Italia e esperto di cryptovalute
«In questo momento l’attenzione è focalizzata sul prezzo del Bitcoin e le tendenze speculative. Ma anche se il prezzo è altalenante, non è il fattore più importante del Bitcoin. La decentralizzazione è ciò che spinge la Bitcoin Community a crescere. Se il suo valore è cresciuto così rapidamente ciò è dovuto alle recenti crisi valutarie in India, Cina e Russia. Inoltre molti paesi come il Giappone stanno utilizzando sempre di più il Bitcoin negli acquisiti quotidiani. Sempre più attività accettano bitcoin come pagamento. Altro fattore da monitorare potrebbe essere l’eventuale annuncio di un ETF Americano se accettato dalla SEC. A mio avviso, il Bitcoin potrebbe raggiungere una quotazione molto alta nel giro di due anni. Ricordiamo che una tale crescita esponenziale è normale per questa cryptovaluta, in quanto si tratta di una moneta deflazionistica. Altre cryptovalute da tenere d’occhio? Ci sarebbe Ehtereum: il suo valore è in un certo modo indicizzato a quello del Bitcoin. Si basa sulla side-chain ethereum, cioè un particolare tipo di Blockchain connessa a quella pubblica del Bitcoin e che permette di realizzare gli smart contract. È la valuta digitale che monitorerei di più nei prossimi mesi. Poi c’è Ripple: alcune banche sembrano crederci ed investono sulla sua piattaforma. Anche se di cryptovaluta in senso stretto ha molto poco, basandosi su altri tipi di protocolli con sistemi di mining totalmente differenti, potrebbe essere un sistema ibrido vincente nel breve-medio termine, e secondo alcuni il suo valore potrebbe crescere con l’ingresso di nuovi istituti nel consorzio. Ma ciò che funziona sul breve termine non è detto che lo faccia a lungo, dunque prima di farci un pensierino, occhio».Elenco degli H2 di https://www.wired.it/internet/web/2017/06/01/internet-italia/Quanto veloce viaggiamo su internet, da fisso e da mobile e a che punto sono le scorte di indirizzi Ipv4? A queste e altre domande vuole rispondere Akamai, piattaforma cloud di content delivery, con un rapporto sullo stato di Internet nel primo trimestre del 2017. Ventisette dei trentuno paesi europei inclusi nello studio hanno registrato velocità medie di connessione uguali o superiori a 10 Mbps (in media col trimestre precedente): l’Italia, in questo panorama, non spicca per eccellenza. Nonostante il continuo aumento della velocità media di connessione infatti, che da 8,7 nel quarto trimestre dello scorso anno a 9,2 Mbps (+ 6,2%), nel primo trimestre 2017 l’Italia scende ancora nella classifica mondiale. Guadagna (si fa per dire) la 61esima a livello globale e la 28esima in area EMEA. Rispetto allo stesso periodo dell’anno precedente (Q1 2016) l’aumento è del 13%. Secondo i dati raccolti dall’azienda, cinque paesi europei si sono classificati tra i primi 10 paesi/aree geografiche per l’adozione della banda larga a 25 Mbps. Si tratta di Norvegia (2°), Svezia (3°), Svizzera (5°), Danimarca (6°) e Finlandia (9°). L’Italia, anche in questo caso, sta così e così: il 79% delle connessioni sono sopra i 4 Mbps (in discesa dalla 28esima alla 29esima posizione in EMEA e dalla 63esima alla 65esima a livello mondiale).
Considerando prestazioni più alte, nel trimestre in esame l’Italia registra solo il 26% di connessioni sopra i 10Mbps e il 12% di quelle superiori ai 15 Mbps. Parlando di connessioni mobili, mentre nel Regno Unito la velocità di connessione media più elevata pari a 26 Mbps (24,1 Mbps in Germania), in Italia la velocità media è di 12,4 Mbps. In termini di penetrazione circa 814 milioni di indirizzi IPv4 si sono connessi alla Akamai Intelligent Platform da 239 località. L’Italia mantiene la decima posizione con 17.108.083 indirizzi connessi, sempre in riferimento ai primi tre mesi di quest’anno.Elenco degli H2 di https://www.wired.it/internet/web/2017/01/25/italiani-report-internet-social-media/Il numero di persone connesse a Internet è cresciuto del 10 per cento rispetto allo scorso anno e adesso metà della popolazione mondiale è connessa a internet. Accenni da Digital in 2017 Global Overview, il report annuale con il quale l’agenzia We Are Social fotografa la rete nel mondo attraverso i dati di 238 paesi. Anche i social media hanno registrato una crescita dell’8 per cento dei loro utenti e dei 2,789 miliardi, 2,549 miliardi arriva da mobile. Non c’è bisogno di dire infatti che laptop e computer fissi hanno registrato un calo d’uso del 20 per cento, reggendo il 45 per cento dell’intero traffico in giro per il mondo. È il mobile che regna indiscusso su scala mondiale, prendendosi metà dell’intero traffico web globale, con la metà delle connessioni mobili veloci e una persona su cinque dell’intera popolazione mondiale che ha fatto un acquisto online negli ultimi 30 giorni. In Europa, se l’uso dei social media in generale è cresciuto del 5 per cento, con 400 milioni di utenti totali in tutto il continente, quello da mobile è aumentato dell’11 per cento, con 340 milioni di persone che li usano da dispositivi mobili ogni mese. A conferma dei dati forniti recentemente dall’International Telecommunications Union (ITU), l’accesso a internet è ancora molto irregolare nella distribuzione globale (vedi penetrazione in Europa occidentale dell’84% e del 29% in Africa). L’Italia, che fa? In termini di penetrazione della rete si attesta al 66% (la media è del 50%), dopo il Brasile e prima della Turchia. Secondo l’ultimo State of the Internet Report di Akami, in quanto a velocità di connessione invece, l’Italia guadagna un punteggio di 8.2 su una media di 6.3. Spicca nella classifica di velocità media di connessione da rete mobile, posizionandosi a metà classifica subito dopo la Corea del Sud (tra i paesi europei, il più forte è la Spagna, terzo posto). In quanto a tempo speso su internet, tuttavia, vince ancora la connessione fissa nella penisola, dove vengono spese 4 ore al giorno in rete davanti al desktop e due ore e otto minuti da mobile. In questo, gli italiani son campioni europei. Il tempo trascorso dagli italiani sui social media è di due ore al giorno e il paese si conferma tra quelli con la più alta penetrazione di telefoni rispetto alla popolazione mondiale, con un tasso dell’85%. Il tasso di connettività mobile – cioè le connessioni mobili del paese rispetto alla sua popolazione  – è del 128% e il 77% delle nostre connessioni mobili sono 3G e 4G. Per gli acquisti online c’è ancora parecchio da fare: la crescita su anno di chi fa shopping online tramite telefono è del 6% (siamo in fondo alla classifica).Elenco degli H2 di https://www.wired.it/internet/web/2017/12/12/rete-numeri-internet-mondo-italia/Il report The State of Broadband 2017: Broadband Catalyzing Sustainable Development mostra le due facce del web mondiale, perché se è vero che il 48% della popolazione è connessa (3,58 miliardi di persone, con una crescita rispetto al 45,9% del 2016) è anche vero che gran parte del Continente asiatico (in tutto 2,5 miliardi di persone circa) non si affaccia su internet. Più in generale, al 79,6% di penetrazione di internet in Europa, si contrappone il 21,8% dell’Africa.  Mercati e conquiste
Alla Cina lo scettro del più grande mercato internet al mondo, con 700 milioni di persone connesse. A seguire l’India, paese double-face, perché è sì il secondo mercato per numero di utenti (355 milioni) ma, nel contempo, è  anche quello con il maggior numero di persone non connesse, 660 milioni di individui in tutto. Numeri sufficienti a fare comprendere perché i big dei social media e della tecnologia profondono sforzi e fatica per entrare nelle grazie di Pechino e di Nuova Delhi.  La crescita (troppo ottimistica?)
Numeri in crescita e forse troppo ottimistici. Nel 2016 le persone connesse da fisso o da mobile erano 3,2 miliardi e entro il 2022 si stima che saranno 5,8 miliardi.  Pur considerando che ci sia una forte sovrapposizione tra i 2,1 miliardi di persone che non hanno accesso all’acqua e l’1,3 miliardi di individui che non possono contare sulla corrente elettrica, resta da considerare che prima di provvedere a una maggiore penetrazione di internet a livello planetario, ci sono problemi funzionali (e più urgenti) da risolvere. I social network da un miliardo di utenti
Ai social network da almeno un miliardo di utenti attivi si aggiunge ora anche YouTube il quale, negli anni, si è affermato anche come motore di ricerca, alle spalle di Google.  Gli italiani e le connessioni mobili
Mentre le compagnie e il governo si danno un gran daffare per portare internet veloce nelle case e nelle aziende, gli italiani sembrano preferire le connessioni mobili. Il 26% degli internauti usa infatti solo dispositivi mobili per navigare, percentuali molto più alte di quella americana (12%), inglese (8%) e tedesca (4%). Non si può escludere che i prezzi alti e la banda scarsa fungano da spinta a questa abitudine, assunta ormai da un italiano su 4. Elenco degli H2 di https://www.wired.it/internet/web/2017/06/26/mozilla-2-milioni-di-dollari-per-decentralizzare-internet/Internet ha diversi problemi ultimamente. Uno di questi, che ne sta mettendo in discussione i principi fondativi, è emblematico di questa fase evolutiva della rete: la de-centralizzazione che, a suoi albori, era caratteristica identitaria di Internet, è un elemento sempre meno evidente e in parte già superato. Internet del 2017 avanzato assomiglia poco a Internet per come la avevamo immaginata e la sua struttura, che è ancora un network di network, si affida sempre di più a nodi sempre più centralizzati e se se ne perde uno molto importante — come accaduto in occasione del devastante attacco della botnet infettata con il malware Mirai che aveva messo in ginocchio i server di Dyn  —  il rischio è che tutta la rete possa avere problemi seri. O andare offline. Una conseguenza di questa impostazione è anche che Internet non è uguale ovunque e in molte aree del pianeta  —  in quelle più povere come in quelle più svantaggiate nei paesi ricchi  —  permangono problemi di connettività e accesso alla rete. Mozilla, insieme alla National Science Foundation statunitense ha deciso di cercare di ovviare a questo problema, offrendo un premio di 2 milioni di dollari a chi volesse provare a immaginare soluzioni tecnologiche wireless per avere una rete più decentralizzata, più sicura e più facilmente accessibile a tutti. Solo negli Usa, si legge sul sito dell’iniziativa, “34 milioni di persone, il 10% del paese, non ha accesso a una connessioni Internet di alta qualità”. L’iniziativa di Mozilla si dà l’obiettivo di risolvere il problema o di immaginare potenziali soluzioni negli Stati Uniti, ma è significativa per il modo in cui affronta la questione, chiedendo di ipotizzare delle soluzioni “off-the-grid” per connettersi a Internet in caso di calamità naturali o “Smart Community Networks” per comunità non coperte dai provider commerciali o le infrastrutture sono scadenti. Alla call possono partecipare organizzazioni e persone di diverso tipo, dagli accademici alle aziende, Ong e attivisti ovviamente inclusi. Per quanto si tratti di un progetto statunitense, il problema riguarda Internet nel complesso e potrebbe essere replicato anche in altri contesti dove l’assenza di Internet ha conseguenze umanitarie importanti e provare a portare soluzioni che non passino inevitabilmente dai giganti della Silicon Valley.Elenco degli H2 di https://www.wired.it/internet/web/2017/06/12/co-fondatore-pirate-bay-internet-tutto-storto/Credere in qualcosa fino in fondo, e poi trovarsi con un pugno di mosche in mano: sembra che alcuni dei protagonisti della rete, di quelli che ci credevano quando erano in pochi a farlo, stiano gettando la spugna. Dopo Evan Williams — ex presidente e Ceo di Twitter, che aveva affidato al New York Times un poco speranzoso “internet non funziona più” — arriva Peter Sunde, co-fondatore di The Pirate Bay, ad alzare le mani. “Il punto non è quello che accadrà in futuro, ma quello che sta succedendo adesso”, ha detto in un’intervista a The Next Web, durante la quale ha attaccato duramente il Ceo di Facebook: “Abbiamo centralizzato tutti i nostri dati a un ragazzo chiamato Mark Zuckerberg, che è fondamentalmente il più grande dittatore del mondo, visto che non è stato eletto da nessuno”. Non solo: anche lui è nelle mani della politica. “Trump ha di fatto il controllo sui dati in possesso di Zuckerberg, quindi ci siamo già. Tutto ciò che potrebbe andare storto è già andato storto e non credo che ci sia un modo per arginarlo”. Il problema è stato “tradire” la missione iniziale della rete: “Internet è stato creato per decentralizzare, e invece continuiamo a centralizzare ai livelli più alti di internet”. La riprova, secondo lui, starebbe nel fatto che negli ultimi 10 anni quasi tutte le tecnologie emergenti sono state acquistate dai grandi cinque: Amazon, Google, Apple, Microsoft e Facebook. Il mercato, poi, si è spostato da un modello basato sul prodotto, a un modello basato sul prodotto virtuale (porta ad esempio Airbnb, Uber, Alibaba). Tutto questo, per Sunde, si chiama centralizzazione, rischio che correrebbero anche le tecnologie più promettenti in arrivo, come le macchine che si guidano da sole: “Chi le possiede e chi possiede le informazioni su dove possiamo o non possiamo andare?” Dovrebbe esserci una discussione più accesa e più etica in merito a tecnologia e proprietà, dice il pioniere del Torrent. “L’unico modo in cui possiamo fare qualsiasi differenza è limitare i poteri di queste società, ma purtroppo l’UE o gli Stati Uniti non sembrano avere alcun interesse a farlo”. Tuttavia, una via d’uscita ci sarebbe, e potrebbe essere quella di un’azione dei singoli governi, che pian piano potrebbero, sempre secondo le sua tesi, indirizzare gli enti sovra nazionali in una diversa direzione. In tutta questa nuova economia della rete, i big data giocano un ruolo importantissimo e delicato: secondo Sunde, le aziende li sfruttano, dando indietro qualcosa, come i servizi e una buona comunicazione.

  “I big data e le grandi multinazionali del Tabacco sono simili, in un certo senso. Prima non ci siamo resi conto di quanto fosse pericoloso il tabacco, ma ora sappiamo che provoca il cancro. Non sapevamo che i big data avrebbero potuto diventare così importanti, ma ora lo sappiamo. Allo stesso modo, abbiamo basato le nostre vite sui big data, e ora non possiamo smettere”.Elenco degli H2 di https://www.wired.it/internet/web/2017/10/16/futuro-cloud-e-internet-of-things/Las Vegas  — C’è un mondo in pieno fermento, che lavora per preparare il futuro del cloud e dell’Internet of Things (IoT), tecnologie che già usiamo e useremo in modo sempre più diffuso e, nonostante facciano parte del nostro quotidiano, necessitano di essere rese sempre più sicure e affidabili, capaci di rispondere al crescente numero di minacce più articolate e imprevedibili. Prevedere l’imprevedibile è l’impegno degli ingegneri software e hardware, effervescenti nel mostrare pubblicamente il loro lavoro durante l’Akamai Edge 2017 in quella Las Vegas adrenalinica. Una delle tante città che non solo non dormono mai ma danno il meglio di loro durante le lunghe notti che le luci degli alberghi, dei casinò e delle strade illuminano a giorno; nonostante i recenti fatti di cronaca. Las Vegas non è solo il brusio di sottofondo di chi aspetta che la pallina smetta di girare sul disco della roulette. Akamai Technologies Inc. ha sede a Cambridge, nel Massachusetts, e conta oltre 240mila server distribuiti in 130 paesi. Un colosso da 2,3 miliardi di dollari di fatturato all’anno e in costante crescita, dà lavoro a più di 7mila persone e annovera, tra i propri clienti, aziende come Apple e, in generale, che spaziano dall’Automotive al gaming e dal manifatturiero alla ristorazione. La filosofia che fa da collante in questo particolare momento è “alta velocità e protezione dei dati”. Un binomio che, se fosse una promessa, sarebbe difficile da mantenere. Diventa più facile intrecciando tra di loro diverse tecnologie, a partire dalla suite Bot Manager Premier, scudo di difesa dalle botnet che chiamano a raccolta i dispositivi IoT per sferrare attacchi mirati, come nel caso di Mirai, il malware che esattamente un anno fa ha messo a sedere internet. Bot Manager Premier smaschera i bot che tentano di simulare un’attitudine umana, e riesce a farlo anche se questi cambiano i propri modelli comportamentali. Non è un problema da poco, è di fatto un’evoluzione di un problema, quello degli attacchi mirati tramite hardware utilizzato senza la consapevolezza di chi lo possiede, che si è già manifestato in passato diverse volte. I palati più fini ricorderanno l’attacco del collettivo di hacker Lizard Squad con cui, a fine 2014, sono stati messi in ginocchio i server di Sony e Microsoft, rovinando le festività di chi aspettava il Natale per concedersi alla propria console. Attacchi che possono essere sferrati con spirito di iniziativa, coordinazione, le necessarie doti tecniche e una ventina di euro. Non è un caso che le offensive DdoS (inviare tante richieste a un server affinché questo non sia in grado di soddisfarle tutte e renderlo così inutilizzabile) siano cresciute del 129% in un solo anno. Per rendere arduo il compito agli hacker non basta la tecnologia, ci vuole anche una strategia. Per questo motivo nasce Akamai Intelligent Platform, che garantisce l’affidabilità e la scalabilità (la capacità di adattarsi, per crescita o decrescita, alla mole di dati da analizzare, elaborare e archiviare) e che può essere facilmente distribuita dalle aziende ai propri dispositivi IoT, ovunque essi si trovino. La distribuzione è importante, aiuta infatti a definire degli standard, compito che poche aziende al mondo sono in grado di fare da sole, a prescindere dalla propria grandezza e forza commerciale. Per questo motivo IBM renderà disponibili, nelle proprie piattaforme cloud, i servizi erogati da Akamai. Un assist per rendere meglio l’idea lo fornisce Mark Weeks a Wired.it, direttore dell’area EMEA: “Akamai gestisce da sola più di due trilioni di richieste per contenuti web ogni giorno. Di fronte alla progressiva complessità dei dati e alla diffusione inarrestabile dell’Internet of Things, la situazione non si risolverà spontaneamente” . La sicurezza, questa sconosciuta?
Qualcosa non quadra e, per trovare una spiegazione, va condotta alla sbarra la capacità commerciale di chi produce dispositivi IoT che, per non sacrificarne il design e proporsi sul mercato a prezzi concorrenziali, tende a non mettere l’aspetto della sicurezza al centro. Tra i complici anche una corposa fetta degli utenti, presi dal gingillo hi-tech che hanno tra le mani più di quanto si mostrino sensibili alla privacy e alla garanzia che i propri dati vengano trattati in modo sicuro. Il cloud è molto di più dei servizi messi a disposizione da Google o da Microsoft, tant’è che la nuvola e i servizi erogati tramite questa sono fonte di lauti guadagni per tutti gli attori e — per fare un esempio — al contrario di quanto si possa credere, rappresentano la fetta più grande del fatturato di Amazon. Un comportamento di massa che sta cambiando, come conferma il regional manager di Akamai Italia Alessandro Livrea: “le persone danno importanza alla sicurezza e alla privacy, solo che in passato non erano contemplate. L’IoT sta portando alla luce questi temi e le cose stanno cambiando. Del resto ai tempi dell’informatica, al di là dell’antivirus, pochi erano sensibili alla sicurezza. Gli attacchi informatici sembravano esotici, sembrava potessero capitare solo in America. Con riferimento al mondo aziendale, e con certezza, si sta correndo ai ripari e dove non arrivano i singoli arriva il legislatore” . Negli Usa infatti alcuni senatori hanno depositato lo scorso agosto una proposta di legge, il cui testo impone agli enti governativi di acquistare solo quei dispositivi IoT che rispondono a degli standard di sicurezza di alto livello. Ma, come osserva Livrea “quando deve intervenire il legislatore, c’è qualcosa che non va” . Infatti è innegabile che il comparto dell’IoT, da chi produce a chi compra, abbia almeno all’inizio fallito l’appuntamento con la sicurezza e che poi sia stato costretto a rincorrere la situazione per colmare il gap. Privacy e sicurezza sono state percepite come qualcosa di irrilevante. Gli episodi che si sono consumati nel tempo hanno imposto ai consumatori maggiore attenzione e, in alcuni casi, i risarcimenti milionari hanno fatto cambiare le priorità dei produttori. Che le cose stiano cambiando lo conferma anche Mark Weeks il quale, numeri alla mano, afferma che in tutta l’area EMEA “sicurezza e privacy sono temi molto sentiti, i nostri clienti che producono dispositivi IoT ci chiedono tecnologie sempre migliori” . Secondo i dati raccolti dall’Osservatorio del Politecnico di Milano, a fine 2014 in Italia il 55% degli 8 milioni di SIM dedite all’IoT era destinato alle smart car, un comparto molto caro gli italiani. Mark Weeks assicura, senza sbilanciarsi sui progetti futuri che “Akamai ha intenzione di sviluppare con continuità anche le tecnologie per la protezione dei dati delle vetture intelligenti e della domotica, tenendo conto delle norme e delle leggi che i governi stanno preparando” .Elenco degli H2 di https://www.wired.it/attualita/politica/2017/11/09/dati-traffico-telefonico-internet/La camera ha appena approvato in via definitiva la norma secondo cui i dati relativi al traffico telefonico e a quello internet dovranno essere conservate per 72 mesi, ovvero 6 anni. Un testo approvato  dai deputati con 247 voti a favore, 72 contrari e 44 astensioni, allineandosi alla direttiva Ue 2017/541 la quale, all’articolo 24 dispone la conservazione dei dati “al fine di garantire contrasto al fenomeno del terrorismo, anche internazionale“, senza però creare uno standard relativo al periodo di conservazione. La corte di Giustizia europea, nel 2014, aveva bloccato ogni tentativo di allargare il periodo di conservazione dei dati, inserendo nel contesto il diritto alla privacy. Il termine di 6 anni è stato emendato da Walter Verini (Pd) sostenendo che “dalle audizioni parlamentari la Procura nazionale antiterrorismo ha suggerito alla politica uno strumento ulteriore per prevenire e contrastare il terrorismo, questo è proprio una conservazione più a lungo termine dei dati del traffico telefonico e telematico“. Fino a oggi, in linea con quanto descritto dal codice della privacy, in Italia i dati del traffico telefonico venivano conservati per 2 anni, per un solo anno quello telematico e per 30 giorni le informazioni relative alle chiamate senza risposta. Il decreto antiterrorismo del 2015 ha permesso di rendere più elastici questi termini fino al 30 giugno 2017. Il governo non è ritornato sull’argomento e quindi se ne è occupato il parlamento. Le voci critiche
Il Garante per la privacy Antonello Soro e il Centro per la trasparenza e i diritti umani digital Hermes hanno espresso dubbi e malcontenti perché giudicata indiscriminata.    Elenco degli H2 di https://www.wired.it/attualita/tech/2017/12/05/intelligenza-artificiale-riccardo-zecchina-wired-digital-day/Intelligenza artificiale e robotica stanno cambiando il mondo e il modo di percepirlo. Una rivoluzione tecnologica, in particolare quello dell’AI, che negli ultimi 10 anni ha avuto un’accellerazione esponenziale e che sta trasformando tutti i settori economici. Siamo davanti a un cambiamento epocale e la grande domanda posta dalla società in generale è quali conseguenze ci si possa aspettare da questa rivoluzione, in particolare sul mondo del lavoro. Secondo uno studio del 2016 della Stanford University (One hundred year study on Artificial Intelligence/AI 100) un lavoro su due dovrà evolvere. In che modo queste tecnologie cambiano, ristrutturano e possono migliorare le imprese e le attività economiche in generale? Le trasformazioni sono uguali per ogni azienda o ogni settore affronta questa rivoluzione a suo modo? Nel video l’intervento di Riccardo Zecchina al Wired Digital Day. Fisico ed esperto di Machine Learning e Deep Learning, il professor Zecchina fa parte del Dipartimento di Scienze delle Decisioni dell’Università Bocconi di Milano.Elenco degli H2 di https://www.wired.it/internet/web/2017/10/12/google-mostra-machine-learning/Sull’Intelligenza Artificiale si sentono (e leggono) parole su parole, spesso senza avere idea di cosa vogliano dire al fondo. Per dirne una, cos’è il machine learning, ma soprattutto, come funziona l’apprendimento delle macchine? Google ha provato a spiegarlo con un esperimento pratico. Sul sito Teachable Machine è possibile provare direttamente come si allena un sistema in base a dati di partenza e come il sistema di riconoscimento li possa poi far corrispondere a risultati specifici. Il meccanismo consente, attraverso la videocamera del proprio computer, di fornire immagini di partenza alla macchina: più sono, meglio è. Ci sono tre pulsanti (verde, viola e arancione): premendoli, si permette al sistema di acquisire serie di immagini diverse. A ogni set, viene collegato un risultato diverso (sia una Gif, un suono o uno parlato). Dopo aver allenato ogni bottone (si tiene premuto qualche secondo per fargli acquisire più “esempi” possibili), si può osservare il risultato. Muovendosi davanti alla videocamera, si vedrà il sistema fornire gli output di riferimento, in base a quello che ha riconosciuto. Per esempio: se si è allenato il sistema a far corrispondere la gif di un gattino al movimento di una tazzina di caffè davanti allo schermo, questa si attiverà ogni volta che il sistema riconoscerà quel gesto. Dinnanzi a gesti ambigui (alzo la mano, poi la abbasso di colpo e sto ferma), il sistema sarà confuso, e fornirà risultati alternati (una barra di percentuale, in alto a ogni set, indica quanto la macchina stia assimilando il riconoscimento al gesto). “Questo esperimento consente a chiunque di esplorare l’apprendimento delle macchine, in modo divertente e pratico. È possibile insegnare a una macchina l’utilizzo della fotocamera, che vive nel browser -senza coding alcuno. Si forma una rete neurale localmente sul dispositivo senza inviare immagini a un server”, si legge sul sito, che offre diversi spunti per allenare le macchine (e ne promette di nuovi a venire). Nota: Se, come nell’esperimento di Wired, il sito sembra bloccare la videocamera con Chrome, provare con Safari o altro browser.Elenco degli H2 di https://www.wired.it/gadget/computer/2017/10/13/la-carica-delle-macchine-autonome/Monaco di Baviera — C’è IFM (Intelligent Flying Machine), il drone che vola nei magazzini per agevolare la gestione della logistica contando pacchi e scatole, verificandone la posizione e segnalando eventuali errori. E poi c’è il piccolo rover a sei ruote di Starship, che viaggia a sei chilometri orari e consegna autonomamente e in pochi minuti la spesa o la cena ordinata al fast food. I due sono in buona compagnia, perché con loro c’è anche R1, il robottino dell’Istituto Italiano di Tecnologia che impara a individuare e riconoscere gli oggetti. Ad accomunare tutti questi sistemi, così diversi nelle forme e negli scopi, c’è l’intelligenza artificiale che li anima e il deep learning che consente loro di apprendere, rendendoli progressivamente più abili nello svolgere i loro compiti. Siamo a Monaco di Baviera mentre si svolge il GTC Europe 2017, la GPU Technology Conference organizzata da NVIDIA per aggiornare l’esercito dei suoi developer e raccontare alla stampa lo stato dell’arte della proprie tecnologie. Lo conferma il System Architect per Tegra GRID di NVIDIA Vincent Nguyen, mentre mi accompagna nell’area espositiva dedicata alle autonomous machines. Nello spazio riservato c’è un po’ di tutto, dai semplici prototipi ai prodotti già testati e immessi sul mercato, come i già citati IFM e Starship rover. Quest’ultimo si aggira tranquillo sul pavimento della fiera di Monaco mentre Kristian Korjus, estone, capo della divisione Computer Vision and Perception di Starship, osserva divertito le reazioni del pubblico. “Il nostro è un robot che si guida da solo e che deve svolgere un compito apparentemente semplice: portare un carico dal punto A al punto B”, mi spiega senza mai perderlo un attimo d’occhio. “Funziona grazie alla piattaforma hardware NVIDIA Tegra TK1, una delle più economiche disponibili, che quindi ci permette di scalare e produrre in serie contenendo i costi”. Di rover della Starship in giro per il mondo ce ne sono già oltre cento, sparsi tra Stati Uniti (in Silicon Valley e a Washington), Inghilterra (a Londra), Germania (ad Amburgo) e poi ovviamente in Estonia, dove l’azienda è stata fondata. “L’interesse dei potenziali clienti è molto alto”, rivela Kristian Korjus. “Ci stiamo espandendo in fretta, e per crescere abbiamo bisogno di nuove persone e competenze, ma anche di tecnologia sempre più aggiornata, stabile e affidabile”. Poco lontano da Kristian c’è anche l’italiano Raffaello Bonghi: trent’anni, ha appena finito il Dottorato di ricerca in robotica e lavora per la giapponese NTT Data su un progetto relativo alla guida autonoma. “Sono qui a titolo personale”, spiega: “Volevo presentare la mia attività di robotica fatta al di fuori della ricerca che mi ha portato in NTT”. A Monaco è venuto per mostrare il progetto Panther, una piattaforma hardware e software che oggi si concretizza come un piccolo rover fatto in casa e strapieno di sensori, il cui compito è mappare tridimensionalmente l’ambiente che attraversa. Raffaello ha creato il rover comprando — spesso di tasca sua — e assemblando da solo l’hardware necessario. L’idea era studiare il funzionamento del deep learning, la navigazione, la localizzazione, la pianificazione e capire meglio come scegliere i sensori migliori o la piattaforma hardware più adatta. Che, nel caso specifico, è risultata essere la Nvidia Jetson TX2. Nel dettaglio, il piccolo rover robot usa una stereo camera per ricostruire una mappa di profondità che fonde altri dati provenienti da un radar lidar, da una piattaforma inerziale, da un accelerometro e da svariati altri sensori, compreso il rilevatore della velocità. Il risultato è una mappa estremamente accurata della realtà circostante utilizzabile per più scopi, come ad esempio l’esplorazione di ambienti a rischio o ostili per l’uomo. Il software è basato sul sistema operativo Open source ROS (Robot Operating System), adattato allo scopo in collaborazione con altri due ricercatori sparsi per il mondo. Da notare infine che persino lo chassis e il telaio in plastica sono stati progettati e assemblati da Raffaello, che li ha fatti prima tagliare con una laser cutter e poi li ha anche sagomati a mano. Fascino dei robot e ammirazione per chi li fa funzionare a parte, viene da chiedersi quando intelligenza artificiale ci sia veramente in quelli esposti al GTC Europe: “Al momento, il limite di questi sistemi è che hanno pochissima o addirittura nessuna intelligenza on board”, chiarisce a riguardo ancora Vincent Nguyen. “Significa che se si disconnettono dal cloud sono come morti, mentre la sfida è spostare le capacità cognitive dal cloud ai singoli gadget e renderli completamente indipendenti”.Elenco degli H2 di https://www.wired.it/internet/web/2017/10/09/google-intelligenza-artificiale-con-numero-minore-di-dati/Big data, grandi strumenti computazionali in grado di interpretarli, relativa paura che lo studio di quei numeri, per quando aggregati e anonimi, vada un po’ troppo oltre in tema di sicurezza e privacy. Questo il filo logico che spesso lega il complesso mondo dei meccanismi di apprendimento profondo. E se per i dati, in futuro, le dimensioni contassero sempre meno? Dopotutto, per un buon machine learning, serve anche molto altro. Questo è quello che emerge da uno scambio sui massimi sistemi dell’Intelligenza Artificiale con Prabhakar Raghavan Vice President of Engineering per Google. Per molti “l’uomo dell’algoritmo”, ha partecipato all’ultima edizione di Internet Festival di Pisa e ci ha risposto così: “La maggior parte del successo nell’apprendimento automatico deriva da nuovi e migliori algoritmi (costruzione di nuovi tipi di reti neurali), dall’esperienza e dall’intuizione dei ricercatori e dall’ingegneria necessaria a tradurlo in prodotti reali”, dice in riferimento al limite “etico” della raccolta di informazioni: “I dati sono un fattore, ma molti dei più grandi successi nell’apprendimento provenivano da quelli apertamente disponibili sul web, come i testi sui quali molti sistemi di traduzione (tra cui Google Translate) sono stati addestrati”. Google stessa, spiega, ha liberato dozzine di set di dati per i ricercatori, come quelli dei testi collegati alle immagini e ai video, perché tutti potessero beneficiare non solo dei dati grezzi reperibili online, ma anche di quelli già curati. “Sappiamo che la mente umana è in grado di farlo, quindi siamo ottimisti che gli algoritmi di apprendimento delle macchine possano lavorare anche su archivi più piccoli”, svela Raghavan. “Per fare un esempio, sono stati necessarie solo 270 esami istologici, come dati informativi per il nostro lavoro, per rilevare la metastasi del cancro al seno”. Tornando al presente, mentre la ricerca danza tra progetti diversi, uno più fantasioso dell’altro, le applicazioni pratiche dell’intelligenza artificiale sono pane quotidiano per tutti. Prendiamo Google: “Il deep learning è stato utilizzato per migliorare il riconoscimento vocale di Google Assistant (del 25% circa), mentre l’elaborazione della lingua naturale sfruttata per capire cosa venga detto. Negli Stati Uniti, il 20% delle ricerche che arrivano su app Android sono vocali, e l’azienda comprende 119 lingue. Si parla di machine learning anche quando si usa il sistema di Google Foto in grado di riconoscere se nell’immagine ci sia un cane o due persone che si abbracciano. Il sistema che suggerisce risposte veloci (Smart reply) di Gmail, utilizzato per il 12% di tutte le risposte che partono dall’app mobile, riconosce il contesto del messaggio grazie alle reti neurali. Grazie a queste, Google blocca il 99.9% dello spam”. Una delle più recenti applicazioni riguarda l’editoria: The Big G ha infatti annunciato di voler sfruttare il machine learning per capire come aiutare i produttori di contenuti. Secondo Raghavan, non rischia di sbilanciare il sistema informativo. “Il machine learning rappresenta un valore enorme per i media e può aiutarli ad affrontare i problemi più difficili: partecipazione dei lettori, aumento dei profitti ed efficienza delle redazioni. Recentemente abbiamo annunciato l’aggiornamento dell’API di Cloud Natural Language, che contiene un nuovo classificatore di contenuti e di sentiment, che scava nel dettaglio della storia, capendo di cosa parla in realtà. Ad esempio, un articolo su uno stadio hi-tech per i Golden State Warriors può tranquillamente essere classificato nella sezione “Tecnologia” di un giornale, quando  invece il suo contenuto dovrebbe rientrare tanto in “Tecnologia” quanto in “Sport”. Questo sistema di tag indipendente può far guadagnare numero di letture provvedendo raccomandazioni più intelligenti e dati migliori riguardanti i trending topics”.Elenco degli H2 di https://www.wired.it/ai-intelligenza-artificiale/storie/2017/09/06/__trashed-205/Google è in fermento sul fronte del fotoritocco. Lo dimostrano alcuni dei progetti diffusi negli ultimi tempi e che attingono a piene mani dalle potenzialità del machine learning e, in generale, dell’intelligenza artificiale. Un ambito contraddistinto da un elemento chiave: l’assenza dell’oggettività di giudizio. Considerata paradossalmente come chiave di salvezza per certi mestieri, maggiormente caratterizzati da un tasso di specializzazione ma anche di una componente artistica che potrebbe salvarli dall’automazione. “Il machine learning eccelle in molte aree con obiettivi precisi, compiti nei quali esiste una risposta giusta o sbagliata e che sostengono l’addestramento dell’algoritmo conducendolo al risultato desiderato, che debba identificare oggetti nelle immagini o effettuare una traduzione decente da una lingua all’altra – spiega Hiu Fang, ingegnere del software, in un intervento di recente pubblicato sul blog dedicato alla ricerca di Mountain View – tuttavia esistono settori in cui queste valutazioni oggettive non sono disponibili. Per esempio, dire se una fotografia sia bella o meno dipende dal suo valore estetico, che è un concetto estremamente soggettivo”. Come si pone, dunque, il machine learning alle prese con le creazioni artistiche e creative? I ricercatori di Big G Fang e Meng Zhang del gruppo Machine Perception di Google Research hanno messo a punto un sistema sperimentale di deep-learning, Creatism, dedicato alle immagini. E hanno raccontato il tutto in un paper pubblicato su ArXiv. Come funziona? In sostanza mima lo stile di lavoro di un fotografo professionista, dall’inquadratura alla composizione, alle prese con un’operazione particolare: elaborare – tagliando e postproducendo – panorami pescati da Google Street View in creazioni esteticamente piacevoli. L’hanno chiamato “fotografo virtuale”: ha analizzato oltre 40mila panorami tratti dai punti più diversi del globo (le Alpi, i parchi nazionali canadesi Banff e Jasper, Big Sur e Yellowstone in California) e li ha perfezionati ed elaborati in modo molto profondo. Tanto da, dice l’esperimento, avvicinarsi a una qualità professionale. “Almeno stando ai giudizi di fotografi professionisti”. Eh già, perché ne sono stati scomodati sei. Ma andiamo con ordine. Sembrerebbe che questo progetto s’intersechi a un altro sistema messo a punto sempre da Google, stavolta in collaborazione col Mit di Boston. Quello, di cui abbiamo parlato, che ruota intorno a una serie di meccanismi in grado di ritoccare le immagini con le stesse abilità di un fotografo esperto in tempo reale e senza grande impegno per l’utente. Il principio è stato il medesimo ma in quel caso i ricercatori hanno utilizzato 5mila immagini create da Adobe e dall’istituto di Boston. Ciascuna foto è stata ritoccata da cinque diversi esperti dai quali gli algoritmi hanno “rubato il mestiere”. Rendendosi efficaci a elaborare dati di imaging quasi prima dello scatto. L’altro esperimento, quello di cui si parlava in precedenza, è stato se possibile ancora più sofisticato. Il sistema ha fatto praticamente tutto da solo dividendo il panorama nei suoi vari livelli di composizione (saturazione, High dynamic range, luminosità) e imparando non solo da 15mila immagini di fotografia di paesaggio particolarmente riusciti (a giudizio degli utenti) tratte dal sito 500px.com ma anche da esempi negativi datigli in pasto, cioè da pessimi esempio di saturazione, Hdr e composizione prodotti in modo casuale da una combinazione d’immagini. Insomma, l’addestramento dell’algoritmo è avvenuto tramite una cosiddetta generative adversarial network, una classe di algoritmi d’intelligenza artificiale introdotta nel 2014 e composti da due sistemi di reti neurali che si “affrontano” in un contesto a somma zero. Dettagli tecnici a parte, quel che conta sono i risultati. E questi raccontano di immagini in effetti impressionanti che hanno in qualche modo tratto in inganno anche fotografi professionisti. “Per giudicare l’efficacia dell’algoritmo abbiamo creato una specie di test di Turing – spiegano i ricercatori di Google – abbiamo mescolato le nostre creazioni con altre foto di diversa qualità e le abbiamo mostrate a una serie di professionisti”. Cosa dovevano fare? Esatto: valutarle. Cioè assegnare un punteggio senza sapere di questa mescolanza fra foto “artificiali” e reali e disponendo di quattro livelli possibili: fotografia “punta e scatta” priva di ogni considerazione di sorta, “buona foto” che potrebbe realizzare chiunque senza un background in fotografia e da cui non emerge nulla di artistico, “semi-pro” cioè bellissime foto con alcuni aspetti artistici evidenti e “professionale”. Ebbene, delle 173 fotografie “artificiali” sottoposte a giudizio (puoi vederle qui) al 41% è stato assegnato il giudizio semi-professionale e un altro 13% di buon livello, ricalcando a grandi linee le valutazioni effettuate dai ricercatori. Come se fossero riuscite a ingannare anche occhi molto esperti che d’altronde a scatti veri, cioè non generati e ricomposti e realizzati da un fotografo in carne e ossa, hanno assegnato simili giudizi solo nel 45% dei casi. Un progetto che ovviamente ha molta altra strada davanti. “I panorami pescati da Street View sono serviti da piattaforma per i nostri piani” spiega Hiu Fang, che spera un giorno, come nell’altro esperimento, di poter condurre gli utenti a scattare foto migliori nella loro vita quotidiana. Superando i sistemi attualmente disponibili sui nostri smartphone con la forza dell’intelligenza artificiale.Elenco degli H2 di https://www.wired.it/ai-intelligenza-artificiale/storie/2017/09/20/microsoft-mette-turbo-sullai-la-task-force-battere-deepmind/Che quello dell’intelligenza artificiale sia uno dei campi su cui si giocheranno le sfide del futuro, ma di quello dietro l’angolo, fra colossi hi-tech si capisce non solo dai numeri ma anche dagli ultimi movimenti di truppe. Di unità, settori e aree di ricerca dedicate ne esistono e da tempo: dalla celeberrima DeepMind di Google, acquisita da BigG nel 2014, da cui passano alcune delle scoperte e degli avanzamenti più affascinanti (basti pensare alle sconvolgenti vittorie di AlphaGo contro i campioni in carne e ossa di Go), al Fair, il Facebook Artificial Intelligence Research, la divisione di Menlo Park diretta da Yann LeCun, guru della robotica e delle neuroscienze computazionali. L’obiettivo di questo settore di Menlo Park, come più o meno in tutte le altre società, è sviluppare sistemi neurali con un livello di intelligenza sempre più prossimo a quello umano, prendendo di petto i problemi accademici più scottanti che ruotano intorno a questi ambiti: teorie, algoritmi, applicazioni, infrastrutture software e hardware. Sono parti interessanti e stimolanti di questi gruppi perché, contrariamente ad altri settori dei colossi statunitensi – e non solo, la Cina ha buone probabilità di sorpassare gli Usa nell’intelligenza artificiale sotto diversi parametri – sono costretti a mantenere una comunicazione e una collaborazione più stringente con l’esterno (accademie, altri centri di ricerca e in genere con la comunità scientifica in senso ampio) pubblicando paper, studi, rilasciando software open source o partecipando a incontri internazionali. Anche Microsoft ha ovviamente la sua divisione di ingegneri ed esperti. Proprio lo scorso anno ha allargato il suo Microsoft AI & Research Group – anzi, lo ha ricostruito da zero affidandolo alle cure di un veterano di Redmond come Harry Shum – includendo nella squadra più di 5mila ingegneri. L’obiettivo, lo abbiamo visto in particolare nell’ambito della salute, è democratizzare le soluzioni di intelligenza artificiale. Non è un caso che alla nuova divisione si siano uniti altri team come quello di Information platform, Cortana e Bing o l’Ambient Computing and Robotics guidati rispettivamente da David Ku, Derrick Connell e Vijay Mital. Eppure adesso una piccola mossa racconta qualcosa di più. Microsoft ha infatti annunciato da pochissimo di aver messo in piedi, all’interno di questo perimetro così ampio dedicato all’AI, una specifica unità che farà un po’ da avanscoperta. Cercherà cioè di concentrarsi su alcune delle sfide più concrete. In particolare, come sfruttare le tecnologie di intelligenza artificiale per rendere i software più intelligenti. Microsoft Research AI, battezzata dal vicepresidente Harry Shum, dispiega un centinaio di ingegneri di base proprio a Redmond. I più tosti. Msr AI, questo il nome in codice, “pescherà dai migliori talenti nella ricerca di Microsoft per sviluppare gli avanzamenti essenziali nel settore” si legge nella presentazione. L’iniziativa combina dunque le ricerche nel machine learning con le innovazioni nello sviluppo e nelle analisi del linguaggio e del dialogo uomo-macchina. Sembra quasi che la flottiglia (per gli standard di un gigante come quello guidato da Satya Nadella) sia stata incaricata, mentre il resto della divisione prosegue sulle ricerche di lungo periodo, di sfruttare le potenzialità delle macchine “in modi nuovi” per aiutare le persone a essere più efficienti, coinvolte e produttive. Basta d’altronde analizzare le 13 squadre in cui quest’eccellenza con cui Microsoft vuole insidiare Google e gli altri per rendersi conto degli ambiti di ricerca: dal “conversational system” al “deep learning” passando per “information and data sciences”, “language and information technology”, “machine learning” e “machine teaching” fino a “perception and interaction” e al gruppo specializzato in “natural language”. Sono piccoli nuclei d’eccellenza che svilupperanno progetti come quelli di assistenza virtuale contestualizzata, intelligenza conversazionale, microproduttività e RoomAlive, uno dei più interessanti, che pare quasi lo sviluppo di ricerche passate sulla realtà aumentata, anzi immersiva, all’interno di ambienti domestici. Dal Microsoft Bot Framework a Cortana passando per tutti gli scenari futuri, le sponde sono infinite. All’ultima conferenza Build dello scorso maggio, non a caso, Nadella ha insistito moltissimo proprio sulla necessità di rendere disponibile l’intelligenza artificiale su diversi dispositivi, piattaforme e programmi, dal motore di ricerca ai bot fino al cloud. Darle, cioè, un elemento di maggiore concretezza e operatività. Un po’ come ha fatto Google col suo nuovo Assistant, vero agente dialogante che però deve ancora arrivare in italiano. Tanto per fare un esempio e cambiando latitudini, non è un caso che Richard Yu, ceo della divisione consumer dei cinesi di Huawei, abbia annunciato che il nuovo flagship phone, il Mate 10 atteso da un paio d’anni e in arrivo entro l’anno, dovrebbe proprio disporre di soluzioni d’intelligenza artificiale superando di slancio le assistenti virtuali a cui siamo abituati ora. Al di là delle applicazioni nei dispositivi, però, c’è da ricordare uno dei punti-chiave di Microsoft anche in termini di bilancio: i servizi infrastrutturali per il cloud. Il secondo trimestre dell’anno è stato totalmente positivo per questo ambito, facendo segnare una crescita del 47% anno su anno fino a toccare un valore complessivo di 14 miliardi di dollari. Se al vertice del mercato dei cloud service provider (+42%) c’è Amazon Web Services, che raccoglie il 30% della spesa, Microsoft ha registrato un’impennata del 97% e Google del 92%. Segue Ibm. Ciò che conta, tuttavia, e che giustifica anche movimenti come quelli appena visti, è la disponibilità di soluzioni di intelligenza artificiale on demand nell’infrastruttura cloud. Canalys, fonte dei dati riportati, ha infatti spiegato che la crescita continuerà proprio grazie ai clienti che utilizzeranno sempre di più piattaforme per l’intelligenza artificiale. Già oggi tutti i protagonisti del settore mettono a disposizione sistemi per la comprensione del linguaggio, il riconoscimento vocale, la ricerca visuale, applicazioni text to speech e altre possibilità. SwiftKey, Genee, Maluuba: oltre alla ricerca interna anche lo shopping di startup e società specializzate compiuto da Satya Nadella negli ultimi due anni marcia proprio in questa direzione: AI first.Elenco degli H2 di https://www.wired.it/gadget/computer/2017/12/20/evoluzione-intelligenza-artificiale/La capacità di riconoscere le persone, gli animali e gli oggetti è una delle principali abilità delle intelligenze artificiali, le cui applicazioni vanno ben oltre la capacità di Facebook di taggare da solo gli amici presenti nella foto di gruppo che avete appena postato. La image recognition viene infatti utilizzata dalle auto autonome (per riconoscere i segnali stradali, le corsie e i pedoni), da Watson di IBM — per diagnosticare il melanoma della pelle con una precisione superiore a quella dei medici umani — e in moltissimi altri casi. Risultati impressionanti, giusto? Parole che colpiscono, soprattutto considerando chi le ha pronunciate: Geoff Hinton, l’uomo che nel 2012, dall’università di Toronto, ha dato il via alla rivoluzione del deep learning e della visione artificiale: “Al momento funziona meglio di qualunque altra cosa, ma questo non significa che sia il metodo giusto”. Hinton non è soddisfatto: per addestrare un network neurale a riconoscere una penna, per esempio, non solo bisogna rifornirlo di centinaia di migliaia di immagini di penne; ma anche fargliele vedere da tutte le possibili angolazioni. Altrimenti, basterebbe capovolgere la vostra Bic e il network neurale non saprebbe più che cosa gli si sta mostrando. Questi software, infatti, non sono per niente bravi ad astrarre e generalizzare la conoscenza, abilità tipicamente umane che consentono ai bambini di imparare a riconoscere un gatto dopo averne visti pochissimi esemplari. A prima vista, questo limite delle AI non sembra così grave: in fondo, viviamo nell’epoca dei big data e siamo quotidianamente sommersi da un mare di informazioni. Essere in grado di estrarre una maggiore conoscenza da una minore quantità di informazioni, però, potrebbe tornare molto utile in campi in cui i dati per l’addestramento di un network neurale non sono poi così numerosi; per esempio, nel settore della sanità. Ed è proprio questo il nuovo obiettivo del 69enne Geoff Hinton, che sta lavorando a un progetto chiamato capsule network — già presentato in alcuni paper — che consente ai network neurali di riconoscere un oggetto utilizzando molti meno dati. Sintetizzando al massimo, il capsule network (qui una spiegazione dettagliata) funziona grazie a gruppi di neuroni digitali, ognuno dei quali tiene traccia di un diverso elemento dell’immagine — per esempio, le orecchie o il naso di un cane — e della loro relativa posizione nello spazio. In questo modo, un network di svariate “capsule” può utilizzare ciò che ha imparato per capire quando una nuova immagine è, in realtà, solo una diversa angolatura di un oggetto già noto. Se l’intuizione di Hinton si dimostrerà di successo, i network neurali funzioneranno in maniera un po’ più simile al cervello umano, imparando a generalizzare e a riconoscere un gatto indipendentemente dalla posizione in cui si trova o dall’angolatura dalla quale lo vediamo. Ma il cervello umano non è bravo solo a generalizzare ciò che apprende, è anche estremamente abile a memorizzare le informazioni importanti e a cancellare quelle superflue: un’abilità che sarebbe molto utile anche alle intelligenze artificiali, che devono ricominciare da capo l’addestramento ogni volta che sono destinate a un nuovo compito. Anche in questo caso, però, la situazione potrebbe cambiare a breve: il ricercatore Rafah Aljundi, assieme ad alcuni colleghi dell’università di Leuven (Belgio) e del Facebook AI Research, sta infatti progettando intelligenze artificiali in grado di conservare le informazioni che potrebbero tornare nuovamente utili. “Quando imparano un nuovo compito, i cambiamenti nei parametri che hanno avuto maggiore successo vengono penalizzati”, hanno spiegato i ricercatori. Il sistema sviluppato da Aljundi permetterà di conservare e sfruttare più di una volta i legami neuronali che hanno funzionato bene nello svolgimento dei compiti precedenti, creando così una specie di memoria. I network neurali dotati di questa nuova abilità hanno effettivamente performato meglio di quelli che ne sono privi, riuscendo a passare con successo dal riconoscimento dei fiori a quello degli uccelli e dimostrando di poter diventare sempre più flessibili nel loro apprendimento. Non solo: la ricerca di Aljundi ricorda da vicino gli esperimenti con cui DeepMind (la startup di Google) aveva mostrato come, sfruttando la memoria, le intelligenze artificiali potessero compiere l’equivalente elettronico di un rudimentale ragionamento. Il trend dell’evoluzione dell’intelligenza artificiale, insomma, è chiaro: macchine che imparano a generalizzare, a usare la memoria e in definitiva a imitare sempre meglio il cervello umano. E questo vale anche per una delle questioni più pressanti che gli esperti del settore stanno affrontando: il cosiddetto problema “black box”, ovvero l’impossibilità di capire perché una AI sia giunta a una determinata conclusione. Ricostruire il percorso che ha portato un network neurale alle sue conclusioni significherebbe infatti perdersi in miliardi di calcoli matematici, un’impresa umanamente impossibile. Un problema non da poco, considerando quanto le macchine siano alle prese con compiti di sempre maggiore responsabilità in campo medico, legale e finanziario (per fare solo alcuni esempi). Per questa ragione, alcuni ricercatori dell’università di Berkeley (California) e del Max Planck Institute di Saarbrücken (Germania) vogliono insegnare alle intelligenze artificiale a spiegare chiaramente le loro ragioni. L’algoritmo che stanno progettando analizza i dati in due modi: il primo ha l’obiettivo di rispondere alla domanda posta dai ricercatori (“che cosa c’è in questa immagine?”), il secondo mostra invece i dati specifici utilizzati per rispondere alla domanda. Quando gli viene chiesto di spiegare perché ha riconosciuto in una foto un giocatore di baseball, il network neurale controlla i dati che gli sono stati forniti, risponde a un set di domande appositamente predisposte dai ricercatori e afferma, per esempio, “l’uomo sta colpendo la palla con una mazza”. Se vi sembra un progresso da poco, immaginate quanto sarebbe stato utile un sistema di questo tipo quando l’algoritmo di Google Immagini aveva iniziato a confondere alcune persone di colore con dei gorilla. Non solo: pensate a quanto sarà importante che l’intelligenza artificiale alla guida di un’automobile sia in grado di spiegare perché ha compiuto una manovra che ha causato un incidente; o che una AI che diagnostica le malattie spieghi perché ha sbagliato una determinata valutazione. Come ha affermato Tommi Jakkola del MIT, “giustificare le decisioni prese sarà una questione decisiva per i sistemi complessi: le intelligenze artificiali devono imparare a comunicare con noi”. Ma tutti questi progressi significano forse che le macchine stanno per diventare davvero intelligenti? In verità, l’avvento di una vera intelligenza artificiale — una macchina in grado di eseguire tutti i compiti di cui un uomo è capace al suo stesso livello — è ancora molto lontano: basti pensare che, al momento, tutte le intelligenze artificiali che vediamo al lavoro (da quelle che si occupano di riconoscere le immagini, a quelle in grado di tradurre sempre meglio da una lingua all’altra, fino a quelle che trascrivono ciò che dettiamo loro) sono in grado di compiere un solo compito. Anche in questo campo, comunque, si stanno facendo progressi: c’è chi sta cercando di far collaborare network neurali specializzati in compiti diversi e chi sta insegnando a un solo algoritmo a giocare a videogiochi molto diversi tra di loro (vedendo in questo una prima scintilla di “generalità”). È impossibile escludere che, prima o poi, saremo in grado di progettare un’intelligenza artificiale; quel che è certo è che non avverrà già nel 2018.Elenco degli H2 di https://www.wired.it/attualita/tech/2017/12/21/ruolo-illuminazione-internet-things-aec/Nessuno più ha dubbi, l’Internet of things (Iot) segnerà un’evoluzione tecnologica paragonabile – se non superiore – a quella del web. Gli oggetti connessi in rete potranno comunicare con le persone e tra di loro, abilitati da una potente infrastruttura, e l’enorme mole di informazioni raccolte sarà gestita in ottica big data con approcci innovativi come il machine learning e il deep learning. Quando si parla di Internet delle cose si possono immaginare le applicazioni più svariate, dai frigoriferi intelligenti che ci segnalano quali prodotti sono in scadenza alle macchinette del caffè che si attivano appena scendiamo dal letto, fino ai televisori che ci permettono di interagire tramite la voce, i gesti o addirittura (più in prospettiva) con il pensiero. Ma non si tratta solo di elettrodomestici: pensiamo a pneumatici capaci di darci informazioni sul loro stato di usura, a farmaci che ci aiutano a rispettare i tempi previsti dalla prescrizione medica o a sistemi robotizzati per innaffiare le piante. Anche un’attività quotidiana come lo shopping in negozi e supermercati cambierà forma, permettendoci di pagare in automatico senza fermarci alla cassa e magari di selezionare direttamente dallo smartphone quali dei prodotti esposti farci spedire a casa. Una rivoluzione altrettanto epocale sarà quella che coinvolgerà i sistemi di illuminazione, sia dal punto di vista più immediato dei punti luce domestici e dei lampioni cittadini, che potrebbero diventare dei punti di riferimento anche per la connettività urbana. Infatti, in ottica Iot i lampioni avranno un ruolo sempre più importante all’interno delle realtà urbane. Una volta collegati tra loro in una rete comune, potranno giocare un ruolo chiave nella raccolta e nella trasmissione delle informazioni, sfruttando anzitutto la loro diffusione capillare sul territorio cittadino. Se pensiamo alla mobilità, ad esempio, la possibilità di mettere in comunicazione veicoli e lampioni apre a una serie di applicazioni, che spaziano dalla gestione in tempo reale dei flussi di veicoli alla regolazione dei semafori, fino all’ottimizzazione dei parcheggi. Qualunque entità circolante, dai veicoli ai pedoni agli animali, potrà essere monitorata, sia per aumentare la sicurezza di chi è per strada sia supportando la lotta alla criminalità. Oppure, sul fronte della manutenzione, si potrebbe essere informati tempestivamente su eventuali guasti alle infrastrutture pubbliche o anche coordinare, grazie all’intelligenza artificiale, la manutenzione predittiva. Questo è solo uno dei numerosi esempi mostrati da Aec, azienda specializzata nel settore dell’illuminazione pubblica, che racconta attraverso un video come i corpi illuminanti, ossia i lampioni, ad alto contenuto tecnologico possano essere sfruttati per svariate applicazioni urbane. Anziché perdere tempo alla ricerca di un posto auto libero, dunque, si potrebbe pensare a dei sensori installati sulle strisce dei posteggi, i quali potrebbero dialogare con i lampioni per far arrivare poi alle automobili (magari a guida autonoma) l’informazione su quale sia il parcheggio libero più vicino. Il risultato non sarebbe solo un beneficio in termini di tempo e un risparmio in termini di denaro, ma anche una riduzione delle emissioni inquinanti. In parallelo, un sistema come questo sarebbe anche garanzia di legalità, soprattutto in un Paese come il nostro in cui ancora si vedono parcheggiatori abusivi e automobili lasciate nei posteggi per disabili. Su un fronte diverso, ma accomunato dall’approccio Iot, i corpi illuminanti dei lampioni, proprio per la loro caratteristica di onnipresenza sul territorio, sono in una posizione privilegiata per il monitoraggio della qualità dell’aria, dalla misura delle polveri sottili fino alla concentrazione di gas inquinanti. Una grande quantità di dati che, aggregata da un orchestratore unico immaginabile come una centrale di controllo, potrebbe permettere agli amministratori di prendere decisioni più consapevoli sulla gestione delle emissioni urbane. In casa invece, ad esempio, potremo gestire l’illuminazione con un battito delle mani o magari, a distanza, direttamente dallo smartphone. Se le lampadine saranno equipaggiate con sensori connessi, potranno generare informazioni utili per gestire i consumi energetici e diventare un punto di raccolta dati, con applicazioni anche in termini di sicurezza. In ottica di intrattenimento, le lampadine connesse potrebbero essere in comunicazione con il televisore e gestire in diretta l’illuminazione della stanza, andando oltre il tradizionale buio da effetto cinema. Il risultato sarebbe un’esperienza più coinvolgente per lo spettatore, grazie alla complementarietà tra tv e illuminazione. Quelli descritti sono gli obiettivi più importanti – per noi e per l’ambiente – che saranno raggiungibili più facilmente grazie agli oggetti connessi. Meno inquinamento e più tempo libero per dedicarsi a hobby e passioni sono le prospettive più promettenti abilitate dalla Internet delle cose, che già oggi non è più una promessa futuristica ma una realtà tangibile. Il risultato di questa evoluzione sarà un mondo, che ottimisticamente possiamo pensare realizzabile in pochi decenni, ancora più a misura di essere umano.Elenco degli H2 di https://www.wired.it/attualita/media/2017/11/10/intelligenza-artificiale-business/Le aziende italiane hanno compreso la portata dell’artificial intelligence come strumento per cambiare fisionomia, anche nella relazione business to business? E per quali processi, in particolare? Al convegno “Il futuro digitale del business tra aziende” se ne parlerà diffusamente, partendo dai risultati della ricerca “Artificial Intelligence Business Evolution: l’intelligenza artificiale come acceleratore della digital transformation”. Seconda edizione, quindi, per l’evento organizzato da Casaleggio Associati, di scena al Centro Svizzero di Milano il 14 novembre e dedicato a una platea business, alle prese con la transizione digitale e il conseguente riposizionamento nello scenario competitivo globale. Dalla formazione dei dirigenti ai vari ambiti dell’attività aziendale, la leva dell’artificial intelligence può cambiare le dinamiche interne; nelle due tavole rotonde si parlerà di innovazione attraverso il cognitive computing e il deep learning ma anche di fattore umano e Ai, dalla progettazione al business. In ambito aziendale, artificial intelligence e machine learning non sono astrazioni che guardano a futuro generico ma mezzo concreti per creare subito nuovi servizi e potenziare i risultati aziendali; non solo la gestione di svariati processi (dall’analisi di mercato al customer service) anche l’intero passaggio dalla progettazione al business potrebbe cambiare grazie a strumenti come chatbot o all’interazione uomo-macchina. Temi che saranno discussi a B2B-Il futuro digitale del business da Luca Scagliarini di Expert System, da Federico Zuin di Mashfrog, da Leandro Agrò di Design Group, da Ettore Murciano di Loop AI, da Mattia De Rosa di Microsoft Italia.    Elenco degli H2 di https://www.wired.it/internet/web/2017/04/26/intelligenza-artificiale-film-colori/Il beige sbatte? Beh, dipende dal film. Posto che i gusti sono gusti, lo sviluppatore canadese Jack Qiao ha trovato il modo di generare tavolozze di colore che ben si abbinano a immagini di qualsiasi tipo, tratte da film, videoclip, o qualsiasi altra fonte si preferisca. Il suo prodotto si chiama Colormind che, come spiega il sito stesso,“può estrarre tavolozze di colori dalle immagini. Invece di trovare i colori più rappresentativi, punta a trovare i colori che funzionano insieme in una palette di colori”. Nessuna presunzione di verità assoluta, dunque, quanto un sistema che Qiao ha elaborato seguendo due passaggi. Il primo, è la quantizzazione di colore (MMCQ): in questo caso, gli algoritmi tirano fuori i colori più rappresentativi. Il secondo passaggio, necessario prima del verdetto finale, prende i risultati che mescolano a casaccio i colori rappresentativi e li mette al vaglio di un “classificatore”, che si pone come una sorta di “giudice finale”. L’allenamento del deep learning in questo caso è stato messo al servizio di un assortimento che non generasse accoppiamenti dallo scarso contrasto. “Come designer una delle prime cose che faccio quando si inizia un nuovo progetto è quello di ottenere un senso della tavolozza dei colori – scriva Qiao – Fare palette di colori è un processo difficile perché mentre la maggior parte delle persone può indicare quando trova una combinazione di colori piacevole, è difficile da spiegarne esattamente il perché”. Per chi è a digiuno di tecnicismi ed esperienza nell’illustrazione e nella grafica, Colormind è comunque un esperimento divertente per scoprire quali colori vengono associati alle proprie immagini preferite. Per sguardi più poetici, poi, c’è sempre l’uomo che fotografava i film.Elenco degli H2 di https://www.wired.it/gadget/foto-e-video/2017/10/31/phancer-intelligenza-artificiale-foto/Si fa un gran parlare in questo periodo di algoritmi di intelligenza artificiale in grado di dare i superpoteri alle fotocamere dei nostri smartphone: gli ultimi iPhone 8, i Google Pixel e Huawei Mate 10 Pro utilizzano chip dedicati allo scopo e restituiscono risultati di qualità eccellente, eppure per ottenere scatti migliori di quanto possa mai catturarli un comune sensore per smartphone non è necessario un telefono di ultima generazione. A dimostrarlo c’è il progetto WESPE realizzato in seno al laboratorio di computer vision del politecnico federale di Zurigo, che ruota attorno a un sistema di machine vision per migliorare le fotografie che gli vengono date in pasto, e che funziona online tramite browser con qualunque immagine gli venga inviata. Come tutti gli algoritmi di machine learning, il WEakly Supervised Photo Enhancer (questo il significato del nome) è stato inizialmente nutrito con un quantitativo significativo e diversificato di foto, sottoposte all’analisi di cinque diversi network neurali; partendo da un catalogo realizzato con un comune smartphone e uno uscito da una reflex, il sistema è divenuto così in grado di isolare le caratteristiche delle immagini da esaltare e di imparare a esaltarle. Il risultato è Phancer, una piattaforma web che migliora la qualità degli scatti in modo avanzato, ad esempio ritoccando le zone in ombra in modo più intelligente rispetto a quanto farebbe un semplice filtro di fotoritocco. Per provare il software in prima persona basta recarsi sul sito allestito dai ricercatori e premere il pulsante per il caricamento della foto. I risultati non sono sempre sbalorditivi, in particolare per quel che riguarda la tutela dei dettagli, e il processo non è istantaneo, anzi: dal momento che opera in cloud, l’algoritmo ha bisogno di tempo per ricevere la foto dal telefono o dal computer dell’utente, e di altro tempo per elaborarla e per rispedirla al mittente. In ogni caso, il sistema messo in piedi è una buona dimostrazione delle potenzialità del machine learning applicato alla fotografia: una volta perfezionati gli algoritmi, trasformare tutta la piattaforma in un’app sulla falsa riga di Prisma non è difficile, magari portando in futuro tutto il sistema di elaborazione a bordo dei telefoni.Elenco degli H2 di https://www.wired.it/attualita/tech/2017/07/12/stephen-brobst-teradata/“Gli algoritmi lineari di machine learning davano un 25% di errore nelle analisi predittive. Ora con i nuovi algoritmi, quelli delle reti neurali, la percentuale di errore è scesa al 3%. È persino inferiore a quella degli uomini, che oscilla tra il 3% e il 5%. E questo risultato è stato raggiunto in 18 mesi”. Stephen Brobst fa una pausa, lascia che il suo ascoltatore assapori i numeri e la velocità con cui le macchine stanno diventando sempre più intelligenti. Brobst è uno dei maggiori esperti mondiali nel campo dei big data e dello stoccaggio delle informazioni. Si è laureato al Massachusetts Institute of Technology, di cui è oggi professore onorario, e ora è direttore tecnologico di Teradata, multinazionale statunitense dell’informatica, specializzata in analisi dei dati e servizi cloud. Brobst è in Italia di passaggio. Oggi interverrà a Napoli all’Eastwest Forum. Il tema del dibattito è il rapporto tra algoritmi e democrazia. “Facebook non mi fa vedere tutto quello che postano i miei amici, ma come fa a scegliere? – esemplifica Brobst -. Conosce il mio passato, i miei gusti, le mie idee politiche. Però se mi mostra solo ciò che mi piace, solo un aspetto della realtà, non mi permette di conoscere altre idee e di fare confronti. Così si diventa ignoranti”. La questione ha anche implicazioni più “terra terra” e di natura economica. “È il caso delle raccomandazioni sui siti di ecommerce”, osserva l’esperto. A dispetto della promessa di migliaia di prodotti, il portale consiglia quelli che rimangono all’interno del tuo orticello. La “comfort zone”, come la definisce Brobst. E qui entrano in gioco gli algoritmi, che devono calcolare il giusto mix per inserire, nel ventaglio delle offerte, una piccola percentuale di proposte che si trova al di fuori, ma non troppo, dalla comfort zone dell’utente. È una questione di democrazia, ma per i giganti della tecnologia è una questione di affari e concorrenza. “Netflix usa un sistema sofisticato per portarti fuori dalla comfort zone – osserva Brobst -. Altrimenti quando finisci di vedere quello che ti piace, disdici l’abbonamento”. Il deep learning è lo strumento informatico per migliorare queste capacità di analisi e risposta. I nuovi algoritmi simulano il funzionamento delle reti neurali del cervello. Non eseguono funzioni matematiche lineari, ma scompongono il pacchetto di informazioni su tanti livelli per semplificare la densità di dati che devono elaborare e raccoglierli uno a uno. C’è però un problema. “I data scientist ancora non sanno spiegare come si arrivi a certi risultati – avverte Brobst -. Le reti neurali a multi-livello sono come delle scatole nere, in cui inserisci i dati ma non sai come arrivi a certe risposte”. Per questo uno dei campi di ricerca più decisivi per il prossimo futuro è quello del reverse engineering: risalire dai risultati finali ai dati iniziali per comprendere come i secondi producano i primi. Come salmoni che risalgono la corrente. Non avere una spiegazione ferrea, osserva Brobst “è un problema per il machine learning applicato a mercati regolati”, nei quali deve essere chiaro il funzionamento. Come la finanza. Per questo, aggiunge l’informatico, “non mi aspetto che le banche adottino queste tecnologie decisionali a breve. Funzionerà meglio con decisioni che non hanno impatto sulle persone e per le quali non c’è bisogno di spiegazioni”. Tuttavia per Brobist il percorso è irreversibile: “Il deep learning permetterà alle macchine di rimpiazzare l’uomo in decisioni operative, che devono essere prese in pochi secondi e a basso costo. All’uomo spetteranno le decisioni più creative”. Ma come la mettiamo con le intelligenze artificiali che guideranno le automobili senza conducente? Come prenderanno decisioni che hanno un impatto sulle persone, come possono essere quelle in caso di incidenti che mettono a repentaglio vite umane? Brobst ricostruisce un classico dilemma da driverless car. La macchina corre lungo una strada bagnata dalla pioggia, è notte e la visuale è ostacolata dal riflesso di un lampione nelle pozzanghere. Una mamma con due bambini per mano attraversa la strada, nonostante il semaforo sia rossa, mentre un’anziana signora attende sul marciapiede. L’impatto è inevitabile: cosa deve fare l’auto? Quale vita può essere “sacrificata”? Quella dell’anziana perché è avanti con l’età o quella della mamma perché ha violato la legge? “Come data scientist posso dire all’intelligenza artificiale di fare qualunque cosa – taglia corto Brobst -. È una questione politica. Deve essere la politica a dire come comportarsi, ma la politica sta evitando il problema”. È la stessa politica, almeno quella degli Stati Uniti, che ha compreso quanto l’analisi dei big data possa tornarle utile in campagna elettorale, per individuare gli elettori indecisi o quelli che, pur sostenendo un candidato, sono più pigri al voto e convincerli ad andare alle urne. In questo scambio di dati l’anello debole resta il consumatore, che non è cosciente o poco attento alla raccolta di informazioni che lo riguardano. Per Brobst, però, lo scenario è destinato a cambiare a breve. In Europa a cominciare dal prossimo anno, quando diventerà operativa la nuova disciplina sulla privacy. “Aumenterà la visibilità dei dati che sono richiesti e ciascun utente avrà maggiore coscienza di quanto sta condividendo”. Ma è un futuro possibile quello in cui il consumatore deciderà a chi vendere le proprie informazioni? Brobst fa una pausa di qualche minuto prima di rispondere, poi annuisce. “Sarà così. Il consumatore deciderà cosa fare dei suoi dati e a chi venderli. Ci saranno aziende con le quali il consumatore avrà interesse a condividere i propri dati. Con altre no e potrà proporre un pagamento in cambio. Sono cose che già succedono: pensiamo ai profili dei frequent flyer. È una raccolta dati continua in cambio di vantaggi, come sconti sui voli. In futuro però sarà più efficiente e su larga scala”. Per Brobst, però, “è difficile immaginare che un’azienda vada da cliente a cliente a chiedere i dati. Servirà un aggregatore. Negli Stati Uniti la risposta arriverà dal mondo delle imprese, in Europa dai governi”.Elenco degli H2 di https://www.wired.it/attualita/tech/2017/03/28/elon-musk-cervello-computer/Fantascienza o realtà? Sembra sempre più difficile riuscire a distinguere, soprattutto quando a parlare è l’eclettico Elon Musk. Sempre lui, l’esuberante imprenditore creatore di Pay Pal, di SpaceX e alle prese con le missioni spaziali per Marte. Anche stavolta nello scenario, prospettato dalle pagine del Wall Street Journal, gli elementi per stupire ci sono tutti: creare dispositivi da impiantare nel cervello per potenziare le nostre abilità cognitive e evitare che le intelligenze artificiali ci surclassino rendendoci schiavi. “Penso che non manchino più di quattro o cinque anni per avere un’interfaccia parziale con il cervello”, afferma Musk, che ha fondato una startup – la Neuralink – proprio con l’obiettivo di sviluppare sistemi che permettano all’essere umano di fondersi con i computer, per tenere il passo delle intelligenze artificiali. L’obiettivo di Neuralink sarebbe in un primo momento quello di potenziare le abilità del cervello umano, per poi passare a sviluppare interfacce in grado di alleviare i sintomi di alcune patologie croniche del cervello (epilessia, Parkinson, ecc). Non è la prima volta che Musk fa dichiarazioni di questo tipo. In questo video possiamo ascoltare come già nel 2016 alla Code Conference prospettasse il funzionamento del neural lace, un laccio neurale costituito da un dispositivo connesso chirurgicamente al cervello umano che permetterebbe all’utente di interagire con i computer senza le limitazioni attuali. Niente più interfacce come tastiere, mouse e schermi, insomma. Musk non è il solo a pensare che i continui e velocissimi sviluppi della tecnologia dell’intelligenza artificiale costituisca un pericolo per il genere umano. “Lo sviluppo dell’intelligenza artificiale potrebbe significare la fine della razza umana” ha affermato tempo fa il fisico-cosmologo Stephen Hawking “Se ne va per conto suo e si ridisegna ad un ritmo sempre crescente. Gli esseri umani, che sono limitati dalla lentezza dell’evoluzione biologica, non potranno competere, e verranno superati”. Sul concetto di evoluzione, o meglio di co-evoluzione con le macchine, si fonda anche il progetto di Bryan Johnson, fondatore di Braintree, che ha investito 100 milioni di dollari per realizzare una futura protesi neurale per sbloccare tutte le potenzialità del cervello umano, e addirittura riprogrammarlo per essere quello che vogliamo essere: “La nostra connessione con le nuove tecnologie di intelligenza artificiale è limitata dagli schermi, dalle interfacce gestuali e dai comandi vocali – siamo costretti dalle modalità di input e output. Il nostro cervello è assai poco accessibile e limita la nostra capacità di co-evolvere con le macchine a base di silicio”. Per superare queste difficoltà l’azienda di Johnson – Kernel – è impegnata nella ricerca sul funzionamento del cervello allo scopo poi di replicare il modo in cui le cellule cerebrali comunicano tra loro. Tra non molto, dunque, potremmo trovarci a vivere in una realtà in cui la maggior parte delle persone avrà un dispositivo impiantato in grado di potenziarne, per esempio, la memoria (un po’ alla Black Mirror, insomma), ma anche di compensare i danni provocati da malattie degenerative come Alzheimer, Sla, Parkinson. La domanda è: siamo pronti?Elenco degli H2 di https://www.wired.it/scienza/spazio/2017/07/07/piano-elon-musk-marte/Elon Musk ha deciso: “Voglio che Marte diventi una meta possibile. Voglio che sia possibile raggiungerlo entro la nostra vita. E c’è un modo per far sì che chiunque voglia possa raggiungerlo”. E sappiamo bene (vedi Tesla, vedi PayPal, vedi SpaceX, vedi Boring Company) che quando Elon dice di voler fare una cosa, c’è da star certi che dice sul serio. La dichiarazione, in realtà, risale al settembre scorso – Musk l’ha rilasciata nel corso del 67° International Astronautical Congress svoltosi a Guadalajara, in Messico, a settembre 2016 – ma è stata resa pubblica, con tutti i dettagli, solo pochi giorni fa, in un paper sulla rivista New Space. Il documento, in particolare, passa in rassegna diverse questioni legate alla fondazione di una colonia autosufficiente su Marte, enucleando difficoltà e criticità dell’impresa e cercando di trovare soluzioni ai problemi tecnologici, logistici ed economici del progetto. Lo abbiamo esaminato con la consulenza di Enrico Flamini, chief scientist dell’Agenzia spaziale italiana, che da anni si occupa di missioni spaziali per il pianeta rosso e che era presente lo scorso anno a Guadalajara. La prima riflessione di Musk riguarda la questione del perché partire – e perché partire proprio per Marte. “La storia si sta per biforcare in due direzioni”, scrive il Ceo di SpaceX. “La prima è quella in cui l’umanità rimane per sempre sulla Terra, e terminerà con la nostra estinzione. Non so quando, ma sono certo che avverrà. L’alternativa, su cui spero tutti siano d’accordo, è quella di diventare una specie multi-planetaria”. La prima e più realistica possibilità di farlo, arguisce ancora Musk, prevede la fondazione di una colonia autosufficiente su Marte. “Il pianeta rosso”, commenta Flamini, “è effettivamente l’unico del Sistema solare che consentirebbe a una colonia umana di essere autosufficiente dalla Terra. La Luna, che pure in passato era stata valutata per una missione del genere, non si presta bene allo scopo: non contiene acqua e ha una gravità troppo bassa, quindi una colonia lunare sarebbe sempre dipendente dalla Terra”. Marte, al contrario, sembra avere acqua a sufficienza, non è troppo lontano e ha una gravità pari a un terzo di quella terrestre. “I radar italiani Marsis (a bordo di Mars Express) e Sharad (a bordo del Mars Reconnaissance Orbiter)”, continua Flamini, “hanno eseguito una radiografia del polo nord marziano, e hanno svelato che al di sotto del suolo esiste acqua in quantità tale da ricoprire l’intero pianeta con un oceano profondo 8 metri. E probabilmente c’è acqua anche altrove”. Anche la raccolta di energia, su Marte, non sarebbe un problema: in linea di principio, infatti, è possibile sviluppare tecnologie per costruire piccole centrali nucleari sul pianeta e raccogliere l’energia solare tramite pannelli fotovoltaici. I punti più delicati, in realtà, sono altri: “Anzitutto”, spiega Flamini, “c’è il problema del ritorno: far decollare in modo completamente automatico una navicella da Marte è qualcosa che non è ancora stato tentato dal genere umano. Tra l’altro dobbiamo ancora perfezionare le tecniche di ammartaggio, come ci ha recentemente insegnato l’esperienza di Schiaparelli: l’atmosfera rarefatta di Marte rende estremamente complesso arrivare morbidamente sul pianeta, e c’è bisogno di imparare a farlo in sicurezza prima di inviarvi esseri umani”. Lo step intermedio, insomma, dovrebbe essere quello di completare con successo una missione non umana di andata e ritorno per e dal pianeta rosso, che preveda l’arrivo e l’atterraggio in sicurezza, il recupero di un campione, la costruzione automatica di una rampa di lancio e, infine, il rientro. Un’altra criticità rappresenta il sistema di comunicazioni con la Terra: “Marte ha un ritardo radio nelle comunicazioni con il nostro pianeta di circa 20 minuti. E quando il Sole si interpone tra le antenne su Marte e la Terra ogni comunicazione è impossibile”, continua lo scienziato dell’Asi. “Per questo è fondamentale, prima dell’invio di esseri umani, la costruzione di un sistema di comunicazioni affidabile e continuo”. E ancora, last but not least, il problema delle radiazioni: “La vera limitazione, al momento, resta quella di capire come schermare le radiazioni provenienti dallo Spazio e dannose per il corpo umano. Marte non ha un campo magnetico in grado di farlo, e – almeno al momento – è impensabile di dotare il pianeta di un campo magnetico planetario. Sarà necessario mettere a punto delle schermature locali che proteggano i primi residenti. Dobbiamo ancora capire come”. Nella sua proposta, naturalmente, Musk passa in rassegna anche i dettagli del viaggio: quale propellente usare, come produrlo in loco, la scelta del motore, del vettore e della navicella. Tutto, naturalmente, pensato nell’ottica di riciclo e scalabilità: “Il razzo decolla e porta la navicella in orbita”, spiega nel paper. “Dopo 20 minuti, il razzo si stacca e torna sulla Terra, dalla quale può ripartire periodicamente per rifornire di carburante la navicella che aspetta in orbita il momento giusto per partire. C’è una finestra di lancio ottimale una volta ogni 26 mesi: a regime, prevediamo che ci saranno fino a mille navicelle attorno alla Terra, una vera e propria flotta orbitante”. L’idea, secondo Flamini, è vincente: “L’architettura proposta da Musk è corretta”, spiega. “Si tratta della naturale evoluzione di quello che SpaceX sta già facendo con successo. Il vettore proposto dovrebbe riuscire ad arrivare su Marte in appena tre mesi, un tempo ragionevolmente breve”. Abbiamo parlato di tempo. La timeline proposta da Musk è uno degli aspetti più incerti e delicati della storia. Stando alle previsioni del Ceo di SpaceX, da qui al 2019 dovrebbe completarsi la fase di scelta e addestramento della crew e di sviluppo di strutture e sistemi di propulsione. La navicella e il razzo dovrebbero essere testati a cavallo tra il 2019 e il 2023. Poi potrebbero cominciare i lanci veri e propri. Senza equipaggio, all’inizio; in seguito, se andrà tutto come previsto, potremmo cominciare a pensare a mettere un manipolo di esseri umani a bordo di una navicella diretta verso il pianeta rosso. Certamente non avverrà prima della metà degli anni ’30. Quanto alla posa della prima pietra della colonia, ci sarà certamente da aspettare ancora parecchio.Elenco degli H2 di https://www.wired.it/economia/business/2017/07/11/elon-musk-si-ricompra-il-dominio-x-com/Da oggi potremo chiamarlo Mister X. “Grazie a PayPal per avermi permesso di riacquistare X.com! Non ci sono piani al momento, ma ha un grande valore affettivo per me”. Parola di Elon Musk che, con questo tweet di qualche ora fa, ha annunciato di essere tornato in possesso del dominio X.com. Un acquisto concluso nella giornata del 3 luglio, dunque poco più di una settimana fa. A cifre top secret. Secondo DomainInvesting un’operazione paragonabile a quella di Z.com, venduto per quasi 6,8 milioni di dollari nel 2014.  Sono passati quasi vent’anni da quando il numero uno di Tesla riuscì a registrarlo nell’ormai lontano 1999, quando era una società di servizi finanziari online. In seguito, la fusione di X.com con Confinity, l’appellativo attribuito alla startup che poi sarebbe diventata PayPal. Era il 2001 quando il dominio venne definitivamente ceduto a PayPal. Ora Musk torna in possesso della sua creatura, ma mantiene il mistero sugli obiettivi dell’operazione. Motivi sentimentali? Certo, da SpaceX alla Tesla Model X, l’imprenditore non ha mai nascosto la sua predilezione per questa lettera, spesso utilizzata nel mondo hi-tech per identificare progetti misteriosi e ad elevato tasso di innovazione (pensiamo anche al laboratorio X di Google). Difficile però credere (soltanto) a questa versione. Non è ancora chiaro infatti se Musk abbia in mente di rientrare nel settore dei pagamenti online o utilizzare il domino per uno dei suoi visionari progetti. Forse SpaceX diventerà semplicemente X e il nome di dominio verrà utilizzato per il suo sito web? Oppure X.com potrebbe fungere da contenitore per tutti i progetti targati Elon Musk, da SpaceX fino a The Boring Company. A meno che, non stia già bollendo in pentola qualcosa di nuovo. E da questo signore, o meglio da Mister X, possiamo aspettarci davvero di tutto.Elenco degli H2 di https://www.wired.it/scienza/spazio/2017/09/29/razzo-bfr-spacex-marte-musk/ Il genio dei razzi, Elon Musk, l’inventore dell’azienda aerospaziale statunitense SpaceX, ha appena rilanciato il suo ambizioso progetto di colonizzare Marte, trovando una nuova chiave di accesso al pianeta rosso. Ne ha parlato oggi lo stesso Musk, all’International Astronautical Congress in corso ad Adelaide, in Australia. La novità è rappresentata da uno straordinario veicolo: un razzo, più piccolo dei modelli precedenti da lui immaginati lo scorso anno, ma più grande di qualsiasi missile mai lanciato. Lungo 9 metri di diametro al posto dei 12 di quello descritto precedentemente, il mega missile, chiamato Big F**king Rocket (Bfr) sarebbe più potente dei precedenti. Il Bfr sarebbe in grado di trasportare 40 cabine contenenti ciascuna due o tre persone, per un totale di circa 100 viaggiatori dello Spazio e 150 tonnellate di materiali. L’idea è quella che Marte possa essere colonizzato e diventare una meta interplanetaria ambita in cui le persone vivono stabilmente. Un obiettivo ambizioso, che presenta indubbiamente notevoli ostacoli, ma che, qualora realizzabile, aprirebbe le porte a nuovi mondi. Ma non è tutto. Il razzo odierno, potenziato rispetto ad alcuni suoi predecessori, come ad esempio il Falcon 9, che già aveva fatto registrare dei successi, questo super razzo potrebbe permettere non solo voli extraterrestri, ma anche viaggi terrestri molto più rapidi, come ha spiegato Elon Musk ad importanti testate americane. Ad esempio si potrebbe volare oltreoceano, percorrendo le distanze fra Londra e New York, in circa mezz’ora: un record assoluto. Con questo razzo, dunque, si potrebbe arrivare in qualsiasi punto del globo in meno di un’ora, tempi inferiori rispetto a quelli necessari per attraversare città grandi come Roma o Milano. E Musk ha presentato oggi i dettagli tecnici ed ingegneristici di questa mega macchina spaziale, basata sul sistema Interplanetary Transport System. Oltre alle minori dimensioni rispetto a Falcon 9, rispetto al quale il razzo odierno Bfr risulta rafforzato, l’autore sottolinea che tutte le sue parti sono riutilizzabili, motivo per il quale la spesa vale l’impresa secondo Musk, che sottolinea come i costi di realizzazione potrebbero abbassarsi. Costi che sono stati stimati dall’inventore in una misura di dieci miliardi di dollari, quasi otto miliardi e mezzo di euro. Se il suo piano potrà essere realizzato, sia a livello tecnico che economico, Elon Musk pensa che il primo lancio, senza passeggeri, potrebbe avvenire già nel 2022, un’aspettativa di tempo più rosea rispetto alla precedente, che prevedeva tempi di circa 10 anni. Mentre i primi passeggeri potrebbero salirvi nel 2024, cioè fra meno di dieci anni, con viaggi ogni 26 mesi. Certo, il ticket di viaggio potrebbe essere piuttosto costoso, aggirandosi fra i 100mila e i 200mila dollari. Ma l’obiettivo, seppure molto ambizioso, permetterebbe di bonificare territori finora mai colonizzati.Elenco degli H2 di https://www.wired.it/lifestyle/mobilita/2017/05/02/elon-musk-rete-di-tunnel-per-le-auto/Da un po’ di tempo, in California — a Los Angeles soprattutto — il traffico è un bel problema, e così Elon Musk, il patron di Tesla, ha fondato una nuova azienda pronta a risolverlo, la Boring Company. Il nome non confonda: quel boring non sta per noioso ma per perforazione. Il primo prodotto uscito dall’impresa infatti è un cilindro hi-tech che consente di creare dei tunnel sotterranei con all’interno dei binari. Dal piano stradale la vettura sarebbe portata sotto terra da una sorta di vagone che, una volta all’interno del tunnel, conduce l’auto a destinazione senza bisogno che il conducente tocchi il volante. http://www.youtube.com/watch?v=pBAt2ygF0d4 Stando ai primi dati, il macchinario consentirebbe di viaggiare a 200 chilometri orari creando di fatto una sorta di treno ad alta velocità per vetture. Ancora non ci sono dati circa le prime installazioni ma nel mentre la sperimentazione va avanti e la mobilità intelligente ha trovato un nuovo alfiere.Elenco degli H2 di https://www.wired.it/attualita/tech/2017/11/28/elon-musk-inventore-bitcoin/Idea che sta facendo il giro del mondo, quella secondo cui Elon Musk sarebbe l’inventore dei bitcoin. La rivelazione è partita da un ex stagista di SpaceX di nome Sahil Gupta su Medium ed è stata poi ripresa dall’accreditato e calibrato Bloomberg, che non esclude (né conferma) che Elon Musk e Satoshi Nakamoto, il padre putativo dei bitcoin la cui reale identità è ancora misteriosa, possano essere la stessa persona. Gli indizi che portano a Musk
In gergo sarebbero prove indiziarie, a cominciare dal fatto che Musk (come del resto tante altre persone) abbia conoscenze approfondite del linguaggio di programmazione C++, usato per creare bitcoin. Inoltre, precisa Gupta, il patron di Tesla ha a lungo riflettuto sulla fragilità del sistema bancario e sulla scarsa fiducia che questo riscuote. A suffragare questa tesi ci sono i fatti: nel passato imprenditoriale di Musk ci sono i pagamenti digitali e Paypal, azienda che ha co-fondato nel 1998. La sua predisposizione a proporre soluzioni per i grandi problemi globali la si evince anche dal suo presente, con Tesla, le energie alternative e i viaggi spaziali. Inoltre i bitcoin hanno visto la luce proprio durante la crisi del comparto bancario del 2008 e, questa tesi è corroborata dalla cronaca recentissima, il fatto che la criptovaluta stia raggiungendo quotazioni di rilievo è anche legata alla necessità di uscire dal sistema di intermediazione bancaria. In questo caso però tre indizi non fanno una prova, lo stesso Musk nega (anche questa non è una prova) e sostiene di avere ricevuto qualche bitcoin in regalo e di non ricordare più su quale computer li conservi.  Musk è un personaggio di indubbia genialità, uno che porta avanti progresso, ma è anche un personaggio tallonato a vista dai media e dotato di una buona dose di egocentrismo. Ha annunciato di volere impiantare protesi nel nostro cervello e di volerci portare sulla Luna. Per quale motivo dovrebbe nascondersi se fosse l’inventore dei bitcoin?Elenco degli H2 di https://www.wired.it/scienza/spazio/2017/08/24/spacex-elon-musk-nuove-tute-spaziali/“La prima immagine delle tute spaziali SpaceX. Ne arriveranno altre nei prossimi giorni. Notate che si tratta di una tuta reale, non di un modello, già testata nel vuoto. Bilanciare estetica e funzionalità è stato incredibilmente difficile. Sarebbe stato più facile occuparsene separatamente”. Con questa didascalia Elon Musk, patron di SpaceX (e di tanto altro) ha lanciato sul proprio profilo Instagram la prima immagine ufficiale delle tute spaziali che saranno presumibilmente indossate dagli astronauti che un giorno voleranno sulle navicelle spaziali riciclabili messa a punto dall’azienda spaziale privata. Come specifica The Verge, si tratta di tute progettate non per le attività extraveicolari (più note come passeggiate spaziali), ma per essere indossate a bordo ed evitare problemi derivanti da eventuali depressurizzazioni della capsula. Il design degli indumenti ricorda molto quello dei modelli comparsi un anno fa su Reddit e attribuiti a SpaceX, che però non aveva mai confermato né smentito la notizia. In ogni caso, l’azienda di Musk non è l’unica alle prese con la progettazione di tute spaziali: come ricorda il New Scientist, anche la Nasa ha all’attivo tre progetti di sviluppo di tute di nuova generazione – e, stando ad alcune voci circolate in rete all’inizio dell’anno, potrebbe terminare il proprio stock di tute prima che siano pronte quelle nuove. Boeing, dal canto suo, ha svelato il proprio design delle tute spaziali che saranno presumibilmente indossate dagli astronauti durante il viaggio verso la Stazione spaziale internazionale.Elenco degli H2 di https://www.wired.it/scienza/lab/2020/08/29/elon-musk-neuralink-cervello-computer/Si chiama Gertrude, ed è un maiale. È lei la protagonista della demo andata in onda questa notte e targata Neuralink, la startup di Elon Musk nata nel 2017 con la mission di mettere in comunicazione il cervello umano con l’intelligenza artificiale. Con un dispositivo ad hoc impiantato nel cervello, Gertrude ha dato dimostrazione dell’attuale livello di sviluppo della tecnologia di interfaccia neuroni-elettronica. Mostrando che i progressi rispetto a un anno fa sono notevoli, ma anche rendendo palese come l’obiettivo dichiarato dall’imprenditore visionario sia ancora parecchio lontano. Partiamo subito dal risultato mostrato durante la diretta streaming: mentre il maiale azionava il suo principale e più sviluppato organo sensoriale, il muso, le immagini mostrate su uno schermo e i suoni diffusi da un sistema audio hanno mostrato l’attività cerebrale. Dando quindi una suggestione di quanto variasse l’intensità dell’attività a seconda di quale punto odorasse e di quel che facesse. Rispetto al 2019, quando della tecnologia erano state mostrate solo alcune fotografie e nessuna prova pratica di funzionamento, il design è decisamente cambiato. Se prima il sistema di Neuralink consisteva in un impianto esterno da installare dietro l’orecchio, ora invece ha l’aspetto di una monetina che può essere adagiata direttamente nella scatola cranica scavando una piccola cavità, tanto da non essere di fatto visibile. E la comunicazione con l’esterno, che era prima cablata attraverso una porta usb, ora avviene con un sistema wireless basato su tecnologia bluetooth a bassa energia. Da interfacciare con un computer, o anche con uno smartphone. Probabilmente l’analogia migliore per raccontare che cosa faccia il dispositivo è quella utilizzata dallo stesso Musk, descrivendo il tutto come “un fitbit nel cranio”. Nella sostanza, infatti, il sistema registra una serie di informazioni associate all’attività cerebrale, che a oggi possono fornire alcune indicazioni di massima su quello che sta accadendo all’interno del cervello. In pratica, un misuratore di performance, un contapassi cerebrale che si applica – per esempio – all’attività sensoriale. Naturalmente l’esistenza di un sistema che traduce in dati digitali l’attività cerebrale, e quindi fa da interfaccia cervello-macchina, non è di per sé una novità. Come noto, tecnologie di questo genere esistono dal 2006. L’aspetto più interessante del lavoro di Neuralink è probabilmente la struttura stessa del dispositivo, e in particolare il sistema di 1.024 sottilissimi fili flessibili che raccolgono gli impulsi per poi tradurli in informazioni digitali. Per il momento i fili pescano informazioni dalla corteccia cerebrale (dove comunque si trova la parte ritenuta più interessante per le applicazioni pratiche, perché lì hanno sede le funzioni mentali cognitive compresse), ma l’idea è che in prospettiva possano andare anche più in profondità, attraverso una sorta di micro-tunnel nel cervello. Il tutto, ingegnerizzato all’interno di un dispositivo compatto e di installazione relativamente facile, dovrebbe diventare la chiave del futuro sviluppo di Neurolink. Musk a lungo termine punta infatti a far diventare The Link (questo il nome specifico dell’oggettino) un prodotto di massa. Le sfide che la startup sta affrontando dal punto di vista hardware sono almeno un paio: da un lato rendere i fili sempre più sottili e soprattutto più numerosi, per poter raccogliere sempre più informazioni, dall’altro far resistere il più a lungo possibile il dispositivo nell’ambiente altamente corrosivo del cervello. L’obiettivo dichiarato è che, alla fine dello sviluppo, The Link possa durare “per decenni”. A proposito di innovazione, va però detto che – nonostante gli indiscutibili passi in avanti rispetto a un anno fa – è probabilmente mancato l’effetto wow dal punto di vista delle attuali applicazioni del dispositivo. Di tutte le promesse di lungo corso che Musk ha fatto a proposito di Neuralink, per ora non c’è sostanzialmente nulla: manca un sistema capace di interpretare i segnali raccolti nel cervello, e men che meno si vede all’orizzonte una soluzione che possa permettere di dare ordini o di trasmettere informazioni al cervello a partire da un computer. Nonostante la strada sia ancora lunga, Musk durante la conferenza stampa (e pure su Twitter) ha parlato di “telepatia concettuale“, di un futuro in cui “l’intelligenza umana e quella artificiale diventano simbiotiche“, di “visione aumentata”, di “salvare e rivedere i propri ricordi” e di by-pass per persone paraplegiche e tetraplegiche. Applicazioni interessanti e da sempre negli obiettivi della startup, ma che al momento sembrano essere al limite della fantascienza, o rievocative di Black Mirror.  L’appuntamento della scorsa notte è stato l’occasione per fare il punto non solo sullo sviluppo tecnologico del progetto, ma anche sulla salute della startup dal punto di vista imprenditoriale ed economico. Al momento lavorano in azienda un centinaio di persone, che Musk vorrebbe portare a 10mila. Significativo però è che a Neuralink ci sia un turnover rapidissimo, tanto che rispetto al momento della fondazione nel 2017 i lavoratori sono cambiati tutti, eccetto due persone. Secondo un rapporto indipendente uscito proprio questa settimana, alcuni ex dipendenti dell’azienda hanno riferito di un’organizzazione interna caotica, di un eccesso di stress dovuto a tempi di lavoro troppo compressi, e soprattutto di qualche perplessità etica nell’utilizzare il classico approccio da startup move fast and break things quando si tratta di esperimenti che coinvolgono attività delicate come queste, che includono anche interventi chirurgici su animali che spaziano dai topi ai maiali e fino ai primati. Elon Musk si è invece concentrato già sul lancio sul mercato di The Link, chiarendo che all’inizio sarà molto costoso ma anche che l’obiettivo è di ridurre progressivamente il prezzo “fino a qualche migliaio di dollari”. Oltre al prezzo, una delle sfide da affrontare per trasformare l’interfaccia cervello-macchina in un prodotto a larga diffusione sarà il superare i timori delle persone nel farsi impiantare un simile apparecchio, che (secondo quando riferito da Cnet) riguardano anche la possibilità che l’installazione generi infezioni. Le prime sperimentazioni sull’uomo dovrebbero iniziare già entro quest’anno, e riguarderanno un piccolo gruppo di persone che hanno già gravissime lesioni al midollo spinale. La speranza, infatti, è che lo sviluppo di Neuralink possa permettere a queste persone (in un futuro non meglio definito) di riacquisire parte della loro mobilità.Elenco degli H2 di https://www.wired.it/lifestyle/mobilita/2017/07/21/musk-another-hyperloop/Da New York a Washington in 29 minuti nel prossimo futuro? A indicare la possibilità è ancora una volta Elon Musk che via Twitter ha annunciato una “approvazione verbale”, di ambito governativo, per un progetto da attuare con una delle sue compagnie, the Boring Company, per connettere più città ad est e consentire un comodo New York City-Washington Dc in 29 minuti, in via sotterranea.  Dichiarazione che però ha spinto molti a chiedere all’imprenditore di origine sudafricana cosa intendesse per “approvazione verbale” e soprattutto da parte di chi, posto che il progetto dovrebbe prendere piede in più Stati. Musk si è limitato a confermare la sua visione del progetto, che porterebbe a un collegamento nel pieno centro delle città e un accesso con ascensori per entrare e uscire in superficie.  Musk, che non ha aggiunto particolari dettagli, ha comunque ammesso che ci vuole un sacco di lavoro per ricevere una approvazione formale al progetto, ma resta ottimista sul fatto che potrà succedere in breve tempo. E chiede anche ai cittadini di fare la differenza, testimoniando l’interesse per la futura infrastruttura ai rappresentanti locali e federali. E più di uno chiede se la approvazione a cui fa riferimento Musk venga o meno dall’amministrazione Trump, da cui pure però Musk ha consumato uno strappo chiamandosi fuori come adviser dopo lo strappo presidenziale sull’accordo di Parigi. Un progetto che, se mai venisse realizzato, potrebbe certamente riscrivere le tempistiche dei collegamenti, se, come sostiene il New York Times, un viaggio dalla Grande Mela alla Capitale, fatto anche con l’Acela Express di Amtrak, richiede ancora 2 ore e 45 minuti. Che i progetti di Musk siano però suggestivi lo dimostra anche la domanda di chi si chiede se siano già in previsione ampliamenti sulla futuristica linea e a cui Musk risponde perfino positivamente: Elenco degli H2 di https://www.wired.it/economia/finanza/2017/11/24/tesla-perdite/Stando a quanto riportato da Bloomberg, Elon Musk e la sua Tesla non se la stanno passando benissimo. Anzi. Dopo i ritardi nella produzione della Model 3, i licenziamenti e le voci ricorrenti di problemi economici infatti, ora arrivano anche le previsioni nefaste degli analisti dell’agenzia americana, che hanno calcolato che negli ultimi 12 mesi il costruttore californiano di auto elettriche avrebbe “bruciato” 8000 dollari al minuto. Parliamo di una somma vicina al mezzo milione di dollari all’ora. Insomma, uno sproposito. Eppure, nei giorni scorsi si sono susseguite novità importanti per l’azienda automobilistica, con la nuova roadster ed il camion elettrico annunciati per il 2019. Ieri l’ultimo annuncio: in Australia Tesla ha completato lo sviluppo della batteria agli ioni di litio più grande al mondo, la mastodontica Powerpacks da 129 megawattora. Il fondatore di Tesla aveva promesso che nell’arco di 100 giorni sarebbe riuscito a costruirla per alleviare i problemi energetici dell’Australia Meridionale ed evitare i frequenti blackout. In caso contrario, avrebbe fatto il lavoro gratis. Il progetto è stato però ultimato nei tempi stabiliti e presentato al mondo via Twitter dallo stesso Musk.  Segnali di un’azienda forte e in salute. Se non fosse che Bloomberg ha già fissato addirittura la data precisa in cui Tesla rimarrà senza fondi: 6 agosto 2018. Alle 2.17, ora di New York, per la precisione. Secondo Kevin Tynan (Bloomberg Intelligence) infatti, entro l’estate dell’anno prossimo la casa di Palo Alto avrà bisogno di almeno due miliardi di dollari di nuovi fondi. Critico anche l’ex numero due di General Motors Bob Lutz, secondo cui “a questo ritmo [Tesla] non arriverà al 2019″. L’85enne dirigente sostiene che l’azienda di Palo Alto stia andando completamente fuori mercato. E, non riuscendo a sostenere tutti i costi per i suoi faraonici progetti, sia costretta a stimolare continuamente il mercato per alimentare la fiducia degli investitori. Si tratterà solo di invidia? Staremo  vedere. Intanto, gli investitori non sembrano preoccupati, visto che le azioni di Tesla sono aumentate di quasi il 3%, conferendo al titolo una capitalizzazione di mercato di 53 miliardi di dollari. Ma in un mercato così pazzo, si sa, gli annunci si susseguono a ritmo vertiginoso. E il mese di agosto, in fondo, non è poi così lontano.Elenco degli H2 di https://www.wired.it/economia/finanza/2017/07/31/spacex-nuovo-round-investimenti/Nuovo importante round di investimenti per SpaceX. L’azienda di Elon Musk che sogna di inaugurare l’era del turismo spaziale di massa ha raccolto 351 milioni di dollari, diventando così una delle private company (ossia società non ad azionariato diffuso) più valutate al mondo: 21,2 miliardi di dollari (circa 18 miliardi di euro). I dati sono stati resi noti dalla piattaforma di analisi finanziarie Equidate. Leggendo con attenzione i numeri, appare evidente l’incontenibile ascesa del valore di SpaceX, passato dai 4,5 miliardi del dicembre 2012 agli attuali 21. In soli 5 anni, un incremento complessivo del 371%. Un 2017 ricco di soddisfazioni per la compagnia spaziale di Elon Musk che nei mesi scorsi ha testato con successo il sistema di recupero dello stadio iniziale del suo razzo di punta, da riutilizzare per nuovi lanci. Una svolta significativa se si pensa che il primo stadio è il componente più costoso e recuperarlo significa ridurre di molto i costi delle operazioni. Musk, inoltre, ha appena annunciato il via ai test per il nuovo razzo Falcon Heavy, in grado di sostenere carichi molto più pesanti, allargando così le potenzialità dei servizi offerti da SpaceX. Si partirà il prossimo novembre.  E ora questo nuovo traguardo, che porta SpaceX a diventare la quarta compagnia privata statunitense di maggior valore. Prima di lei soltanto Uber, in testa a questa speciale classifica con una valutazione di 69,8 miliardi di dollari, seguita dal sito di alloggi AirBnb (31 miliardi) e dalla società di analisi Palantir (21,3). Nel mondo invece, esistono soltanto altre due compagnie private sopra i 20 miliardi di dollari. Entrambe in Cina. Si tratta del produttore di device tecnologici Xiaomi (45) e della concorrente asiatica di Uber, Didi (50 miliardi).Elenco degli H2 di https://www.wired.it/ai-intelligenza-artificiale/storie/2017/04/14/neil-harbisson-uomo-cyborg/La storia di Neil Harbisson inizia in un romanzo di Italo Calvino e si sviluppa in uno di Philip Dick. Il primo cyborg riconosciuto per legge sale agli onori delle cronache come un novello Barone rampante. Artista britannico, ma cresciuto in Catalogna, nel 2001, a 19 anni, Harbisson si fa conoscere dalla stampa spagnola perché si arrampica in cima a un albero per difendere tre piante secolari dal taglio nel centro di Matarò, in provincia di Barcellona. Per qualche giorno tiene in scacco il cantiere, finché il Comune capitola alla sua protesta e cancella il taglio degli alberi. Ma non sono questi titoli a rendere famoso Neil Harbisson. Da bambino gli viene diagnosticata l’acromatopsia. È l’incapacità di distinguere i colori. Per Neil, classe 1982, il mondo è un grande film in bianco, nero e scala dei grigi. Mentre studia al Darlington College of Arts, nel Regno Unito, si appassiona di cibernetica e sviluppa insieme a un informatico, Adam Montandon, la prima bozza di quello che chiamerà eyeborg, ossia un’antenna che trasforma le onde dei colori in 360 onde sonore. Neil sente i colori attraverso l’antenna, che ora è impiantata in modo permanente nel cranio. “È un’opera d’arte. Non è dispositivo medico né un ausilio per la vista”, racconta al margine del Forum organizzato a Milano dalla società di software Sas e a cui Neil è stato invitato come relatore. In una stanza del centro congressi Mico l’artista racconta la sua storia e la scelta di diventare un cyborg, il primo riconosciuto per legge da uno Stato. Quasi fosse la storia al contrario dell’Uomo bicentenario di Isaac Asimov. Quando Neil, nel 2004, bussa alle porte degli ospedali per presentare il suo progetto, incassa solo no. “I comitati etici erano preoccupati di tre cose – ricorda -. Dicevano che il dispositivo era pericoloso, che non era necessario e che avrebbe potuto ledere l’immagine dell’ospedale vedere uscire un uomo con un’antenna in testa”. “Mi hanno mosso le stesse osservazioni che facevano negli anni Cinquanta e Sessanta alle persone transessuali”, aggiunge. Alla fine Harbisson trova un medico disponibile, che in cambio dell’anonimato lo opera nel suo giorno di riposo e in tre ore aggancia l’impianto al cervello. “Ho dovuto tenere la testa fasciata per due mesi mentre l’osso si ricostruiva intorno all’antenna”. “Da allora è come se avessi un nuovo organo”, spiega. Ed è quello che l’artista deve spiegare ogni volta che viaggia. “Pochi giorni fa sono rimasto bloccato due ore a Vienna. Arrivava polizia su polizia. Alla fine hanno fatto venire il medico dell’aeroporto, che ha diagnosticato che era mentalmente sano per viaggiare su un aereo”, racconta. Nel 2004 il governo britannico lo riconosce come cyborg. Timido, gracile, con i capelli paglierino tagliati a scodella, l’artista potrebbe ricordare un personaggio di un film di fantascienza, anche se dice di non avere mai guardato pellicole sci-fi o fumetti a tema. Tuttavia ha del futuristico la sua Cyborg Foundation, un’organizzazione che sostiene gli uomini che vogliono diventare cyborg. “Ci sono un sacco di teenager che vogliono un pezzo del corpo da cyborg”, racconta. Qualcuno ha parlato di sinestesia nel suo caso, ma è errato. La definizione corretta è sonocromatismo e mette in relazione due dimensioni fisiche e misurabili, quindi oggettive: l’onda luminosa e l’onda sonora. La connessione tra i tessuti del cervello e l’antenna, però, nel tempo ha travalicato la visione dei colori. L’eyeborg ha un dispositivo bluetooth e può connettersi al wi-fi, quindi Neil all’occorrenza dichiara di vedere direttamente nel suo cervello informazioni che viaggiano in rete. “Una volta sono stato anche hackerato – ridacchia -. Ma è stato piacevole”. Tuttavia, se gli stimoli diventano troppo forti o fastidiosi, “spengo l’antenna”. E quando ha mal di antenna, una pastiglia per il mal di testa sopisce il problema. “Prima dell’impianto potevo provare sensazioni simili solo con le droghe – ironizza l’artista -. Però si può pensare a una cibernetica da usare nel weekend, per modificare i tuoi sensi in un sistema più controllato”. Harbisson si professa ateo e spiega che la sua scelta gli ha provocato non poche inimicizie tra i credenti. “Qualcuno pensa che non avrei dovuto farlo”, dice. Ma aggiunge: “La cosa importante non è quanti sensi hai, ma come li usi. Per decenni abbiamo dato sensori alle macchine e sono apparecchi non costosi. Basta applicarli agli uomini per espandere le loro capacità”. Sostenitori della cibernetica per tutti, il primo cyborg riconosciuto legalmente descrive la sua antenna con la sigla R-R: realtà reale. “Non è realtà virtuale o realtà aumentata – chiosa -. Penso che la realtà virtuale sia una perdita di tempo, quando c’è una realtà vera che non si riesce a sperimentare fino in fondo”.Elenco degli H2 di https://www.wired.it/scienza/biotech/2017/12/18/persone-scienza-2017-nature/Telecomunicazioni quantistiche, editing del genoma, cambiamenti climatici, onde gravitazionali. La lista delle personalità più influenti del 2017 in ambito scientifico, stilata come di consueto dalla rivista Nature, è anche quest’anno molto eterogenea. E contiene anche una ricercatrice italiana, l’astronoma Marica Branchesi, della collaborazione Virgo, responsabile, insieme agli interferometri dell’esperimento analogo Ligo, dall’altra parte dell’oceano, dell’individuazione del primo segnale di onde gravitazionali provenienti dallo scontro di due stelle di neutroni. Ma ci sono anche menzioni meno onorevoli: come specifica Brendan Maher, uno dei caporedattori di Nature, la lista contiene infatti “gli alti e i bassi della scienza”. Non anticipiamo niente, e andiamo con ordine. Genetica e immunoterapia
Apre la classifica – e non poteva essere altrimenti, dato quanto se ne è parlato negli ultimi mesi – la biotecnologia, e in particolare l’ingegneria genetica e Crispr/Cas9, la tecnica di editing del genoma che sta letteralmente rivoluzionando la medicina. Lo scienziato che si è meritato la menzione di Nature è David Liu, del Broad Institute di Cambridge, Massachusetts, che, come vi avevamo raccontato, ha modificato la proteina Cas0 aggiungendovi un altro enzima, l’Apobec1, che rende Crispr ancora più precisa e adatta, secondo i trial preliminari, a correggere mutazioni genetiche che giocano ruoli importanti in diverse malattie. Sempre per restare nel campo della salute, Nature ha omaggiato Emily Whitehead, una bambina di dodici anni “testimone vivente” delle potenzialità dell’immunoterapia nella lotta contro il cancro. Emily è stata la prima bambina al mondo a ricevere una terapia sperimentale, la cosiddetta Car-T, per trattare la leucemia linfoblastica acuta e ora, stando a quel che dicono i medici, è completamente guarita dalla malattia. La terapia, all’inizio di quest’anno, è stata approvata dalla Food and Drug Administration statunitense per il trattamento della malattia; una sua variante, progettata per la terapia dei linfomi non-Hodgkin, ha ottenuto il via libera nei mesi successivi. Un’altra menzione è andata a Jennifer Byrne, genetista e oncologa al Children’s Hospital di Weastmead, a Sydney. La scienziata, in particolare, si occupa di scovare gli errori negli articoli scientifici che si basano sull’analisi di vastissimi database genetici. Errori che, a quanto pare, sono purtroppo più frequenti del previsto: grazie al lavoro di Byrne, che ha messo a punto un software che analizza automaticamente i paper e evidenzia quelli con dati e conclusioni sospetti, diversi articoli fallati sono stati ritirati dalle riviste che li avevano pubblicati. Anche questo è progresso scientifico. Onde e particelle
L’evento certamente più importante dell’anno, nel campo dell’astronomia, è stata la prima osservazione sperimentale di onde gravitazionali provenienti dalla collisione di due stelle di neutroni, operata in contemporanea dai potenti occhi degli interferometri Ligo, negli Stati Uniti, Virgo, in Italia, e dai telescopi dell’osservatorio Eso in Cile. Nature ha omaggiato la scoperta inserendo nella classifica l’italiana Marica Branchesi, ricercatrice a Virgo dell’Università di Urbino, che ha ricoperto il delicato ruolo di  connessione tra astronomi e fisici: “Il mio lavoro”, spiega a Nature Branchesi, che oggi lavora al Gran Sasso Science Institute, all’Aquila, “era quello di convincere gli astronomi che la ricerca di segnali di questo tipo era un campo molto promettente”. Ha avuto ragione, evidentemente. Rimanendo nel settore della fisica ma spostandoci verso l’infinitamente piccolo, segnaliamo la menzione di Pan Jianwei, della University of Science and Technology of China, a Hefei, che a luglio scorso è riuscito, con la sua équipe, a teletrasportare (quantisticamente, s’intende) un fotone dal nostro pianeta a un satellite in orbita. Tutto grazie del cosiddetto entanglement, il fenomeno quantistico per cui due o più particelle sono intrinsecamente legate e riescono in qualche modo a parlarsi a distanza. Quello di Kaled Toukan, invece, è stato un delicato lavoro a metà tra scienza e diplomazia. Toukan è il direttore del Synchrotron-light for Experimental Science and Application in the Middle East (Sesame), il primo sincrotrone mai costruito in Medio Oriente. Un risultato diplomatico senza precedenti, per l’appunto: Toukan ha messo a sedere allo stesso tavolo scienziati, ingegneri e decisori provenienti da Israele, Turchia, Egitto, Iran, Giordania, Pakistan, Cipro e Palestina. Paesi tra cui non scorre certamente buon sangue. Eppure, dopo oltre vent’anni di sviluppo, il sincrotrone ha visto la luce nel 2017. A testimonianza che la scienza non ha confini. Se la Terra trema
Il 20 settembre scorso, un terribile terremoto di magnitudo 7.1 ha colpito Città del Messico, causando la morte di centinaia di persone e la distruzione di decine di edifici, tra cui una scuola. La triste circostanza è stata l’occasione per testare i modelli predittivi messi a punto da Victor Cruz-Atienza, geofisico alla National Autonomous University of Mexico, che ha studiato estensivamente le dinamiche fisiche che regolano la rottura delle faglie sotto la crosta terrestre. Le previsioni di Cruz-Atienza (in particolare quelle riguardanti la stabilità dei sedimenti molli) si sono rivelate in ottimo accordo con i dati raccolti durante il sisma. Un risultato dall’alto valore scientifico che ha garantito allo scienziato l’inclusione nella classifica delle personalità più influenti dell’anno. Contro le discriminazioni, contro le armi nucleari
Nella classifica di Nature compaiono anche i nomi di due persone che si sono battute per i diritti civili e per promuovere la pace nel mondo. La prima è Ann Olivarius, avvocatessa britannica che da decenni fa luce sui casi di molestie sessuali e gender gap nell’ambiente accademico. Il secondo è Lassina Zerbo, a capo della Nuclear-Test-Ban Treaty Organization (Ctbto), organizzazione internazionale che si occupa di monitorare i test nucleari che si conducono nel mondo. Zerbo, come è facile immaginare, non ha avuto vita facile quest’anno (chi non ricorda i ripetuti test missilistici di Kim Jong-un e le conseguenti crisi diplomatiche che hanno fatto tremare il mondo?). “Zerbo”, ricorda Nature, “ha lavorato duramente per scoraggiare la proliferazione nucleare, nonostante la tensione globale in aumento, ed è stata una figura chiave nella risposta internazionale a seguito dei testi missilistici nordcoreani”. Un negazionista a capo dell’Epa
A chiudere la classifica, Scott Pruitt, nominato a gennaio capo della Environmental Protection Agency (Epa) statunitense dal presidente Trump. La sua è una personalità certamente influente, ma non in positivo: la nomina di Pruitt ha fatto discutere perché si tratta di un negazionista risoluto del cambiamento climatico (e, in particolare, della sua origine antropica) e perché ha più volte promosso l’ammorbidimento delle politiche anti-inquinamento. Speriamo che la menzione di Nature possa aiutarlo a ripensare alle proprie idee.Elenco degli H2 di https://www.wired.it/scienza/biotech/2017/11/28/biohacker-dna-crispr-geni/Se ne parla da quando Josiah Zayner, a ottobre, si è iniettato il proprio dna modificato attraverso la tecnica Crispr con l’obiettivo di gonfiarsi i muscoli: si tratta della prima volta che un simile esperimento viene condotto su una persona, ma ormai l’editing genetico è una tecnologia pronta a raggiungere un vasto pubblico. Complici la semplicità della tecnica e il costo contenuto, possiamo immaginare che presto Crispr smetterà di essere confinata nei laboratori sperimentali e invaderà il mondo, a prescindere dall’esistenza di un’adeguata regolamentazione. Il caso di cronaca del primo self biohacker del dna sembra essere – secondo la comunità scientifica dei biotecnologi – più una mossa mediatica che un vero esperimento scientifico. Zayner si è sottoposto a un’iniezione all’avambraccio durante una diretta streaming, affermando di aver modificato il proprio dna in modo da ridurre la produzione di miostatina, la proteina che inibisce la crescita muscolare. In questo modo, ha spiegato Zayner, si potrebbe sperare di osservare una significativa crescita muscolare in quella parte del corpo. Nonostante il biohacker sia effettivamente specializzato in biologia molecolare e biofisica (con un passato da ricercatore alla Nasa per l’adattamento genetico della vita su Marte), le probabilità che l’esperimento funzioni davvero sono molto basse. Egli stesso ha ammesso che test precedenti svolti in segreto non hanno mai funzionato, e secondo molti colleghi l’assenza di effetti rappresenta il miglior scenario possibile, dato che in teoria potrebbero anche svilupparsi infezioni o infiammazioni potenzialmente letali. Qualcuno per questo ha definito il test sperimentale (al minuto 21 del video qui sotto) come una pericolosa e deliberata truffa. Ma non è il valore scientifico dell’esperimento a meritare attenzione, quanto piuttosto le implicazioni che questo caso evidenzia a livello etico, commerciale e giuridico. Anzitutto va detto che Zayner è Ceo di una startup, Odin, che promuove il biohacking e vende kit con tanto di siringa e soluzione in stile do it yourself a venti dollari l’uno. Difficile pensare che tutta la storia non abbia, almeno in prospettiva, lo scopo di favorire la commercializzazione di quei prodotti. Zayner lo ha ammesso solo in parte, affermando che lo scopo della sua azione è “creare un mondo in cui tutti possano sperimentare Crispr su se stessi, e magari utilizzarlo da ubriachi per modificare il proprio dna anziché essere tradizionalisti e farsi un tatuaggio”. Al di là delle esagerazioni pubblicitarie, proprio nelle settimane in cui la Food and Drug Administration (Fda) statunitense ha autorizzato la prima terapia sperimentale basata sull’editing genetico, vediamo che la situazione è già pronta a sfuggire di mano. Lo ha denunciato anche la rivista New Scientist appena qualche giorno fa, evidenziando i rischi dell’auto-sperimentazione clandestina e spiegando la necessità di una discussione urgente sulla regolamentazione. Molti altri biohacker potrebbero seguire a ruota Zayner, o magari lo stanno già facendo senza che i loro esperimenti siano stati raccontati ai media e quindi resi noti alla comunità scientifica. A oggi, secondo quanto riportato dai diversi media, siamo già ad almeno cinque casi accertati. La Bbc, per esempio, racconta la storia di Tristan Roberts, un ragazzo sieropositivo che ha deciso di iniettarsi una terapia genetica sperimentale direttamente nel tessuto adiposo dello stomaco, assistito da un amico istruttore di yoga anziché da una equipe medica. Roberts non ha alcuna formazione medica o in biologia, ma è un programmatore che si è formato (se così si può dire) seguendo gli eventi organizzati da una comunità di biohacker. A monte della sua decisione non c’è stata alcuna riflessione etica e alcun timore per i possibili effetti avversi, ma la speranza di guarire è bastata per farlo agire d’impulso, in una sorta di atto di fede. Ma è possibile arrestare una simile moda? L’auto-sperimentazione è un fenomeno dalle radici antiche: l’hanno praticata anche 15 scienziati che poi hanno vinto il premio Nobel, e fortunatamente dal 1928 in poi nessuno scienziato è morto suicida per aver testato qualcosa su di sé. Modificare il proprio dna, a oggi, non è di per sé illegale o perseguibile per legge, però semmai qualcuno dovesse avere gravi conseguenze cliniche si aprirebbero complessi scenari giuridici. Nel caso della morte di un biohacker inesperto che si fosse lasciato convincere da uno spot promozionale non veritiero, per esempio, si potrebbe configurare il reato di istigazione al suicidio. E che cosa accadrebbe se un biohacker decidesse di sperimentare una modifica genetica su un’altra persona, magari ignara della pericolosità dell’esperimento? In ogni caso, secondo le attuali norme della Fda, l’esperimento di Zayner è legale, o quantomeno non è illegale. Tuttavia non è chiaro fino a che punto il biohacker sarà responsabile dell’operato dei suoi eventuali fan, anche perché la distribuzione di materiali e attrezzature sperimentali via internet tocca un’area grigia non ancora regolamentata dalle istituzioni sanitarie internazionali. In teoria le istituzioni andrebbero avvisate e consultate anche quando si conduce un esperimento sul proprio corpo, ma far rispettare un simile principio è praticamente impossibile. Zayner, dal canto suo, prova a tutelarsi legalmente scrivendo sull’etichetta delle proprie fiale che la soluzione che vende non è né iniettabile né adatta all’uso umano, ma tutti sappiamo che uso potrebbero farne gli eventuali acquirenti. Qualcosa del punto di vista giuridico comunque si sta già muovendo. In Germania il biohacking è già illegale, e gli esperimenti clandestini possono essere sanzionati con una multa fino a 50mila euro o tre anni di carcere. E dal 2018 l’agenzia mondiale antidoping vieterà qualunque forma di editing genetico sugli atleti, anche se non è ancora chiaro come si riuscirà a controllare il rispetto di un simile divieto. Con tutta probabilità, comunque, non vedremo a breve alcun superbraccio ipermuscoloso né in Zayner né altrove. Gli slogan del biohacking come “smettiamo di essere schiavi della nostra genetica”, però, possono sembrare invitanti, soprattutto per i meno esperti e per i meno consapevoli della complessità scientifica dei processi Crispr e degli effetti biologici delle modificazioni del dna. Tra atleti disonesti che potrebbero vedere nella modifica genetica il doping del futuro, malati che potrebbero sperare in qualche effetto miracoloso e persone bizzarre che potrebbero svegliarsi la mattina sognando di avere la pelle viola, la regolamentazione del biohacking è una questione transazionale che merita immediata attenzione, prima che la situazione sfugga di mano. E, nel frattempo, vale il solito don’t try this at home.Elenco degli H2 di https://www.wired.it/scienza/biotech/2017/03/31/de-estinzione-funzionamento/Dodo. Mammut. Tirannosauro. Uomo di Neanderthal. Animali estremamente differenti tra loro, con un (evidente) tratto comune: sono tutte specie estinte. Ma se l’estinzione non fosse davvero per sempre? Se fosse possibile in qualche modo riportare alla vita le specie ormai scomparse e reintrodurle nell’ecosistema? Per quanto suoni fantascientifico, lo è meno di quanto sembri: la pratica si chiama de-estinzione – o resurrezione biologica, o revivalismo della specie – ed è già realtà. Nel senso che diverse équipe di scienziati in tutto il mondo stanno lavorando da tempo a questa possibilità: l’ultimo annuncio, in ordine di tempo, è quello di un team di Harvard, che nel corso del congresso annuale della American Association for the Advancement of Science (Aaas) ha dichiarato di essere quasi pronto a creare un embrione ibrido che contenga tratti genetici dell’elefante asiatico e del mammut lanoso, specie estinta circa 5mila anni fa. E non è la prima volta che accade: già nel 2011, un’équipe di ricercatori della University of Kyoto aveva annunciato la propria intenzione di clonare un mammut, utilizzando il tessuto congelato preservato in un laboratorio di ricerca russo. Stando alle dichiarazioni di allora, l’animale sarebbe dovuto essere pronto entro cinque anni, ma evidentemente così non è stato. O, per lo meno, non abbiamo più avuto notizie del progetto. Come si fa
La tecnica per far tornare in vita animali estinti è una sorta di versione avanzata della clonazione animale. A renderla possibile (o almeno ipotizzabile) è stato il recente avvento delle nuove tecniche di ingegneria genetica, prima fra tutte la Crispr/Cas9. Per Crispr si intende Clustered Regularly Interspaced Short Palindromic Repeats, locuzione che indica segmenti di dna che contengono brevi sequenze regolari e ripetute, particolarmente interessanti perché a esse è associato un complesso di geni, il Cas (o Crispr-ASsociated) che codificano enzimi in grado di tagliare le molecole del dna stesso. In altre parole, si tratta di una sorta di sistema immunitario degli elementi genetici: le sequenze Crispr-Cas riconoscono il dna estraneo e lo tagliano ed eliminano. Da quando, nel 2012, gli scienziati sono riusciti a ingegnerizzare queste sequenze, mostrando che è possibile utilizzare Cas9 (uno degli enzimi Cas) per eseguire in modo relativamente semplice operazioni di taglia e cuci sul dna, si è aperta una nuova era per la genetica. Che per l’appunto, tra le altre cose, ha riacceso le ambizioni dei deestinzionisti, rendendo possibile rimpiazzare le sequenze perdute del dna di specie estinte (non sempre infatti si ha a disposizione il loro codice genetico) con altre sequenze prelevate dai loro parenti più prossimi. Una volta creato in questo modo un codice completo, questo viene impiantato artificialmente nell’ovocita di un altro animale (il più possibile affine a quello estinto) per far sviluppare un embrione che infine viene trasferito nell’utero di una madre surrogata. Animali fantastici e come ricrearli
Il bestiario delle specie estinte (o sul punto di estinguersi) che si vuole riportare alla luce è in costante aggiornamento. Del mammut abbiamo già detto: ma i casi sono molti di più. Nel maggio 2013, un’équipe di scienziati della University of Newcastle e della University of New South Wales ha annunciato di essere riuscita a clonare Rheobatrachus silus, una particolarissima rana, la cui peculiarità è quella di incubare la propria prole nello stomaco, dichiarata estinta nella metà degli anni ottanta (il progetto si chiama Lazarus, un nome più che evocativo): gli embrioni si sono sviluppati per diversi giorni, ma alla fine sono morti. Un altro candidato alla resurrezione è il moa, nome che in realtà designa nove specie di grandi uccelli inetti al volo che popolavano la Nuova Zelanda fino al 1500 circa: ci sta lavorando l’équipe di David Iorns, fondatore dell’azienda californiana Genetic Rescue Foundation. Attualmente, gli scienziati sono ancora al primo step, cioè sequenziare l’intero genoma dell’animale, ma sono fiduciosi di riuscire nell’impresa. In generale, per identificare le specie che dovrebbero avere la priorità rispetto alle altre nel processo di de-estinzione, gli scienziati seguono diversi criteri: “Anzitutto l’utilità dell’animale nel proprio ecosistema”, spiega al New Scientist Douglas McCauley, ecologo della University of California, Santa Barbara. “Se scompare una specie che gioca un ruolo cruciale nel proprio habitat, la conseguenza potrebbe essere un effetto a cascata che porta anche altre specie all’estinzione”. I moa, per l’appunto, soddisfano questo criterio: gli uccelli erano infatti indispensabili per la riproduzione di diverse specie di piante neozelandesi, disperdendo i loro semi; da quando si sono estinti, anche le piante stentano a sopravvivere. Oltre all’utilità, spiega ancora McCauley, bisognerebbe dare la precedenza a specie scomparse negli ultimi cinquant’anni – perché avrebbero più possibilità di sopravvivere una volta reintrodotte nel loro ambiente naturale, che auspicabilmente non dovrebbe essere cambiato troppo rispetto al momento della loro estinzione – e concentrarsi su specie che potrebbero effettivamente migliorare gli ecosistemi e non deteriorarli. Un esempio è il ratto dei nidi intrecciati minore, un roditore che popola(va) il deserto australiano, il cui ultimo esemplare è stato osservato nel 1933, in grado di costruire nidi complessi usando ramoscelli e altri frammenti di vegetazione usati anche da altre specie per proteggersi da freddo e predatori. “È una sorta di acceleratore della biodiversità”, dice McCauley. “Inoltre, ha una gestazione molto rapida e un’aspettativa di vita piuttosto breve, il che lo rende un soggetto ideale per la resurrezione. Con un programma aggressivo di ripopolamento, potremmo ricostruire una comunità solida in meno di dieci anni”. Al momento, comunque, ancora nessuno sta lavorando sul ratto dei nidi intrecciati. E ancora: lo stambecco dei Pirenei, specie dichiarata ufficialmente estinta il 6 gennaio 2000, quando l’ultimo esemplare noto, una femmina di nome Celia, fu trovata morto con il collo spezzato a causa della caduta di un albero. Pochi giorni dopo, un’azienda di biotecnologie, la Advanced Cell Technology, si offrì di clonare l’animale usando un’altra specie di capra come madre surrogata. Il primo esemplare nacque il 20 giugno 2003, ma morì pochi minuti dopo essere venuto alla luce a causa di una malformazione polmonare. Ma c’è un altro problema: non si disponeva – e non si dispone a tutt’oggi – del dna di esemplari maschi di stambecco dei Pirenei, e la clonazione di sole femmine non potrebbe ovviamente garantire la continuità della specie. Una proposta è quella di sostituire il cromosoma X con un cromosoma Y, ma qui sconfiniamo davvero nel campo della fantascienza: al momento non esiste alcuna tecnica in grado di farlo. Un altro progetto è quello di Katshuhiko Hayashi, della Kyushu University di Fukuoka, in Giappone, che ha da poco creato otto cuccioli di topo usando uova ottenute da cellule epiteliali riprogrammate. E ha in mente di usare la stessa tecnica con il rinoceronte bianco, una specie di cui sono in vita solo tre esemplari, tutti con problemi riproduttivi. I pericoli per l’ecosistema
Naturalmente, oltre agli entusiasti, non mancano i critici e gli scettici, convinti che la de-estinzione, alla fine, faccia più male che bene al nostro ecosistema. Una delle obiezioni principali riguarda il fatto che le biotecnologie, al momento, non sono ancora abbastanza mature da poter garantire la creazione di individui sani e vitali, come insegna il caso dello stambecco dei Pirenei. E comunque, continuano gli scettici, le specie reintrodotte nell’ecosistema sarebbero ad altissimo rischio di scomparire di nuovo, a meno che non si modifichino i fattori che ne hanno causato la prima estinzione. Un altro fattore di incertezza riguarda il fatto che è impossibile ricreare fedelmente una specie estinta: inserendone il dna in una cellula uovo di un’altra specie, infatti, l’embrione ottenuto contiene anche parte del dna (quello mitocondriale, che si trova al di fuori del nucleo) della specie ospite. Ma la preoccupazione più grande è di carattere economico. O meglio, riguarda il rapporto costi benefici: uno studio appena pubblicato sulle pagine della rivista Nature Ecology and Evolution da parte di un’équipe di economisti della Carleton University of Ottawa, infatti, ha mostrato che, paradossalmente, riportare in vita specie estinte potrebbe portare a una diminuzione della biodiversità. Perché utilizzare risorse economiche per coprire i costi della creazione e del mantenimento delle nuove specie vorrebbe dire non poterle utilizzare per coprire i costi della conservazione delle specie già in vita: in particolare, gli scienziati hanno calcolato che, riportando alla luce 11 specie in Nuova Zelanda, ne scomparirebbero ben 33. Ancora peggio nel New South Wales, dove all’introduzione di 5 nuove specie seguirebbe la scomparsa di 42 vecchie specie. I de-estinzionisti sono avvisati.Elenco degli H2 di https://www.wired.it/scienza/biotech/2016/03/09/nuovo-tipo-cellule-staminali/Un nuovo tipo di cellule è appena entrato nel novero delle staminali. Si chiamano Xen indotte, o iXen, e finora erano erroneamente ritenute un sottoprodotto di altre cellule staminali. Ma oggi, stando ai risultati di uno studio pubblicato sulla rivista Stem Cell Reports da un’équipe di scienziati della Michigan State University, sono state innalzate al rango di staminali a sé stanti, con le proprie funzionalità indipendenti. La ricerca sulle Xen è iniziata lavorando sulle famose staminali pluripotenti, cellule non differenziate che hanno l’incredibile capacità di trasformarsi in qualsiasi altro tipo di cellula specializzata. Nel 2007, l’équipe di Shinya Yamanaka (Nobel per la medicina nel 2012) scoprì come percorrere il cammino inverso, trasformando le cellule mature del corpo in staminali pluripotenti (dette, per questa ragione, indotte). La scoperta di Yamanaka aprì le porte alla creazione di oltre mille tipi di cellule diverse, tra cui, per l’appunto, le Xen. Le Xen, tipicamente, crescono insieme alle staminali embrionali, e finora si riteneva che il loro dna potesse in qualche modo influenzare la crescita delle pluripotenti. L’équipe di ricercatori della Michigan State University, guidata da Anthony Parenti, ha invece mostrato che le Xen sono un tipo di cellule staminali a sé stanti, le cui abilità potrebbero aprire nuove strade nel campo della medicina rigenerativa e per lo studio dei problemi riproduttivi. Dopo sei mesi di studio nei topi, infatti, gli scienziati hanno osservato che le cellule Xen producono il cosiddetto tessuto extraembrionale, che svolge un ruolo essenziale nello sviluppo del feto. L’équipe, inoltre, ha scoperto che se si inibisce l’espressione genica delle Xen aumenta la produzione di pluripotenti indotte: “La natura è perfetta nel creare le staminali. Noi stiamo cercando di migliorare”, ha spiegato Parenti. “Abbiamo applicato le nostre conoscenze sugli embrioni alla riprogrammazione delle staminali, il che ha aperto una nuova strada per ottimizzare la riprogrammazione”.Elenco degli H2 di https://www.wired.it/scienza/biotech/2016/03/25/cellula-artificiale-genoma-minimo/https://www.wired.it/scienza/biotech/2016/05/13/frontiere-delle-staminali/La ricerca ormai non solo ci salva la vita, ma ce la allunga sensibilmente. Le scoperte scientifiche e le nuove tecnologie permettono di vivere più a lungo rispetto a quanto accadesse già venti anni fa. L’aspettativa di vita aumenterà ancora anche grazie agli studi sulle cellule staminali: da un lato ci potremo curare meglio, dall’altro invece saremo in grado di sostituire gli organi non funzionanti. Sarà anche una questione di bioetica: perché le cellule staminali fanno così paura? Ci risponde Marco Annoni, bioeticista e ricercatore sostenuto dalla Fondazione Umberto Veronesi nel 2014, che insieme al professor Carlo Alberto Redi, biologo dell’università di Pavia e membro del Comitato etico della Fondazione, sarà ospite del Wired Next Fest di Firenze, per raccontare le sfide biologiche e bioetiche che ci attendono in futuro.Elenco degli H2 di https://www.wired.it/scienza/medicina/2016/06/06/iniezioni-staminali-ictus/Un solo trial, per di più piccolo. Così Gary Steinberg della Stanford University School of Medicine ha presentato i risultati del suo studio sull’utilizzo delle cellule staminali mesenchimali in alcuni pazienti colpiti da ictus. Completamente diverso il tono da quelli che avevano caratterizzato la vicenda Stamina, sebbene anche qui si abbia a che fare con disturbi neurologici e con cellule staminali mesenchimali (in questo caso vere, e non presunte). Lo studio di Steinberg, messo in piedi soprattutto per valutare la sicurezza dell’iniezione di staminali mesenchimali nel cervello, ha che mostrato anche efficacia come trattamento. Le cellule sembrerebbero infatti capaci di ristabilire parte delle funzioni motorie perse, come raccontano ricercatore e colleghi nella pubblicazione su Stroke. L’ictus, se non gestito nelle fasi acute, ovvero in quelle immediatamente successive all’evento (che può essere di tipo ischemico o emorragico), può lasciare il paziente con disabilità che solo in alcuni casi possono essere riparate. Anche in tal caso, il recupero delle funzioni compromesse avviene generalmente in un tempo limitato dopo l’ictus, tipicamente entro i sei mesi. Anche per questo i risultati di Steinberg sono in qualche modo sorprendenti. Nello studio sono stati arruolati 18 pazienti (età media 61 anni), per la maggior parte dei quali era trascorso più di un anno dall’ictus, tutti con disabilità motorie gravi: alcuni non riuscivano a camminare, altri a muovere le braccia, per esempio. In questi pazienti i ricercatori hanno osservato quale effetto potesse avere l’iniezione nel cervello – praticata da un neurochirurgo, attraverso perforazione del cranio, non quindi iniettate nel circolo sanguigno come per Stamina – di cellule staminali mesenchimali, in più aree intorno alla zona colpita da ictus. Più correttamente, nei pazienti sono state introdotte cellule SB623, tecnicamente preparazioni staminali prelevate dal midollo osseo e modificate in modo da aiutare il recupero dei neuroni danneggiati, per ristabilire la funzione neurologica persa, spiegano i ricercatori. Le staminali mesenchimali sono un tipo di staminali adulte, che possono differenziarsi in diversi tipi cellulari, come quelle che costituiscono il tessuto osseo o il tessuto adiposo e sembrerebbero essere ben tollerate quando trapiantate in un ricevente diverso dal donatore (sebbene al riguardo la discussione sembrerebbe ancora aperta). In seguito all’intervento, gli scienziati hanno monitorato strettamente i pazienti, senza rivelare sostanziali effetti collaterali, se non mal di testa principalmente imputabili all’intervento stesso più che all’iniezione delle cellule, e temporanei vomito e nausea. Malgrado le cellule non sembrino rimanere a lungo nel cervello (circa un mese), come suggerito anche dagli studi preclinici, i medici hanno osservato che i pazienti mostravano recuperi nel primo mese dopo l’iniezione, ma anche a seguire, mantenendoli fino a un anno dall’operazione. Fino a due in alcuni casi. Miglioramenti – come la riacquisizione del movimento del pollice o della capacità di deambulare, sottolinea Steinberg – clinicamente osservati e misurati. Ma in che modo le cellule avrebbero prodotto i benefici osservati? L’idea di Steinberg è che i fattori secreti dalle staminali subito dopo la loro infusione stimolerebbero la riattivazione o la rigenerazione del tessuto nervoso circostante. Notevole, conclude il ricercatore, anche il fatto che i benefici siano stati osservati indipendentemente dall’età dei pazienti o dal grado di gravità all’inizio dello studio. Ma, come cautela e mancanza di prove certe impongono, sarà necessario allargare il set di studio per avere dati più affidabili. Per confermare che circuiti cerebrali una volta creduti morti in realtà non lo sono, conclude Steinberg.Elenco degli H2 di https://www.wired.it/scienza/medicina/2016/06/13/staminali-trapianto-sclerosi-multipla/Si torna a parlare di staminali ematopoietiche contro la sclerosi multipla. L’occasione è la pubblicazione, su Lancet, di uno studio che ha mostrato l’efficacia del trapianto di staminali ematopoietiche su un piccolo gruppo di pazienti sul lungo termine. Anche se, sottolineano i ricercatori, si tratta di un trattamento pericoloso e i risultati dello studio, per quanto incoraggianti, vanno presi con cautela. La sclerosi multipla, malattia che secondo le ultime stime solo in Italia colpisce circa 110mila pazienti, è una patologia a base immunitaria, in cui le cellule impazzite sferzano il loro attacco anche verso i componenti self dell’organismo, portando nello specifico alla distruzione della guaina mielinica che ricopre le fibre nervose. L’idea, trapiantando le staminali ematopoietiche autologhe (ovvero provenienti dallo stesso paziente), è quella di si è quella di resettare il sistema immunitario, riportandolo indietro fino allo stadio in cui le cellule non hanno sviluppato le capacità autodistruttive (le staminali ematopoietiche sono infatti precursori del sistema immunitario). Per farlo gli approcci di questo tipo si concentravano sull’utilizzo di immunosoppressori per sopprimere il sistema immunitario maturo prima del trapianto, da cui ne sarebbe derivato uno nuovo. Nel nuovo studio però un team di ricercatori canadesi ha cercato di utilizzare un approccio più drammatico, tentanto di distruggere e non solo di sopprimere il sistema immunitario maturo del paziente sottoposto a trapianto. Nello studio sono stati coinvolti 24 pazienti di età compresa tra i 18 e i 50 anni, tutti con grado di disabilità moderato-grave e malattia in fase attiva. Prima del trapianto i ricercatori hanno sottoposto i pazienti a un ciclo pesante di chemioterapia, con busulfano, ciclofosfamide e globulina anti-timociti di coniglio. Un approccio simile a quelli già utilizzati nel campo, ma più forte rivendicano i ricercatori, grazie anche a una combinazione di molecole in grado di attraversare la barriera ematoencefalica e di distruggere così, almeno potenzialmente, le cellule del sistema immunitario mature e dannose dal sistema nervoso centrale. I risultati hanno mostrato che un approccio del genere sembrerebbe dare buone speranze. Il tasso di sopravvivenza a 3 anni libero da attività da malattia (misurato come ricadute nei sintomi, nuove lesioni e progressioni della disabilità) era di circa il 70%. Se – prima dei trapianti – le ricadute erano di circa 1,2 l’anno, nessuna ricaduta è stata osservata nel follow-up (dai 4 ai 13 anni), e solo una nuova lesione è stata trovata nelle scansioni effettuate dopo trapianto. Anche dal punto di vista della disabilità ci sono stati notevoli miglioramenti per molti pazienti, tanto che sei, dopo tre anni, sono stati in grado di tornare a lavorare o a studiare. Un paziente però è morto in seguito agli effetti della chemioterapia, e un terzo del totale ha sviluppato effetti tossici moderati in risposta alla terapia. La terapia quindi potrebbe funzionare ma non senza costi elevati per la salute. Senza considerare che lo studio ha riguardato un piccolo campione, senza controlli, ha ricordato anche Mark Freedman della University of Ottawa, che aiuta a contestualizzare i risultati dello studio di cui è a capo: “Dal momento che parliamo di un trattamento aggressivo, i potenziali benefici dovrebbero essere pesati con i rischi di potenziali complicazioni associati con i trapianti di staminali autologhe ematopoietiche, e questo trattamento dovrebbe essere offerto solo da centri specialistici con esperienza sia nel campo della sclerosi multipla che nelle terapie con staminali, all’interno di trial clinici”. In futuro, i prossimi passi sul campo saranno quelli di cercare di ridurre i rischi associati al trattamento e di capire anche quali sono i pazienti più idonei a ricevere questa terapia.Elenco degli H2 di https://www.wired.it/scienza/medicina/2016/10/25/vannoni-metodo-stamina-georgia/Davide Vannoni è tornato. A oltre un anno di distanza dal triste epilogo della vicenda Stamina, che si era chiusa con la richiesta di patteggiamento da parte del laureato in scienze delle comunicazioni Vannoni, si ricomincia purtroppo a parlare del suo trattamento a base di staminali mesenchimali (bocciato più volte dalla comunità scientifica). Stando a un servizio andato in onda sul tg de La7, infatti, Vannoni, interdetto a replicare in Italia o all’estero il metodo, starebbe somministrando le infusioni di staminali a Tbilisi, in Georgia. La notizia, in verità, era già stata comunicata dall’Ansa il 29 luglio, ma ancora non erano arrivate conferme. Oggi, la testimonianza diretta di un paziente che si è sottoposto al trattamento sembra fugare il dubbio. L’uomo che ha raccontato la sua storia ai giornalisti è affetto dalla sclerosi laterale amiotrofica (Sla) da quattro anni. “Sono stato a Tblisi tre volte”, ha detto davanti alle telecamere. “Ho fatto tre infusioni. A luglio ho fatto le prime due. A settembre ho fatto la terza. Vannoni era a Tiblisi quando c’ero anch’io, siamo anche stati a cena insieme”. Come spiega il servizio di La7, all’inizio dell’anno il paziente ha cercato Vannoni su Facebook e ha così iniziato l’avventura in Georgia, preceduto dal fratello che è andato a farsi prelevare il midollo a maggio. “C’è la soluzione da tre infusioni o da cinque infusioni”, ha continuato. “5 infusioni sono 27mila euro e 3 infusioni 18mila euro. Il discorso è che lui [Vannoni] mi ha sempre promesso e garantito che ci sarebbero stati dei risultati invece ad oggi, a distanza di tre mesi non ci sono stati. Ho parlato anche con altri malati di Sla e con nessun malato ha avuto successo”. L’ex procuratore aggiunto di Torino Raffaele Guariniello, che nella primavera del 2015 ha dato il via libera al patteggiamento di un anno e dieci mesi di pena per Vannoni, si è espresso così ai microfoni de La7: “Il patteggiamento è condizionato al fatto che non si facciano più dei reati né in Italia né all’estero”. Sul divieto internazionale, però, la questione sarebbe assai complessa. Infatti a livello giuridico si rischia di dover fare i conti con le leggi vigenti nei paesi che, eventualmente, possono ospitare le miracolose infusioni.  All’epoca del patteggiamento, Vannoni è stato a processo per associazione a delinquere e truffa. In totale sono sei le persone legate a Stamina a cui è stato concesso il rito alternativo vincolato, appunto, alla sospensione immediata delle attività in Italia e all’estero. Più tardi, nel giugno 2015, il Gup torinese Giorgio Potito ha definito il metodo Stamina “una truffa scientifica” nelle motivazioni della condanna a sei mesi di Carlo Tomino, componente dell’Agenzia italiana del farmaco (Aifa), e a due anni di Marcello La Rosa, ex socio di Davide Vannoni. In seguito alle prime querele dei pazienti traditi e all’avvio delle indagini, Vannoni aveva cercato di costruirsi una nuova identità fondando Stamina Foundation, un’organizzazione dichiaratamente senza scopi di lucro atta a “sostenere la ricerca sul trapianto di cellule staminali mesenchimali e diffondere in Italia la cultura della medicina rigenerativa”. Il trattamento che viene adesso somministrato in Georgia funziona così: dopo un primo intervento per il prelievo delle cellule del midollo osseo, queste vengono messe in coltura (Vannoni non ha mai divulgato dettagli relativi al protocollo seguito in questa fase) e infine ci si sottopone a un’iniezione lombare per mettere il preparato in circolo e nel sistema nervoso. Il metodo Stamina, ideato per curare malattie neurodegenerative attraverso iniezioni di staminali mesenchimali, ha ricevuto solo bocciature sia dalla giustizia che dalla comunità scientifica. Ricordiamo infatti che, già nel 2013, il Comitato scientifico incaricato di esprimere un parere sulla metodica ne aveva negato all’unanimità la consistenza scientifica.Elenco degli H2 di https://www.wired.it/internet/social-network/2016/02/29/why-we-post-come-usiamo-social-media/Di: Philip Di Salvo
Pubblicato: febbraio 29, 2016 Sono gli utenti a plasmare il modo in cui i social media sono utilizzati e si evolvono, e non il contrario. A raccontarlo, i risultati complessivi di un grande progetto di ricerca che, con le lenti dell’etnografia – l’osservazione sul campo – e dell’antropologia ha guardato a come le piattaforme social vengono utilizzate in otto paesi del mondo, in piccole comunità ben definite. Coordinato dallo University College London (Ucl), il progetto Why We Post ha avuto una durata di 15 mesi, spesi sul campo da un team di antropologi in diversi contesti sociali peculiari in del pianeta dalla Cina, fino a una piccola città del Salento, passando per il Brasile e il confine turco-siriano. Scopo finale della ricerca era guardare agli usi peculiari delle piattaforme social che vengono attuati in questi luoghi e il modo in cui le persone hanno inventato nuovi usi, connessi alle proprie esigenze sociali. Il video riassuntivo del progetto “Why We Post”:
 I risultati sono vastissimi (qui un riassunto) e hanno a che vedere con dieci diversi ambiti di applicazione e utilizzo dei social media, come l’educazione, la privacy, l’educazione, le questioni di genere, l’utilizzo delle immagini, la relazione tra offline e online e il coinvolgimento politico delle persone. Oltre all’osservazione sul campo, ci sono diversi risultati interessanti che emergono da un sondaggio che ha ottenuto risposte da oltre 1100 persone in tutti i paesi coinvolti. Un primo argomento che salta all’occhio riguarda la socialità nel complesso: secondo i risultati, in tutti i paesi analizzati, i social media hanno avuto un impatto importante e positivo sul numero di persone con cui i partecipanti sono in contatto. In sostanza, no, i social media non ci rendono più soli, nonostante quello che pensiamo:  “I social media sono più che comunicazione: sono anche un posto in cui viviamo”, spiega a Wired Daniel Miller, Antropologo dell’Ucl e coordinatore del progetto, “Hanno certamente le loro peculiarità, ma allo stesso modo della ‘vita di ufficio’ in contrapposizione alla ‘vita privata’: non diremmo mai che la prima non è ‘vita vera’. Pertanto, anche se ci sono delle differenze, dovremmo smettere di pensare che l’online sia meno vero che l’offline”, continua Miller. Questo approccio è spiegato dai ricercatori con il concetto di “scalable sociality”, secondo il quale le sfumature di intensità nelle relazioni umane sono molteplici, sia online che offline, e le piattaforme digitali possono inserircisi e annullare quella separazione, ormai vetusta: “WhatsApp, ad esempio, rappresenta un’espansione del mandare messaggi dall’impostazione da uno-a-uno all’uso dei gruppi, mentre Instagram continua a muoversi dal broadcasting puramente inteso a gruppi di persone di scala diversa”, spiega Miller. Questo è visibile in modo chiaro in diversi dei numerosissimi risultati delle osservazioni sul campo svolte dal team. Tra gli altri, un aspetto della ricerca ha interessato anche un gruppo di operai cinesi di una cittadina industriale nei pressi di Shanghai: per loro, ad esempio, i videogiochi online sono un modo per avere connessioni con i propri amici che altrimenti non potrebbero in alcun modo conservare, per via dei ritmi di lavoro e la sostanziale assenza di vita sociale. Per queste persone, scrivono i ricercatori, le esperienze virtuali sono un modo per essere “più umani”. Per quanto riguarda la questione della privacy, invece, emergono risultati molto interessanti dal corpus completo dello studio. Spiega Daniel Miller: “In Inghilterra le persone sono ossessionate dalla privacy sui social media, ma se si guarda in una prospettiva storica, questo avveniva già con la riservatezza in casa rispetto agli occhi dei vicini. In contrasto, in Cina e in India, le persone vivono in famiglie molto estese, dove nessuno bussa alle porte o dorme in stanze separate. In questi contesti molte persone vedono i social media come la prima vera esperienza di privacy della loro vita”. L’uso dei social media in Inghilterra, riassunto in video:
 Questo significa che il concetto stesso di privacy, almeno su un piano personale e non relativo al modo in cui le piattaforme e le aziende trattano i dati, è liquido e cambia di prospettiva a seconda del contesto geografico e sociale in cui viene definito. Un esempio emblematico che emerge dai risultati dello studio è quello del modo in cui le persone gestiscono le proprie password degli account sui social media. Nel caso della Cina, questa volta rurale e non industriale e l’India, ad esempio, condividere le credenziali di accesso con parenti e amici è pratica molto più comune che in Inghilterra, Brasile e Italia:  Il sondaggio generale, come tutte le analisi etnografiche sul campo, si è anche concentrato sul rapporto tra social media e impegno politico. I risultati sono piuttosto interessanti perché in tutti i contesti analizzati la stragrande maggioranza dei partecipanti ha risposto che i social media non hanno avuto un impatto considerevole in questo senso. “Quello che abbiamo riscontrato è che i social media sono principalmente sociali”, spiega ancora Daniel Miller, “La preoccupazione principale degli utenti riguarda l’impatto di quello che postano sulle persone che sono a loro connesse o che sono loro amici”. Per questo, continua l’antropologo, “la politica è spesso un argomento divisivo che può essere origine di scontri e discussioni. Per questo c’è meno politica sui social media di quello che ci si potrebbe aspettare“.  Oltre ai risultati complessivi, Why We Post è composto anche dai diversi studi etnografici sul campo, dai quali emergono usi dei social media peculiari per ogni paese analizzato. Sarebbe impossibile qui fornire una carrellata completa, ma alcuni sono emblematici. Il primo proviene dal Cile ed è un adattamento locale alla pratica del scattare selfie: dall’osservazione svolta in una città di 100mila abitanti nella parte settentrionale del paese, ad esempio, è emerso come sia diffusa la pratica di scattarsi “footie”, autoscatti che ritraggono i piedi degli autori in contesti di riposo: Secondo Dan Miller, adattamenti e modifiche di pratiche social già riconosciute avvengono di nuovo per via della capacità che gli utenti hanno di cambiare il modo in cui i social media sono percepiti e utilizzati e, non a caso, il libro centrale e riassuntivo della serie si intitola proprio per questo How the world changed social media. Questo è visibile sia nel modo in cui vengono utilizzate le piattaforme sia i suoi linguaggi, selfie incluse: “Spesso la stampa suggerisce che le selfie siano uno strumento narcisistico per i teenager, ma ad esempio ho scoperto di recente che per i monaci buddisti in Birmania essi sono un modo di associare se stessi con le statue del Buddha che hanno visitato”. Il progetto “Why We Post” ha interessato anche l’Italia, grazie al lavoro che il ricercatore Razvan Nicolescu ha svolto in una città del Salento, il cui nome non è rivelato per ragioni di privacy. I risultati della sua ricerca sul campo, passata a osservare come gli abitanti utilizzano i social media, saranno inclusi in un libro dedicato, incluso nella serie Why We Post. Ne è emerso uno scenario nel quale gli utenti utilizzano i social per rinforzare il proprio ruolo nella comunità in due modi, che rispecchiano la socialità offline dell’ambiente analizzato: pubblici, per creare solidarietà sociali ideali e, dall’altro, modalità private che, invece, puntano a rafforzare i legami solidi e tradizionali. “Quello che emerge in modo chiaro dalla ricerca svolta in Italia è che, contrariamente al credo comune, i social media non ci stanno rendendo più narcisisti o individualisti: al contrario stanno rafforzando il nostro senso di comunità e famiglia“, spiega a Wired Nicolescu. “La ricerca ci ha anche aiutato a vedere il ruolo che i social hanno nel rafforzare le norme esistenti e nel riflettere la struttura sociale”, continua l’antropologo. “In particolare, le tecnologie digitali aiutano le persone, nel caso italiano, a risolvere molte tensioni tra le norme sociali molto rigide, gli ideali collettivi e le vite che, invece, vivono davvero”. Ad esempio, i risultati dell’etnografia mostrano che gli abitanti del paese analizzato non usano Facebook per relazionarsi con le proprie amicizie già consolidate, ma per tentare modalità di socialità altrimenti non disponibili. Questo perché non servono piattaforme tecnologiche per perpetuare quello che la società crea già di per sé: “Facebook non offre tanto alla vita di comunità perché le persone hanno già molteplici modi di esprimerla offline. Al contrario, Facebook diventa importante quando risolve alcune questioni o diventa un buon modo di esprimere certe relazioni o quando le cose si mettono male, come nel caso di famiglie separate dal lavoro o dall’immigrazione o quando qualcuno con un altro grado di istruzione si sposta altrove”, spiega Nicolescu. Anche nel caso italiano, sono la vita offline e gli usi che gli utenti fanno delle piattaforme ad adattare i social media: “Se i nuovi media erano stati visti come tecnologie di liberazione e molto creative, nella regione in cui ho lavorato, essi sono soggetti continuamente alle norme esistenti”, spiega Nicolescu, “Facebook, ad esempio, è troppo pubblico e le persone devono rinforzare le norme sociali anche qui”. Allo spettro opposto, invece, c’è WhatsApp, “che viene utilizzato per relazioni più private e intime, ma ancora in un modo diverso da come si comporterebbero offline”. Questo si traduce nell’uso dei social media non tanto come uno strumento di cambiamento, quanto piuttosto di rinforzamento dello status quo sociale preesistente offline e la ricerca di un'”adeguata” presenza online da parte degli abitanti del paese analizzato ha a che vedere di nuovo con questo, con il perpetuare dinamiche sociali preesistenti. Guardando al progetto Why We Post nel complesso si nota quanto la tendenza a pensare che i social media siano monoliti uguali a loro stessi in tutto il mondo sia in realtà poco concreta. Inoltre, la mole di risultati indica chiaramente come, con buona pace del determinismo tecnologico e certa retorica dell’innovazione, siano le persone a plasmare gli usi della tecnologia e non il contrario. “Guardando tutti i luoghi in cui abbiamo realizzato “Why We Post””, spiega ancora Nicolescu, “possiamo vedere come non sono i servizi che fanno qualcosa per essere adottati, ma sono al contrario le persone che decidono quali servizi si adattano meglio ai loro bisogni e se ne appropriano di conseguenza”. Il progetto Why We Post è una raccolta di 11 volumi in open access, tre dei quali già pubblicati: il volume riassuntivo, quello dedicato alla Turchia (a cura dell’Italiana Elisabetta Costa) e quello incentrato sull’Inghilterra. Il sito del progetto è disponibile qui, anche in Italiano, come in tutte le lingue dei paesi coinvolti nello studio. Why We Post sarà anche un corso online in diverse lingue, dedicato all’utilizzo dei social media. I libri saranno scaricabili in pdf gratuitamente. I grafici e le immagini sono tratte dal libro “How The World Chabged Social Media” (UCL Press)Elenco degli H2 di https://www.wired.it/internet/social-network/2016/04/04/social-media-italia-crollo-twitter-esplode-snapchat/La Total Digital Audience fornita da Audiweb e Nielsen comprende gli accessi ai social media fatti da fisso e da mobile, epurando i numeri dalle sovrapposizioni. C’è un asse di scostamento di cui tenere conto, come sottolinea Vincenzo Cosenza sul proprio blog. Per le connessioni da fisso si considera un pubblico che parte dai 2 anni di età, mentre per quelle da mobile la fascia è definita tra i 18 e i 74 anni. “Un grande problema di Audiweb è quello di non riuscire a catturare i comportamenti dei minori da mobile, questo rende i dati meno completi”, dice il social media strategist di Blogmeter. Un problema tecnico che comporta differenze palesi soprattutto per i grandi numeri. Secondo Menlo Park, gli italiani che accedono a Facebook su base mese sono 27 milioni, stando ai dati Audiweb sono poco più di 23,5 milioni (23,6 milioni durante il solo mese di dicembre 2015). Altre differenze, questa volta non misurabili, sono con ogni probabilità da addebitare a Snapchat che è cresciuto del 151%, percentuale orfana di quei tanti giovanissimi che si collegano da mobile. Lo stesso vale per Twitter e Instagram. Facebook negli ultimi due anni ha perso aficionados e Cosenza interpreta questi dati come un normale assestamento, soprattutto considerando che è il social media su cui passiamo più tempo, ben 12 ore al mese. Instagram cresce del 14% rispetto al 2014 e, con 8 milioni di utenti, supera i 6,4 milioni di utenti attivi Twitter (in calo del 28%). Crescono sia Tumblr (+20%) sia Pinterest (+15%) mentre LinkedIn perde il 16% di audience. Google+, pur restando il secondo social media, perde il 22% di accessi. “Brin e Page non hanno mai creduto fino in fondo nel progetto, ed è diventato un network di interessi e gruppi”, continua Cosenza. Ogni mese passiamo 12 ore e 20 minuti su Facebook, seguito a distanza siderale da Snapchat, ibrido tra instant messenger e social media, al quale dedichiamo 2,5 ore. “Sono dati utili a capire le logiche di comunicazione utili anche agli sforzi di marketing”, conclude Cosenza. Il futuro, appare chiaro, è difficilmente prevedibile. “L’unica certezza è Facebook, destinato a rimanere a lungo”.Elenco degli H2 di https://www.wired.it/internet/social-network/2016/05/27/social-network-stadio-finale-champions/Dimenticate il Maracanà. Lasciate perdere il Camp Nou. Ignorate Wembley. Lo stadio più grande del mondo sono i social network, Facebook in primis. “Facebook è la più grande comunità di appassionati di sport del mondo, con oltre 650 milioni di utenti connessi alla pagina di un campionato, una squadra o un atleta”, spiega Dan Reed, Head of Global Sports Partnerships a Menlo Park. “E il calcio è il più seguito, con oltre 400 milioni di utenti”. Le persone sono affamate di sport e i social network lo sono di interazioni. Uno dei banchetti ideali a cui incontrarsi è la finale della UEFA Champions League: “La scorsa finale ha fatto registrare 28 milioni di persone collegate e 76 milioni di interazioni durante la partita”, rispettivamente 32 milioni su Facebook e ben 44 milioni su Instagram. “Un numero simile a quello di altri eventi sportivi di portata globale”. Quest’anno si punta a superarli, ma il record assoluto spetta ai mondiali di due anni fa. “Brasile 2014 ha generato un picco di 350 milioni di interessati e 3 miliardi di interazioni durante l’intera manifestazione”. Su Instagram la fotografia è la stessa. “Tra i 100 account più seguiti sulla piattaforma 1 su 5 è collegato al calcio, e 1 su 4 allo sport in generale”, illustra Brandon Gayle, Head of Global Sports Partnerships di Instagram. “Escluso il pallone, le discipline più seguite sono i soliti sospetti come pallacanestro, football americano e cricket, ma anche il Wrestling – anche se forse per qualcuno è una sorpresa”. Che si tratti di Superbowl, di finali NBA, di Copa America o di campionati Europei l’intento non cambia. “Se ingaggiamo i fan, se diamo loro contenuti rilevanti e di qualità che quindi tornano costantemente a cercare sui nostri canali, è un bene sia per i nostri affari sia per i nostri partner”, concordano Brandon e Dan. “Per questo lavoriamo spalla a spalla con squadre, leghe professionistiche, emittenti e trasmissioni, per allargare il pubblico”. Più audience significa più interazioni, uno dei parametri chiave per misurare il successo dei contenuti. In un contesto simile soluzioni come i video 360 o le dirette sono un alleato importante. Ideale per fare sessioni di domande e risposte tra campioni e tifosi o per permettere agli spettatori di percorrere il tunnel degli spogliatoi, seguire l’ingresso in campo della coppa ed essere accanto alla squadra durante i festeggiamenti.  Senza trascurare il diritto d’autore. “Abbiamo un efficace sistema di protezione e un nuovo strumento chiamato Rights Manager che permette per esempio alla UEFA di marcare i propri contenuti sulla piattaforma in modo che qualsiasi streaming non autorizzato venga rilevato automaticamente e vengano offerte una serie di opzioni su come trattare l’infrazione”. Anche su Instagram la componente video è in prepotente aumento. Il tempo dedicato ai filmati è cresciuto del 40%, quello destinato alla loro produzione del 20% per le leghe, del 22% per gli atleti, del 24% per i media e del 36% per le squadre. Lo smartphone diventa così un secondo schermo a tutti gli effetti, con l’85% degli spettatori abituato a usare Facebook per commentare eventi in diretta. La chiave per catturare l’attenzione è la condivisione di materiali esclusivi, originali e dedicati: un aspetto ormai prioritario per molti protagonisti del pallone. Tra loro il più seguito è Cristiano Ronaldo, top player in campo e capocannoniere anche sui social con oltre 110 milioni di like su Facebook e quasi 60 milioni di follower su Instagram. Tra le due finaliste invece il primato spetta al Real Madrid, più popolare dell’Atletico e sempre impegnato in un Clasico virtuale con i rivali del Barcellona, fatto di continui sorpassi in classifica intorno a quota 90 milioni di fan. L’arma in più per vincere il duello è spesso nei piedi e nell’estro dei fantasisti. In particolare su Instagram. “La community è caratterizzata da un alto tasso di creatività visiva. Fan art e video acrobatici di appassionati che emulano le gesta dei loro campioni sono la nostra marcia in più”, conclude Brandon. Sul pronostico del match invece non si sbilanciano né lui né Dan. “Non so come andrà a finire, ma so che è la mia prima finale di Coppa dei Campioni dal vivo quindi non vedo l’ora di vederla”. L’entusiasmo c’è e si respira nell’aria. Le interazioni sono pronte a seguirlo.Elenco degli H2 di https://www.wired.it/internet/social-network/2017/06/20/10-social-network-dimenticati/Il mondo dei social network sembra vasto tanto quanto spietato. Al di là di alcune piattaforme giganti come Facebook, Instagram, Twitter (pur coi suoi problemi) e Pinterest, tutte le altre alternative sono un po’ in affanno. Fra alcune buone promesse come Snapchat che vengono subito cannibalizzate dai colossi e vecchi modelli che resistono imperterriti come Tumblr, il mercato delle piattaforme sociali è duro e imprevedibile. Eppure le reti sociali non sono nate con Facebook: fin dai primi anni Duemila diversi tentativi come Friendfeed e MySpace popolavano una crescente Internet globale. E anche oggi startup e imprese illuminate cercano di trovare l’alternativa vincente a strade fin troppo battute. Ma molto spesso le vecchie glorie e i nuovi tentativi finiscono nel dimenticatoio, spazzati via dall’oblio istantaneo dei millenial. Ecco però alcuni dei social network dal passato più o meno glorioso che ci piace ricordare mentre tutti gli altri, invece, se ne stanno dimenticando.Elenco degli H2 di https://www.wired.it/internet/social-network/2016/10/13/crisi-social-network-celebrita-linus-chiude-il-blog/Quella che andiamo a raccontare probabilmente non è una vera e propria notizia, però ci permette di fare alcune considerazioni su celebrità e comunicazione, social media e haters. La non-notizia è che Linus, direttore artistico di Radio Deejay, ha deciso di abbandonare il proprio blog personale contenuto all’interno del sito del network radiofonico. Lo ha fatto attraverso un videopost intitolato Arrivederci in cui spiega le motivazioni di questa decisione: “Mi mancherà come occasione per raccontare cose di me che non dico a nessuno” racconta Linus davanti alla telecamera “Ma odio questa sensazione da giorno della marmotta, il continuare a ricalcare un cliché, e poi l’imbarbarimento nel commento dell’attualità che genera polemiche antipatiche”. Poi continua: “Come tutti sto diventando grande (vecchio), quindi come per tutti aumentano gli acciacchi fisici e nervosi e ho notato nella mia scrittura emergevano sopratutto questi”. Il suo blog era una delle pagine più lette all’interno del sito del network, sicuramente una delle più commentate, specialmente in quei post in cui rilevava qualche aspetto della sua vita personale o quando motivava certe sue decisioni editoriali della radio. Linus non è certo un pioniere del blogging, anzi, si è avvicinato alla scrittura in rete quando ormai il fenomeno era già nella fase di piena maturità; tuttavia, lui come altre celebrità del mondo dello spettacolo, cercava attraverso questo spazio di trovare un contatto più intimo con il proprio pubblico. Purtroppo, come sempre più spesso accade, anche Linus come tante altri personaggi pubblici era costantemente attaccato da gruppi, il più delle volte neanche organizzati, di critici seriali, polemisti e hater di vario tipo e specie, figure come Napalm51, il meraviglioso personaggio recentemente introdotto da Maurizio Crozza nel suo show su La7. Il caso di Linus forse è il più visibile, ma non è certo il solo: molte celebrità che avevano iniziato un dialogo sincero con il proprio pubblico su Facebook o su altri social sono state costrette ad abbandonare. Forse il mondo del 2.0 e dell’engagement sta iniziando a mostrare la corda, per colpa sopratutto di quegli aspetti deleteri della cosiddetta democrazia della rete, dove tutti ben protetti dal black mirror si sentono in dovere di criticare e rovesciare in rete nevrosi e insoddisfazioni. Non è un caso che molte celebrità (anche Linus tra questi) si siano tutte spostate su Instagram, dove si condividono più immagini che pensieri e dove il fenomeno degli hater è per il momento ancora ridotto. Una specie di ritorno al passato, dove le celebrità continuano ad essere quelle icone bidimensionali lontane e irraggiungibili piuttosto che persone con cui avere l’illusione di chiacchierare del più o del meno.Elenco degli H2 di https://www.wired.it/internet/social-network/2016/12/27/snapchat-2016/Siamo ormai ai titoli di coda per il 2016. Un anno cruciale per Snapchat, che negli ultimi 12 mesi ha ampiamente ritoccato ed evoluto la sua piattaforma, ridefinendo passo dopo passo la propria relazione con le persone e i brand. Ripercorriamo le tappe principali di questo viaggio e cerchiamo di capire cosa è migliorato e quali sono invece le aree su cui lavorare. A marzo viene lanciato Chat 2.0. L’obiettivo di Snapchat è “imitare ciò che rende speciale una conversazione faccia a faccia”: una delle caratteristiche principali della nuova chat infatti è passare da una modalità di interazione all’altra, avvicinando l’esperienza vissuta tramite smartphone a quella reale di tutti i giorni. Per fare una panoramica dei servizi disponibili, lo strumento consente di chattare, videochiamare, inviare adesivi e note vocali con un semplice tocco. Un nuovo approccio alla funzione di messaggistica per l’app, che avvicina la piattaforma ai principali competitor come Facebook Messenger e Whatsapp. Siamo in una fase del 2016 in cui Snapchat cerca di arricchire l’esperienza vissuta dalle persone e di colmare il proprio gap in termini di servizio nei confronti delle altre app presenti sul mercato. Deve essere vista in quest’ottica la nascita di Ricordi, lo strumento reso disponibile all’inizio di luglio per salvare i propri Snap e le Storie. Un cambiamento quasi epocale per Snapchat, che fino a quel momento aveva fatto dell’istantaneità un manifesto differenziante. Gli utenti possono quindi intervallare contenuti live a Snap già realizzati e salvati in precedenza, costruendo la propria Storia in modo più articolato e ragionato. L’unica differenza tra le due tipologie di contenuto è una cornice bianca che caratterizza i Ricordi, con indicazione del momento in cui è stato realizzato lo Snap. https://youtu.be/nm1RfWn0tQ8 Una data da segnare con il pennarello rosso è il 2 agosto 2016, giorno del lancio a livello globale di Instagram Stories. Ma che c’entra con Snapchat, vi chiederete voi. Dopo aver lungamente corteggiato invano l’app del fantasmino giallo per farla entrare nella propria scuderia, Mark Zuckerberg ha trovato un modo più semplice e diretto per offrire lo stesso servizio: lo ha copiato. Nel giro di pochissimi mesi Instagram Stories ha già raggiunto i 100 milioni di utenti attivi giornalieri e di fatto offre un’esperienza molto simile a quella della piattaforma di Los Angeles, con il vantaggio però di avere una fanbase di partenza molto più strutturata. La risposta da parte di Snapchat non si è fatta però attendere e quasi due mesi più tardi arriva la vera rivoluzione del 2016 per il fantasmino giallo. Il 24 settembre infatti Evan Spiegel annuncia Spectacles e modifica la denominazione social in Snap Inc. Un cambiamento necessario visto che l’azienda ora non offre più un solo prodotto ma ha allargato la propria offerta proprio con il nuovo tipo di fotocamera. https://youtu.be/XqkOFLBSJR8 Gli Spectacles sono occhiali da sole con una fotocamera integrata in grado di realizzare Snap e Ricordi. Sono collegati tramite Bluetooth o wifi allo smartphone e trasferiscono direttamente all’interno dell’app quello che vediamo con i nostri occhi. Il formato del contenuto è un video circolare che può essere riprodotto su qualsiasi dispositivo. Il focus di Snapchat diventa quindi la fotocamera, come dichiarato dalla società sul proprio sito ufficiale: “Crediamo che reinventare il concetto di fotocamera rappresenti la più grande opportunità per migliorare il modo di vivere e comunicare delle persone”. Aggiustamenti, novità, vere rivoluzioni. Com’è andato quindi il 2016 in casa Snapchat? Partiamo dagli aspetti positivi. Il miglioramento della funzione di messaggistica di inizio anno ha reso la piattaforma più completa e competitiva, fornendo alle persone gli strumenti giusti per interagire con i nostri Amici. L’introduzione di Spectales inoltre ha di fatto definito una nuova modalità per produrre i nostri contenuti, mostrando ancora una volta l’anima innovativa di Snapchat. In entrambi i casi lo scopo è stato migliorare la capacità di relazionarsi delle persone, sia essa riferita ad altri soggetti o allo spazio che le circonda. Un obiettivo che potremo definire pienamente centrato solo quando valuteremo il reale impatto di Spectacles, ad oggi ancora limitato a specifiche aree geografiche. Passiamo alle note dolenti. L’anno che sta per concludersi poteva essere quello della definitiva consacrazione, visti i numeri ormai sempre più interessanti a livello globale. L’arrivo di Instagram Stories però ha rovinato i piani di Spiegel: l’app si sta avvicinando giorno dopo giorno in termini di servizio a quella del fantasmino giallo e le caratteristiche che avevano differenziato per anni Snapchat dai competitor sono ormai diventate quasi tutte disponibili anche su Instagram. È vero che le audience e la tipologia di contenuti prodotti sono differenti, ma è innegabile come molti utenti ormai considerino le due app simili in termini di servizio. Nessuna resa ovviamente: Snapchat ha ora bisogno di una nuova evoluzione che sia in grado di offrire agli utenti qualcosa di unico e divertente oltre che affinare l’esperienza attuale. Il miglioramento della funzione di ricerca, ad esempio, è necessario per trovare nuovi profili interessanti da seguire e l’inserimento di link di approfondimento all’interno delle Storie – e non solo in Discover – potrebbe attirare nuovi investitori e brand (Instagram ha già previsto questa possibilità per i profili verificati). Nuove sfide in arrivo quindi per Snapchat, con la presenza di Instagram sempre più ingombrante all’orizzonte. Spiegel però ha già dimostrato la sua capacità di sorprendere: che ci sia già qualcosa in cantiere per il 2017?Elenco degli H2 di https://www.wired.it/internet/social-network/2016/04/28/facebook-1-65-miliardi-utenti-al-mese/Facebook non molla lo scettro: ha appena annunciato i nuovi dati riguardanti l’ultimo trimestre. Gli utenti ogni mese sono 1,65 miliardi, in crescita del 3,77% sui dati del trimestre precedente (1,59 miliardi). Ottime notizie per l’azienda, che si traducono in 5,83 miliardi di dollari di introiti (finora cresciuti del 52% anno su anno) e di ricavi dello 0,77 dollari per azione. Restando in tema numero utenti sono un miliardo gli utenti mensili di WhatsApp, 900 milioni quelli di Messenger e 400 milioni quelli di Instagram.  Nell’annunciare gli aggiornamenti della community dell’ultimo trimestre, Zuckerberg ha approfittato per fare il punto sulle altre novità, come l’introduzione delle Reactions e quella, ancor più importante, di Facebook Live per tutti. Senza dimenticare le persone connesse nel mondo con Internet.org e gli oltre 50 tra giochi e app rilasciati per i visori di realtà virtuale Oculus Rift.