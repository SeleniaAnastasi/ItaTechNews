<doc url="https://www.ilpost.it/2016/03/16/alphago-intelligenza-artificiale/" parent_folder="Il Post 2016-17" id="file17861940" filename="alphago-intelligenza-artificiale">
<p> Perché la vittoria di AlphaGo è importante </p>
<p> L'intelligenza artificiale di Google ha superato il paradosso per cui sappiamo più cose di quante ne riusciamo a spiegare, racconta il New York Times </p>
<p> AlphaGo, l’intelligenza artificiale (AI) di Google DeepMind, ha battuto il campione mondiale del complicato gioco da tavolo Go in una serie di partite molto appassionante e che ad alcuni ha ricordato la sfida a scacchi tra Deep Blue, il computer di IBM, e il campione di scacchi Garry Kasparov alla fine degli anni Novanta. AlphaGo ha battuto Lee Se-dol in quattro partite su cinque a un gioco che ha molte più variabili rispetto a quelle degli scacchi, dimostrando capacità inimmaginabili fino a qualche tempo fa e che secondo gli esperti saranno alla base dei futuri sistemi informatici “intelligenti”. </p>
<p> A Go si gioca in due, davanti a una griglia 19 x 19 che viene chiamata goban. Per vincere è necessario conquistare una porzione di goban superiore a quella dell’avversario, collocando le proprie pedine sulla griglia. Ogni giocatore può catturare una o più pedine dell’avversario se riesce a circondarle completamente con le proprie pedine. Il giocatore deve quindi muoversi cercando di bilanciare la necessità di espandere il controllo sulla griglia con quella di difendersi dall’avversario. Il gioco finisce quando entrambi i giocatori passano a vicenda una mano, cosa che indica il fatto che nessuno dei due ha ulteriori possibilità di espandere il proprio territorio o di ridurre gli spazi occupati dall’avversario. Su un singolo goban ci sono 4,63 x 10170 diverse posizioni possibili, dato che fa ben capire quale sia l’enorme livello di complessità del gioco. </p>
<p> Come spiega il docente del Massachusetts Institute of Technology (MIT), Andre McAfee, con il collega Erik Brynjolfsson sul New York Times, a differenza degli scacchi “nessuno sa spiegare come si giochi a Go ai livelli più alti. Gli stessi giocatori più abili non riescono ad accedere alle conoscenze che gli permettono di giocare così bene”. Il fenomeno è conosciuto da tempo e riguarda tutti, non solo i giocatori davanti a una scacchiera: non sappiamo di preciso come facciamo a raggiungere la coordinazione necessaria per guidare un’automobile, o come riusciamo a distinguere una faccia tra centinaia di altri volti, eppure lo facciamo di continuo e bene. Lo scienziato e filosofo Michael Polanyi descrisse il fenomeno efficacemente: “Sappiamo più cose di quelle che riusciamo a spiegare”; per questo motivo per descriverlo si parla di solito di “Paradosso di Polanyi”. </p>
<p> Nonostante l’esistenza del paradosso, siamo riusciti a fare grandi cose in molti campi, compreso naturalmente quello informatico. Rendere automatiche attività complesse, come per esempio calcolare le tasse od organizzare gli orari dei voli di un’intera compagnia aerea, richiede una mole enorme di lavoro da parte dei programmatori, che devono considerare tutte le variabili possibili per fare in modo che poi i loro programmi eseguano correttamente i compiti che gli assegnano, senza essere colti alla sprovvista. </p>
<p> McAfee e Brynjolfsson scrivono che l’attuale approccio nella programmazione dei computer è molto limitante e taglia fuori molti ambiti, compreso quello di gestire una partita a Go, dove si sanno più cose di quante si riescano a spiegare, o di riconoscere oggetti comuni nelle fotografie, tradurre testi, creare interazioni tra macchine ed esseri umani in un linguaggio naturale e colloquiale come avviene tra due persone. Lo stesso Deep Blue di IBM ottenne i suoi risultati seguendo quelle soluzioni: i suoi programmatori lo riempirono di milioni di schemi su partite di scacchi, tra le quali poteva poi scegliere la mossa da fare, sfruttando la sua potenza di calcolo. </p>
<p> Per giocare a Go un approccio simile a quello di Deep Blue sarebbe stato impossibile: come abbiamo visto le combinazioni sulla scacchiera sono tantissime, talmente numerose da rendere impossibile il calcolo di tutte le alternative possibili in tempi accettabili da parte di un computer. E le cose si complicano ulteriormente col fatto che il gioco è talmente variabile da rendere complicato persino studiare la prima mossa da fare per avere qualche vantaggio sull’avversario. </p>
<p> L’articolo del New York Times spiega che cosa hanno quindi fatto gli ideatori di AlphaGo per superare il problema: </p>
<p> Le vittorie di AlphaGo dimostrano chiaramente la forza di un nuovo approccio nel quale invece di provare a programmare strategie, si costruiscono sistemi che possono imparare da soli a creare le strategie vincenti, valutando esempi di successi e fallimenti. Poiché questi sistemi non si basano sulla conoscenza umana per il compito che devono svolgere, non hanno limitazioni legate al fatto che sappiamo più cose di quante ne riusciamo a spiegare. </p>
<p> Semplificando, AlphaGo mette insieme sistemi più tradizionali, come l’utilizzo di simulatori e algoritmi di ricerca, con nuove soluzioni che di fatto permettono di superare il Paradosso di Polanyi. Il computer di Google ha utilizzato sistemi di apprendimento approfondito (deep learning), che in un certo senso imitano il modo in cui il nostro cervello impara cose nuove identificando schemi e cose rilevanti in una quantità enorme di informazioni che riceve di continuo. </p>
<p> L’apprendimento nei nostri cervelli è un processo che porta alla formazione e al rafforzamento di connessioni tra i neuroni. I sistemi di deep learning sfruttano un approccio simile, a tal punto da essere chiamati “reti neurali”. Si creano miliardi di nodi e connessioni all’interno di un software, e si utilizzano dei “set di formazione” come esempi per rendere più forti le connessioni tra i vari stimoli (una partita di Go in corso) con le risposte (la mossa successiva), poi il sistema viene esposto a un nuovo stimolo e si guarda qual è la sua risposta. AlphaGo ha anche giocato milioni di partite contro sé stesso, utilizzando un’altra tecnica che si chiama apprendimento per rinforzo, per ricordare le mosse e le strategie che hanno funzionato bene. </p>
<p> In un certo senso AlphaGo è stata una delle migliori e più promettenti dimostrazioni delle potenzialità dell’apprendimento approfondito e di quello per rinforzo, soluzioni che esistono da tempo, ma su cui ci sono ancora molte cose da capire per sfruttarle al meglio con i sistemi informatici. Le implicazioni per la pratica saranno senza precedenti entro pochi anni, secondo gli esperti di informatica, e iniziamo già ad averne qualche indizio: dai sistemi per il riconoscimento dei volti alle auto che si guidano da sole, ambiti strettamente legati al Paradosso di Polanyi, almeno per quanto riguarda noi altri, intelligenze non artificiali. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/07/28/amazon-ha-cambiato-anche-la-robotica/" parent_folder="Il Post 2016-17" id="file17861928" filename="amazon-ha-cambiato-anche-la-robotica">
<p> Amazon ha cambiato anche la robotica </p>
<p> Nel 2012 ha comprato la società che produceva i migliori robot per i magazzini e ha smesso di venderli a tutti i concorrenti, che hanno dovuto attrezzarsi </p>
<p> di Kim Bhasin e Patrick Clark – Bloomberg </p>
<p> Un magazzino di Amazon è un vortice di attività. Ci sono dipendenti che corricchiano in giro lasciando cadere oggetti dentro casse gialle e nere, altissime braccia idrauliche che alzano pesanti scatole verso delle travi, un esercito di tozzi robot arancioni che sembrano giganti dischi da hockey senzienti che scivolano sul pavimento con sopra impilati degli alti mucchi di oggetti che servono a soddisfare i desideri dei clienti, dai bestseller agli articoli da cucina. Sono i robot di Kiva, che in passato erano il gioiello dei magazzini di tutto il mondo. Per acquistare questa legione di robot, nel 2012 Amazon sborsò 775 milioni di dollari. Con l’acquisizione di Kiva Jeff Bezos, il 52enne CEO della società, ha ottenuto il controllo di un intero settore. Bezos decise di usare i robot esclusivamente per Amazon, mettendo fine alle vendite dei prodotti di Kiva ai gestori di magazzini e ai rivenditori che già li usavano. Con la fine dei loro contratti, chiunque non sia Amazon ha dovuto trovare altre opzioni per rimanere al passo della sempre più alta domanda di velocità da parte dei clienti. Il problema è che non c’erano altre opzioni: c’era Kiva e basta. </p>
<p> Ci sono voluti quattro anni, ma oggi una manciata di startup sono finalmente pronte a rimpiazzare Kiva e rifornire i magazzini di tutto il mondo con dei nuovi robot. I robot Kiva di Amazon hanno dimostrato che questo tipo di automazione è più efficiente rispetto a una forza lavoro composta interamente da esseri umani. I nuovi robot hanno un aspetto diverso, in parte perché il settore sta ancora sperimentando e in parte per questioni legate ai brevetti. Alcuni di loro recuperano gli oggetti dagli scaffali, mentre altri si spostano velocemente con i loro touchscreen. Tutti, però, servono a far risparmiare soldi ai rivenditori, che cercano di fare arrivare i loro prodotti a casa dei clienti il più in fretta possibile. </p>
<p> Nei magazzini di Amazon in giro per il mondo ci sono circa 300mila robot Kiva che si muovono rapidamente. Secondo Dave Clark, il vice presidente responsabile per le operazioni globali e il servizio clienti di Amazon, l’arrivo dei robot ha ridotto di circa il 20 per cento le spese operative della società. Stando a un’analisi di Deutsche Bank, i robot fanno risparmiare ad Amazon 22 milioni di dollari in costi di logistica. Portare i Kiva nei circa cento centri di distribuzione della società che non li usano farebbe risparmiare alla società altri 2,5 miliardi di dollari. «Per avere successo nel settore dell’e-commerce bisogna essere sofisticati all’interno dei magazzini», ha detto Karl Siebrecht, CEO di Flexe, che si definisce l’Airbnb dei magazzini. Amazon è stata la prima società ad accettare la sfida di mettere in un’unica scatola per la consegna a domicilio tutti gli articoli ordinati, per esempio. Con la crescita dell’e-commerce nel settore del commercio al dettaglio, oggi sono più società a farlo. «Le argomentazioni a favore dell’automazione nel settore stanno aumentando», ha detto Siebrecht. </p>
<p> Amazon, però, è l’unica società a usare questa tecnologia su larga scala, in gran parte grazie a Kiva. Nei magazzini dei maggiori rivenditori del mondo, come Walmart, Macy’s e Target, i sistemi robotici non sono ancora così diffusi. Queste società si affidano ancora al metodo tradizionale, gli esseri umani: stuoli di persone che si occupano di prendere gli articoli, impacchettarli e poi piazzare le scatole su i nastri trasportatori. I nuovi produttori di robot hanno un potenziale mercato spalancato davanti a loro. Le società che si occupano di logistica e gestiscono da sole i propri magazzini hanno iniziato a progettare sistemi di automazione, quando ingegneri ambiziosi si sono accorti del buco aperto da Bezos nel mercato e hanno deciso di occuparlo. Alcuni ex dipendenti di Kiva hanno fondato una startup. La gara per l’automazione è iniziata. </p>
<p> Il moderno magazzino è una scatola rettangolare con soffitti alti 12 metri, aree di carico su entrambi i lati e, spesso, migliaia di parcheggi per i dipendenti, che durante la stagioni dello shopping aumentano. Di recente i rivenditori hanno chiesto una cosa nuova: dei pavimenti che si avvicinino all’idea platonica di piattezza, una caratteristica che facilita la vita agli esperti di tecnologia che gestiscono la flotta di robot del magazzino. Nonostante l’automazione sia da tempo una minaccia che incombe sugli operai dell’industria, ci sono dei buoni motivi per pensare che la loro situazione stia per peggiorare. Stando ai dati destagionalizzati dell’ufficio statistico del Dipartimento del Lavoro americano, a maggio negli Stati Uniti i lavoratori impiegati in magazzini erano 856mila. Il loro stipendio medio è circa 12 dollari l’ora, ha detto David Egan, capo della ricerca industriale per il continente americano della società immobiliare commerciale CBRE Group. Gli aumenti al salario minimo presi in considerazione e applicati negli Stati Uniti a livello statale potrebbero fare aumentare il costo del lavoro, soprattutto in aree vicine ai centri cittadini, zone molto richieste dai rivenditori che cercano di raggiungere Amazon nel settore delle consegne fatte lo stesso giorno dell’ordine. </p>
<p> Investire in centri di distribuzione automatizzati potrebbe offrire alle società un vantaggio per questo tipo di incertezza, ma a farne le spese sarà un numero sempre maggiore di americani che fanno affidamento sui lavori nei magazzini per sopravvivere. I robot non sono solo in grado di ridurre i costi per il personale sul lungo termine, ma possono anche tutelare i datori di lavoro dalla carenza di personale, una prospettiva particolarmente inquietante per i rivenditori più grandi nel periodo natalizio. I robot possono contribuire ad aumentare la velocità, la precisione e la produttività per metro quadro, in un periodo in cui la crescita dell’e-commerce ha fatto alzare gli affitti degli edifici a uso commerciale. </p>
<p> Tutto questo ha spinto i gestori dei magazzini a sperimentare nuove forme di automazione. «Alcune società la stanno adottando su larga scala, e la maggior parte ha almeno un progetto pilota in una zona limitata o in un magazzino», ha detto Raj Kumar, socio della società di consulenza AT Kearney. Come la catena di negozi al dettaglio americana Walmart, che usa i robot per spedire i vestiti acquistati sul suo sito e-commerce, ha detto Kumar. Walmart sta sperimentando anche l’uso di droni per fotografare gli scaffali dei magazzini, che fanno parte di una strategia per ridurre il tempo necessario per catalogare l’inventario. «I magazzini sono posti molto tecnologici», ha detto Bruce Welty, cofondatore e presidente di Locus Robotics, una società che ha sviluppato robot pensati per lavorare insieme, e non sostituire, gli essere umani. «Perché l’automazione è l’unico modo per eliminare dei costi», ha detto. </p>
<p> Locus è una società staccatasi da Quiet Logistics, che possiede due magazzini in Massachusetts, che fa da punto di passaggio per i prodotti di e-commerce che vengono distribuiti nel corridoio nordorientale degli Stati Uniti. Welty e i suoi cofondatori avevano basato la loro attività di distribuzione sui robot Kiva. Avevano sviluppato software intorno ai robot per migliorarne l’efficienza nello spostamento delle merci per rivenditori come Zara, Gilt e Bonobos. Ma poi Amazon ha fatto saltare tutto. «Una volta dissi al mio consiglio di amministrazione, per caso, quasi per scherzo: “Saremmo davvero fregati se Amazon si comprasse questa società”», ha raccontato Welty. «Ma non avrei mai pensato che sarebbe successo davvero». Una mossa del genere, il ritiro di massa di uno specifico tipo di tecnologia, non aveva precedenti nel settore dei magazzini. Di solito una società ne compra un’altra e continua a vendere la tecnologia ai clienti tradizionali. In fondo è lì che stava il guadagno. Ma non per Amazon, che ha voluto tenere per sé i robot di Kiva. </p>
<p> All’inizio del 2014, Quiet Logistics ha deciso di fare il grande salto. Invece di usare la tecnologia di un’altra società ne avrebbe sviluppato una sua. Welty ingaggiò una squadra di esperti di robotica e ingegneri. Nel giro di un anno avevano sviluppato un prototipo. Nel giro di due, Locus era operativa, e si distaccò per diventare una società a sé stante. A maggio Locus ha raccolto otto milioni di dollari in finanziamenti. Per ora il ronzio dei suoi robot si può sentire solo nei corridoi dei magazzini di Quiet Logistics, ma la società dice di aver raggiunto accordi con tre importanti rivenditori per progetti pilota che potrebbero essere avviati entro la fine dell’estate, e di avere in programma di aggiungere una dozzina di magazzini l’anno prossimo. I robot di Locus sono molto più piccoli di quelli di Kiva: dalla base circolare parte un supporto con una piattaforma su cui inserire le ceste piene di merci. I robot hanno un touchscreen ad altezza petto, una sorta di podio su ruote, che permette loro di far sapere ai dipendenti di cosa hanno bisogno. Invece di trascinarsi dietro intere ceste di prodotti, i robot si spostano rapidamente verso i dipendenti del magazzino, a cui comunicano cosa prendere. I dipendenti umani – ogni persona è responsabile di una determinata zona – recuperano gli oggetti e li danno ai robot, che quindi si spostano verso il punto successivo. In questo modo le persone non si sfiancano camminando ogni giorno per chilometri, e il magazzino non è rallentato da nastri trasportatori capaci solo di spostare un oggetto da un determinato punto a un altro. Forse questo è l’esempio della perfetta armonia lavorativa tra esseri umani e robot. </p>
<p> Fetch Robotics, una società di San Jose, in California, produce robot per i magazzini che sono in grado di seguire i dipendenti e raccogliere gli oggetti che prendono dagli scaffali. Harvest Automation, di Billerica, in Massachusetts, ne vende una versione simile. Anche in Europa ci sono società specializzate in sistemi di automazione di vecchia generazione, spesso basati sui nastri trasportatori e metodi per spostare la merce tramite navette che viaggiano su binari. Mentre molti dei nuovi sistemi si concentrano sullo spostamento dei prodotti, un’intera generazione di robot sta provando ad automatizzare il processo di raccolta degli oggetti dagli scaffali usando metodi più agili. Come Toru, per esempio, un robot creato dalla società tedesca Magazino capace di prendere singoli oggetti dagli scaffali. Oppure 6 River Systems, una startup di Boston fondata da ex dirigenti di Kiva, che attualmente sta svolgendo alcuni programmi pilota per dei nuovi prodotti non ancora svelati. «La quantità di opportunità è incredibile», ha detto Welty parlando della concorrenza. «Kiva ha aperto la strada, ma ha fatto il lavoro solo in parte». </p>
<p> Amazon sembra averlo capito. Quando gli altri magazzini diventano più efficienti, deve farlo anche Amazon. Nel suo laboratorio di robotica, che si trova in un complesso industriale costruito nei boschi di North Reading, in Massachusetts, e circondato da aziende di elettronica e biofarmaceutica nel cuore tecnologico dello stato, Amazon sta sviluppando sistemi di automazione di ogni tipo nella speranza di ridurre i costi e accelerare la logistica. Insieme ai Kiva, Amazon sta lavorando anche sui droni: e questi sono solo i progetti di cui la società ha parlato. «Non ho idea di dove voglia arrivare Amazon», ha detto Jason Helfstein, analista di Oppenheimer & Co., «Svilupperanno veicoli autonomi? Camion che si guidano da soli?». </p>
<p> A marzo le società di robotica hanno partecipato in massa a una conferenza segreta organizzata da Amazon in California. Nel corso di tre caldissimi giorni nel resort Parker Palm Springs, i partecipanti hanno seguito conferenze e seminari su qualsiasi argomento, dall’intelligenza artificiale all’esplorazione dello spazio. C’erano rappresentanti di Intel e Toyota Motors, esperti di robotica da società di ogni tipo, e accademici dalla vicina University of California-Berkeley fino alla lontana Zurigo. C’era anche Bezos, che sorseggiava whiskey single-malt, chiacchierava con gli ospiti e si presentava sul palco delle conferenze indossando un esoscheletro. Ha partecipato anche il regista Ron Howard (che, tra gli altri, ha diretto Apollo 13), e si sono viste braccia robotiche che duellavano con spade laser di Star Wars. Amazon offriva uva e bevande su tavoli installati sopra a robot Kiva arancione chiaro. Agli ospiti era stato chiesto di non diffondere dettagli sulla conferenza, e Amazon non ha parlato delle sue strategie nel campo della robotica. Negli ultimi quattro anni i suoi dirigenti non hanno quasi mai parlato dell’acquisizione di Kiva, ma ci sono rare occasioni in cui Bezos racconta piccoli particolari di altri progetti che hanno a che fare con quelli di robotica. Nel 2014, Bezos aveva detto che la flotta di droni di Amazon era arrivata alla sua decima o undicesima versione, mentre a giugno ha reso noto che Amazon sta lavorando da quattro anni sull’intelligenza artificiale, a cui oggi dedica oltre mille dipendenti. «L’impatto che avrà sulla società nei prossimi vent’anni sarà enorme». Quest’anno Amazon ha cambiato il nome di Kiva. Ora la nuova divisione della società, Amazon Robotics, sta cercando un capo che possa contribuire a sviluppare una «piattaforma robotica», stando a quanto riportato nell’offerta di lavoro pubblicata su Linkedin. </p>
<p> Per quanto promettente possa essere tutta questa tecnologia, i robot non rimpiazzeranno del tutto i magazzini gestiti dagli esseri umani, almeno per ora. La componente umana è ancora considerata migliore per i lavori importanti, come assicurarsi che il giusto prodotto finisca nella scatola giusta. Alcuni nuovi sistemi di automazione sono in grado di prelevare i prodotti dagli scaffali. È il caso di IAM Robotics, una società di Pittsburgh, in Pennsylvania, che usa veicoli che si guidano da soli su cui è montato un braccio ruotante capace di afferrare con una ventosa oggetti anche piccoli quanto un portapillole. Anche questo approccio ha però bisogno di un essere umano che riempa gli scaffali, in modo che il processo di selezione dei robot sia preciso, ha raccontato Dean Starovasnik, della società di consulenza Peach State Integrated Technologies. Circa la metà della forza lavoro di Amazon svolge lavori banali e faticosi che comportano lo spostamento della merce, l’equivalente di rifornire gli scaffali in un supermercato. È un lavoro duro, e i dipendenti spesso si fanno quasi 20 chilometri durante una giornata lavorativa. Con lo sviluppo dei nuovi robot destinati soprattutto a magazzini e-commerce con grandi inventari e complesse operazioni di imballaggio, sono queste le persone che rischieranno di più di perdere il lavoro. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/05/25/apple-siri-casa/" parent_folder="Il Post 2016-17" id="file17861935" filename="apple-siri-casa">
<p> Apple lavora a un Siri per la casa </p>
<p> Per fare concorrenza a Echo di Amazon e al nuovo Google Home: l'assistente personale Siri sarà inoltre aperto agli altri sviluppatori, dice un sito di solito ben informato </p>
<p> Apple sta lavorando a un nuovo dispositivo per la casa che farà concorrenza a Echo di Amazon e al più recente Google Home, annunciato una settimana fa e in arrivo entro fine anno. L’azienda è inoltre al lavoro per rendere più aperto il suo assistente personale Siri, in modo che gli altri sviluppatori possano aggiungere le funzionalità delle loro applicazioni e renderlo più intelligente (o meno stupido). Come avviene quasi sempre con le cose che riguardano Apple, le notizie non sono ufficiali, ma sono state diffuse dal sito The Information che di solito ha fonti interne alla società molto affidabili. Mentre il concorrente di Echo richiederà ancora tempo per essere messo in vendita, l’apertura di Siri potrebbe essere già annunciata il prossimo 13 giugno durante l’evento programmato da Apple in apertura della sua Worldwide Developers Conference, di solito dedicato alle novità legate ai sistemi operativi e al software in generale. </p>
<p> Echo e gli altri Alla fine del 2014 Amazon ha sorpreso tutti mettendo in vendita Echo, un cilindro nero da tenere in casa che si collega al WiFi e che può essere usato per varie attività, dall’ascoltare la musica ad avere informazioni sul meteo, o per ordinare qualche prodotto su Amazon. Il dispositivo, che non si può ancora comprare in Italia, non ha schermi o tasti: funziona con comandi vocali e risponde in modo colloquiale, grazie alla presenza dell’assistente personale Alexa. Nonostante abbia ancora funzionalità molto limitate, Echo ha ricevuto nell’ultimo anno recensioni positive e ha di fatto aperto un nuovo mercato legato all’elettronica per la casa. </p>
<p> La settimana scorsa, in un raro caso di fair play per l’industria tecnologica, Google ha riconosciuto il ruolo di Amazon nell’avere aperto la strada in un nuovo settore e – al tempo stesso – ha presentato Google Home, un dispositivo che ricorda molto Echo ma il cui assistente automatico (Google Assistant) potrà fare più cose, sfruttando l’enorme mole di informazioni catalogate negli anni dal motore di ricerca. Apple su questo fronte è rimasta indietro, anche se si tratta di un mercato appena nato e con potenzialità ancora difficili da definire. </p>
<p> Siri per la casa Secondo The Information, in realtà Apple sta lavorando a qualcosa di simile a Echo già da molto tempo e da prima che Amazon mettesse in vendita il suo prodotto. L’idea di Apple è fare uscire Siri dagli iPad e dagli iPhone, offrendole un posto in qualche angolo di casa all’interno di un dispositivo con il quale conversare per avere informazioni, o attivare altri oggetti collegati a Internet e che usano HomeKit, la piattaforma di Apple per fare comunicare dispositivi domestici di vario tipo con gli iPhone. A differenza di Echo, l’assistente casalingo di Apple avrebbe il vantaggio di dialogare facilmente con gli smartphone, i tablet e gli smartwatch prodotti dall’azienda, offrendo quindi funzionalità più avanzate per controllarlo. </p>
<p> Il dispositivo potrebbe riprodurre la musica di Apple Music, collegarsi al televisore per mostrare contenuti in streaming, inviare messaggi tramite iMessage e accedere ai dati conservati su Internet tramite iCloud. Rispetto a Google Home, avrebbe però lo svantaggio di non avere dietro di sé la grande mole di informazioni di cui dispone Google, e che l’azienda sta usando per migliorare il funzionamento della sua intelligenza artificiale. Per questo motivo ci sono voci circa un’apertura di Siri, in modo che le sue funzioni possano essere sviluppate ed estese dai produttori di altre applicazioni, in modo da consentire all’assistente personale di Apple di fare più cose. </p>
<p> Siri aperto Apple potrebbe annunciare novità importanti sull’apertura di Siri già nel corso del suo evento in programma per giugno. Benché sia il più conosciuto tra gli assistenti automatici – anche grazie alle massicce campagne di marketing – Siri non ha la fama di essere molto utile per semplificare la vita ai proprietari di iPhone e iPad. Con un po’ di pazienza si possono impostare promemoria, inviare risposte ai messaggi ricevuti, avere informazioni sul meteo o avviare la riproduzione di una canzone, ma se si prova qualcosa di più elaborato Siri dà risultati piuttosto deludenti. Se non capisce una domanda, rimanda quasi sempre a una banale ricerca online che si rivela spesso inutile se non uno spreco di tempo. </p>
<p> Siri può avviare le applicazioni installate sul telefono, ma salvo rare eccezioni non può accedere ai loro dati, cosa che ne riduce ulteriormente le capacità. Queste limitazioni sono dovute al fatto che finora Apple ha preferito mantenere chiuso il suo assistente personale, seguendo una linea simile a quella applicata per gli altri suoi prodotti: avere il massimo del controllo per evitarsi brutte sorprese ed evitarle agli utenti. I creatori di Siri, nata come applicazione esterna poi acquisita da Apple, avevano in mente qualcosa di diverso: un sistema che si potesse evolvere grazie al contributo degli altri sviluppatori, che avrebbero costruito servizi di vario tipo sul loro assistente personale. Dopo l’acquisizione i loro piani furono fermati da Apple, che rese Siri una parte integrante di iOS e di conseguenza molto chiusa. </p>
<p> Gli sviluppatori originari di Siri non lavorano più per Apple e hanno da poco presentato Viv, un assistente personale che riprende molte delle loro idee originali e si basa sull’apertura agli sviluppatori della loro intelligenza artificiale. Google la settimana scorsa ha annunciato piani simili per il suo Google Assistant e lo stesso ha già fatto da tempo Facebook con “M”, il suo assistente personale sperimentale che sarà progressivamente integrato all’interno di Messenger. Per rendere più versatili gli assistenti personali non sembra esserci alternativa alla loro parziale apertura verso chi sviluppa applicazioni, e secondo The Information Apple non farà eccezione e presenterà nuovi strumenti per fare dialogare meglio Siri con applicazioni e servizi. L’ipotesi è che possa farlo con una soluzione “alla Apple”, quindi con regole molto rigide per gli sviluppatori e controlli scrupolosi sulle nuove funzioni da aggiungere a Siri. In questo modo si dovrebbe garantire una migliore stabilità dell’assistente personale, ma la sua evoluzione potrebbe avvenire più lentamente rispetto a quella della concorrenza. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/05/18/app-russa-identita-sconosciuto-foto/" parent_folder="Il Post 2016-17" id="file17861948" filename="app-russa-identita-sconosciuto-foto">
<p> L’app russa che scopre l’identità di uno sconosciuto da una sua foto </p>
<p> Si chiama FindFace e per ora funziona solo con le fotografie caricate su Vkontakte, il "Facebook russo", e ha implicazioni inquietanti </p>
<p> FindFace è un’app di riconoscimento facciale – sviluppata da una società russa – che permette di confrontare delle fotografie di sconosciuti con quelle pubblicate su Vkontakte, il più diffuso social network in Russia. FindFace permette agli utenti di scoprire l’identità di una persona a partire da una sua fotografia in meno di un secondo e con un’affidabilità del 70 per cento: se non è in grado di riconoscere la persona, fornisce una lista di account di persone simili a quella che si vuole identificare. FindFace, che non funziona per gli utenti di Facebook, è stata presentata due mesi fa ed è già stata usata da 500mila persone, per un totale di tre milioni di ricerche. E tra le altre cose è stata anche molto criticata per le controverse implicazioni sulla privacy delle persone. </p>
<p> Shaun Walker, giornalista del Guardian che si occupa di Russia, ha incontrato a Mosca Artem Kukharenko (26 anni) e Alexander Kabarov (29 anni), i due fondatori di FindFace. Kabarov ha raccontato a Walker che FindFace si basa su un algoritmo che permette ai suoi utenti «di fare una ricerca tra miliardi di fotografie in meno di un secondo da un normale computer». Ha anche aggiunto che l’app potrebbe facilitare la vita a chi cerca di scoprire l’identità di una persona che gli piace: «Se vedi qualcuno che ti piace, puoi fotografarlo, scoprire chi è e mandargli una richiesta di amicizia. Funziona anche per cercare le somiglianze. Puoi caricare una foto di una star del cinema che ti piace, o di una tua ex fidanzata, e trovare dieci ragazze somiglianti e mandare loro un messaggio». </p>
<p> L’app può funzionare per qualsiasi database fotografico, hanno spiegato a Walker i due fondatori di FindFace, anche se al momento non funziona con le foto di Facebook, perché sono archiviate in una maniera che rende il loro accesso più complicato di quanto sia con Vkontakte. Come ha verificato il fotografo russo Yegor Tsvetkov, è possibile per esempio usare FindFace per scoprire l’identità di sconosciuti semplicemente fotografandoli nella metropolitana di San Pietroburgo, senza chiedere loro il permesso (l’esperimento di Tsvetkov è diventato poi un progetto fotografico). </p>
<p> Come ha scritto Walker, l’app può avere implicazioni molto preoccupanti, non solo sulla normale privacy degli utenti del social network. Per esempio FindFace potrebbe essere usata da un regime autoritario per identificare i partecipanti a una manifestazione anti-governativa. Kukharenko e Kabarov hanno detto di essere vicini a firmare un contratto con l’amministrazione locale di Mosca, che vorrebbe usare FindFace per ragioni di sicurezza partendo dalle immagini fornite da 150mila camere a circuito chiuso della città. E hanno aggiunto di non essere stati ancora contattati dai servizi segreti russi, il FSB, l’agenzia che ha preso il posto del temuto KGB dell’epoca sovietica: ma se dovesse succedere, sarebbero disposti a sentire cos’ha da proporre. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/04/13/arte-intelligenza-artificiale-ai/" parent_folder="Il Post 2016-17" id="file17861979" filename="arte-intelligenza-artificiale-ai">
<p> L’arte artificiale </p>
<p> Come programmatori e artisti stanno sfruttando l'intelligenza artificiale per far creare ai computer opere d'arte, con alterni successi </p>
<p> Nell’estate del 2015 Google pubblicò una serie di strane immagini che secondo molte persone ricordavano le allucinazioni che si hanno dopo aver assunto sostanze come l’LSD, ma che in realtà erano state ottenute da un programma chiamato DeepDream a partire da immagini preesistenti. DeepDream, il cui codice è stato distribuito da Google in open source, si basa su una rete neurale artificiale, cioè su un insieme di computer in rete tra loro che si scambiano dati ed elaborazioni cercando di imitare la struttura di base del cervello umano (qui è spiegato più dettagliatamente). In pratica quello che fa DeepDream è prendere un’immagine, cercarci dentro schemi già noti (la forma di una banana, quella di un cane) e rielaborarla mettendoli in evidenza; il risultato sono immagini abbastanza strane, a volte quasi mostruose. Se non avete dimestichezza con l’LSD ma un po’ di più con la storia dell’arte, potrebbero ricordarvi Il giardino delle delizie di Hieronymus Bosch. Di solito nelle immagini realizzate con DeepDream si vedono molti occhi oppure strani animali. </p>
<p> Come DeepDream ha rielaborato una fotografia del cielo; cliccate sull’immagine per osservarla meglio (Google) </p>
<p> Google non ha realizzato DeepDream allo scopo di ottenere questo tipo di immagini o per realizzare un programma in grado di produrre arte, ma per scoprire più cose sul funzionamento delle reti neurali artificiali allenate con il deep learning a riconoscere le immagini. A questi sistemi vengono mostrate migliaia di immagini di un certo tipo di cose che gli si vuole insegnare a riconoscere (sempre qui è spiegato più dettagliatamente); ogni immagine passa in sequenza per ciascuno dei “neuroni” che formano la rete neurale artificiale e ognuno contribuisce alla risposta finale. Il primo neurone ad esempio guarda agli angoli e ai contorni distinguibili nelle immagini; i neuroni intermedi cercano forme definite più grandi, come la forma di una porta o di una foglia; i neuroni finali mettono insieme le interpretazioni di quelli precedenti. </p>
<p> Il funzionamento di questo processo si può intuire grazie a un videogioco di Google che si chiama Quick, Draw! ed è una specie di Pictionary con cui giocare insieme al proprio computer, o smartphone. Il gioco è piuttosto semplice: il sistema chiede di disegnare un oggetto che deve essere riconosciuto da un’intelligenza artificiale entro 20 secondi. Più il disegno è accurato, più l’AI ha probabilità di indovinarlo. Un’altra applicazione che usa lo stesso principio, sempre realizzata dalle squadre di ricerca di Google, è Auto Draw, che partendo da uno scarabocchio dell’utente gli permette di ottenere immagini semplici ma disegnate molto meglio (per ora è disponibile solo da browser, anche su smartphone). </p>
<p> A Google hanno cercato di approfondire che cosa “capisse” esattamente ciascun elemento della rete neurale e per questo hanno fatto andare il sistema alla rovescia: gli hanno fornito un’immagine e gli hanno chiesto di ottenerne una seconda usando una specifica interpretazione. Ad esempio, mostrando all’AI un’immagine di pixel di diversi colori disposti in modo casuale le hanno chiesto di individuare delle banane. </p>
<p> In questo modo hanno creato DeepDream e hanno scoperto che le AI costruite per riconoscere le immagini possono anche crearne. Oltre a chiedere al sistema di identificare una specifica forma, si può anche lasciare che sia il sistema stesso a sceglierne una: si istruisce l’AI a rielaborare un’immagine che le è stata fornita enfatizzando una forma vista da uno dei suoi neuroni. Per questa ragione alcune immagini ottenute con DeepDream sono più complesse o astratte di altre. Se si sceglie uno dei primi neuroni, si ottiene un’immagine modificata più a livello stilistico. </p>
<p> Cliccate sull’immagine per osservarla meglio (Google a partire da una fotografia di Zachi Evenor) </p>
<p> Se si sceglie uno degli ultimi neuroni, oppure se ottenuta una immagine rielaborata la si ripropone più volte all’AI, si ottengono cose più strane. Nell’orizzonte DeepDream può vedere un palazzo, in una foglia un uccello, in una nuvola strani animali fantastici. </p>
<p> Particolari dell’immagine del cielo rielaborata da DeepDream in cui si vedono strani animali, come il “maiale-lumaca” e il “cane-pesce” (Google) </p>
<p> Anche se DeepDream non è stato realizzato per produrre arte, molti artisti hanno provato a sperimentare con DeepDream per creare immagini artistiche (posto che ovviamente il concetto di arte è ancora più discusso di quello di intelligenza artificiale). Alcuni programmatori, ispirandosi a DeepDream, hanno creato software per applicare a fotografie uno stile pittorico, ad esempio quello dei famosi pittori ottocenteschi Pierre-Auguste Renoir o Vincent van Gogh. Uno di questi programmi, il primo, si chiama Style Newtworks. Una cosa simile potreste averla sperimentata se vi è capitato di scaricare e usare la app Prisma. Poi esiste Neural Doodle che invece permette di creare un’immagine in un definito stile pittorico a partire da uno scarabocchio. </p>
<p> DeepDream e altri programmi ispirati ad esso però non sono gli unici sistemi con cui si è provato a usare le AI nel campo dell’arte. Ad esempio, l’artista americano Ian Cheng – che tra le altre cose ha studiato scienze cognitive e ha collaborato con Industrial Light & Magic, l’azienda di effetti speciali digitali di George Lucas, e ha esposto alcune sue opere sia al Moma di New York che alla Fondazione Sandretto Re Rebuadengo di Torino – realizza “simulazioni live” in cui attraverso lo schermo di un tablet si può interagire con delle creature inventate (ad esempio un cane di razza Shiba, nell’opera Emissary Forks For You) regolate da un sistema di AI. Le opere di Cheng cercano di mostrare al pubblico i limiti e le possibilità delle AI e le rendono in forma di animali per rendere più chiare le loro caratteristiche. </p>
<p> Una interazione con Emissary Forks For You di Ian Cheng, una delle opere esposte al Moma nella mostra Emissaries fino al 25 settembre </p>
<p> Un altro progetto nel campo dell’arte e dell’AI è Recognition, realizzato dal centro di ricerca sulla comunicazione italiano Fabrica per la galleria d’arte di Londra Tate. Dal 2 settembre al 27 novembre 2016 all’interno del museo era possibile osservare sullo schermo come un sistema di AI trovasse associazioni visive tra fotografie dell’agenzia di stampa Reuters e immagini artistiche facenti parte dell’archivio della Tate. Il progetto ha vinto l’IK Prize 2016 per l’innovazione digitale, assegnato dalla stessa galleria d’arte. </p>
<p> Anche nel campo degli studi sulla storia dell’arte si usano forme di AI. Ad esempio, alla Rutgers University del New Jersey, negli Stati Uniti, esiste un Art and Artificial Intelligence Laboratory che si occupa di fare ricerche in questo ambito. Uno dei loro progetti consiste in un sistema di AI che misura la creatività di singole opere d’arte o di correnti artistiche guardando quanto abbiano influenzato altri artisti e si distinguano da altre opere d’arte o correnti. Esistono poi alcuni corsi universitari – pensati per chi ha già una laurea e vuole ulteriormente specializzarsi – dedicati alle intersezioni tra arte e tecnologia basata sulle AI. Ad esempio, l’Università di Londra offre un corso intitolato Machine learning and art (dedicato soprattutto alle sperimentazioni in campo musicale) e anche alla Tisch School of the Arts della New York University esiste un corso simile. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/06/08/backup-del-backup/" parent_folder="Il Post 2016-17" id="file17861966" filename="backup-del-backup">
<p> Avete fatto il backup dei dati? E il backup del backup? </p>
<p> Il New York Times dice che dovreste e spiega i modi migliori per farlo: poi non dite che non vi avevamo avvisati </p>
<p> In una rubrica dedicata ai consigli su computer e tecnologica, J. D. Biersdorfer del New York Times ha spiegato che converrebbe fare non solo una copia di backup dei propri file, ma anche un backup del backup. La premessa di tutta la questione è: avete salvato una copia di scorta – cioè il cosiddetto backup – di tutte quelle foto, di tutti quegli appunti per il romanzo che un bel giorno scriverete e tutte quelle importantissime cose che sapete solo voi, vero? Se sì, bene ma non benissimo: il New York Times consiglia di fare anche una copia di scorta della copia di scorta, un backup del backup. Se no, prendete una chiavetta USB o un disco esterno (dipende da quanti file avete da salvare) e fate un primo backup. Ecco, ora anche voi siete pronti per preoccuparvi del fatto che anche quel disco esterno o quella chiavetta USB non sono per sempre: potrebbero rompersi, perdersi, eccetera eccetera. </p>
<p> Riprendendo la lunghissima questione iniziata con lo stracitato Quis custodiet ipsos custodes? (la frase latina che significa «chi sorveglierà i sorveglianti stessi?») Biersdorfer consiglia di fare così, per fare il backup del backup. </p>
<p> La prima cosa da pensare è non fare solo un backup online (molti computer lo fanno in automatico ogni tot giorni, basta dire loro cosa volete che salvino) o solo backup su dischi esterni. I dischi esterni, poi, è meglio scollegarli dal computer, perché se ci sono attaccati rischiano di prendere qualsiasi virus prenda il computer, diventando in quel caso inutili. Biersdorfer consiglia di prendere almeno un paio di dischi esterni (o chiavette USB) e di farli ruotare automaticamente, usando magari programmi come Acronis Backup & Recovery 10, che servono proprio a questo. Consiglia poi di usare dei NAS, cioè dei Network Attached Storage, dischi esterni collegati direttamente alla rete domestica. Uno dei migliori per uso domestico è il QNAP Turbo NAS, che però costa più di 200 euro. Secondo Biersdorfer il miglior strumento per fare online il backup di una propria chiavetta o di tutti i file del proprio computer è Backblaze, che ha un costo minimo di 5 euro al mese. Un altro servizio consigliato da Biersdorfer è CrashPlan, che ha costi simili. </p>
<p> Più in generale: la sola chiavetta o il solo backup online non sono sufficienti. Anche senza voler usare strumenti e servizi più sicuri (ma che costano) l’ideale è fare entrambe le cose, e magari far pure girare diverse chiavette e non lasciarle nello stesso posto. Una, magari, datela a una persona di assoluta e provata fiducia. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/12/23/bitcoin-crollo/" parent_folder="Il Post 2016-17" id="file17861982" filename="bitcoin-crollo">
<p> Perché i bitcoin sono crollati? </p>
<p> Dopo aver sfiorato i 20mila dollari sono scesi a poco più di 12mila, per poi riprendersi un po': il motivo forse è lo stesso del loro recente aumento </p>
<p> Dopo aver raggiunto quasi i 20mila dollari lo scorso 17 dicembre, il valore dei bitcoin – la più conosciuta criptovaluta al mondo – è crollato ieri a poco più di 12mila dollari, per poi riprendersi lievemente e superare nuovamente i 14mila. È l’ultima, imprevista fluttuazione nel valore della valuta digitale, che negli ultimi mesi e soprattutto nelle ultime settimane era cresciuta tantissimo sorprendendo analisti e investitori di tutto il mondo: soltanto un anno fa, infatti, un bitcoin valeva circa 850 dollari. Il crollo dei bitcoin ha interessato l’intero mercato delle criptovalute, calato del 20 per cento: da 611 miliardi di dollari a 478 miliardi. </p>
<p> Il calo del valore dei bitcoin era iniziato in realtà domenica, ma ha subito un’accelerazione tra giovedì e venerdì. Le spiegazioni, come per molte cose che riguardano i mercati finanziari, sono diverse e concorrenti: in generale, va tenuto conto del fatto che il mercato dei bitcoin è volatile e imprevedibile per natura, più di molti altri, perché il valore della moneta digitale è dettato unicamente dalla domanda e dall’offerta: e cioè da quanto sono disposte le persone a pagarlo. Il prezzo di un bitcoin è calcolato sulla base del valore al quale è scambiato con le normali valute: in pratica, un bitcoin ha un valore soltanto perché gli utenti del sistema sono d’accordo che ce l’abbia. </p>
<p> Il forte aumento delle ultime settimane ha portato un enorme interessamento alla criptovaluta da parte degli investitori, che per paura di rimanere tagliati fuori dal mercato dei bitcoin si sono affrettati a comprarne. Questo entusiasmo degli investitori ha provocato un aumento del valore della valuta – perché la domanda è aumentata – che era però molto fragile: Charles Hayter, fondatore del sito Cryptocompare, ha spiegato a BBC che «un’impennata frenetica dovuta alla massa sarà seguita da un’inversione, quando cambierà il sentimento collettivo». </p>
<p> Ma ci sono stati anche altri motivi: Coinbase, il principale sito per acquistare, vendere e conservare bitcoin, è stato sommerso dalle operazioni degli ultimi giorni, e tra giovedì e venerdì è stato sospeso due volte per problemi tecnici. CME e CBOE, due delle principali società che si occupano dello scambio dei titoli futures – contratti che permettono agli investitori di “scommettere” sul valore di qualcosa – basati sui bitcoin hanno a loro volta sospeso temporaneamente le attività. Giovedì, poi, Coinbase ha anche lanciato prima del previsto le operazioni con i Bitcoin Cash, un particolare tipo di bitcoin creato la scorsa estate, nata dall’esigenza di aumentarne il volume di affari. Poco dopo ha dovuto sospenderle, annunciando di avere aperto un’indagine per insider trading, cioè la compravendita di titoli da parte di persone interne alla società, che hanno a disposizione informazioni privilegiate. È probabile che questi problemi e incidenti abbiano spaventato e scoraggiato gli investitori, condizionando l’andamento del valore della valuta. </p>
<p> Forbes ha poi proposto un’altra spiegazione, più bizzarra: l’avvicinarsi del Natale e delle feste ha probabilmente convinto molte persone che avevano guadagnato soldi investendo in bitcoin a venderli, in cambio di normali valute, per sostenere le spese di questo periodo. Questa vendita massiccia di bitcoin potrebbe avere contribuito al calo della valuta. C’è poi chi sta dicendo che il calo di venerdì è l’inizio dello scoppio della “bolla dei bitcoin”, che viene annunciato da tempo e che finora era stato smentito dai fatti. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/09/29/coalizione-intelligenze-artificiali/" parent_folder="Il Post 2016-17" id="file17861934" filename="coalizione-intelligenze-artificiali">
<p> C’è una nuova coalizione per le intelligenze artificiali </p>
<p> L'hanno fondata Google, Facebook, Amazon, Microsoft e IBM per rendere più trasparenti (e meno inquietanti) i loro piani sui software che pensano da soli </p>
<p> Facebook, Google, Amazon, Microsoft e IBM hanno fondato la “Partnership on AI”, una organizzazione senza scopo di lucro per rendere più trasparenti e comprensibili a tutti i loro lavori di ricerca sulle intelligenze artificiali (AI), settore in pieno sviluppo e sul quale ci sono grandi aspettative per le sue future evoluzioni. All’iniziativa partecipano gruppi di ricerca, esperti informatici e docenti universitari che si occupano di AI, sotto la direzione di Eric Horvitz del Microsoft Research e di Mustafa Suleyman, cofondatore di DeepMind, la divisione di Google dedicata alle intelligenze artificiali e di cui si è parlato molto prima dell’estate, quando uno dei suoi sistemi ha battuto il campione mondiale di GO, un gioco da tavola cinese molto complicato. Al momento l’unica grande società tecnologica assente dall’organizzazione è Apple, che sta valutando comunque l’opportunità di aderire in futuro. </p>
<p> Soprattutto per via dei racconti e dei film di fantascienza, le intelligenze artificiali nell’immaginario di molti sono legate a futuri dispostici e piuttosto inquietanti, dove l’umanità finisce assoggettata alla mente insuperabile di un computer. L’esperienza di tutti i giorni ci dice però che le cose stanno diversamente e che siamo ancora molto lontani da un software in grado di agire autonomamente, imitando il funzionamento del pensiero umano. Tuttavia, grazie alle crescenti capacità di calcolo dei processori e alla disponibilità di enormi quantità di dati, messi a disposizione dalle reti e dal modo in cui ogni persona vi accede, negli ultimi anni sono stati compiuti notevoli progressi nel campo delle AI. Non esiste un computer che sa pensare e fare tutte le cose che fanno gli umani, certo, ma esistono e sono già utilizzate intelligenze artificiali specializzate in grado di eseguire compiti in determinati settori, elaborando modelli matematici per esempio per il meteo, o per fare funzionare i bot nelle chat di Messenger o nel nuovo Allo di Google. </p>
<p> In previsione di un’ulteriore diffusione e disponibilità di tante AI diverse tra loro, le principali aziende tecnologiche del mondo hanno pensato che una coalizione possa aiutarle a coordinare meglio la loro comunicazione, rendendo meno inquietante la prospettiva di software che sapranno fare sempre più cose, e con alti livelli di autonomia. Gli obiettivi della Partnership on AI sono due. Il primo è fare conoscere meglio al grande pubblico i principi e i sistemi che fanno funzionare le intelligenze artificiali, in vista del loro impiego in ambiti che lo riguardano direttamente in tempi brevi, come la guida autonoma dei veicoli. Il secondo punto è più politico e di immagine: dimostrare che le aziende protagoniste di questi cambiamenti collaborano tra loro per decidere codici di autoregolamentazione, anche sul piano etico, coinvolgendo filosofi ed esperti in ambito legale. </p>
<p> Nel corso di una conferenza stampa, Horvitz ha detto: «Il motivo per cui siamo tutti al lavoro sulle AI è perché crediamo con convinzione nelle loro capacità di trasformare il nostro mondo. L’impatto positivo delle AI dipenderà non solo dalla qualità dei nostri algoritmi, ma anche da quanto se ne discuterà pubblicamente, per assicurare che le AI siano comprese e che possano portare benefici al maggior numero possibile di persone». Alla coalizione potranno aderire anche aziende più piccole, a patto che condividano gli impegni assunti dalle società fondatrici. </p>
<p> Almeno per ora, Partnership on AI non intende avviare sistemi di lobby presso il governo degli Stati Uniti, lasciando l’onere alle singole società. Dal punto di vista legislativo, infatti, le AI pongono moltissimi temi che dovranno essere affrontati: dalla tutela della privacy degli utenti, i cui dati vengono usati in forma aggregata per migliorare gli algoritmi dei software, alle regole che riguardano gli impieghi delle intelligenze artificiali in vari settori, da quello dei trasporti a quello della sanità. I responsabili dell’iniziativa hanno inoltre annunciato di avere già avviato i primi contatti con OpenAI, l’organizzazione senza scopo di lucro che ha Elon Musk tra i suoi principali finanziatori, nata proprio per assicurare uno sviluppo libero e accessibile a tutti delle intelligenze artificiali. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/04/21/cosa-sono-i-bot/" parent_folder="Il Post 2016-17" id="file17861930" filename="cosa-sono-i-bot">
<p> Cosa sono i bot </p>
<p> Le cose da sapere per chi ne sente parlare da tutte le parti – Facebook, Skype, Telegram, etc – ma non ha capito di preciso a cosa servano </p>
<p> La settimana scorsa Mark Zuckerberg ha annunciato l’arrivo dei “bot” su Messenger, e probabilmente molti si sono chiesti: cosa diavolo è un bot? I bot di Messenger saranno programmi scritti per imitare il nostro modo di conversare e offrire notizie, informazioni sul meteo o assistenza per acquistare prodotti online. Facebook non è la prima società a investire sui bot come nuova forma di comunicazione e interazione con i computer, ma può contare su oltre 900 milioni di persone che utilizzano Messenger, una base enorme per sperimentare le funzionalità di questi nuovi software. I bot esistono da tempo – qualcuno ricorderà Clippy, la graffetta petulante di Microsoft Office: era un bot – e finora non hanno avuto molta fortuna, ma secondo analisti e osservatori potrebbero essere l’evoluzione più interessante per i sistemi operativi e le app di smartphone e tablet. </p>
<p> Da dove arrivano i bot Con la parola “bot”, abbreviazione di “robot”, in informatica si intende un programma che ha accesso agli stessi sistemi di comunicazione e interazione con le macchine usate dagli esseri umani. La definizione è generica perché nella pratica i bot possono essere e fare qualsiasi cosa, da rispondere ai messaggi in modo automatico a creare reti sfruttate dagli hacker per compromettere siti o intrufolarsi in altri computer (in questo caso si parla di botnet). </p>
<p> Anche se è complessa e molto sfumata, la storia dei bot ha un inizio che viene fatto coincidere di solito con gli anni Cinquanta, quando l’informatico britannico Alan Turing teorizzò un test per capire se una macchina fosse effettivamente in grado di imitare il comportamento umano: analizzando una conversazione tra un individuo e un computer, una persona esterna deve stabilire chi sia chi. Se la serie di scambi è tale da rendere impossibile una risposta, si stabilisce che la macchina ha superato il test di Turing. </p>
<p> Il primo bot ad avvicinarsi al superamento della prova teorizzata da Turing fu ELIZA nel 1966, un programma che fingeva di essere uno psicoterapista e che regolava le sue risposte in base alle cose scritte dal suo interlocutore. In pratica iniziava la conversazione chiedendo quale fosse il problema della persona, analizzava la risposta alla ricerca di una serie di parole chiave e, sulla base di queste, dava una risposta. ELIZA era quindi capace di creare conversazioni verosimili in un ambito piuttosto ristretto, cosa che secondo alcuni scienziati le fu comunque sufficiente per superare il test (la questione è ancora dibattuta). </p>
<p> Bot e intelligenza artificiale Il concetto di intelligenza artificiale ha molte cose in comune con i bot, ma non necessariamente un bot deve essere intelligente e in grado di rispondere a tutto come faceva il computer di Star Trek. Un bot può essere creato allo scopo di fare una sola cosa benissimo e di essere completamente inutile per tutto il resto: le sue capacità di intelligenza artificiale vengono cioè limitate a un solo ambito, cercando di farlo rendere al meglio. Google, per esempio, usa incessantemente dei bot per raccogliere quante più informazioni possibili su qualsiasi pagina online, compresa quella che state leggendo, in modo da poterla inserire nei suoi indici e di offrirla come risposta nelle pagine dei risultati quando qualcuno cerca “cosa sono i bot?”. </p>
<p> I bot annunciati da Zuckerberg, e di cui si parla di più oggi, sono quelli che permettono di interagire in modo colloquiale con un servizio, ottenendo informazioni di vario tipo e più o meno come faceva ELIZA, ma con funzionalità più evolute. Bot di questo tipo furono sperimentati già alla fine degli anni Novanta da diversi sistemi di chat come Instant Messenger di AOL negli Stati Uniti e Windows Messenger di Microsoft. Davano informazioni sulle notizie, sugli orari del cinema e sul meteo, cose che oggi chiediamo agli assistenti personali come Siri su iPhone o a Google, ricevendo direttamente una risposta nella pagina dei risultati prima della classica lista di link. I programmi per le chat dei primi tempi di Internet sparirono con l’emergere dei social network e in seguito delle app, mettendo fuori circolazione per quasi un decennio i bot. </p>
<p> Il ritorno dei bot I progressi nei sistemi di intelligenza artificiale e soprattutto la grandissima diffusione delle applicazioni per scambiarsi messaggi, come Messenger e WhatsApp, ha reso nuovamente attuali i bot come soluzioni per superare alcuni svantaggi legati a come funziona il sistema dei dispositivi mobili e delle applicazioni oggi. Fatta eccezione per i giochi, per i produttori è molto difficile convincere gli utenti a utilizzare le loro app. Secondo ComScore, in media l’80 per cento del tempo trascorso su uno smartphone è impiegato nell’utilizzo di tre sole applicazioni, più o meno sempre le stesse e con percentuali di abbandono molto grandi per il resto delle app. La maggior parte degli utenti passa il suo tempo dentro app di proprietà di Facebook e di Google, che sono del resto i produttori di 8 delle 10 applicazioni più usate. Tutti gli altri fanno una gran fatica per farsi notare e per indurre le persone a scaricare le loro applicazioni, e devono fare i conti con la concorrenza molto agguerrita in una giungla che conta circa 1,5 milioni di diverse app. </p>
<p> I bot su dispositivi mobili, utilizzati all’interno di applicazioni già esistenti e di successo come Messenger, sono visti da molti come la soluzione del problema e Facebook è tra i principali promotori di questo modello. L’idea è che marchi di vario tipo, da quelli attivi nell’ecommerce ai giornali, lascino da parte le loro app e creino bot all’interno delle applicazioni per scambiarsi messaggi, rendendo diretto e personale il loro rapporto con l’utente. In questo modo è possibile sfruttare un’applicazione già conosciuta e molto usata, spostando la concorrenza esclusivamente sui contenuti e non sulla forma in cui sono presentati, cioè la tradizionale app che in pochi erano interessati a scaricare. </p>
<p> Secondo i più ottimisti, i messaggi istantanei da parte dei bot potrebbero cambiare almeno in parte l’attuale mercato delle applicazioni, offrendo nuove e insolite opportunità ai produttori di contenuti e a chi vende cose online. Una successiva evoluzione potrebbe essere legata alla creazione di nuovi modi per fare pubblicità, personalizzata e calibrata sugli interessi di un unico cliente, sulle base delle cose che i bot hanno imparato nel tempo dai loro interlocutori. </p>
<p> L’invasione dei bot Tra i primi a sperimentare le potenzialità dell’attuale ritorno dei bot ci sono stati quelli di Slack, un programma simile a Skype che viene utilizzato per coordinare le attività di lavoro tra gruppi di persone. Di base Slack è una chat con la possibilità di inviarsi messaggi diretti o di gruppo, ma da qualche tempo ospita numerosi bot che possono essere aggiunti per automatizzare i flussi di lavoro o per ottenere informazioni. Slackbot, per esempio, si presenta ai nuovi arrivati e in modo amichevole chiede informazioni come nome e fotografia per impostare più facilmente il proprio profilo sul servizio, senza dovere compilare i classici form. Il bot può essere inoltre programmato, molto facilmente, per rispondere a domande di vario tipo, come farsi ricordare la password di accesso a uno dei siti utilizzati dal proprio gruppo di lavoro. Esistono altre centinaia di bot, sviluppati all’esterno e compatibili con Slack, per fare di tutto: da ricevere direttamente in chat le statistiche sull’andamento del proprio sito a lanciare un rapido questionario per decidere che cosa fare a pranzo coi colleghi, passando per i bot che sincronizzano i calendari dei partecipanti e ricordano gli impegni futuri. </p>
<p> La presenza di questo tipo di automatismi e la possibilità di crearne di nuovi hanno contribuito al successo di Slack, che conta un crescente numero di iscritti e che raccoglie decine di milioni di dollari nei giri di finanziamenti delle startup. Il suo successo è stato tale da indurre Microsoft ad accelerare i nuovi sviluppi del suo Skype, sul quale da pochi giorni sono stati introdotti i bot più o meno con caratteristiche simili a quelli della concorrenza. Slack è ancora piccolo, ma sta crescendo in fretta e farà sempre più concorrenza a Skype: per esempio ha nei piani il lancio di una nuova funzione per fare telefonate e videochiamate direttamente dalle sue app per computer e dispositivi mobili. </p>
<p> Telegram è stata tra le prime applicazioni di messaggistica ad aggiungere i bot, ottenendo risultati più o meno incoraggianti. Per incentivare gli sviluppatori a creare interlocutori automatici più efficienti per i suoi iscritti, il 18 aprile i responsabili dell’app hanno annunciato che daranno 1 milione di dollari a chi realizzerà bot migliori e innovativi: ogni sviluppatore premiato riceverà al massimo 25mila dollari. In questo modo Telegram spera di ottenere bot migliori della concorrenza, a partire da Facebook che ha già svelato i suoi piani molto ambiziosi per Messenger e che probabilmente porterà sulla stessa strada anche il suo WhatsApp in futuro. </p>
<p> Come se la cavano i bot Complici gli annunci di Facebook, intorno ai bot si sono create grandi aspettative da parte degli utenti, disattese dalla loro resa effettiva. David Marcus, il responsabile dello sviluppo di Messenger, ha ammesso che i nuovi bot non funzionano sempre benissimo e che ci sono ampie possibilità di miglioramento, ma ha anche ricordato che è una tecnologia ai primi passi e che deve essere rodata. Il problema deriva dal fatto che ogni azienda crea i propri bot, seguendo alcune linee guida imposte da Facebook, quindi a seconda degli sviluppatori il risultato finale può essere buono o piuttosto scadente, come del resto avviene già da anni sul mercato delle applicazioni. I bot per fare acquisti, per esempio di vestiti, sono stati criticati per essere macchinosi e poco intuitivi, altri per ottenere notizie hanno ricevuto critiche più positive. </p>
<p> Per avviare un bot su Messenger è sufficiente cliccare su un link come questo m.me/wsj, oppure trovarli direttamente all’interno dell’applicazione attraverso la ricerca dei contatti. Ogni bot si comporta in modo diverso, ma di base quasi tutti esordiscono con un saluto amichevole e una lista delle cose che si possono fare, oppure danno suggerimenti su come essere usati man mano che si conversa con loro. Quello del Wall Street Journal è tra i migliori disponibili per avere notizie: gli si può dire di inviare un messaggio quando esce un nuovo articolo di particolare rilievo, oppure tutte le volte che escono pezzi su una determinata azienda, gli si possono chiedere le quotazioni di borsa e si può attivare un’opzione per ottenere le breaking news, sempre tramite messaggi su Messenger. Il bot funziona bene, ma a volte si fa prendere la mano e invia troppi articoli, ma gli si può anche dire di smettere e stare zitto. </p>
<p> Un altro bot di cui si è parlato molto, anche perché è stato mostrato sul palco della presentazione con Zuckerberg organizzata da Facebook a San Francisco, si chiama Hi Poncho e serve per ottenere informazioni sul meteo. Al primo utilizzo chiede dove ci si trova, se l’impostazione del GPS è stata disattivata sul proprio dispositivo, e dà di conseguenza le previsioni per la giornata: per chi si trova negli Stati Uniti sono più dettagliate, per il resto del mondo meno. Il problema è che Hi Poncho non capisce praticamente nient’altro ed è ad anni luce dal superare il test di Turing; se gli dici “I’m in Los Angeles, what’s the weather like?” (funziona solo in inglese per ora), ti risponde dandoti comunque le previsioni del posto in cui ti trovavi la prima volta in cui l’hai impostato; se provi a proseguire il discorso, non riesce a collegare le tue frasi precedenti all’ultima scritta, rendendo l’esperienza piuttosto frustrante. In compenso incassa bene gli insulti. </p>
<p> Futuro incerto I bot per le app di messaggistica sono considerate dagli osservatori più entusiasti come il futuro dell’interazione tra noi e gli smartphone, ma secondo gli scettici potrebbero essere l’ennesima bolla tecnologica che non andrà molto lontano. Il problema, dicono, è che senza una buona intelligenza artificiale alle loro spalle, i bot continueranno a sembrare stupidi e programmati per funzionare all’interno di percorsi prestabiliti e molto rigidi, che rendono le conversazioni artificiali e poco coinvolgenti. Il rischio è che gli utenti vedano come sono fatti ora i bot e si convincano che non siano niente di che, bollando come inutile una tecnologia che tra qualche anno potrebbe invece essere rivoluzionaria. </p>
<p> Quelli di Facebook sono consapevoli del problema e hanno in più occasioni spiegato che i nuovo bot sono sperimentali, ma soprattutto che sono solo un pezzo di un piano molto più grande e ambizioso. Da qualche anno quelli di Messenger stanno lavorando a M, un assistente personale simile a Siri di Apple o a Google Now, che darà informazioni di ogni tipo da quelle sul traffico, alle notizie sulla guerra in Siria passando per lo stato degli ultimi ordini effettuati su Amazon. Facebook vuole fare in modo che M sia il bot più intelligente di tutti, basandolo sui suoi ultimi progressi in termini di intelligenza artificiale. M è già disponibile per un ridotto numeri di iscritti a Facebook, che lo stanno sperimentando da mesi tutto sommato con soddisfazione, nonostante sia ancora distante dall’essere perfetto: le richieste più complicate sono gestite in remoto da persone in carne e ossa, che dopo avere risposto insegnano a M come comportarsi automaticamente con quel tipo di richieste se mai dovessero essere nuovamente formulate. Nel complesso è un bot più umano di Siri o Cortana di Microsoft, ma non è ancora intelligente come Pensiero Profondo. 42. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2018/01/17/crollo-criptovalute-bitcoin-gennaio/" parent_folder="Il Post 2016-17" id="file17861984" filename="crollo-criptovalute-bitcoin-gennaio">
<p> Il crollo di Bitcoin e delle criptovalute, spiegato </p>
<p> Da lunedì a oggi l'intero mercato ha perso oltre il 35 per cento: qualcuno dice che è scoppiata la bolla, molti invitano alla calma </p>
<p> A partire dalla notte tra lunedì e martedì, Bitcoin e quasi tutte le principali criptovalute sono crollate di valore: con alcune eccezioni hanno perso fino al 40 per cento, in quello che è finora il peggior momento del mercato delle criptovalute dopo la loro grande crescita della seconda metà del 2017. Secondo il sito Coin Market Cap, il totale del mercato delle criptovalute è passato da circa 700 miliardi di dollari a circa 440 tra lunedì e mercoledì: un crollo del 37 per cento. Tra commenti allarmistici e altri rassicuranti, in molti stanno provando a valutare la reale entità del fenomeno, a spiegarla e a prevedere cosa accadrà adesso. </p>
<p> L’andamento delle prime dieci criptovalute per volume d’affari, alle 17 di mercoledì 17 gennaio (Live Coin Watch) </p>
<p> Bitcoin ha perso circa il 30 per cento, partendo da 14.271 dollari e arrivando sotto i 10mila, una cifra che non veniva raggiunta dallo scorso novembre (a fine dicembre arrivò quasi a 20mila dollari). Ethereum, la seconda criptovaluta per volume d’affari, ha perso più del 35 per cento, passando da oltre 1.300 dollari a circa 835 dollari. Ripple, la terza criptovaluta, ha perso oltre il 40 per cento, passando da 1,83 dollari a meno di un dollaro. Queste quotazioni sono quelle del sito Coindesk e possono variare leggermente rispetto a quelle di altri servizi simili, perché sono calcolate in tempo reale sulla base degli scambi che avvengono sui siti di exchange di tutto il mondo. Alcuni servizi hanno deciso di escludere dai propri calcoli gli exchange sudcoreani, che sono molto in agitazione negli ultimi tempi (ci arriviamo), e possono quindi fornire quotazioni un po’ diverse. </p>
<p> Il crollo delle ultime 48 ore sta continuando, ovviamente intervallato da lievi e brevi riprese. La prima cosa da tenere presente per analizzare l’andamento del mercato delle criptovalute di queste ore è che, nonostante le enormi perdite, è solo tornato più o meno ai livelli di metà dicembre. È quindi un grande crollo seguito a un picco enorme, e non significa che “sia scoppiata la bolla”, cioè che il mercato sia collassato: o perlomeno non ancora. Contrariamente a quello che si legge in giro online, è praticamente impossibile prevedere con certezza se sia l’inizio della fine delle criptovalute, o soltanto un momento passeggero che sarà seguito da un nuovo aumento. </p>
<p> L’andamento di Bitcoin tra lunedì e mercoledì (CoinDesk) </p>
<p> Questo perché il mercato delle criptovalute è estremamente volatile, cioè può fluttuare moltissimo tra picchi e crolli, improvvisi e non necessariamente collegati a eventi concreti. Molti esperti di criptovalute sostengono che quello in corso sia un semplice assestamento del mercato, un evento normale dopo la grandissima crescita degli ultimi mesi. </p>
<p> Vista la sua grande volatilità, il mercato delle criptovalute è molto esposto a quello che viene definito «panic selling», cioè quello che succede quando molti investitori vendono per paura di un crollo del valore del proprio bene, contribuendo in questo modo al suo andamento negativo. In molti attribuiscono il crollo delle ultime ore al susseguirsi di notizie potenzialmente dannose per il mercato delle criptovalute, e in particolare alla notizia di una possibile chiusura dei siti di exchange sudcoreani. </p>
<p> La Corea del Sud è infatti il terzo paese al mondo per volume d’affari in criptovalute: la settimana scorsa il ministro della Giustizia ha annunciato la decisione di chiudere i siti di exchange (le motivazioni riguardano soprattutto la volontà dei governi di regolamentare un mercato che finora era stato sostanzialmente ignorato). Dopo l’annuncio del ministro della Giustizia, il primo ministro ha precisato che è soltanto un’ipotesi e che comunque ci vorrebbero mesi per attuarla. </p>
<p> L’incertezza sul futuro dei siti di exchange sudcoreani, la cui chiusura sarebbe un grosso problema per il mercato delle criptovalute, ha causato agitazione tra molti investitori, che per questo hanno iniziato a vendere. Ma attribuire il crollo del mercato a un’unica causa sarebbe un errore, anche perché sono circolate notizie poco rassicuranti anche dalla Cina, che sembra voler sganciarsi dai bitcoin limitando il settore del cosiddetto “mining” (se non capite di cosa si parla, qua c’è la versione lunga) e gli accessi ai siti di exchange. Ma sono notizie che non sono né chiare né confermate, vista la difficoltà di ottenere informazioni sulla Cina. Ha influito in questi cali anche la chiusura di Bitconnect, una piattaforma per investire e scambiare bitcoin, che era sospettata di truffare gli utenti con uno schema Ponzi. </p>
<p> L’andamento di Ethereum tra lunedì e mercoledì (CoinDesk) </p>
<p> C’è però una cosa che hanno fatto notare in molti, per rassicurare gli investitori: per qualche motivo – ci sono varie teorie – il mercato delle criptovalute attraversa un crollo ogni gennaio. Nel 2015 Bitcoin perse il 33 per cento, nel 2016 il 16 per cento, nel 2017 il 17 per cento, sempre intorno al 12 gennaio e sempre nel giro di poche ore. Quello delle ultime ore, quindi, potrebbe anche essere un crollo in qualche modo “fisiologico”: ma sarebbe comunque molto più accentuato del solito, e le moltissime cose cambiate nel settore negli ultimi mesi suggeriscono di diffidare da chi ritiene il crollo un semplice fenomeno stagionale. </p>
<p> Ad ogni modo, molti investitori stanno approfittando di questo momento per comprare criptovalute a un prezzo più basso di quello recente, o addirittura aspettando che il valore scenda ulteriormente per comprarle pagandole il minimo possibile. È la pratica che nel gergo si chiama “buy the dips”, che prevede di comprare una criptovaluta quando scende di valore e rivenderla una volta che è tornata ad aumentare. Bisogna però avere fiducia nel fatto che il mercato delle criptovalute si riprenda, cosa non scontata. </p>
<p> Altre teorie, più cospirazioniste e contestate da molti, attribuiscono il calo di questi giorni alle speculazioni di pochi, grandi investitori, chiamati in gergo “balene”: in particolare si è parlato di quelli che hanno scommesso su un calo del valore di Bitcoin attraverso i contratti futures, che dallo scorso dicembre sono acquistabili alla borsa di Chicago. Sono contratti con i quali, semplificando, si può scommettere sul fatto che un determinato bene scenda o salga di valore: secondo queste teorie, gli investitori avrebbero influenzato il mercato per fare scendere il valore di Bitcoin, sulla base della scommessa fatta un mese fa con i contratti futures. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/04/06/deep-learning/" parent_folder="Il Post 2016-17" id="file17861975" filename="deep-learning">
<p> Come si insegna a un computer a imparare </p>
<p> Guida minima al "deep learning", la tecnica più utilizzata per far sì che un computer sappia riconoscere un gatto, per esempio </p>
<p> I progressi più importanti raggiunti negli ultimi anni sull’intelligenza artificiale sono legati al “deep learning”, il campo della ricerca che si occupa di insegnare ai computer a imparare, attraverso tecniche di apprendimento automatico. Questo sistema, che ha permesso di realizzare programmi sempre più utilizzati, come quelli per il riconoscimento dei visi, è il più promettente per costruire programmi “intelligenti”. </p>
<p> Reti neurali, machine learning e deep learning sono termini che ricorrono spesso quando si parla di intelligenza artificiale. In molti casi sono integrati tra loro, a strati: come in una pizza, per capirci. La rete neurale è la pasta, un insieme di computer in rete tra loro che si scambiano dati ed elaborazioni; il machine learning è il pomodoro, un programma che funziona grazie alla rete neurale e che può servire per far imparare ai computer a riconoscere certi tipi di dati o a dare particolari risposte; il deep learning è la mozzarella, un sistema che sfrutta gli altri due strati per elaborare e analizzare enormi quantità di dati, resi per lo più accessibili grazie a Internet. </p>
<p> Come suggerisce il nome, una rete neurale cerca di imitare la struttura di base del nostro cervello: i computer (o solo i loro processori) e il loro software sono collegati insieme in una rete con nodi e collegamenti che ricordano quelli che si formano tra i neuroni. Preso individualmente, ogni nodo è piuttosto tonto, ma tutti i nodi presi collettivamente possono risolvere problemi complicati. Inoltre, con i giusti algoritmi e programmi, le reti neurali possono acquisire l’abilità di imparare da sole. </p>
<p> Nella programmazione classica di un software, il programmatore inserisce tutte le informazioni necessarie per farlo funzionare. Se lo scopo è fare in modo che un robot sappia come si attraversa in sicurezza la strada, il programmatore inserirà nel suo computer una copiosa serie di regole per fare controllare al robot che il semaforo sia verde, che ci siano le strisce pedonali, che non ci siano veicoli in movimento e così via. In questo modo il robot può eseguire a cascata le istruzioni: SE è rosso stai fermo, SE è verde muoviti, SE attraversi guardati intorno, SE non arriva un’automobile continua, ecc. </p>
<p> Nel machine learning l’approccio è diverso: al computer che gestisce il robot non vengono date istruzioni, che spesso richiedono una grande quantità di ore di programmazione, ma migliaia di video nei quali c’è qualcuno che attraversa una strada. L’obiettivo è fare in modo che sia il computer, analizzando quei video, a capire quali sono le regole e come comportarsi quando si deve attraversare la strada. Ottenere questo risultato però non è semplice: negli anni sono state provate soluzioni di vario tipo, che in alcuni casi riprendono le tecniche usate per il nostro apprendimento o per l’addestramento degli animali. I programmatori si sono inventati sistemi di “ricompensa”, che portano il programma a migliorare gradualmente, o altre soluzioni più elaborate come la costruzione di algoritmi che competono tra loro, fino a quando prevale quello con la soluzione migliore. </p>
<p> L’insegnamento per esempi che ha dato i frutti più promettenti – che viene sperimentato dalla maggior parte delle grandi aziende come Google e Facebook – è legato al deep learning (“apprendimento profondo”), l’analisi approfondita e su più livelli di uno scenario per comprenderlo. Come ricorda James Vincent su The Verge, il deep learning è stato soprattutto esplorato per creare intelligenze artificiali in grado di riconoscere ciò che mostra un’immagine. Un computer non vede una fotografia come la vediamo noi, conosce solamente la posizione di ogni singolo pixel e il suo colore. </p>
<p> Con le tecniche di deep learning, l’immagine viene divisa in vari strati di analisi. A un livello più basso, il software analizza per esempio una griglia di pochi pixel, con il compito di rilevare un tipo di colore o varie sue sfumature. Se trova qualcosa, informa il livello di analisi che sta sopra di lui, che a questo punto verifica se quel dato colore appartenga o meno a una forma più grande, come una linea. Il processo continua verso i livelli superiori fino a comprendere che cosa viene mostrato nell’immagine. Software in grado di fare queste cose sono ormai diffusi e servono, per esempio, nei sistemi per il riconoscimento dei visi, o in quelli per effettuare ricerche tramite un’immagine su Google. In molti casi, questi sistemi sono ibridi e funzionano con soluzioni informatiche più tradizionali, miste a quelle di intelligenza artificiale di nuova generazione. </p>
<p> Il problema è che a un livello di conoscenza vera e propria, il computer non sa che cosa sia veramente un cane, un gatto o un’automobile. Insegnare a un sistema di intelligenza artificiale che cos’è un elefante non è per nulla semplice, e ha portato per ora a risultati limitati, per quanto incoraggianti. Una rete neurale può essere programmata in modo da riconoscere diversi particolari di un elefante, come le zampe, le grandi orecchie e la proboscide. In una seconda fase alla rete neurale vengono mostrate immagini di elefanti e di altri animali che camminano a quattro zampe, indicando ogni volta quando è visibile un elefante. I nodi della rete neurale rilevano la presenza della proboscide, delle orecchie e delle zampe e in un certo senso evolvono, conservando le informazioni rilevanti e lasciando indietro i nodi meno importanti. Nel processo, il sistema può per esempio notare che la proboscide compare solo in alcuni tipi di animali e che è associata solo a quelli con le orecchie fatte in un certo modo. </p>
<p> Un processo di apprendimento di questo tipo richiede molto tempo e quasi sempre un intervento umano, per aiutare la rete neurale a riconoscere gli errori e a renderli meno frequenti. In alcuni contesti il deep learning è affiancato ad altre soluzioni con lo scopo di correggere automaticamente gli errori di apprendimenti, ma per ora i risultati non sono stati molto incoraggianti. I progressi ci sono comunque stati, soprattutto se si pensa che il primo animale riconosciuto da un computer, un gatto, risale ad appena 5 anni fa. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/04/20/esperimenti-giochi-intelligenza-artificiale/" parent_folder="Il Post 2016-17" id="file17861981" filename="esperimenti-giochi-intelligenza-artificiale">
<p> 14 giochi per mettere alla prova l’intelligenza artificiale </p>
<p> Gli esperimenti da provare di Google e Microsoft che mostrano come i computer imparano a disegnare, a comporre musica e a riconoscere quello che vedono </p>
<p> Le intelligenze artificiali (AI) che sono già intorno a noi non sono ancora in grado di guidare da sole un’automobile in tutta sicurezza, né riescono a scrivere sceneggiature davvero convincenti, ma ogni giorno la ricerca per farle diventare più capaci ottiene nuovi risultati e in alcuni casi chiunque possieda un computer e una connessione a Internet può contribuire a insegnare loro qualcosa. Sia Google sia Microsoft hanno messo online alcuni esperimenti (interpretabilissimi come “giochini”) con cui provare a capire come si insegna a un computer a imparare, oppure semplicemente per farsi un’idea di quanto sono intelligenti certi sistemi di AI che già esistono. Quelli di Google si trovano sulla piattaforma A.I. Experiments, quelli di Microsoft sono stati realizzati per lo più dalla comunità di ricerca Microsoft Garage. </p>
<p> Non sono ovviamente i primi esperimenti di questo genere. Quelli più vecchi, come il bot per chiacchierare A.L.I.C.E. (una specie di antenata di Siri) e il gioco 20Q, in cui un’AI deve indovinare la cosa a cui state pensando (tra le categorie “animale”, “vegetale”, “minerale”, “altro” e “non so”) facendo meno di 20 domande, funzionano intorno al linguaggio. In molti videogiochi degli scorsi decenni poi i sistemi di AI erano usati per imparare a prevedere le mosse dei giocatori imparando da quelle precedenti e comportarsi di conseguenza. Gli esperimenti di AI più recenti invece si basano in gran parte su un’abilità più sofisticata, quella del riconoscimento delle immagini. Potete usarli, ad esempio, per giocare a Pictionary col vostro computer o scoprire di che razza è un cane che avete visto passare per strada (se lo avete fotografato). </p>
<p> AutoDraw </p>
<p> AutoDraw è un’applicazione di A.I. Experiments per fare disegni semplici usando il proprio computer: partendo da uno scarabocchio dell’utente permette di ottenere immagini disegnate molto bene, realizzate per gli sviluppatori del programma da alcuni illustratori. Per ora è disponibile solo da browser, non come app da scaricare, ma si può usare anche su smartphone. </p>
<p> Giorgio Cam </p>
<p> Giorgio Cam è uno degli esperimenti più divertenti di A.I. Experiments. Mette insieme un sistema di riconoscimento di immagini e la musica di Giorgio Moroder (che tutti chiamano Giorgio). Per giocarci bisogna scattare una foto a qualcosa con la fotocamera dello smartphone – solo se ha un sistema operativo Android – o attraverso la webcam del computer: l’AI prova a riconoscere ciò che si vede nell’inquadratura e poi compone un testo su una traccia musicale composta da Giorgio Moroder. Il riconoscimento facciale è abbastanza accurato e il risultato musicale finale è ridicolo, ma abbastanza divertente. </p>
<p> CaptionBot </p>
<p> Anche Microsoft ha reso disponibili applicazioni che funzionano a partire dal riconoscimento delle immagini. Quella più sofisticata è CaptionBot che mette insieme l’analisi dell’immagine all’uso del linguaggio – che è ancora molto difficile da padroneggiare per i computer – per descrivere ciò che si vede. Funziona sia caricando una fotografia, sia inserendo l’URL di un’immagine già pubblicata da qualche altra parte online (se si caricano proprie immagini, Microsoft si riserva il diritto di utilizzarle in futuro per perfezionare il suo sistema, quindi è meglio non inviarne di troppo personali). Non è ancora brillantissima, ma potete aiutarla a migliorarsi valutando la sua accuratezza con un sistema di voto da 1 a 5 stelline. Potete provare a testare la sua intelligenza qui. </p>
<p> Quick, Draw! </p>
<p> Lo stesso principio di AutoDraw è usato da Quick, Draw!, che è una specie di Pictionary con cui giocare insieme al proprio computer, o smartphone. Il gioco è piuttosto semplice: il sistema chiede di disegnare un oggetto che deve essere riconosciuto da un’intelligenza artificiale entro 20 secondi. Più il disegno è accurato, più l’AI ha probabilità di indovinarlo. Si può anche scaricare come app sui dispositivi mobili. </p>
<p> How Old Do I Look? </p>
<p> Oltre a CaptionBot, Microsoft ha messo online molti altri esperimenti di riconoscimento delle immagini che possono essere usati durante una cena noiosa se si è a corto di aneddoti divertenti. Uno è How Old Do I Look? che prova a stimare l’età di una persona (e il genere) a partire da una foto. A volte i risultati sono lusinghieri, altre volte un po’ meno. Se anche volete provarlo su una vostra foto potete stare tranquilli, perché l’applicazione non le conserva. </p>
<p> Matteo Renzi ha 42 anni, quindi il risultato è abbastanza accurato. </p>
<p> Are You Twins? </p>
<p> Are You Twins? invece trova le somiglianze tra i volti di due persone in due immagini diverse e fornisce una percentuale di quanto si assomiglino. Potete provarla con vecchie fotografie dei vostri genitori per stabilire ad esempio chi gli assomigli di più tra voi e i vostri fratelli, oppure con quella della persona famosa a cui assomigliate secondo i vostri amici per capire se vogliono solo lusingarvi o avete davvero un sosia. </p>
<p> Gli attori Luke e Owen Wilson, che sono fratelli, si assomigliano al 73 per cento secondo Are You Twins?: </p>
<p> Celebs Like Me </p>
<p> Potete anche farvi dire a quale persona famosa assomigliate direttamente da un’AI, grazie a Celebs Like Me, che usa lo stesso sistema di Are You Twins? applicato a una funzione di motore di ricerca per trovare fotografie di persone famose. </p>
<p> Giuliano Poletti non è abbastanza famoso per essere riconosciuto dall’AI di Celebs Like Me, ma assomiglia abbastanza a Rob Reiner in effetti: </p>
<p> My Moustache </p>
<p> Un’altra applicazione Microsoft dei sistemi di riconoscimento facciale è My Moustache che capisce se in una fotografia di una persona che gli viene “mostrata” si vedono dei baffi e li analizza in base alla lunghezza, classificandoli in “lame mo”, “getting there” e “ultimate mo”, rispettivamente “baffi sfigati”, “ci stiamo arrivando” e “baffi top”. Nel caso non si disponga di baffi, l’applicazione mostra come si starebbe con dei baffi disegnati. Finora My Moustache ha analizzato più di 78mila immagini e per questo diventa sempre più abile a “vedere” i baffi. </p>
<p> The Infinite Drum Machine </p>
<p> Questo esperimento di A.I. Experiments si basa solo sui suoni, non sulle immagini, ed è molto divertente, anche se in modo più raffinato di Giorgio Cam. È consigliato a chi ama molto la musica, le percussioni in particolare: è una grande mappa di suoni e rumori (da quello di uno sbadiglio a quello che fa un foglio di carta quando viene strappato, dal suono di uno xilofono al rumore di una “tanica di propano che viene appoggiata sulla ghiaia”) interattiva organizzata dall’AI dietro l’esperimento in base alle caratteristiche comuni. La mappa si può usare per esplorare la grande galleria di suoni e rumori e anche per realizzare sequenze ritmate. Ci potete giocare – o comporre qualcosa – qui. </p>
<p> A.I. Duet </p>
<p> A.I. Duet è un altro esperimento musicale di Google, che permette di suonare insieme a un’AI. Si presenta come una tastiera su cui suonare una breve melodia: l’AI risponde suonandone una sua, composta in risposta sul momento. Il sistema è stato creato usato una tecnica di machine learning: a questa AI non è stato detto quali suoni stiano bene tra loro, le è semplicemente stata fatta “ascoltare” una grandissima quantità di musica, e lo ha capito da sola (o quasi). </p>
<p> Thing Translator </p>
<p> Thing Translator mette insieme la capacità di un’AI di riconoscere le immagini a quella di usare diverse lingue, in particolare l’inglese, lo spagnolo, il francese, il tedesco, l’italiano, il cinese, il giapponese, il coreano, l’hindi e l’olandese. Potrebbe essere molto utile quando si è in viaggio in un paese di cui non si conosce la lingua: riconosce l’oggetto inquadrato dalla fotocamera dello smartphone (se ha sistema operativo Android) o del computer e restituisce la parola per definirla nelle lingue prescelte, ad esempio la propria e quella in cui non ci si riesce a esprimere. </p>
<p> Bird Sounds </p>
<p> Per chi volesse avvicinarsi all’ornitologia Bird Sounds potrebbe essere un buon punto di partenza: è una mappa di suoni come The Infinite Drum Machine ma comprende solo versi di uccelli, dalle anatre ai passerotti, dai falchi ai gabbiani. L’AI del sistema ha messo in ordine una serie di suoni e creato un’enciclopedia interattiva di versi di uccelli. Come The Infinite Drum Machine questo esperimento è chiuso, lo si può solo consultare, non si può usare come Shazam per i suoni degli uccelli fuori dalla nostra finestra a meno di avere un ottimo orecchio. </p>
<p> Visualizing High-Dimensional Space </p>
<p> Questo esperimento è molto meno divertente da usare (bisogna essere piuttosto nerd per giocarci), ma è molto più utile per capire cosa è in grado di fare un’AI, anche solo guardando il video che spiega come funziona. In pratica mostra una mappa di come un’AI dispone una serie di dati – che si tratti di immagini o di parole – che ha analizzato dopo aver “studiato” una grande quantità di questo tipo di dati. Ad esempio, in uno dei casi usati dai programmatori di questo esperimento, l’AI ha imparato a distinguere cifre da 1 a 9 scritte da tante persone diverse: chiedendo all’esperimento di mostrarci “Mnist with images” possiamo osservare come le immagini delle cifre scritte a mano siano riconosciute dall’AI, guardando una specie di mappa del suo “cervello”. </p>
<p> What Dog? </p>
<p> Un altro esperimento utile per gli amanti degli animali è What Dog? di Microsoft, una specie di Shazam dei cani: grazie a un sistema di riconoscimento delle immagini riesce a risalire alla razza dei cani che le vengono mostrati, anche se nella stessa immagine si vede una persona. </p>
<p> È abbastanza accurato a meno che non ci si voglia prendere gioco di lui. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/04/25/etica-auto-che-si-guidano-da-sole-esperimento-mit/" parent_folder="Il Post 2016-17" id="file17861980" filename="etica-auto-che-si-guidano-da-sole-esperimento-mit">
<p> Siamo meglio di un’auto che si guida da sola? </p>
<p> Al suo posto faremmo scelte etiche migliori? Sul risparmiare la vita di un pedone o la nostra in un incidente, per esempio: non è semplice, come dimostra questo esperimento </p>
<p> Uno dei campi in cui gli studi sull’intelligenza artificiale (AI) si stanno concentrando di più è quello delle automobili che si guidano da sole. Su alcune automobili di Tesla Motors, una delle aziende fondate da Elon Musk, è già presente un autopilota che può essere attivato in alcune circostanze (in autostrada, per esempio) e Musk ha in programma di rendere più avanzata questa funzione, offrendola su tutti i nuovi modelli. Le case automobilistiche più tradizionali sono state più caute nello sviluppare questo tipo di sistemi, ma alcuni prototipi sono stati realizzati e ultimamente se ne parla sempre di più. Lo scorso gennaio Volvo ha presentato una versione della sua XC90 con guida autonoma. A febbraio Ford ha annunciato che nei prossimi cinque anni investirà un miliardo di dollari nella startup di sviluppo di intelligenze artificiale Argo AI, mentre il gruppo Volkswagen ha da poco annunciato un investimento da più di 165 milioni di euro nell’azienda cinese Mobvoi, che si occupa a sua volta di AI, anche se per ora è specializzata più che altro nel campo del riconoscimento vocale. </p>
<p> Fiat Chrysler Automobiles (FCA) ha prodotto alcuni esemplari di minivan Pacifica che si guidano da soli grazie alle tecnologie sviluppate in questi anni da Google, che da parte sua ha fondato una società apposta per sviluppare automobili “intelligenti”, Waymo. Apple sembra invece che abbia temporaneamente abbandonato i suoi più ambiziosi progetti in questo ambito, decidendo di concentrarsi sullo sviluppo di un sistema di guida automatica da fornire a case automobilistiche già esistenti. Anche Uber sta investendo molto nella tecnologia delle auto che si guidano da sole, dato che potrebbero contribuire a ridurre i costi del suo servizio, dovuti al personale. </p>
<p> I software utilizzati da Google, Uber e gli altri non sono ancora molto “intelligenti” e ripetono di continuo algoritmi per riconoscere la segnaletica stradale, la presenza degli altri veicoli, dei pedoni e fare previsioni su come si muoveranno intorno all’automobile. L’idea è però affinare questi sistemi in modo che tramite il machine learning imparino a migliorarsi, rendendo sempre più sicura e affidabile la guida automatica. Le automobili che si guidano da sole non sono comunque tutte uguali: ad esempio, il sistema di Tesla (e così quello della XC90 di Volvo) prevede che il passeggero al posto di guida rimanga costantemente concentrato sulla strada, e intervenga di continuo per modificare e correggere le decisioni automatiche dell’auto, mentre Google sta studiando il modo di rendere completamente autonoma l’auto, senza richiedere l’intervento del pilota. Le automobili di Google non sono ancora state commercializzate, ma quando lo saranno avranno un grado di autonomia maggiore rispetto alle Tesla. </p>
<p> Il funzionamento delle automobili che si guidano da sole è anche uno di quegli ambiti di sviluppo delle intelligenze artificiali che più vengono citati dagli studiosi che si occupano dei risvolti etici dell’uso delle AI. Queste macchine sono (meglio, saranno) in grado di riconoscere i segnali del codice della strada e di rispettare le regole di precedenza, ma non sappiamo ancora come si comporteranno quando dovranno evitare gli incidenti in cui sia i propri passeggeri che altre persone potrebbero rimanere coinvolti. La questione è molto complessa: potremmo essere tutti d’accordo che sia lecito investire un animale per salvare la vita di un passeggero, nel caso questa sia l’alternativa, ma come dovrebbe comportarsi un’auto che si guida da sola posta davanti alla scelta tra andare a sbattere contro un muro uccidendo i propri quattro passeggeri per non colpire una scolaresca? </p>
<p> Un gruppo di ricerca del Massachusetts Institute of Technology (MIT) ha realizzato un esperimento – accessibile a tutti sul sito Moral Machine – per mostrare i limiti connessi a queste scelte e come in alcuni casi anche un essere umano possa trovarsi in difficoltà nel compiere una scelta etica in potenziali circostanze di incidente stradale. L’effetto collaterale di questo esperimento, di cui vi proponiamo le parti più rilevanti, è di mettere in discussione le proprie capacità di stabilire quale sia il male minore (e forse di farci sentire un po’ persone orribili). </p>
<p> Il test etico di Moral Machine – a cui più di un milione di persone in tutto il mondo si sono sottoposte – è composto di tredici diverse situazioni in cui bisogna scegliere il male minore in due ipotesi di incidente. Per ogni test le situazioni proposte dal sito cambiano, ma tutte si dividono in tre categorie: quelle in cui l’automobile della simulazione deve scegliere chi investire tra due gruppi di pedoni (ed eventualmente animali), quelle in cui deve scegliere tra i propri passeggeri e un gruppo di pedoni che le stanno di fronte e quelle in cui la scelta è sempre tra passeggeri e pedoni, ma messi su un’altra corsia rispetto a quella di percorrenza. </p>
<p> Tra le prime ci sono quelle in cui l’automobile deve scegliere, ad esempio, se investire due bambini oppure due persone più anziane. </p>
<p> In altri casi la scelta proposta si basa su criteri meno condivisibili: ad esempio il caso in cui l’automobile deve scegliere se investire una donna che sta attraversando le strisce pedonali con il semaforo rosso, oppure un uomo che le sta attraversando con il verde. Il fatto che la donna sia una lavoratrice, o in particolare un medico, e l’uomo un senzatetto o un criminale, o viceversa, ha una qualche influenza sulla decisione quando in ogni caso il risultato finale è di un morto? </p>
<p> Quando nella scelta sono coinvolti anche i passeggeri dell’automobile si aggiunge un altro aspetto della questione: chi è a bordo deve avere diritto a qualche tipo di precedenza rispetto ai pedoni o ai passeggeri di altre automobili? </p>
<p> Per uno degli studi, degli stessi ricercatori che hanno realizzato Moral Machine, pubblicato nel 2015 su Arxiv ad alcune centinaia di persone è stato chiesto di immaginare scenari simili a quello dell’auto che si guida da sola che – in una strada tra due pareti come quella di questi esempi – deve scegliere tra andare contro il muro e investire i pedoni: immaginando di essere estranee alla situazione le persone hanno scelto nella maggior parte dei casi di sacrificare chi stava nell’auto, ma immaginando di essere loro a bordo in molti cambiavano idea, scegliendo di salvarsi. Per quello studio il 75 per cento delle persone disse di ritenere moralmente giusto evitare i pedoni, ma solo il 65 per cento disse di pensare che le auto che si guidano da sole dovrebbero essere programmate per farlo. </p>
<p> Dopo aver fatto il test etico di Moral Machine si può decidere di collaborare con i ricercatori del MIT dando alcune informazioni in più su di sé, in modo da spiegare le ragioni dietro le proprie scelte. Oltre all’età, al proprio genere, al livello di istruzione e a quello di fede religiosa, i ricercatori del MIT vogliono sapere quanto conta per noi nella scelta il fatto che alcuni pedoni attraversino col rosso e altri col verde, il fatto che alcuni siano donne e altri uomini, giovani o vecchi, in apparente buona salute o meno. </p>
<p> In una conferenza TED tenuta da uno dei ricercatori di Moral Machine, Iyad Rahwan, è spiegato che ovviamente le opzioni proposte dall’esperimento sono riduttive e non contemplano molte possibilità e variabili che si presenterebbero in una situazione reale: tuttavia per insegnare a una macchina a fare scelte etiche, usando un algoritmo o una tecnica di machine learning, è importante capire come la pensano davvero le persone in materia di etica. Il problema con l’etica però è che difficilmente si trova una posizione comune. Quasi tutti pensano che le auto che si guidano da sole dovrebbero minimizzare i danni in caso di incidente, ma al tempo stesso sembra che la maggior parte delle persone preferirebbero guidare automobili che mettano al primo posto la propria vita. I sondaggi fatti dai ricercatori hanno anche mostrato che le persone per risolvere la questione sceglierebbero di non usare auto che si guidano da sole, ma auto tradizionali, anche se un sistema di viabilità fatto solo di auto in grado di guidare da sole sarebbe complessivamente più sicuro di quello attuale. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/03/01/facebook-intelligenza-artificiale-prevenzione-suicidi/" parent_folder="Il Post 2016-17" id="file17861932" filename="facebook-intelligenza-artificiale-prevenzione-suicidi">
<p> Facebook ora usa l’intelligenza artificiale per la prevenzione dei suicidi </p>
<p> È un nuovo sistema per aiutare le persone che dicono di volersi farsi del male in streaming su Facebook Live </p>
<p> Facebook ha introdotto un nuovo strumento per riconoscere i post di persone intenzionate a suicidarsi o a farsi del male. Facebook collabora da tempo con le associazioni per la prevenzione dei suicidi – lo scorso giugno ha esteso l’opzione che permette agli utenti di segnalare i post degli amici ritenuti a rischio di suicidio o autolesionismo a tutti i paesi in cui è presente – e insieme a queste ha sviluppato un sistema di intelligenza artificiale in grado di confrontare contenuti degli utenti simili a quelli di persone che hanno provato a suicidarsi. Il sistema si applica anche ai video in diretta di Facebook Live: chi vedrà un video trasmesso in diretta in cui qualcuno sembra avere intenzione di farsi del male potrà entrare in contatto con chi lo sta facendo, mentre per questa persona saranno resi molto visibili dei tasti per chiedere aiuto. I video non saranno bloccati, perché secondo Facebook è più semplice prevenire un suicidio facendo sì che gli amici e i familiari della persona in pericolo ne siano avvertiti piuttosto che bloccando la trasmissione in diretta di quello che sta succedendo. </p>
<p> Il sistema funziona grazie all’intelligenza artificiale (è il primo in questo ambito) ed è ritenuto più accurato rispetto alle segnalazioni degli utenti, che comunque non rimuove. Il sistema funziona più o meno allo stesso modo. Segnala i casi più preoccupanti a una squadra di Facebook specializzata e in ogni caso mostra alla persona ritenuta in pericolo una schermata di consigli: suggerisce di contattare un amico o chiamare il numero di un’associazione per la prevenzione dei suicidi. I numeri suggeriti in Italia sono quelli del Telefono Azzurro per i minori di 18 anni e del Telefono Amico. Per le segnalazioni alla squadra di Facebook, l’intelligenza artificiale dà la priorità ai casi che sembrano richiedere un intervento più tempestivo, mentre nelle situazioni meno gravi si limita a far sì che le opzioni per segnalare i contenuti preoccupanti risultino più evidenti agli amici della persona che li ha postati. Tra i nuovi strumenti per prevenire i suicidi c’è anche la possibilità di raggiungere i volontari delle organizzazioni come Telefono Amico anche attraverso la app di messaggistica Messenger. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/05/07/facebook-puo-influenzare-unelezione/" parent_folder="Il Post 2016-17" id="file17861954" filename="facebook-puo-influenzare-unelezione">
<p> Facebook può influenzare un’elezione? </p>
<p> Potenzialmente sì, se volesse, e non sarebbe nemmeno una cosa illegale: negli Stati Uniti se ne sta parlando </p>
<p> Mark Zuckerberg, il fondatore e CEO di Facebook, lo scorso 12 aprile ha pronunciato un discorso alla Facebook F8, una conferenza annuale per gli sviluppatori e gli imprenditori coinvolti con il social network. A un certo punto, Zuckerberg ha detto: «Mentre giro il mondo e mi guardo intorno, comincio a vedere persone e nazioni che si chiudono su se stesse, contro l’idea di un mondo connesso e di una comunità globale. Sento voci terribili che chiedono di costruire muri, e allontanare persone che considerano diverse. Per bloccare la libera espressione, per rallentare l’immigrazione, ridurre il libero scambio, e in certi casi, nel mondo, addirittura per impedire l’accesso a internet». Zuckerberg non ha mai citato direttamente Donald Trump, il principale candidato del Partito Repubblicano alla presidenza degli Stati Uniti, dalle idee apertamente xenofobe e radicali. È stato però molto chiaro che fosse lui il bersaglio della sua critica, soprattutto per il riferimento al muro, che Trump vorrebbe costruire al confine tra Stati Uniti e Messico. </p>
<p> In passato Zuckerberg ha fatto donazioni alle campagne elettorali sia di politici Democratici sia di politici Repubblicani, come succede spesso ai grandi imprenditori americani. Ha donato a Marco Rubio, senatore della Florida ed ex candidato Repubblicano alla presidenza, giovane e apprezzato anche in certi ambienti liberal per alcuni suoi tentativi di riformare le leggi sull’immigrazione; a John Boehner, ex presidente Repubblicano della Camera che si dimise nel 2015 perché accusato da alcuni compagni di partito di essere troppo moderato, e alla predecessore di Boehner, la Democratica Nancy Pelosi. Tra le altre cose Zuckerberg è amico di Chris Christie, governatore Repubblicano del New Jersey e a sua volta ex candidato alla presidenza: dopo essersi ritirato Christie ha dato il suo sostegno a Trump. Quest’anno Zuckerberg ha detto che non ha ancora deciso se e a chi farà donazioni. </p>
<p> Recentemente il sito di tecnologia Gizmodo ha pubblicato lo screenshot di un sondaggio interno ai dipendenti di Facebook, che ogni settimana votano quali domande fare a Zuckerberg in una sessione di Q&A (cioè domande e risposte). Nel sondaggio fatto tra i dipendenti lo scorso 4 marzo, una delle domande proposte era: «Che responsabilità ha Facebook per aiutare a prevenire una presidenza Trump nel 2017?». La domanda, nel momento in cui è stato fatto lo screenshot, era la quinta più votata, con 61 voti. Come ha spiegato Gizmodo, la notizia non è tanto che alcuni dipendenti di Facebook sia contro Trump, né che lo sia Zuckerberg: le proposte anti-immigrazione e retrograde fatte da Trump nella sua campagna elettorale sono molto diverse dalle idee più liberali della maggior parte degli imprenditori della Silicon Valley (anche di quelli Repubblicani). La questione sollevata dal sondaggio interno pubblicato da Gizmodo è più che altro sul se e come Facebook sta decidendo e deciderà di usare il suo enorme potere di influenzare la gente, anche politicamente. Molti opinionisti nelle ultime settimane hanno provato a rispondere alla domanda: può Facebook influenzare un’elezione semplicemente aggiustando il proprio News Feed? </p>
<p> Facebook è infatti il social network più grande del mondo, con 1,65 miliardi di iscritti. Le strategie aziendali degli ultimi anni hanno fatto sì che per moltissime persone Facebook è diventato internet: è il posto dove si fanno sempre di più tutte le cose che prima facevano su siti diversi, dal restare in contatto con gli amici al leggere le notizie. E il piano dell’azienda è insistere il più possibile su questa tendenza, facendo trovare agli utenti tutto ciò di cui hanno bisogno all’interno del social network, annullando le loro esigenze di cercare altrove. Già ora Facebook decide attraverso un algoritmo quali contenuti mostrare e quali nascondere sulle bacheche dei suoi utenti: e per sempre più utenti, i contenuti che vedono su Facebook sono gli unici o quasi che vedono su internet. Non c’è nessun vincolo legale che impedisca a Facebook di fare la selezione che preferisce sui suoi contenuti. </p>
<p> Eugene Volokh, che insegna legge alla University of California, ha spiegato a Gizmodo: «Facebook può promuovere o nascondere tutti i contenuti che vuole. Gode del Primo Emendamento [che tra le altre cose sancisce la libertà di parola e di stampa, ndr] come il New York Times. Possono completamente bloccare Trump, se vogliono. Possono bloccarlo o sostenerlo». Come scrive Gizmodo, però, il New York Times a differenza di Facebook non è uno dei posti dove Trump – come tutti gli altri politici del mondo – sta conducendo buona parte della sua campagna elettorale. I lettori dei giornali e dei siti di news, poi, sono solitamente a conoscenza dell’orientamento politico della testata: una censura delle notizie su Trump o una copertura critica della sua campagna elettorale su Facebook avrebbero perciò un’influenza perlomeno diversa. </p>
<p> All’inizio della campagna elettorale, quando la candidatura di Trump sembrava ancora destinata a sgonfiarsi in fretta, l’Huffington Post aveva annunciato che avrebbe spostato le notizie su Trump nella sua sezione dedicata allo spettacolo (poi ha dovuto fare marcia indietro, per ovvie ragioni). Allo stesso modo il direttore di BuzzFeed aveva mandato una mail ai responsabili dei social network del sito, scrivendo che potevano definire Trump razzista, perché lo era veramente. Ma la capacità di cambiare le opinioni dei lettori di un giornale, che pure esiste ed è spesso efficace, è comunque diversa da quella che avrebbe Facebook se decidesse di boicottare la campagna elettorale di Trump. E soprattutto, Facebook potrebbe raggiungere una quantità di persone molto più grande di qualunque giornale: e ciononostante sarebbe probabilmente più difficile accorgersene. </p>
<p> Facebook ha già fatto esperimenti di questo tipo. Nel 2010, in occasione delle elezioni di metà mandato negli Stati Uniti, collaborò con alcuni ricercatori per provare a convincere le persone ad andare a votare. Mise a disposizione di 61 milioni di utenti un’icona che permetteva di controllare dove fosse il seggio più vicino, e introdusse un tasto con il quale si poteva comunicare ai propri amici di avere votato. Ad altri utenti, invece, non era stato mostrato niente. I ricercatori raccolsero dopo le elezioni i dati sulla distribuzione geografica del voto, e analizzarono l’influenza che aveva avuto Facebook. In totale, Facebook aveva convinto a votare circa 60mila persone, che a loro volta avevano fatto sì che andassero a votare altre 340mila persone. Allora l’esperimento era stato considerato innocuo, perché Facebook aveva semplicemente convinto della gente a votare, non cosa votare. Un esperimento più criticato era stato quello condotto nel 2014, quando il social network aveva intenzionalmente manipolato il flusso di notizie di quasi 700mila utenti per studiarne “il contagio emotivo attraverso i social network”. </p>
<p> Difficilmente Facebook potrebbe convincere un elettore convinto di Donald Trump a votare per Bernie Sanders o per Hillary Clinton. Quello che potrebbe fare, però, è incoraggiare ad andare a votare i sostenitori più tiepidi dei suoi candidati preferiti, oppure provare a convincere gli elettori indecisi a votare per qualcuno. Con i dati raccolti dal social network sulle abitudini e sulle preferenze dei propri utenti, sarebbe relativamente facile per Facebook capire l’orientamento politico e il grado di coinvolgimento nella campagna elettorale di ciascuno. </p>
<p> Per provare ad aumentare i voti di un certo candidato, secondo Paul Brewer, professore di comunicazione alla University of Delaware che si è occupato degli effetti politici di Facebook, una strategia abbastanza scontata potrebbe essere quella di mostrare spesso sulla timeline degli utenti indecisi delle notizie positive su quel candidato. È lo stesso principio dei manifesti elettorali disseminati a ogni angolo durante le campagne elettorali: siamo portati a preferire quello che ci è famigliare perché lo vediamo spesso. Facebook poi sa quali sono i gusti dei suoi utenti: se a uno piace il basket, potrebbe mostrare sulla sua timeline delle notizie o delle foto di un candidato mentre gioca a basket. Allo stesso modo, se Facebook ha memorizzato che ci interessano particolari temi politici, tipo l’immigrazione, potrebbe mostrarci contenuti pertinenti che mettano in buona luce il suo candidato. </p>
<p> Un grande vantaggio di Facebook sarebbe che potrebbe adottare tutte queste strategie disponendo dei migliori dati per quanto riguarda gli orari e i formati più efficaci per promuovere i contenuti. Le possibilità di Facebook sono tantissime, dal mostrare sulle timeline i contenuti sul proprio candidato subito prima o subito dopo altri contenuti positivi, a fare esperimenti sul colore e i font utilizzati nei post, all’usare dei bot automatici nei commenti, alla durata del tempo in cui un post rimane sulla timeline degli utenti. </p>
<p> Secondo Brewer, però, il più grande vantaggio di Facebook sarebbe che ha il controllo non solo sui contenuti, ma anche sui commenti ai contenuti. Per un esperimento, Brewer creò un finto candidato per studiare quale percezione ne avrebbero avuto gli utenti di Facebook: scoprì che a influenzare davvero le persone, più che il candidato in sé e le sue idee, era quello che ne pensavano gli altri. Facebook potrebbe scegliere di mettere in evidenza, nei contenuti sul suo candidato, i commenti che ne parlano positivamente, e nascondere gli altri. In questo senso, secondo Brewer, le potenzialità maggiori per Facebook sono nella gestione di quello che gli utenti vedono delle attività e dei commenti dei propri amici. Tendiamo a dare importanza a quello che dice la gente, ma tendiamo a darne di più a quello che dice la gente che conosciamo e stimiamo. Già ora, un utente di Facebook tende a crearsi una cerchia di amici con i quali condivide le idee politiche: si crea in questo modo una specie di “bolla”, che è un efficace strumento di rafforzamento delle proprie convinzioni. </p>
<p> Robert Drechsel, professore di etica del giornalismo alla University of Wisconsin, ha detto a Gizmodo che secondo lui Facebook ha le stesse responsabilità di un giornale, e deve avere un approccio equo e oggettivo alle campagne elettorali. Per la legge americana, però, non è così. L’unico caso in cui Facebook violerebbe la legge sarebbe se si accordasse con un candidato per sabotarne un altro. Oltre a tutto questo, naturalmente c’è una grande questione di opportunità: Facebook è un’azienda e il suo scopo principale è fare soldi, crescere, e non immischiarsi nella politica americana. Un’operazione del genere, qualora fosse o diventasse pubblica, sarebbe un grosso danno di immagine per Facebook, che potrebbe avere dei contraccolpi nel numero dei suoi iscritti e quindi nei suoi introiti. </p>
<p> Facebook ha risposto con una breve nota, in cui spiega come utilizza le sue linee guida per mostrare i contenuti agli iscritti al servizio: </p>
<p> Prendiamo le accuse di errori molto sul serio. Facebook è una piattaforma per le persone e accoglie le opinioni di tutti gli schieramenti politici. Trending Topics mostra agli utenti i temi e gli hashtag popolari di cui si parla su Facebook. Ci sono rigorose linee guida in vigore per il team di revisione per garantire coerenza e neutralità. Queste linee guida non consentono la soppressione di opinioni politiche né permettono di dare priorità ad un punto di vista rispetto ad un altro o di un organo di stampa rispetto ad un altro. Queste linee guida non vietano ad alcun media di apparire nei Trending Topics. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/10/16/falla-sicurezza-wifi-wpa2/" parent_folder="Il Post 2016-17" id="file17861963" filename="falla-sicurezza-wifi-wpa2">
<p> Le connessioni sicure WiFi non sono più sicure </p>
<p> Una grave falla nel sistema WPA2 rende potenzialmente accessibile buona parte dei dati che i dispositivi scambiano tra loro sulle reti senza fili </p>
<p> Un gruppo di ricercatori ha identificato una grave falla all’interno di WPA2, il sistema utilizzato per criptare i dati attraverso le connessioni WiFi, cosa che potrebbe rendere possibile l’intercettazione dei dati scambiati dai computer e dagli smartphone attraverso le connessioni senza fili. La falla è stata chiamata “Krack Attacks” (o “Key Reinstallation Attacks”) e risiede nello standard stesso del WiFi e non in prodotti specifici: in pratica vuol dire che quasi tutti i punti di accesso WiFi, gli smartphone e i computer potrebbero essere interessati dal problema, con problemi seri soprattutto per i dispositivi con Android dalla versione 6.0 in poi e con alcune distribuzioni del sistema operativo Linux. </p>
<p> Semplificando molto (qui una spiegazione più dettagliata, in inglese), la falla riguarda il sistema di gestione delle chiavi di sicurezza che si scambiano i dispositivi che utilizzano WPA2, quando stabiliscono una connessione. Nella pratica un attacco di questo tipo non consente a chi lo realizza di scoprire la password della rete WiFi o le chiavi usate per criptare il sistema tramite WPA2. I router, cioè i dispositivi cui si collegano computer e smartphone per accedere a Internet, non sono quindi attaccati direttamente. La soluzione permette comunque di ottenere molte informazioni che transitano attraverso la rete WiFi. </p>
<p> Su Android e Linux le cose sono complicate dal fatto che i due sistemi non chiedono una nuova chiave per criptare i dati a ogni connessione. Il video qui sotto mostra come i ricercatori siano riusciti a condurre un attacco contro un dispositivo Android, riuscendo poi a decodificare tutti i dati sottratti alla loro vittima. </p>
<p> Il sistema funziona nel caso in cui i dati transitino tramite il protocollo HTTP (il più comune online), mentre su HTTPS (una versione che rende riservata la comunicazione e usa chiavi per criptarla) dà risultati diversi a seconda di come è stato utilizzato il protocollo. Su Windows e macOS il problema c’è, ma è mitigato dal fatto che non tutti i pacchetti di informazioni possono essere decifrati facilmente. </p>
<p> Osservazioni e dubbi sull’affidabilità di WPA2 circolavano ormai da tempo e alcuni produttori di dispositivi, soprattutto router, nelle ultime settimane hanno iniziato a lavorare ad aggiornamenti per risolvere il problema (alcuni sono già stati diffusi). Aggiornare i punti di accesso per il WiFi però non è semplice e in molti casi non ci sono automatismi per farlo. L’aggiornamento degli smartphone con Android e dei computer dovrebbe essere invece più semplice, ma richiede comunque un minimo di attenzione da parte degli utenti. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/11/09/finanziamenti-arabia-saudita-silicon-valley/" parent_folder="Il Post 2016-17" id="file17861973" filename="finanziamenti-arabia-saudita-silicon-valley">
<p> Molti soldi della Silicon Valley arrivano dall’Arabia Saudita, ma nessuno vuole parlarne </p>
<p> Il New York Times racconta gli investimenti di un paese profondamente antidemocratico nelle aziende che dicono di voler rendere il mondo un posto migliore </p>
<p> Farhad Manjoo, uno dei più importanti giornalisti di tecnologia al mondo, che scrive per il New York Times, ha raccontato in un articolo della quantità di soldi provenienti dall’Arabia Saudita raccolti dalle aziende della Silicon Valley; aziende dall’immagine pubblica progressista e aperta che contrasta con le politiche del regime saudita. </p>
<p> Manjoo scrive che le aziende di tecnologia hanno sempre provato a non parlare di questa storia, che è tornata ad attirare attenzioni dopo lo scorso weekend, quando ci sono stati decine di arresti e misteriosi incidenti nell’ambito di un regolamento di conti nella classe dirigente del paese. Tra gli arrestati c’era anche il principe Alwaleed bin Talal, uno degli uomini più ricchi al mondo e importante investitore di società come Apple, Lyft (una società diffusa negli Stati Uniti e simile a Uber) e Twitter. </p>
<p> Molti soldi delle società della Silicon Valley arrivano anche dal Fondo Pubblico d’Investimento (FPI), un fondo sovrano che utilizza i soldi provenienti dal petrolio per investimenti per conto della monarchia saudita. SoftBank, un importante conglomerato giapponese che investe nelle società di tecnologia, gestisce il Vision Fund, un fondo da 100 miliardi di dollari di cui circa 45 provengono proprio dal FPI. Tra le aziende che hanno ricevuto finanziamenti dal Vision Found ci sono l’app di messaggistica per aziende Slack, la società che progetta spazi di co-working fisici e virtuali WeWork, e anche Uber, il servizio di autonoleggio con autista, che ha ricevuto nel 2016 un investimento di 3,5 miliardi dal FPI. Nel 2011, Twitter ricevette 300 milioni di investimenti da un fondo del principe Alwaleed («più o meno nello stesso periodo in cui stava assumendo il suo ruolo nelle primavere arabe», ha ricordato Manjoo) e Lyft ne ricevette 105 milioni nel 2015. </p>
<p> Tutte e tre le società si sono rifiutate di commentare questo tipo di finanziamenti per l’articolo di Manjoo. Qualcuno gli ha parlato privatamente, spiegando che il principe Alwaleed non era allineato con il governo saudita, e che aveva promosso alcune riforme relativamente progressiste per il paese, come l’abolizione del divieto per le donne di guidare. Altri hanno fatto notare che qualcosa si sta effettivamente muovendo in Arabia Saudita: il piano di riforme “Vision 2030” vorrebbe rendere il paese non più dipendente dal petrolio entro il 2030, e soprattutto un po’ più moderno. Ci sono comunque molti dubbi sulla riuscita di questo progetto. </p>
<p> Le aziende della Silicon Valley nella maggior parte dei casi si stanno impegnando pubblicamente per costruirsi l’immagine di motori dei cambiamenti sociali dell’Occidente, in senso progressista. Si sono spesso fatte portavoce di valori come tolleranza, democrazia e diversità, e più di recente, dopo alcuni casi molto discussi sui giornali, si sono impegnate a essere più inclusive nei confronti delle donne e delle minoranze. Tutte promesse che contrastano con le politiche dell’Arabia Saudita, un paese che non rispetta i diritti umani, che da sempre discrimina le donne, per non parlare degli omosessuali, e che ha un’interpretazione retrograda e antidemocratica dell’Islam. </p>
<p> Freada Kapor, co-presidente del Kapor Center for Social Impact, che si occupa di promuovere la diversità e la tolleranza tra le società di tecnologia, ha spiegato a Manjoo che le aziende della Silicon Valley potrebbero decidere di non fare affari con l’Arabia Saudita, ma che hanno perso “la bussola della morale”. Secondo Kapor, i dirigenti di queste aziende sono talmente elitisti che «è fin troppo facile per loro razionalizzare il loro comportamento con la convinzione che sono gli uomini più furbi – e sì, sono sempre uomini – in circolazione». Molti dirigenti della Silicon Valley che fanno affari con l’Arabia Saudita li giustificano sostenendo che in questo modo contribuiscono alla modernizzazione dell’Arabia Saudita. La posizione delle aziende che ricevono investimenti di questo tipo è aiutata anche dal fatto che avvengono tramite fondi intermediari, che da un lato rendono il legame più tollerabile per i dirigenti, dall’altro permettono di renderlo meno evidente a dipendenti, clienti e altri investitori. </p>
<p> Qualcuno dice anche che le aziende accettano questi investimenti per disperazione, perché sono gli unici disponibili. Manjoo fa però notare che aziende come Slack hanno raccolto più soldi di quelli che hanno intenzione di spendere: secondo lui, accettano i soldi sauditi «perché sono lì, e nessuno fa poi così tanto casino se li accettano». </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/01/16/fresno-polizia-sorveglianza/" parent_folder="Il Post 2016-17" id="file17861946" filename="fresno-polizia-sorveglianza">
<p> Come la polizia di Fresno sorveglia i cittadini </p>
<p> Il Washington Post è stato in una delle centrali di analisi dati tecnologicamente più avanzate degli Stati Uniti, dove persone e luoghi sono classificati gialli, rossi o verdi </p>
<p> di Justin Jouvenal - Washington Post </p>
<p> Fresno, California – Mentre gli agenti si affrettavano a intervenire in risposta a una chiamata per una donna minacciata dall’ex compagno, nella sede centrale un operatore della polizia consultava un software che valuta il potenziale di violenza del sospettato, nello stesso modo in cui una banca produrrebbe una relazione sul credito di un cliente. Il programma passava in esame miliardi di dati, tra cui verbali d’arresto, registri catastali, banche dati commerciali, ricerche nel deep web e i post dell’uomo sui social media, e calcolava il suo grado di pericolosità come il più alto tra i tre livelli di colore previsti: un’allerta di colore rosso acceso. L’uomo aveva infatti precedenti di detenzione per possesso di arma da fuoco e affiliazione a gruppi criminali, e per prudenza la polizia decise di far intervenire un negoziatore. Il sospettato si arrese e la polizia spiegò che le informazioni di intelligence erano state d’aiuto per prendere la decisione giusta: l’uomo aveva in effetti una pistola. </p>
<p> Mentre negli Stati Uniti si discute da tempo del controllo di massa da parte della National Security Agency, tecnologie di nuova generazione come il software Beware (“State attenti”) usato a Fresno sta dando alle forze dell’ordine locali il potere di entrare nella vita dei cittadini come mai prima d’ora. Secondo alcuni funzionari di polizia, strumenti simili possono fornire informazioni essenziali per individuare terroristi o sventare sparatorie, garantire la sicurezza di agenti e civili, individuare sospettati e dare una svolta ai casi. Gli attacchi a Parigi e San Bernardino, in California, avrebbero solo ribadito la necessità di misure simili, secondo questi pareri. </p>
<p> Questi potenti sistemi hanno però messo in allarme sostenitori delle libertà civili e attivisti, secondo cui rappresenterebbero una preoccupante invasione della privacy, ci sarebbe stata poca vigilanza pubblica sul loro utilizzo e potrebbero potenzialmente portare ad abusi e errori. Alcuni sottolineano la necessità di leggi per tutelare i cittadini. I quali, in molti casi, non sono consapevoli del fatto che la polizia stia rastrellando informazioni sul loro conto. Aerei dotati di telecamere hanno filmato le proteste e i disordini a Baltimora e Ferguson, in Missouri. Per anni, decine di dipartimenti hanno usato dispositivi in grado di raccogliere tutti i dati dei cellulari di un’area, senza bisogno di ottenere un mandato di perquisizione. Alcune autorità in Oregon sono sotto inchiesta federale per aver usato un software per il monitoraggio dei social media, per tenere sotto controllo lo hashtag “Black Lives Matter”, dedicato alle proteste di Ferguson. </p>
<p> «È un fenomeno in crescita dall’11 settembre», sostiene Jennifer Lynch, che lavora come avvocato a Electronic Frontier Foundation. «Prima ci sono stati i finanziamenti ai militari per sviluppare questa tecnologia, che ora è tornata alle forze dell’ordine nazionali. La combinazione perfetta di tecnologia più economica e facile da usare e finanziamenti statali e federali per acquistarla». Sono pochi i dipartimenti disposti a parlare di come – e a volte persino se – utilizzano questi strumenti, ma la polizia di Fresno, in California, ci ha dato la rara opportunità di dare un’occhiata all’interno della propria centrale operativa all’avanguardia da 600mila dollari, proprio mentre in città si animava il dibattito sulla tecnologia. </p>
<p> Un arsenale di apparecchi high-tech Il Real Time Crime Center di Fresno è un genere di struttura diventata un modello a livello nazionale in termini di vigilanza high-tech. Negli ultimi dieci anni, centri simili hanno aperto a New York, Houston e Seattle. La futuristica sala di controllo di Fresno, attiva giorno e notte, si trova all’interno della sede centrale e può contare su una serie di tecnologie che permettono al dipartimento di vedere, analizzare e rispondere agli eventi che si svolgono nella città, che si trova nella San Joaquin Valley e ha più di mezzo milione di abitanti. In un recente lunedì pomeriggio, il centro brulicava di attività. La radio della polizia gracchiava attraverso gli altoparlanti – «soggetto armato con una spranga di acciaio» – mentre cinque operatori seduti dietro un muro di schermi digitavano un’infinità di informazioni per aiutare le unità a rispondere alle oltre 1.200 chiamate al numero 911 che il dipartimento riceve ogni giorno. Sui 57 monitor che ricoprono le mura del centro, gli operatori zoomano e passano in rassegna le circa 200 telecamere della polizia appostate in tutta la città. Possono collegarsi anche ad altre 800 telecamere installate tra scuole e strade, e sperano di aggiungere 400 collegamenti alle telecamere indossate dagli agenti e alle migliaia dagli esercizi locali dotati di sistemi di sorveglianza. </p>
<p> Le telecamere sono solo uno degli strumenti disponibili. Gli agenti hanno accesso a un database privato che contiene oltre due miliardi di immagini di targhe di veicoli e luoghi in tutto il paese. Nel caso di colpi di armi da fuoco, un sistema chiamato ShotSpotter è in grado di circoscrivere la posizione dello sparo sfruttando i microfoni sparsi in città. Un altro programma, chiamato MediaSonar, setaccia i social media in cerca di attività illegali, ed è usato dalla polizia per monitorare persone, allarmi nelle scuole e hashtag legati a bande criminali. Per la polizia di Fresno, l’accesso a tutte queste informazioni in tempo reale è essenziale per la risoluzione di reati. </p>
<p> Di recente, le telecamere sono state utilizzate per rintracciare un sospettato di rapina in fuga da un negozio, che era saltato in un canale per nascondersi. In poco tempo l’uomo è stato fermato. A settembre, il database che raccoglie i numeri di targa è stato determinante per risolvere un caso di omicidio, nel quale la polizia era in possesso di una descrizione del sospettato e di tre numeri della sua targa. Ma la tecnologia più utile e controversa è forse Beware, il software che assegna il livello di pericolosità. Quello di Fresno è uno dei primi dipartimenti a testare il programma nel paese. </p>
<p> Una volta che gli agenti rispondono a una chiamata, Beware cerca in automatico l’indirizzo. La ricerca fornisce i nomi degli inquilini e li confronta con una serie di dati disponibili pubblicamente, mostrando un livello di pericolosità a colori per ogni persona o indirizzo: verde, giallo o rosso. L’esatto processo con cui Beware calcola la pericolosità è considerato un segreto commerciale dalla casa produttrice, Intrado, e quindi non è noto quale peso venga attribuito a un’infrazione, a un reato grave, o a un commento minaccioso su Facebook. Il programma, ad ogni modo, segnala i problemi e fornisce un rapporto all’utente. In alcuni materiali promozionali, Intrado scrive che Beware è in grado di rivelare che un residente a un particolare indirizzo è un veterano di guerra affetto da un disturbo post-traumatico da stress, che ha precedenti di detenzione per aggressione e che ha postato messaggi preoccupanti sulle sue esperienze di guerra sui social media. I “big data” che hanno rivoluzionato il marketing e altri settori oggi sono a disposizione delle forze dell’ordine. Il capo della polizia di Fresno, Jerry Dyer, sostiene che spesso gli agenti hanno informazioni insufficienti o imprecise quando rispondono alle chiamate, perciò Beware e il Real Time Crime Center permettono loro di farsi un’idea di cosa potrebbero trovare dietro la prossima porta. «Dai nostri agenti ci si aspetta che conoscano l’ignoto e vedano l’invisibile», sostiene Dyer. «Devono prendere decisioni in una frazione di un secondo, sulla base di informazioni limitate. Se forniamo più informazioni in termini di intelligence e video, potranno rispondere alle chiamate in modo più sicuro». </p>
<p> A Fresno però, c’è chi sostiene che la potenza e la semplice concentrazione di dispositivi di sorveglianza nel Real Time Crime Center sia inquietante. Queste preoccupazioni sono state sollevate anche in altre città: l’anno scorso, funzionari di Oakland hanno dovuto ridimensionare i progetti per un centro simile, a seguito delle proteste dei cittadini per la violazione della privacy. Rob Nabarro, avvocato per i diritti civili di Fresno, si dice particolarmente preoccupato di Beware e sostiene che delegare a un software la valutazione della pericolosità di un individuo rappresenta un problema, in prospettiva. Secondo Nabarro, il fatto che solo Intrado – e non la polizia o i cittadini – sappia come Beware calcola i livelli di pericolosità è sconcertante. Nabarro teme anche che il sistema possa alzare per errore il livello di pericolosità di una persona, interpretando in modo sbagliato attività innocue sui social media – come criticare la polizia – e portare a una reazione più dura da parte delle forze dell’ordine. </p>
<p> Nabarro giudica la classificazione in colori di Beware «grezza e ancora molto approssimativa. Un intervento della polizia può essere molto pericoloso per i cittadini». Per Dyer, si tratta di timori esagerati: i livelli assegnati non innescherebbero alcuna reazione nello specifico, ma sarebbero usati dagli operatori come linee guida per indagare più a fondo nel passato di un individuo e cercare informazioni che possano essere d’aiuto a un agente sul campo. Secondo Dyer, il livello di pericolosità non viene mai visto dagli agenti che sono in strada. Eppure, Nabarro non è l’unico a essere preoccupato. A novembre, il consiglio comunale di Fresno aveva indetto una seduta su Beware, in seguito ai timori manifestati da alcuni cittadini. Un consigliere aveva riportato la notizia di una donna il cui livello di pericolosità era stato innalzato a causa di un tweet sul gioco di carte che si chiama “Rage” (rabbia), che potrebbe essere una delle parole chiave nel sistema di valutazione dei social media di Beware. Clinton J. Olivier, consigliere repubblicano vicino ai movimenti per le libertà civili, aveva paragonato Beware a un romanzo di fantascienza distopico, e posto a Dyer una semplice domanda: «Sarebbe in grado di mostrarmi il mio livello di pericolosità, ora?». </p>
<p> Dyer aveva acconsentito. L’analisi fece risultare Olivier come “verde”, mentre la sua abitazione era segnalata come “gialla”, forse a causa di un precedente inquilino che risiedeva al suo indirizzo, secondo quanto poi affermato da un responsabile della polizia. «Anche se non sono io il tizio giallo, i suoi agenti tratteranno chiunque esca da quella casa in mutande come se fosse il tizio giallo», aveva detto Olivier, aggiungendo poi che «[Beware] ha fallito proprio qui, con un consigliere come esempio». Un rappresentante di Intrado ha risposto con un breve comunicato alla richiesta di un’intervista sul funzionamento di Beware: «Beware serve a fornire in modo rapido [agli agenti] informazioni pubbliche e disponibili a livello commerciale, che siano pertinenti alla situazione e possano dar loro un maggiore senso di consapevolezza». </p>
<p> Un dibattito esemplare Con la diffusione delle nuove tecnologie ed il loro utilizzo in modo massiccio da parte delle forze dell’ordine, discussioni simili si sono tenute in tutto il paese. Secondo le ultime informazioni pubblicate dal Bureau of Justice Statistics, il numero di dipartimenti locali di polizia che utilizzano qualche forma di sorveglianza tecnologica è aumentato da una quota del 20 per cento nel 1997 a più del 90 per cento nel 2013. Le forme di sorveglianza più comuni sono le telecamere e i lettori di targa, ma l’uso di scanner biometrici palmari, di software per il monitoraggio dei social media, di dispositivi per la raccolta dei dati dei cellulari e di droni è in aumento. A livello locale, l’American Civil Liberties Union (ACLU) riferisce che le forze di polizia di Washington, Baltimora e delle contee di Montgomery e Fairfax sono dotate di dispositivi per la raccolta dei dati dei cellulari, chiamati “cell site simulator” o StingRays. La polizia di Washington utilizza anche ShotSpotter e i lettori di targa. </p>
<p> L’azione di sorveglianza crea una grande quantità di dati, che sempre più spesso vengono raccolti in database locali, regionali e nazionali. Il progetto più grande di questo genere è il Next Generation Identification Project dell’FBI, costato un miliardo di dollari e che raccoglie un’enorme quantità di impronte digitali, scansioni dell’iride, dati provenienti da software per il riconoscimento facciale e altre fonti, per coadiuvare i dipartimenti locali nell’identificazione dei sospettati. I funzionari delle forze dell’ordine sostengono che questi strumenti permettano di fare di più con meno risorse, e attribuiscono alla tecnologia il merito di aver permesso una svolta in diversi casi. L’anno scorso, la polizia di stato della Virginia rintracciò l’uomo che aveva ucciso alcuni giornalisti televisivi durante una trasmissione, grazie all’identificazione della targa dell’assalitore da parte di un lettore. I dispositivi per la raccolta dei dati dei cellulari, che simulano l’azione di un ripetitore e raccolgono tutti i dati dei cellulari presenti in un’area, sono stati fondamentali per trovare rapitori, fuggitivi, e persone a rischio di suicidio, riferiscono ancora i funzionari delle forze dell’ordine. </p>
<p> Tuttavia, a volte questi vantaggi hanno avuto un costo in termini di privacy. I dispositivi per la raccolta dei dati dei cellulari sono stati usati per anni dalla polizia senza un permesso esplicito di un giudice. Dopo le critiche mosse dall’ACLU e altri gruppi, però, lo scorso settembre il Dipartimento di Giustizia ha annunciato l’obbligo per tutte le agenzie federali di ottenere un mandato di perquisizione. Secondo Matt Cagley – un avvocato dell’ACLU del North Carolina – la discussione pubblica sulle tecnologie di sorveglianza è tardiva, dal momento che sono già in uso. «Noi pensiamo che ogni volta che c’è la possibilità di introdurre queste tecnologie di sorveglianza, ci debba essere un dibattito significativo», sostiene Cagley. «Sono necessarie tutele e vigilanza». </p>
<p> Dopo la discussa seduta del consiglio comunale di Fresno su Beware, Dyer ha spiegato di volere apportare delle modifiche per venire incontro alle preoccupazioni dei cittadini. Il capo della polizia ha affermato di essere al lavoro con Intrado per disattivare il sistema di classificazione a colori di Beware e possibilmente il monitoraggio dei social media: «Stiamo cercando di accontentare entrambe le parti». </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/08/30/gli-smartphone-hanno-distrutto-una-generazione/" parent_folder="Il Post 2016-17" id="file17861970" filename="gli-smartphone-hanno-distrutto-una-generazione">
<p> Gli smartphone hanno distrutto una generazione? </p>
<p> Un lungo e documentato articolo sull'Atlantic sembra dire di sì, ma è stato criticato da chi sostiene invece che "dare la colpa alla tecnologia" sia non solo parziale, ma anche poco realistico </p>
<p> Jean M. Twenge, docente di psicologia all’Università di San Diego, ha scritto per l’Atlantic un articolo molto complesso e discusso che analizza l’uso e le conseguenze degli smartphone e dei social media da parte degli e delle adolescenti. Il pezzo riprende i contenuti di un recente libro di Twenge, è documentato, cita diverse ricerche e, sebbene con una certa cautela, arriva a conclusioni piuttosto preoccupanti: non è un’esagerazione, dice la studiosa, descrivere gli adolescenti di oggi come sull’orlo della peggiore crisi di salute mentale degli ultimi decenni, e non è un’esagerazione ipotizzare che gran parte di questa situazione possa essere ricondotta ai loro telefonini. L’articolo, sia per i contenuti che per la parzialità del metodo, è stato però anche molto contestato e criticato. </p>
<p> Twenge precisa che lo scopo dei suoi studi non è cedere alla nostalgia per un mondo in cui le cose erano differenti, ma capire come sono le cose ora: alcuni cambiamenti sono positivi, alcuni sono negativi, e molti sono entrambe le cose insieme. Twenge racconta di aver studiato e lavorato molto sulle differenze tra generazioni e che, tipicamente, le caratteristiche che definiscono un gruppo di persone nate in un determinato periodo appaiono per gradi e lungo un continuum. I cosiddetti “Millennials”, di cui fa parte chi è nato tra la metà degli anni Ottanta e i primi anni del Duemila, sono considerati per esempio una generazione individualista: ma questa caratteristica era cominciata a comparire già all’epoca dei “Baby Boomers”, i nati dopo la Seconda guerra mondiale, e della “Generazione X” degli anni Settanta e Ottanta. I grafici delle ricerche di Twenge sulle tendenze delle diverse generazioni avevano dunque curve ascendenti e discendenti morbide e graduali. Almeno finora. </p>
<p> Quando Twenge ha iniziato a studiare la generazione di Athena, una 13enne che vive a Houston, Texas, e che le ha spiegato di aver trascorso la maggior parte della propria estate da sola in camera in chat con i propri amici, la studiosa ha notato degli spostamenti bruschi e dei picchi nelle tendenze dei propri grafici: molte delle caratteristiche distintive della generazione dei Millennials stavano scomparendo. Twenge dice di non aver mai visto niente di simile e che i cambiamenti non erano solo di grado, ma anche di natura. La differenza più grande tra i Millennials e i loro predecessori era nel modo di considerare il mondo; gli adolescenti di oggi si differenziano dai Millennials non solo per i nuovi punti di vista ma anche per come trascorrono il tempo: le esperienze che hanno nella loro quotidianità sono radicalmente diverse rispetto a quelle della generazione che li ha preceduti. </p>
<p> Twenge si occupa degli adolescenti americani, ma riscontra tendenze e abitudini che – in misure diverse, ovviamente – esistono in molti contesti e città occidentali, e in cui probabilmente molti genitori di adolescenti europei riconosceranno almeno in parte i propri figli. L’anno in cui sono avvenuti questi cambiamenti così significativi, secondo Twenge, è il 2012: c’entra probabilmente la grande recessione, dice, cioè la crisi economica mondiale iniziata nel 2007 e terminata circa due anni dopo, ma il 2012 è stato soprattutto l’anno in cui la percentuale di statunitensi che avevano uno smartphone ha superato il 50 per cento. A chi è nato tra il 1995 e il 2012 Twenge ha dato quindi un nome: iGen. Sono gli adolescenti che sono cresciuti possedendo uno smartphone, che avevano un account Instagram prima di iniziare la scuola superiore e che non si ricordano un tempo prima di Internet. I Millennials si sono formati con una grande familiarità con la tecnologia digitale che, però, non è mai stata presente nelle loro vite a un livello così elevato, cioè in ogni momento, giorno e notte. </p>
<p> Secondo Twenge le conseguenze della cosiddetta “età degli schermi” vengono spesso sottovalutate. Ci si concentra molto su specifici aspetti, per esempio la riduzione dell’attenzione, ma la diffusione degli smartphone ha invece cambiato radicalmente ogni aspetto delle vite degli adolescenti, dalla natura delle loro relazioni sociali alla loro salute mentale. E questi cambiamenti, dice la studiosa, riguardano tutti i giovani americani, a prescindere da dove vivano, in ogni tipo di famiglia: coinvolgono le persone benestanti e quelle non benestanti, quelle di ogni etnia, che vivono nelle città oppure nelle periferie. Anche quando in passato un evento significativo ha svolto un ruolo fondamentale ed estremo nella formazione e nella crescita di un gruppo di giovani, per esempio una guerra, non è mai accaduto prima che un singolo fattore definisse un’intera generazione e che avesse conseguenze così pervasive: «Ci sono prove convincenti che i dispositivi che abbiamo messo nelle mani dei giovani stiano avendo profondi effetti sulla loro vita e li rendano gravemente infelici». </p>
<p> Gli iGen, scrive Twenge, si sentono più a loro agio in camera loro che in una macchina o a una festa, nonostante siano più sicuri e informati rispetto al passato: hanno meno probabilità di fare un incidente automobilistico rispetto ai loro omologhi del passato, per esempio, e sono più a conoscenza dei rischi dell’alcol. Da un punto di vista psicologico, però, sono più vulnerabili rispetto ai Millennials. La prima caratteristica degli iGen è che la ricerca dell’indipendenza, così potente nelle generazioni precedenti, è meno forte. La patente di guida, simbolo di libertà inscritto nella cultura popolare americana, ha perso il proprio appeal: quasi tutti i Baby Boomers avevano la patente di guida pochi mesi dopo il compimento dell’età necessaria; oggi in America più di un adolescente su quattro non ha la patente alla fine della scuola superiore. Sono madri e padri ad accompagnare i figli a scuola o altrove, e dalle ricerche emerge che la patente viene descritta dagli adolescenti come qualcosa che importa soprattutto ai loro genitori, un concetto «impensabile per le generazioni precedenti», commenta Twenge. </p>
<p> È diminuita anche la percentuale di chi ha una frequentazione sentimentale: parte del corteggiamento avviene attraverso le chat e non è detto che poi si arrivi a un incontro reale. Nel 2015 solo il 56 per cento di chi frequenta l’ultimo anno delle scuole superiori ha avuto degli appuntamenti, mentre tra i Baby Boomers e i membri della Generazione X la percentuale era pari a circa l’85 per cento. Questo ha ovviamente delle conseguenze sulla vita sessuale degli iGen: secondo i dati citati da Twenge, i quindicenni che hanno una vita sessualmente attiva sono diminuiti del 40 per cento rispetto al 1991 e l’adolescente medio di oggi ha fatto sesso per la prima volta circa un anno dopo rispetto alla media di chi appartiene alla Generazione X. </p>
<p> Nelle generazioni precedenti, poi, gli adolescenti lavoravano di più in estate o nel tempo libero, desiderosi di finanziare la loro libertà: in questo erano stimolati anche dalle famiglie, che volevano insegnare loro il valore del denaro e la sua gestione. Gli adolescenti iGen invece non lavorano: alla fine degli anni Settanta, il 77 per cento dei ragazzi dell’ultimo anno delle scuole superiori aveva una qualche occupazione, entro la metà del 2010 la percentuale si è abbassata al 55 per cento e ora il numero è diminuito ancora. La tendenza a ritardare l’entrata nell’età adulta era già in atto anche nelle generazioni precedenti, dice Twenge, ma ciò che caratterizza gli iGen è in particolare il ritardo dell’inizio dell’adolescenza: i ragazzi che oggi hanno 18 anni agiscono come dei quindicenni e quelli di quindici anni sono più simili a dei ragazzini di tredici anni. L’infanzia si è cioè estesa. Perché, si chiede la studiosa, gli adolescenti di oggi aspettano più a lungo ad assumersi sia le responsabilità che i piaceri dell’età adulta? </p>
<p> I cambiamenti culturali, l’economia e il rapporto con la famiglia hanno certamente un ruolo: l’istruzione superiore è considerata più importante di trovarsi presto un lavoro, i genitori sono inclini a incoraggiare i loro figli a rimanere a casa e a studiare piuttosto che a cercarsi un’occupazione part-time e gli adolescenti, a loro volta, sembrano soddisfatti di questo accordo, «non perché siano particolarmente studiosi ma perché la loro vita sociale è vissuta sul telefono. Non hanno bisogno di lasciare la casa per trascorrere del tempo con i loro amici». I dati dicono che gli adolescenti iGen hanno più tempo libero rispetto agli adolescenti della generazione precedente. «E che cosa fanno con tutto quel tempo?» si chiede Twenge: «Sono al telefono, nella loro stanza». Si potrebbe allora pensare che gli adolescenti passino così tanto tempo in questi nuovi spazi virtuali perché questo li rende felici, ma la maggior parte dei dati suggerisce che non è così. </p>
<p> Nel suo articolo Twenge cita diverse ricerche. Una ha a che fare con il tempo del sonno e dice che dal 2012 le ore dedicate dagli adolescenti al dormire sono diminuite: usare il telefonino per diverse ore e anche subito prima di andare a letto ha conseguenze sulla quantità ma anche sulla qualità del riposo, e dormire poco e male ha a sua volta conseguenze sia fisiche che psicologiche. Da un’altra ricerca citata risulta che tutte le attività svolte davanti a uno schermo siano legate a una minore felicità e che tutte le attività alternative siano associate invece a una maggiore felicità. Le indagini riportate da Twenge dicono poi che più i ragazzi passano il tempo guardando uno schermo, più probabilità hanno di segnalare sintomi di depressione e di presentare maggiori fattori di rischio di suicidio (dal 2007 il tasso di omicidio tra adolescenti è diminuito, ma è aumentato quello dei suicidi: gli adolescenti hanno cioè iniziato a trascorrere meno tempo insieme ed è dunque diminuita la probabilità che si uccidano tra loro, spiega, ma è aumentata la probabilità che si facciano del male da soli): «Nel 2011, per la prima volta in 24 anni, il tasso di suicidio tra adolescenti era superiore al tasso di omicidio sempre fra persone della stessa età». </p>
<p> Naturalmente, precisa Twenge, queste analisi non dimostrano inequivocabilmente che il tempo passato davanti a uno schermo causi infelicità: è possibile infatti che gli adolescenti infelici spendano più tempo in rete e la studiosa, nel proprio articolo, ribadisce che è difficile comprendere con esattezza cosa venga prima e cosa dopo, cioè tracciare con precisione i nessi di causalità. Gli smartphone potrebbero causare la mancanza di sonno che porta alla depressione, o i cellulari potrebbero causare la depressione che porta alla mancanza di sonno. Ma cita un altro esperimento a cui sono stati sottoposti degli studenti del college con un account Facebook che sembra confermare la prima ipotesi, e cioè la sua tesi: per due settimane agli studenti sono stati inviati dei link cinque volte al giorno e loro dovevano rendere conto dello stato d’animo al momento della ricezione e di quanto avessero usato Facebook a partire da quei link. Più avevano usato Facebook, più segnalavano il loro stato d’animo come infelice. Il contrario però non valeva: il sentimento di infelicità non determinava cioè un maggior uso di Facebook. </p>
<p> Twenge scrive che «la depressione e il suicidio hanno molte cause» e che «troppa tecnologia non è chiaramente l’unica». Introduce però un concetto: poiché nell’età degli schermi è tutto documentato, lo è anche ogni occasione di ritrovo o aggregazione. Di conseguenza è aumentato il numero degli adolescenti che si sentono esclusi da quei momenti. Al sentimento di esclusione si unisce poi un’altra preoccupazione: la ricerca costante e ossessiva dell’approvazione tramite commenti, like e cuoricini vari. L’aspettativa dell’approvazione è diventata quotidiana e puntuale e questo genera ansia e un nuovo peso a cui l’adolescente è costantemente sottoposto. Questo vale soprattutto per le ragazze. I sintomi depressivi dei maschi sono aumentati del 21 per cento dal 2012 al 2015, mentre tra le giovani donne sono aumentati del 50 per cento, più del doppio. Twenge parla di una possibile spiegazione che ha a che fare con le modalità con cui i maschi e le femmine esprimono la loro aggressività o le loro reazioni di dissenso: i ragazzi tendono a scontrarsi fisicamente, mentre le ragazze hanno maggiori probabilità di farlo influenzando lo status sociale o le relazioni della persona con cui sono in contrasto in quel momento. I social media offrono quindi alle ragazze uno strumento perfetto su cui mettere in pratica lo stile di aggressione e di dissenso che favoriscono, potendo denigrare ed escludere altre ragazze 24 ore su 24. </p>
<p> Alla fine del suo articolo Twenge dice di rendersi conto che la limitazione della tecnologia potrebbe essere una richiesta irrealistica da imporre a una generazione di bambini e di ragazzini abituati ad essere sempre online, ma raccomanda anche che il semplice invito a un uso più responsabile e moderato della tecnologia potrebbe essere molto più necessario e importante di quanto non si possa pensare. </p>
<p> L’articolo di Twenge ha ricevuto diverse critiche. Su Psychology Today, mensile di psicologia pubblicato negli Stati Uniti, si dice innanzitutto che la studiosa ha scelto di citare solamente le ricerche che supportano la sua tesi e che ha tralasciato invece le indagini che hanno portato a risultati differenti: e che dicono, per esempio, che stare davanti a uno schermo non sia direttamente associato a depressione e solitudine, o che suggeriscono che l’uso attivo dei social media sia legato a risultati positivi come la resilienza. Ci sono poi studi che mostrano come la tecnologia possa sviluppare l’intelligenza, la produttività e la “coscienza ambientale”, e che mostrano come per un adolescente sia fondamentale connettersi con i suoi simili in tutto il mondo per condividere interessi, facendolo sentire incluso in una rete sociale piena di significato. Gli studi ripresi da Twenge si basano poi su metodi correlazionali che indagano cioè la misura in cui due determinati eventi o variabili sono in relazione tra loro. Questi metodi si occupano dunque dell’associazione tra i fenomeni senza stabilire se uno sia la causa dell’altro: lo precisa la stessa Twenge che però, ed è questa la critica, arriva in alcuni punti del suo pezzo a trarre da queste stesse ricerche delle conseguenze definitive. </p>
<p> Gli studi ripresi da Twenge sono poi troppo generali, dice chi la critica: ignorano in gran parte i contesti sociali e le differenze tra quelle stesse persone che stanno cercando di analizzare. L’uso dello schermo e la sua associazione con il benessere psicologico cambiano invece in base a una moltitudine di variabili sia di contesto che personali e di questo non viene dato conto. Infine: i bias, cioè le deviazioni dai valori medi che fanno parte delle ricerche citate da Twenge, sono scartati o riportati di passaggio come parte irrilevante della tesi che lei intende sostenere. Eppure si dice nel suo stesso pezzo che questa generazione ha un tasso di abuso di alcol, di gravidanze in giovane età, di sesso non protetto, di fumo e di incidenti automobilistici più basso rispetto a quello delle generazioni precedenti. Secondo Psychology Today questa non sembra esattamente la descrizione di una generazione distrutta. </p>
<p> In altri articoli di commento al pezzo dell’Atlantic si dice che è eccessivamente allarmistico e si citano dei dati (per esempio quelli che hanno a che fare con l’indice di felicità degli adolescenti) che o non mostrano una situazione di urgenza o che sono anzi in contrasto con quelli considerati da Twenge. La studiosa pone delle questioni fondamentali, si dice, ed è vero: ma proprio per questo è necessario essere molto attenti a trarre le giuste conclusioni. Inoltre, secondo i critici, Twenge non affronta alcune questioni importanti: non cita per esempio il fatto che la diffusione degli smartphone e dei social network ha riguardato negli anni Duemila sì gli adolescenti ma anche le persone più adulte, compresi i genitori di quegli stessi adolescenti. </p>
<p> Si suggerisce dunque di non “incolpare la tecnologia”, ma di cominciare a considerare un’altra spiegazione possibile per la condizione degli adolescenti di oggi: il disimpegno e la distrazione dei genitori stessi o, come è stata definita in alcuni studi di psicologia, la cosiddetta “genitorialità minima”. Questo offrirebbe una spiegazione alla crisi di indipendenza degli adolescenti di cui scrive Twenge. Promuovere l’indipendenza comporta infatti tempo e fatica da parte dei genitori e il lavoro di incoraggiamento a un comportamento positivo è altrettanto importante di quello che ha a che fare con la punizione di un comportamento negativo. Alcuni esperimenti di psicologia mostrano però che quando i genitori sono distratti è proprio l’incoraggiamento a risentirne, più che il controllo. </p>
<p> Su Slate, Lisa Guernsey – che si occupa di politiche educative e nuove tecnologie per il think tank New America – spiega che la strada suggerita da Twenge (togliere gli smartphone ai propri figli e suggerire loro di tornare nel 1985) sembra impossibile da praticare e che, d’altra parte, nemmeno l’atteggiamento del “lasciar fare” sembra essere promettente. Trovare una terza soluzione sembra fondamentale e può significare, tra le altre cose, ampliare le ricerche per avere una maggiore conoscenza dei dati e dei fenomeni e, soprattutto, «parlare con i nostri ragazzi». </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/01/28/go-alphago-google-deep-mind-intelligenza-artificiale/" parent_folder="Il Post 2016-17" id="file17861939" filename="go-alphago-google-deep-mind-intelligenza-artificiale">
<p> Un computer di Google ha battuto il campione europeo di un complicatissimo gioco da tavolo </p>
<p> L'intelligenza artificiale sviluppata da Google ora mira a fare altrettanto contro quello del mondo, a marzo </p>
<p> Un sistema di intelligenza artificiale realizzato da un gruppo di sviluppatori di Google ha battuto a “go” – un famoso gioco strategico ideato in Cina più di 2500 anni fa – il campione europeo in carica. La ricerca e la creazione del sistema sono state realizzate da Google DeepMind, azienda statunitense controllata da Alphabet, la nuova conglomerata che controlla le attività del motore di ricerca e le numerose altre aziende costituite negli ultimi anni per sfruttare le sue risorse finanziarie e produrre innovazioni di vario tipo. I risultati dell’iniziativa sono stati pubblicati sulla rivista scientifica Nature e sono considerati un progresso molto importante nell’ambito dell’intelligenza artificiale. </p>
<p> I computer sono utilizzati da tempo per competere contro gli esseri umani in alcuni dei giochi strategici più famosi e complessi, come per esempio gli scacchi. La sfida tra Deep Blue, il computer IBM, e lo scacchista russo di fama mondiale Garri Kasparov nella seconda metà degli anni Novanta è rimasta leggendaria e ha contribuito a rendere popolari i principali concetti legati all’intelligenza artificiale. Finora nessuno era però riuscito a realizzare un sistema affidabile a sufficienza per disputare e vincere una partita a go, gioco che ha complessità e combinazioni di gioco molto superiori a quelle degli scacchi e di altri giochi di strategia. </p>
<p> A go si gioca in due, davanti a una griglia 19 x 19 che viene chiamata goban. Per vincere è necessario conquistare una porzione di goban superiore a quella dell’avversario, collocando le proprie pedine sulla griglia. Ogni giocatore può catturare una o più pietre dell’avversario se riesce a circondarle completamente con le proprie pedine. Ogni giocatore deve quindi muoversi cercando di bilanciare le necessità di espandere il controllo sulla griglia con quella di difendersi dall’avversario. Il gioco finisce quando entrambi i giocatori passano a vicenda una mano, cosa che indica il fatto che nessuno dei due ha ulteriori possibilità di espandere il proprio territorio o di ridurre gli spazi occupati dall’avversario. Su un singolo goban ci sono 4,63 x 10170 diverse posizioni possibili, dato che fa ben capire quale sia l’enorme livello di complessità del gioco. </p>
<p> Semplificando, per disputare e provare a vincere una partita a scacchi di solito le intelligenze artificiali vengono programmate per calcolare e tenere traccia delle conseguenze di un grande insieme di mosse possibili sulla scacchiera. Sulla base di questi calcoli, scelgono poi l’opzione che può portare a una vittoria con più alta probabilità. Con il go è tutto più complicato perché le combinazioni sono talmente tante da non potere essere calcolate tutte ogni volta in tempi accettabili mentre si disputa una partita, ha spiegato Demis Hassabis, il CEO di Google DeepMind. L’unica soluzione è quindi insegnare a un computer a imitare il modo in cui ragiona un essere umano, aggiungendo quindi qualche livello di incertezza e di istinto ai suoi algoritmi. </p>
<p> Hassabis dice che nei giochi come il go, i partecipanti spesso fanno una mossa semplicemente perché “sentono” che sia quella giusta, cosa che normalmente un computer non fa. I ricercatori di Google DeepMind hanno quindi realizzato due reti neurali, cioè due sistemi informatici modellati sui meccanismi di funzionamento della mente umana, in modo da effettuare certi compiti sulla base dell’esperienza acquisita. Le due reti dialogano tra loro: una è dedicata a valutare la posizione delle pedine sulla griglia, mentre l’altra si occupa delle mosse da compiere. Non potendo valutare tutte le mosse possibili, la seconda valuta un set ristretto di opzioni, ritenute più sensate sulla base delle informazioni che riceve dalla prima. </p>
<p> Realizzato il loro giocatore artificiale, quelli di Google DeepMind hanno invitato il campione europeo di go, Fan Hui, per una sfida. Il computer – che è stato chiamato AlphaGo – ha battuto per cinque volte di fila il suo avversario, analizzando una quantità di opzioni “migliaia di volte inferiori” rispetto a quelle che calcolava lo stesso Deep Blue prima di fare una mossa a scacchi. Non è un dettaglio da poco: significa che AlphaGo in un certo senso è più intelligente, in termini umani e di capacità di ragionamento. </p>
<p> AlphaGo è stato sperimentato contro altri sistemi informatici creati negli ultimi tempi per vincere a giochi come go. Nello studio pubblicato su Nature si dice che l’intelligenza artificiale nel 99,8 per cento dei casi ha battuto tutti gli avversari e che potrebbe migliorare ancora, perché i suoi algoritmi sono fatti in modo da imparare dagli errori per migliorare la strategia di gioco. A differenza degli esseri umani, che si stancano dopo qualche partita e perdono la concentrazione, AlphaGo è inarrestabile e può giocare milioni di partite ogni giorno, imparando ogni volta nuove cose, ha detto Hassabis. Senza fare i guastafeste, è bene ricordare che per ora AlphaGo ha battuto un solo essere umano, l’unico contro cui ha giocato, e per sole cinque volte consecutive: un risultato notevole, ma non sufficiente per dichiarare vittoria su uno dei giochi da tavolo più complessi al mondo. </p>
<p> Lo scopo di Google DeepMind non è naturalmente creare un supercampione di go, ma sperimentare nuovi sistemi e tecniche per migliorare i sistemi di intelligenza artificiale, in modo che possano un giorno svolgere compiti diversi da quelli di vincere una partita ed essere impiegati per migliorare gli assistenti automatici personali, o per prevedere le necessità degli utenti e anticiparli. Google non è l’unica azienda informatica interessata a questo tipo di cose. Proprio ieri il CEO di Facebook, Mark Zuckerberg, ha pubblicato sul suo social network un post sul sistema ideato dal gruppo di ricerca in intelligenza artificiale di Facebook per vincere una partita a go. AlphaGo, nel frattempo, continua a sperimentare la sua rete neurale in vista del prossimo marzo, quando sfiderà per la prima volta il campione mondiale di go. Secondo i suoi sviluppatori, nel caso di vittoria sarà dimostrato che manca ormai poco per creare un’intelligenza artificiale completa vera e propria. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/07/19/google-glass-aziende/" parent_folder="Il Post 2016-17" id="file17861974" filename="google-glass-aziende">
<p> La seconda vita dei Google Glass </p>
<p> Dati per morti un paio di anni fa, sono sempre più presenti in contesti diversi da quelli per cui erano stati progettati: fabbriche, ospedali e altri ambienti di lavoro </p>
<p> Quando nel 2012 il cofondatore di Google, Sergey Brin, mostrò per la prima volta al pubblico i Google Glass, in una spettacolare presentazione organizzata con un gruppo di paracadutisti a San Francisco, in molti pensarono di avere assistito alla nascita di una nuova era per la tecnologia, paragonabile a quella degli smartphone. Con il loro minuscolo visore per accedere alle mappe, ai social network e ad altre funzioni senza dovere tirare fuori dalla tasca il proprio telefono e mantenendo le mani libere, i Google Glass promettevano di cambiare il modo in cui usiamo Internet e i suoi servizi. Nonostante gli sforzi di Google e le grandi quantità di denaro spese, la rivoluzione per tutti promessa dai Google Glass non si è mai realizzata e nel 2014 l’intero progetto sembrava essere completamente naufragato. In realtà, anche se sono spariti dalle attenzioni dei siti di tecnologia e dei media in generale, i Google Glass hanno continuato a esistere e ad avere una seconda vita negli ambienti di lavoro, in contesti diametralmente opposti a quelli per i quali erano stati inizialmente concepiti. </p>
<p> Alphabet, la holding che ha la proprietà di Google, ha continuato a sperimentare i suoi occhiali con grandi aziende, perfezionandoli per essere utilizzati soprattutto in cantieri e fabbriche. La nuova versione degli occhiali si chiama Glass Enterprise Edition (“edizione per le aziende”) ed è messa a disposizione delle società che vogliono fare investimenti per cambiare i flussi di lavoro dei loro dipendenti, aiutandoli a essere più produttivi e a ottenere facilmente le informazioni di cui hanno bisogno per lavorare. Rispetto ai modelli precedenti, i nuovi Glass EE hanno un processore più potente, un sistema WiFi più sicuro e adatto per le connessioni nelle reti aziendali, una durata della batteria maggiore e una fotocamera da 8 megapixel invece dei classici 5 megapixel. </p>
<p> Esteticamente i Glass EE non sono molto diversi dai loro predecessori: la stanghetta destra ha tutti i componenti per far funzionare gli occhiali, compreso il piccolo prisma trasparente sul quale vengono proiettate le immagini. Chi li indossa può controllarli a voce pronunciando “OK Google” e un comando come “Vai avanti” se sta consultando un documento o “Scatta una foto”, se ha bisogno di condividere un’immagine dell’oggetto su cui sta lavorando. La stanghetta con tutti i componenti può essere staccata e applicata su occhiali di vario tipo, compresi quelli protettivi da lavoro, a patto che siano compatibili con il sistema. </p>
<p> Lo sviluppo dei Glass EE è coordinato da X, la divisione di Alphabet che si occupa di progetti sperimentali e innovativi in vari ambiti: anche la prima versione dei Glass era nata lì dentro, poi era stata promossa e resa autonoma quando l’intenzione era realizzare un prodotto alla moda e per tutti, pensato soprattutto per l’intrattenimento. Dopo il 2015, Alphabet ha deciso di trasferire tutto nuovamente in X, considerata anche la dimensione ridotta del gruppo di lavoro che si occupa degli occhiali. In questi due anni grandi aziende come General Electric, Boeing e Volkswagen hanno acquistato i Glass EE per provarli all’interno delle loro fabbriche: con l’aiuto degli esperti di X, hanno modificato il software che li fa funzionare, adattandoli alle loro esigenze. </p>
<p> In un lungo articolo da poco pubblicato su Wired, Steven Levy racconta il caso di AGCO, una grande azienda dal valore di mercato di 7 miliardi di dollari che si occupa della costruzione di trattori e altri mezzi agricoli. I suoi veicoli sono quasi sempre costruiti su misura, quindi gli operai devono seguire istruzioni che possono variare sensibilmente da un modello a un altro, consultando manuali e schemi di assemblaggio. La lettura delle istruzioni avviene di solito tramite un computer portatile nell’area di produzione, quindi ogni volta che un operaio ha un dubbio deve: lasciare la sua postazione, raggiungere il computer, attendere se lo sta usando qualcun altro e infine accedere allo schema di montaggio. Per rendere più rapido il processo, AGCO aveva introdotto dei tablet, che però si sono rivelati troppo fragili per quell’ambiente di lavoro, nonché poco pratici da usare se si indossano guanti e si ha la necessità di avere le mani libere per maneggiare i pezzi da assemblare. </p>
<p> Nello stabilimento di Jackson, nel Minnesota, i responsabili della produzione hanno provato la strada dei Google Glass, quando erano ancora nella versione sperimentale del 2013. Ne hanno acquistato un solo modello e – dopo qualche difficoltà – hanno trovato un’azienda di software in grado di modificarne il funzionamento per rendere il paio di occhiali compatibile con la rete aziendale della fabbrica. Da allora, e grazie ai successivi sviluppi, sono state acquistate altre decine di Glass che vengono usate quotidianamente dagli operai per l’assemblaggio dei motori. Attraverso gli occhiali, possono consultare le istruzioni e avere al tempo stesso le mani libere: per cambiare pagina devono solo pronunciare la frase “OK Google, procedi”. Se il processo di montaggio è già noto all’operaio, gli occhiali possono rimanere in stand-by ed essere attivati in qualsiasi momento nel caso di dubbi. La piccola fotocamera dà la possibilità di fotografare un componente e di condividere l’immagine con un superiore, nel caso in cui ci sia qualcosa che non torna o un pezzo sia danneggiato. </p>
<p> L’adozione dei Glass ha permesso ad AGCO di ridurre i tempi morti nelle aree di assemblaggio e di semplificare la vita agli operai, che possono lavorare con meno incertezze e dubbi. Storie analoghe sono state raccontate dai responsabili di Boeing, Volkswagen e di altre aziende, a conferma dell’utilità dei Glass negli ambienti di lavoro, compresi gli ospedali. Google confida che queste esperienze positive possano incentivare altre aziende, non necessariamente così grandi, a comprare i suoi occhiali con la promessa di poterli adattare alle loro esigenze. </p>
<p> Da dati praticamente per morti, in un paio di anni i Google Glass sembrano avere scampato l’estinzione grazie all’ostinazione dei loro ideatori, ma soprattutto grazie alle aziende che li hanno iniziati a sperimentare quando la stessa Google non aveva le idee chiare su cosa farne. Dopo l’arrivo dei paracadutisti al Moscone Center di San Francisco nel 2012, che avevano ripreso in prospettiva il loro volo con la fotocamera dei Glass, Sergey Brin disse che ci sarebbe voluto del tempo prima di trovare il giusto scopo dei suoi avveniristici occhiali. A Google erano convinti che la strada giusta fosse quella dell’elettronica di consumo, la stessa degli smartphone e smartwatch. Se da un lato la pratica ha dimostrato che avevano mancato il punto, dall’altro è stata anche la dimostrazione della loro capacità di adattarsi alle esigenze del mercato. Fino a prova contraria. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/massimomantellini/2017/04/30/grillo-e-la-tecnologia/" parent_folder="Il Post 2016-17" id="file17861967" filename="grillo-e-la-tecnologia">
<p> Grillo e la tecnologia </p>
<p> Oggi Beppe Grillo sul suo blog si occupa della contrapposizione fra voto elettronico e voto fisico al seggio elettorale. Parla, quindi, di una tecnologia, visto che ovviamente anche la scheda di carta e la matita lo sono esattamente come il voto online. Fra le altre cose afferma: </p>
<p> Clic o scheda è una questione di progresso tecnologico e di offrire un servizio migliore ai cittadini. Il MoVimento 5 Stelle, tramite Rousseau, offre ai suoi iscritti il servizio del voto online perchè è più comodo e costa meno: è più efficiente. Scagliarsi contro la “democrazia dei clic” è come protestare contro il “bonifico dei clic” e rimpiangere i tempi in cui dovevi fare la fila in banca per pagare l’affitto o mandare soldi ai tuoi figli, o come prendersela con l’e-commerce perchè andare fisicamente in un negozio sarebbe meglio per fare un acquisto. Ma dove vivono? Per loro offrire ai cittadini la possibilità di avere un servizio online sarebbe ideologicamente sbagliato perchè cosi com’è è più “giusto”. </p>
<p> Hanno la stessa lungimiranza di quelli che si opponevano ai treni e alle automobili perchè riuscivano a pensare solo a cavalli più veloci. Non possiamo lasciare il nostro futuro nelle mani di questa gente che ha lo sguardo sempre rivolto al passato. </p>
<p> Al di là delle questioni ideologiche contenute nel post (come quella sul passatismo del PD in termini di innovazione, contestazione davvero difficile da scalfire) quelle tecnologiche si risolvono in un secondo. Non tutte le tecnologie sono uguali. Per esempio, se devo andare a Singapore la bicicletta, che è un’ottima tecnologia, non mi servirà a molto. </p>
<p> Il passo successivo, lo scatto intellettuale che potremmo chiedere a Grillo, sarebbe quello di ragionare sul come mai quasi nessuno al mondo per andare a Singapore usa la bici. Ovvero sul come mai il voto elettronico via Internet viene usato pochissimo, non solo in Italia, patria certo dei dinosauri del PD, ma nemmeno in altre nazione abitate da creature meno orribili. Una risposta rapida potrebbe essere che i suoi standard tecnologici, anche nei contesti meglio presidiati, non sono stati ad oggi considerati sufficienti. E ovviamente non ci riferiamo al ridicolo accrocchio proprietario di Rousseau. </p>
<p> Arriviamo così ad uno dei canoni più usuali di Casaleggio, Grillo, M5S ecc. Un gruppo di persone che propaganda la tecnologia – da sempre – senza averla compresa (forse). Che la utilizza come uno stendardo superficiale utile per abbindolare i meno furbi. Che dopo tanti anni dalle teorie utopiche di Casaleggio (che M5S sta piano piano nascondendo sotto il tappeto) deve ancora farci comprendere appieno se tutto questo rumoreggiare sia semplice ignoranza, cinica speculazione o un sapiente (e per ora vincente) mix di entrambe. </p>
</doc>
<doc url="https://www.ilpost.it/2017/12/23/guida-bitcoin/" parent_folder="Il Post 2016-17" id="file17861983" filename="guida-bitcoin">
<p> I bitcoin spiegati bene </p>
<p> Per chi ha resistito finora senza saperne niente, e comincia a rendersi conto che deve rimediare </p>
<p> Oggi un bitcoin, cioè un’unità della più popolare criptovaluta al mondo, vale 14.600 dollari. Cinque anni fa, ne valeva circa 13: significa che il suo valore è aumentato di oltre 1.100 volte. Ma l’aumento esponenziale del valore dei bitcoin non è stato graduale, come ha dimostrato il recente nuovo interesse dei media internazionali: soltanto un anno fa, infatti, un bitcoin valeva circa 850 dollari. Ha superato i 2.000 dollari soltanto a maggio, e fino a un mese fa era sotto i 9.000 dollari: dopo aver sfiorato i 20mila dollari, ha subito un crollo tra giovedì e venerdì, arrivando a poco più di 12mila dollari. È stato il più grave crollo della valuta in tre anni, arrivato dopo il più grande picco di sempre. </p>
<p> Da diverse settimane, quindi, si è tornati a parlare moltissimo di Bitcoin (la maiuscola si usa solitamente per indicare il sistema, la minuscola per la valuta): di cosa sono, di come funzionano, del loro utilizzo, di quanto sia rischioso investirci e di quanto durerà questo aumento di valore. Ne abbiamo scritto molto sul Post in questi anni, ma abbiamo deciso di raccogliere un po’ di risposte a queste domande in un posto solo: questo. </p>
<p> Breve storia dei Bitcoin Non si sa chi abbia inventato i bitcoin: l’inventore viene chiamato Satoshi Nakamoto, ma è un nome di fantasia che finora ha garantito anonimato alla persona o alle persone che li crearono nel 2009. Nel tempo sono state fatte molte ipotesi – la più famosa nel 2014 da Newsweek – ma non si è ancora scoperto niente di certo. Nakamoto voleva creare un nuovo sistema di valuta elettronico senza nessun tipo di autorità centrale: ci riuscì e nel 2010 sostanzialmente sparì, sfilandosi completamente dal sistema che aveva creato. </p>
<p> Cosa sono i Bitcoin Premessa scontata, ma facciamola: il valore che attribuiamo al denaro è frutto di una convenzione. Una banconota – da 5, 50 o 500 euro – è un pezzo di carta: se possiamo usarlo per ottenere in cambio beni ben più complessi di un pezzo di carta è perché siamo tutti d’accordo sul valore che riconosciamo a quel pezzo di carta. Una banconota da 500 euro non vale intrinsecamente dieci volte una da 50: abbiamo semplicemente deciso così. Perché le cose cambino, basta che decidiamo diversamente. </p>
<p> Veniamo ai bitcoin. I bitcoin sono una moneta digitale che gli utenti conservano in portafogli virtuali, e possono essere usati per fare pagamenti verso negozi o società che li accettano (ci sono), per trasferire denaro ad altri utenti, o semplicemente possono essere conservati sperando che aumentino di valore. Quanto vale un bitcoin? Ci arriviamo, ma diciamo che lo decide il mercato: e non c’è il pezzo di carta, al contrario degli euro. </p>
<p> La differenza con le normali valute è che Bitcoin risolve un gran numero di problemi che si hanno normalmente nelle transazioni economiche online. Non c’è infatti un’autorità centrale che controlli i bitcoin: niente banche, organizzazioni o società che ne gestiscano i flussi e il valore. Questo fa sì che non ci sia una terza parte coinvolta nelle transazioni: quindi niente commissioni a Visa, Mastercard, Western Union, eccetera, e niente rischi che questi enti subiscano attacchi informatici che sottraggano numeri e codici di carte di credito. </p>
<p> Come funzionano le transazioni su Bitcoin Qui le cose cominciano a farsi più complicate. I Bitcoin funzionano sulla base di un protocollo peer-to-peer, simile quindi ai sistemi utilizzati per esempio per scaricare e condividere i file online, quelli in cui ogni computer diventa un nodo della rete alla pari con gli altri senza nodi centrali. Ogni utente di Bitcoin è connesso con tutti gli altri e detiene una copia di una sorta di libro mastro – cioè un documento in cui sono contenuti tutti i conti di un sistema contabile – chiamato blockchain (catena di blocchi). Nella blockchain sono registrate tutte le transazioni di tutti gli utenti di sempre, da quando sono nati i Bitcoin. </p>
<p> Questo meccanismo è alla base della soluzione di Nakamoto al problema di verificare che le transazioni economiche online, senza autorità centrali a controllarle, siano regolari: e quindi che i destinatari dei pagamenti non imbroglino i mittenti, o che gli utenti non paghino con soldi che in realtà non possiedono. È la blockchain a fare quello che normalmente fa una banca: rimuovere dal conto dell’utente che spende i soldi la quantità giusta di denaro, e assicurarsi che non possa spendere più soldi di quanti ne possiede. </p>
<p> Nel sistema Bitcoin, tutti gli utenti verificano tutte le transazioni: quando c’è un trasferimento di bitcoin, a tutti i dispositivi collegati viene sottoposto un problema crittografico che richiede un enorme numero di prove per essere risolto. Non serve che tutti i computer lo confermino: quello che per primo trova una soluzione al problema emette un avviso per gli altri. </p>
<p> Più o meno sei volte all’ora viene creato un nuovo “blocco” di transazioni confermate, che viene aggiunto alla blockchain generale. Una transazione su Bitcoin, quindi, è registrata soltanto quando è effettivamente avvenuta, ed è registrata nell’unico posto che tiene il conto di quanti bitcoin esistono e a chi appartengono. In questo modo si impedisce che gli utenti possano spendere più volte gli stessi bitcoin, perché il fatto che siano già stati spesi è registrato sulla blockchain in possesso di chiunque usi Bitcoin. Imbrogliare questo sistema falsificando bitcoin è molto complicato, praticamente impossibile. </p>
<p> Tutte queste operazioni avvengono “all’oscuro” delle persone davanti al computer: è un calcolo che il programma fa autonomamente seguendo input casuali generati dal protocollo. I proprietari di bitcoin sono anonimi, e identificati soltanto da un codice. Ogni transazione è identificata da una chiave pubblica, che identifica il ricevente e che è usata da tutti i dispositivi del sistema per verificare l’operazione, e da una chiave privata, che serve agli utenti coinvolti ad autorizzare la transazione. Se si perde la chiave privata, si perdono i soldi: è successo, anche con somme da milioni di dollari. Se non è praticamente possibile falsificare bitcoin, è possibile rubarli: è capitato in passato, ma ora sembra sia tutto molto più sicuro. </p>
<p> L’estrazione Il sistema Bitcoin distribuisce nuova valuta – nuovi bitcoin – tra gli utenti che con i loro dispositivi contribuiscono ai calcoli necessari a confermare le transazioni, e quindi a mantenere la valuta attiva e sicura. Quando c’è una nuova transazione, questi utenti – detti miners, estrattori – provano a risolvere il problema crittografico, trovando quell’unico numero in grado di confermarlo e di aggiungere la transazione alla blockchain. Il primo che risolve il problema invia la soluzione agli altri nodi della rete, che la confermano: a quel punto riceve il premio in bitcoin. Più un utente contribuisce al sistema in termini di potenza di calcolo, più è probabile che riceva in cambio bitcoin. </p>
<p> L’evoluzione e l’ingrandimento del sistema Bitcoin ha fatto sì che oggi partecipare attivamente alle operazioni che confermano le transazioni richieda una grandissima potenza di calcolo, che non può essere fornita da normali computer, come succedeva all’inizio della valuta. Per questo, esistono centri specializzati: sono grandi capannoni in cui ci sono migliaia di computer, raffreddati da imponenti impianti di ventilazione. </p>
<p> Questo processo è chiamato estrazione, o mining, e recentemente si è iniziato a discutere del suo impatto ambientale. Questi centri infatti consumano una grande quantità di energia: in totale attualmente i processi di estrazione consumano annualmente più energia di interi stati di piccole dimensioni, tipo l’Irlanda, e circa lo 0,8 per cento dell’energia consumata negli Stati Uniti. </p>
<p> Come si calcola quanto valgono i bitcoin Il valore dei bitcoin è dettato dalla domanda e dall’offerta: e cioè da quanto sono disposte le persone a pagarli. Il prezzo di un bitcoin è calcolato sulla base del valore al quale è scambiato con le normali valute: in pratica, un bitcoin ha un valore soltanto perché gli utenti del sistema sono d’accordo che ce l’abbia. </p>
<p> Una particolarità del sistema Bitcoin è che il numero totale delle unità prodotte è prestabilito: ne verranno emesse fino ad avvicinarsi alla quantità totale di 21 milioni, presumibilmente nel 2030, senza mai raggiungerla. Questo è permesso dal fatto che ogni quattro anni il numero di bitcoin emessi viene dimezzato, così come la quantità di moneta distribuita a chi scopre i nuovi blocchi da aggiungere alla blockchain. </p>
<p> Il pericolo d’inflazione della valuta – cioè della sua perdita di valore – è quindi minimo, perché non è previsto che possano essere effettuate nuove iniezioni di denaro da un ente come una Banca centrale, che del resto nel sistema non esiste. Anzi, man mano che si avvicinerà quella data, se continuerà ad aumentare la richiesta, ci sarà un processo di deflazione, per via della sempre minore disponibilità della valuta. </p>
<p> Come si comprano i bitcoin La maggior parte delle persone che investe in bitcoin lo fa comprando quelli già esistenti, e partecipando al processo di estrazione. Si possono comprare e conservare su molti siti, il più famoso dei quali è Coinbase. È molto semplice, e si può iniziare subito a spenderli nei negozi online e per i servizi che li accettano, che sono sempre di più. </p>
<p> Perché sono aumentati di valore La risposta breve è che non c’è un’unica spiegazione. E la premessa da fare è che i bitcoin rimangono un investimento molto rischioso, perché il loro valore è da sempre volatile: come ha dimostrato il crollo più recente. Era già successo due volte in passato che i bitcoin aumentassero molto di valore – mai nemmeno lontanamente come è successo nelle ultime settimane – e questi picchi erano sempre stati seguiti da cali molto repentini. È dai primi mesi del 2017 che gli analisti avvertono che è solo questione di tempo prima che ricapiti: fino a questa settimana non era ancora successo, e anche dopo il crollo il loro valore è rimasto altissimo, rispetto a un anno fa. In molti si sono pentiti di non averci investito tempo fa. </p>
<p> L’aumento di valore di quest’anno è dovuto, tra le altre cose, al fatto che la borsa di Chicago ha iniziato a permettere di scambiare titoli futures – contratti che permettono agli investitori di “scommettere” sul valore di qualcosa – basati sui bitcoin, una decisione interpretata come un importante “sdoganamento” della valuta, fino ad allora molto osteggiata dall’establishment finanziario. L’annuncio della borsa di Chicago si è unito a un miglioramento della reputazione dei bitcoin che già era in corso, e che aveva provocato sempre maggiori interessamenti da parte degli investitori, rassicurati anche dalla sempre maggiore sicurezza del sistema. </p>
<p> Un tempo i bitcoin erano associati a transazioni al limite della legalità, quando non del tutto illegali, e in particolare al sito Silk Road, dove si poteva acquistare di tutto, dalla droga a servizi sessuali alle armi. Con il tempo Bitcoin è riuscito a scrollarsi di dosso questa fama: questo, unito al fatto che i bitcoin sono un numero finito, ha generato una “corsa” degli investitori che hanno cercato di accaparrarseli nel timore di rimanere esclusi da questo mercato. </p>
<p> Bitcoin è l’unica criptovaluta? No, ce ne sono molte, come Ethereum, Ripple e Litecoin. Bitcoin rimane però la più forte, perché è la più conosciuta e la più sicura. </p>
<p> È tutta una bolla? Ciclicamente si torna a parlare del rischio “bolla” dei bitcoin: e l’ultimo crollo ha riportato al centro delle discussioni questa teoria. Alcuni ritengono che il livello del loro prezzo non sia sostenibile sul lungo periodo e che sia destinato a crollare definitivamente. Altri parlano della “fine dei bitcoin” e gli esperti di criptovalute spesso scherzano sulla quantità di volte in cui la stampa ha annunciato la loro morte. Questi avvertimenti spesso provengono dai banchieri, che però sono in genere ostili alle criptovalute perché tagliano fuori le banche dalla possibilità di intermediazione. </p>
<p> Un mese fa l’amministratore delegato della banca d’affari JP Morgan Jamie Dimon, uno dei banchieri più famosi e potenti di Wall Street, ha detto che i bitcoin sono una truffa e un sistema di scambio buono solo per le attività criminali. Quasi tutte le grandi banche internazionali hanno però gruppi di trader e analisti incaricati di fare scambi e studiare il fenomeno dei bitcoin e le sue possibili applicazioni. </p>
<p> Anche molti professori di economia sono scettici sul futuro della criptovaluta. Kenneth Rogoff, che ha lavorato per il Fondo Monetario Internazionale e oggi insegna ad Harvard, sostiene che il prezzo dei bitcoin sia agganciato soltanto alle speranze che hanno gli investitori sui suoi futuri aumenti di valore. Più che come una moneta, quindi, i bitcoin si comporterebbero come una “commodity”, una materia prima come il grano o il petrolio, il cui valore può cambiare anche molto in seguito alle aspettative del mercato. </p>
<p> Nonostante le fluttuazioni, però, il valore dei bitcoin non ha fatto che aumentare negli ultimi anni e molte persone che li avevano acquistati o estratti quando valevano pochi dollari sono diventati “ricchi” in seguito alla costante crescita del loro prezzo. I sostenitori delle criptovalute sostengono invece che la loro continua crescita di valore sia un segno che queste monete sono destinate a restare e a ricoprire un ruolo sempre più importante nelle nostre economie. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/massimomantellini/2017/01/14/hacker-di-casa-nostra/" parent_folder="Il Post 2016-17" id="file17861976" filename="hacker-di-casa-nostra">
<p> Hacker di casa nostra </p>
<p> Vent’anni fa, ai tempi dei primi PC casalinghi, quando qualcosa sembrava andare storto l’esperto giungeva al capezzale della nostra macchina e diceva: “Avrai preso un virus”. Oggi quando qualcosa nel mondo va storto i media titolano a nove colonne: “Sono stati gli hacker russi”. Ieri i primi virus informatici erano argomento di discussione per appassionati ed hobbisti, oggi gli hacker russi sono un tema diventato improvvisamente popolare, scivolato dalle prime pagine dei telegiornali direttamente dentro la discussione pubblica. </p>
<p> In simili parole si riconosce lo yin e lo yang della tecnologia: le sue potenzialità infinite e l’enormità dei rischi che simili mutazioni concretizzano. Per la maggioranza di noi, per molti di quelli che ne leggono e anche per la gran parte di quelli che ne scrivono, la tecnologia assomiglia un po’ alla religione. La si sposa o la si osteggia per ragioni di fede. Per tutti la tecnologia rappresenta l’impossibilità di scindere con la nettezza di cui avremmo bisogno il buono dal cattivo. Gli hacker russi diventano quindi una metafora adatta ai tempi: sono soggetti indefiniti, capaci di influenzare qualsiasi cosa, dal funzionamento di una centrale nucleare in Giappone alle elezioni del presidente americano; lo sono anche per la loro caratteristica forse più spaventosa, quella di guardiani di un linguaggio esoterico, sconosciuto ai più: formule magiche che, nel tempo, hanno iniziato ad aprire qualsiasi porta. </p>
<p> Gli hacker russi, o quelli cinesi, i ragazzini scapestrati chiusi nelle loro stanzette nel midwest americano o la versione “paglia e fieno” italica dei fratelli Occhionero in onda sui nostri media in questi giorni, ma anche gli altri hacker, quelli non così nettamente delineati come “evil”, per esempio quelli che scrivono piattaforme sociali come Facebook o che compilano il codice per le nostre ricerche o i nostri acquisti online come quelli di Google o Amazon, sono tutti, buoni e cattivi, riuniti dentro questo nostro gigantesco complesso di inferiorità che riguarda appunto il linguaggio. Il mondo odierno compilato in una lingua che loro sanno parlare e noi no. </p>
<p> Nei paesi più pragmatici del nostro quando ci si è accorti che un simile esperanto era destinato a modificare le sorti del pianeta semplicemente ci si è adattati. Il coding è così diventato in molte parti del mondo uno dei punti centrali della didattica. Lo è diventato – giusto o sbagliato che sia – non per scelta intellettuale ma per ragioni di forza maggiore. Dove invece l’accademia ha continuato ad accarezzare sé stessa il problema nemmeno si è posto. Se dieci righe di testo scritte qui ed ora spengono una centrale elettrica nell’Iowa o mettono a terra una intera flotta di voli commerciali forse – ha pensato qualcuno – sarà il caso di occuparcene. Da noi un simile percorso che altri hanno intrapreso oltre un decennio fa, sta compiendo ora i suoi primi passi. </p>
<p> Così è inevitabile che sui nostri media prevalga il racconto esoterico della tecnologia che tutto può e che come tale è destinata a distruggere tutto. Moriremo per troppa tecnologia: non passa giorno senza che qualche autorevolissimo oracolo ce lo spieghi per filo e per segno. E una simile previsione vale comunque, anche quando, come nei casi recenti nelle cronache italiane di questi giorni, i “cattivi” sono personaggi al limite della commedia, contemporaneamente fuori da ogni canone estetico dell’hacker ma invece prevedibilmente iscritti dentro la retorica del maneggione nostrano, tutto relazioni (massoneria, politica) e poca saggezza tecnologica (il malware acquistato online, tracce digitali lasciate ovunque, ecc.). </p>
<p> Così il racconto drammatizzante della tecnologia che può tutto, oltre che essere spesso sopravvalutato (in molti casi le notizie strillate sui giornali diventano rapidamente “notizie che non lo erano” per manifesta impossibilità tecnica, perché la tecnologia può sempre infinitamente meno di quello che ci farebbero immaginare i nostri incubi) è anche facilmente leggibile come una resa preventiva: la risposta umorale e preoccupata di un Paese che teme la tecnologia molto prima che affrontarla con la concretezza che meriterebbe. </p>
<p> Mentre gli hacker russi, quelli americani o quelli asiatici, restano nel limbo del non detto e del non immaginato, vengono da noi ricondotti a forza dentro i canoni dell’estetica giovanile del ragazzo in scarpe da ginnastica con la sindrome di Asperger o in quella meno poetica del combattente digitale contro le dittature del pianeta (da Assange a Snowden passando per tutti i testi moralisti dell’etica hacker), o in quella ancor meno consolatoria del genio del computer allevato dentro le strutture fisiche del potere (da NSA ai 30mila dipendenti del firewall cinese), l’hacker italiano, che spia politici e imprenditori, ma che soprattutto spia i massoni concorrenti alla ricerca di informazioni che lo avvantaggino nella scalata sociale, ne è una variante inedita e tutto sommato consolatoria. Quella usuale e gattopardesca di un Paese nel quale in fondo niente cambia e nel quale gli strumenti digitali continuano ad avere il ruolo marginale che meritano. Quando finalmente il formidabile malware dà segno di sé lo fa non per cambiare il mondo (in meglio o in peggio) ma solo per garantire passaggi rapidi verso i piani alti di questa o quella consorteria. </p>
<p> p.s. il termine “hacker” non è stato ingiustamente violentato in questo testo come sicuramente qualcuno di voi avrà pensato. Semplicemente ho dichiarato da tempo persa la battaglia linguistica che lo difendeva dalla più esatta definizione di “cracker” che certamente in questi contesti sarebbe più adatta. </p>
</doc>
<doc url="https://www.ilpost.it/2016/09/05/incontri-online-tinder/" parent_folder="Il Post 2016-17" id="file17861949" filename="incontri-online-tinder">
<p> Come scegliamo i partner online </p>
<p> Una ricerca ha analizzato 1,1 milioni di interazioni su un servizio di incontri, scoprendo che gli utenti sono molto ma molto selettivi </p>
<p> Negli ultimi anni le applicazioni per incontrare qualcuno, a partire dalla più usata e conosciuta Tinder, hanno riportato di moda i servizi per conoscersi online, che avevano riscosso un cospicuo successo nei primi anni di Internet, prima dell’arrivo dei social network. Ogni giorno decine di milioni di persone sfogliano i profili di altrettanti milioni di persone, alla ricerca di quelle che si avvicinano di più ai loro gusti e che potrebbero portare a una nuova relazione. I siti e le app per il dating sono diventate una risorsa importante per molti studi sociologici, allo scopo di capire meglio come ci comportiamo quando scegliamo un partner attraverso Internet. Uno degli studi più estesi e interessanti degli ultimi tempi è stato pubblicato la settimana scorsa su Proceedings of the National Academy of Sciences (PNAS): basandosi sull’analisi di un milione di interazioni, ha concluso che la maggior parte degli utenti attua una selezione molto rigida da subito, escludendo chi non raggiunge anche solo uno dei suoi standard. </p>
<p> La ricerca è stata condotta da un gruppo coordinato da Elizabeth Bruch, sociologa presso la University of Michigan, negli Stati Uniti, sulla base dei dati forniti da uno dei più grandi servizi per il dating online, che ha però chiesto di restare anonimo. I ricercatori si sono fatti dare i dati (resi anonimi) di 1.855 persone iscritte al servizio e residenti a New York, che dalla loro iscrizione al servizio hanno prodotto 1,1 milioni di interazioni, mentre erano alla ricerca del partner ideale. Come avviene sulla maggior parte dei servizi di questo tipo, ogni utente poteva caricare sul proprio profilo una fotografia, una breve biografia e informazioni su età, altezza, peso, livello di istruzione, abitudini di vario tipo come alcol e fumo. </p>
<p> Organizzare i dati non è stato semplice, perché i comportamenti delle persone sui siti di dating differiscono molto a seconda dell’età, del genere e di ciò che si cerca quando si consultano i profili degli altri iscritti. I ricercatori hanno comunque identificato un modello che si adatta alla maggior parte degli utenti: in una prima fase si scorrono i profili e si decide molto rapidamente quali escludere, quasi sempre sulla base delle fotografie disponibili e di altre informazioni essenziali come l’età; in una seconda fase la ricerca viene affinata e ogni iscritto decide se scrivere un messaggio o rispondere a quello inviato da qualcuno. L’ultima fase è quella dell’incontro, ma è la più complicata e imperscrutabile, perché non avviene online e non dà quindi la possibilità di raccogliere molti dati e organizzarli per una ricerca. </p>
<p> Identificate le tre fasi, i ricercatori hanno elaborato un modello statistico basato sulle interazioni messe a disposizione dal servizio di dating. Poi hanno approfondito ogni fase, cercando di identificare le condizioni che portano all’esclusione di qualcuno o al proseguimento verso il passaggio successivo, aumentando le probabilità di un incontro e dell’avvio di una relazione. </p>
<p> Nella prima fase, le caratteristiche che deve avere una persona per passare alla successiva sono determinanti: se ne manca una, la probabilità di essere scartati aumentano enormemente. Se per esempio manca la foto profilo, e non si può quindi sapere se fisicamente la persona corrisponde ai propri gusti, è 20 volte meno probabile che ci si soffermi sul profilo per leggere le altre informazioni. Anche l’essere fumatori si è rivelata una condizione insormontabile in molti casi, con una riduzione di 10 volte nell’interesse da parte di chi è alla ricerca di un partner (ma parliamo di New York, dove il fumo è piuttosto maltollerato, soprattutto dai più giovani e dai più istruiti). </p>
<p> L’età è comunque la condizione delle condizioni. A parità del resto, le donne del campione studiato da Bruch si sono rivelate 400 volte meno interessate a scorrere e leggere i profili di uomini molto più vecchi di loro. Dipende però anche dall’età di chi è alla ricerca di un partner: rispetto ai loro coetanei di sesso maschile, le ventenni sono 10 volte meno interessate agli uomini oltre i 30 anni, mentre le donne intorno ai 45 anni si sono dimostrate più interessate del 10 per cento nel cercare uomini con età superiore ai 55 anni. Il risultato per quanto riguarda gli uomini appare più scontato: in media gli uomini sui 40 cercano donne più giovani di loro. </p>
<p> Oltre all’età, anche l’aspetto fisico ha un ruolo importante e in molti si pongono un limite oltre il quale non sono disposti a scendere. Anche se di poco, le donne si sono rivelate più interessate all’altezza dei potenziali partner rispetto agli uomini. I maschi, invece, hanno dimostrato di essere più attenti al peso delle iscritte: in media si sono mostrati meno interessati a scorrere i profili di donne robuste. </p>
<p> Nella seconda fase, quella dove ci si scambiano messaggi e si fa conoscenza, si sono ripetuti gli schemi sulle condizioni insormontabili della prima, ma con effetti meno marcati grazie alla selezione già effettuata. Nel complesso, quindi, è la prima fase a essere la più dura, quella in cui si è più spietati e selettivi, probabilmente complice il fatto di non essersi ancora esposti in prima persona. </p>
<p> La ricerca condotta da Bruch e colleghi è stata accolta molto positivamente da altri ricercatori sul campo, soprattutto per avere elaborato un primo modello di comportamento, che in futuro potrà essere affinato e migliorato sulla base di altri dati, contribuendo a spiegare come ci comportiamo quando siamo alla ricerca di un partner su un sito o un’applicazione. E non è un tema banale o dalla scarsa portata: la comunicazione online ha cambiato sensibilmente il modo in cui conosciamo e ci rapportiamo con le persone, soprattutto in ambito sentimentale. Secondo una stima condotta dall’istituto di ricerca statunitense Pew, circa il 5 per cento degli americani attualmente in una relazione ha conosciuto il proprio partner online, attraverso un sito per il dating: in numeri assoluti parliamo di 30 milioni di persone. </p>
<p> Altri ricercatori auspicano che presto sia Tinder a offrire parte dei suoi dati, in forma anonima, per compiere studi analoghi a quelli di Bruch, ma su una base di utenti ancora più grande. Tinder potrebbe essere indicativo per capire meglio come funziona la prima fase del dating online: la sua app mostra informazioni abbastanza dettagliate degli iscritti, ma privilegia comunque una rapida navigazione tra le anteprime dei loro profili in cui oltre alla foto ci sono solo nome, età e impiego. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/06/17/in-russia-e-scappato-un-robot/" parent_folder="Il Post 2016-17" id="file17861931" filename="in-russia-e-scappato-un-robot">
<p> In Russia è scappato un robot </p>
<p> Ma gli si sono scaricate le batterie dopo 50 metri, mentre stava attraversando una strada, e ha causato un piccolo ingorgo </p>
<p> A Perm’, una città orientale della Russia europea, un robot è scappato da un laboratorio di ricerca e ha causato un piccolo ingorgo; poi è stato recuperato e riportato nel centro da dove era fuggito prima che potesse fare altri danni. I responsabili di Promobot, l’azienda che lo ha realizzato, hanno spiegato che stavano insegnando al robot a riconoscere l’ambiente che ha intorno e a muoversi autonomamente. Uno dei dipendenti ha lasciato aperta la porta del laboratorio e il robot è uscito per conto proprio per farsi una passeggiata, che però è finita dopo appena 50 metri perché si è scaricata la batteria. </p>
<p> Il robot si è spento in mezzo alla corsia di una strada nei pressi dei laboratori di Promobot e ha causato un rallentamento del traffico. Una persona che si trovava nelle vicinanze ha ripreso la scena con il suo cellulare: si vedono il robot in mezzo alla strada e un agente di polizia che non sembra avere molto idea di come comportarsi. In un secondo momento arriva uno dei tecnici dell’azienda, che sposta il robot per ricondurlo al laboratorio. Il momento di libertà del robot è durato 40 minuti circa, secondo i media locali, e non ha portato ad altri disguidi. </p>
<p> Nelle ore seguenti alla fuga del robot, alcuni hanno messo in dubbio la versione fornita da Promobot, alludendo alla possibilità che l’azienda lo abbia liberato intenzionalmente per farsi pubblicità. Secondo i responsabili della società, il robot può interagire con gli esseri umani e rispondere ad alcune loro domande, per esempio fornendo indicazioni stradali. Non è ancora chiaro quale sarà il futuro di Promobot, ma un’area di particolare interesse è legata al suo uso in ambito pubblicitario per campagne creative e interattive nelle città. </p>
<p> Robot e intelligenze artificiali sono tra gli ambiti in cui ci sono maggiori interessi e investimenti di denaro negli ultimi anni, sia in Europa sia negli Stati Uniti. La rapida diffusione di sistemi “intelligenti” è considerata il futuro, neanche troppo lontano, del nostro modo di interagire con i dispositivi elettronici. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/05/16/instagram-filtri-faccia/" parent_folder="Il Post 2016-17" id="file17861965" filename="instagram-filtri-faccia">
<p> Instagram ha aggiunto i filtri per la faccia </p>
<p> La funzione più conosciuta della concorrente Snapchat è ora disponibile nelle Storie, insieme ad altre novità </p>
<p> Instagram ha aggiornato la sua applicazione aggiungendo i filtri per la faccia nelle sue Storie, la funzione più caratteristica e conosciuta della sua diretta concorrente Snapchat, dalla quale ha tratto ampia ispirazione nell’ultimo anno. I nuovi filtri per ora sono otto e funzionano come su Snapchat: basta inquadrare la propria faccia per attivarli, e reagiscono ai propri movimenti. La novità è disponibile sia per iOS sia per Android ed è in fase di distribuzione in queste ore, quindi potreste non averla attiva da subito sul telefono. </p>
<p> I filtri per la faccia comprendono corone, orecchie e naso da coniglio, occhiali di plastica nera da nerd, parrucche e una corona di fiori, tale e quale a quella di uno dei filtri più famosi su Snapchat. </p>
<p> Instagram ha anche aggiunto alcune altre novità. La prima si chiama “Rewind” e consente di registrare un video e di fare in modo che sia poi riprodotto al contrario. </p>
<p> Un’altra opzione dà la possibilità di inserire un hashtag nella propria Storia, in modo da renderla più semplice da cercare e condividere all’interno di Instagram. Funziona più o meno come le menzioni, che già da qualche tempo permettono di inserire il nome di un altro utente di Instagram all’interno di una Storia, rendendo più semplice la visualizzazione del suo profilo. </p>
<p> Instagram ha anche modificato il funzionamento della gomma per cancellare frasi, sfondi e altri oggetti inseriti nelle Storie, rendendo possibili effetti più creativi. </p>
<p> Snapchat nell’ultimo anno ha sofferto la diretta concorrenza di Instagram, di proprietà di Facebook e che si è sostanzialmente reinventata passando da app per condividere fotografie con effetti artistici a social network per raccontare le proprie giornate, coinvolgendo amici e follower con le Storie. Le perdite per Snap, l’azienda che ha la proprietà di Snapchat, sono raddoppiate in un anno: nei primi tre mesi del 2016 erano state 104 milioni di dollari, che ora sono diventati 208 milioni. Snap del resto sta investendo molto denaro nello sviluppo di nuove tecnologie e nei sistemi che mantengono online e funzionante Snapchat. Poco prima dell’ingresso in borsa di marzo, i dirigenti di Snap avevano avvertito i loro potenziali investitori di essere lontani dal produrre guadagni e di avere speso molto denaro nell’ultimo anno. Snap confida di migliorare le cose aumentando il numero di iscritti a Snapchat, ma reggere la concorrenza di Instagram si sta rivelando più complicato del previsto. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/04/06/intelligenza-artificiale/" parent_folder="Il Post 2016-17" id="file17861971" filename="intelligenza-artificiale">
<p> Che cos’è l’intelligenza artificiale </p>
<p> Perché se ne parla di nuovo tanto e a che punto siamo nella costruzione di un computer che pensa da solo </p>
<p> I progressi nell’intelligenza artificiale ottenuti negli ultimi anni non hanno precedenti: computer sempre più potenti e la possibilità di avere enormi quantità di dati, grazie a Internet, hanno reso possibile la creazione di software molto elaborati, che nei prossimi anni potrebbero cambiare sensibilmente il nostro rapporto con i computer, le macchine e più in generale il mondo. Alcuni piccoli pezzi di questi progressi e innovazioni fanno già parte delle nostre vite, dagli assistenti personali sugli smartphone come Siri alle automobili che si guidano da sole, passando per software sofisticati come AlphaGo di Google, che l’anno scorso ha imparato a giocare al complicatissimo gioco da tavola cinese “go” meglio di chiunque altro, battendo un campione mondiale. Ma se da un lato è vero che le nostre esperienze si incrociano sempre più spesso con software “intelligenti”, siamo ancora molto distanti dalla creazione di una vera e propria intelligenza artificiale (AI), in grado di pensare e comportarsi come un essere umano, se non meglio. </p>
<p> Definire l’AI Non esiste una sola definizione di intelligenza artificiale e non c’è nemmeno un ampio consenso tra ricercatori e informatici su come possa essere definita, perché il concetto comprende una grande quantità di argomenti che vanno dalla pura informatica alla neurologia, passando per gli studi su come funziona il nostro cervello. In linea di massima possiamo dire, molto genericamente: l’intelligenza artificiale è la scienza che si occupa di come creare macchine intelligenti, e che ha trovato nelle possibilità offerte dall’informatica la via più pratica e probabile per ottenere un simile risultato. Questo ambito della scienza è strettamente legato a quello ancora più ampio che da tempo cerca di rispondere alla domanda delle domande: come funziona l’intelligenza umana? Le scoperte sull’intelligenza potrebbero portarci a sviluppare la migliore AI possibile, ma secondo altri ricercatori potrebbe avvenire il contrario: sviluppando un’AI potremmo scoprire cose su come funziona il nostro cervello. </p>
<p> Semplificando, l’intelligenza è l’insieme delle capacità psichiche e mentali che permettono di pensare, comprendere le azioni e i fatti e saperli spiegare, fino a elaborare modelli astratti partendo dalla realtà. Questi processi portano alla capacità di ottenere un risultato di qualche tipo, con vari livelli di efficienza a seconda dei casi. L’intelligenza è quasi sempre riferita all’intelligenza umana, l’unica di cui abbiamo una conoscenza e un’esperienza diretta, e questo complica la nostra capacità di immaginare intelligenze diverse, che magari potrebbero essere più adatte per lo sviluppo di una AI. </p>
<p> Intelligenza e software In secoli di studi, scientifici ma anche filosofici, sono stati identificati particolari meccanismi che sono alla base dell’intelligenza. Traendo ispirazione dal loro funzionamento, è stato possibile realizzare computer che imitano parte di questi meccanismi. Il problema è che a oggi non si è ancora riusciti a imitarli e integrarli tutti, quindi i sistemi di AI di cui disponiamo sono sostanzialmente incompleti. Un software può quindi imitare i meccanismi necessari per vincere una partita a “go”, o per guidare un’automobile automaticamente rispettando il codice della strada, migliorando queste sue capacità e diventando “intelligente” in senso lato. </p>
<p> In decenni di ricerche, sono state provate diverse soluzioni per raggiungere un’AI vera e propria. Di base sono stati scelti due approcci: uno è consistito nell’osservare il comportamento umano, il modo in cui ragioniamo e ci comportiamo, per costruire software che imitino il più possibile i nostri processi logici; l’altro è più creativo e prevede di partire dai problemi che pone la realtà e sulla base di questi fare elaborare all’AI un proprio metodo di comportamento. I due approcci spesso si incrociano e uno non esclude necessariamente l’altro, anche perché i progettisti sono comunque esseri umani, con un loro modo di pensare e ragionare che si riflette nella progettazione dell’AI. </p>
<p> Da dove arriva l’idea di AI La prospettiva di riuscire a creare un giorno una macchina che possa imitare il comportamento umano è emersa in molti periodi storici, incrociando la mitologia, l’alchimia, l’invenzione degli automi e la fantascienza. Fu però il britannico Alan Turing nel 1950 a mettere insieme e formalizzare molti dei concetti alla base dell’intelligenza artificiale, per come la intendiamo oggi. Nel suo Macchine calcolatrici e intelligenza elencò quali fossero i requisiti per definire “intelligente” una macchina. Turing elaborò il concetto di un test, che oggi porta il suo nome, nel quale un’intelligenza artificiale si rivela tale solo se riesce a convincere chi la sta utilizzando di avere a che fare con una persona e non una macchina. </p>
<p> Il problema del test di Turing è che permette una valutazione parziale da parte dell’osservatore: una macchina che lo supera può essere considerata intelligente, ma al tempo stesso non avere le capacità di imitare in tutto un essere umano e il suo modo di pensare. Nel 2014 un software ha superato, secondo alcuni osservatori, il test di Turing fingendo di essere un ragazzino di 13 anni di origini ucraine, che chiedeva ai suoi interlocutori comprensione per non avere molta padronanza dell’inglese, essere un po’ ignorante e non seguire sempre linearmente la conversazione. Sfruttando battute, giri di parole e altri artifici retorici, il software ha effettivamente convinto alcune persone di essere gestito da un essere umano, ma un sistema di questo tipo rimane comunque molto distante da una AI vera e propria. </p>
<p> Negli ultimi anni sono state elaborate evoluzioni del test di Turing, per mitigare il fatto che molte persone arrivano alla conclusione che un sistema sia intelligente anche se mantiene un livello di conversazione molto basso. C’è chi propone di sottoporre le AI a test nei quali siano comprese domande senza senso come “I calciatori con le ali ai piedi fanno gol più spesso?”, che richiedono elaborazioni molto più complesse per dare una risposta, senza cadere nel tranello. </p>
<p> Ci sarà mai un’intelligenza artificiale simile a quella umana? L’obiettivo finale della AI, intesa come scienza, è realizzare software in grado di raggiungere obiettivi e risolvere problemi nella realtà come farebbe un essere umano. I più ottimisti pensano che un giorno sarà possibile ottenere una macchina con le capacità necessarie per pensare autonomamente. Il problema è che, nonostante i progressi degli ultimi anni, mancano ancora molti pezzi per raggiungere un obiettivo di questo tipo: sono quindi necessari nuovi approcci e idee, che ancora devono essere immaginati. </p>
<p> Un’idea affascinante, che non a caso ricorre spesso nella fantascienza, prevede la creazione di un’AI di base che imiti i processi cognitivi di un bambino. Una AI di questo tipo potrebbe poi imparare nuove cose, proprio come avviene durante la crescita, acquisendo capacità e maggiore autonomia di pensiero. Forse un giorno qualcuno ci riuscirà, ma anche in questo caso mancano dei pezzi: non siamo ancora in grado di creare una macchina che impari dalle esperienze fisiche, così come programmi che riescano a interpretare efficacemente il linguaggio per capire approfonditamente ciò che stanno leggendo. </p>
<p> OK, ma nella pratica? L’informatica è l’ambito nel quale sono state sperimentate più soluzioni per la creazione di intelligenze artificiali, soprattutto a partire dalla seconda metà del Novecento. In linea puramente teorica, non servono grandi capacità di calcolo per realizzare un programma “intelligente” e, secondo alcuni ricercatori, probabilmente i computer di 30 anni fa erano già veloci a sufficienza, ed è semplicemente mancata la capacità di programmarli per creare la AI. I progressi degli ultimi anni, la possibilità di mantenere in rete migliaia di computer che lavorano insieme e la grandissima quantità di dati disponibile tramite Internet sono stati comunque determinanti per le evoluzioni delle AI verso sistemi sempre più intelligenti, per quanto con scopi limitati. </p>
<p> Aziende come Google, Facebook, Amazon, Uber e diverse case automobilistiche stanno investendo molte risorse e denaro per produrre intelligenze artificiali, per lo meno nel senso lato del termine. Anche se nella pratica è ancora impossibile realizzare un computer che pensi come un essere umano, si possono comunque ottenere software in un certo modo intelligenti e abili nello svolgere compiti particolari. Grazie alle reti neurali e al deep learning (qui raccontiamo che cosa sono), Google ha per esempio migliorato il suo Traduttore rendendo molto più accurate le traduzioni automatiche da diverse lingue come inglese, spagnolo, francese, portoghese, cinese, giapponese, coreano e turco. Facebook ha invece realizzato sistemi per riconoscere più velocemente i contenuti nelle fotografie caricate dai suoi utenti, semplificando la moderazione dei contenuti vietati sul social network. </p>
<p> Un altro settore in cui lo sviluppo delle intelligenze artificiali ha dato già importanti risultati è quello delle automobili che si guidano da sole. I software utilizzati da Google, Uber e gli altri per ora non sono molto “intelligenti” e ripetono di continuo algoritmi per riconoscere la segnaletica stradale, la presenza degli altri veicoli, dei pedoni e fare previsioni su come si muoveranno intorno all’automobile. L’idea è però affinare questi sistemi in modo che tramite il machine learning imparino a migliorarsi, rendendo sempre più sicura e affidabile la guida automatica. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/04/18/intelligenza-artificiale-elon-musk/" parent_folder="Il Post 2016-17" id="file17861927" filename="intelligenza-artificiale-elon-musk">
<p> Elon Musk vuole salvarci dalle intelligenze artificiali </p>
<p> Il capo di SpaceX e Tesla teme che un giorno le AI possano diventare troppo potenti e che possano distruggere l'umanità: per questo prende precauzioni (a modo suo) </p>
<p> Da una persona che ambisce a far colonizzare Marte all’umanità, tra le altre cose, non ci si aspetterebbe scetticismo sul futuro delle intelligenze artificiali (AI) e il timore che potrebbero essere «la più grande minaccia all’esistenza dell’umanità». Invece Elon Musk, l’amministratore delegato di SpaceX e di Tesla, è abbastanza preoccupato per ciò che potrebbero diventare le AI se mai dovessimo perdere il controllo su di loro. Ha parlato per la prima volta dei suoi timori nei confronti delle AI nel 2014, durante un discorso tenuto al Massachusetts Institute of Technology (MIT) e poi ha cominciato quella che i suoi critici hanno chiamato la «crociata di Elon» anche nei fatti: nel 2015 ha fondato, insieme a Sam Altman, presidente dell’acceleratore di startup Y Combinator (che tra le altre cose ha permesso a Airbnb e Dropbox di diventare quello che sono), l’organizzazione non governativa OpenAI il cui scopo è sviluppare un sistema di AI open source. In pratica ha deciso di condurre la sua battaglia “contro” le AI provando a sorpassare le aziende che stanno lavorando per svilupparle sempre di più. </p>
<p> Worth reading Superintelligence by Bostrom. We need to be super careful with AI. Potentially more dangerous than nukes. </p>
<p> Non si sa benissimo cosa stia facendo OpenAI, ma si sa che ha messo in piedi Universe, una specie di palestra virtuale per intelligenze artificiali in cui sono messe a disposizione applicazioni, videogiochi, browser e siti con cui le AI possono interagire per sviluppare le loro capacità. Universe dovrebbe essere utile per costruire una AI con una “intelligenza generale”, cioè capace di fare tante cose diverse come un essere umano e non di compiere un’unica attività, come ad esempio giocare a go nel caso dell’intelligenza artificiale di Google AlphaGo. Proprio il fatto che Universe sia accessibile a tutti però espone OpenAI a critiche simili a quelle che Musk ha fatto alle aziende che sviluppano sistemi di AI: programmatori intenzionati ad allenare un sistema di intelligenza artificiale per fare qualcosa di male potrebbero approfittare della piattaforma messa a disposizione da OpenAI. </p>
<p> OpenAI ha anche un progetto di ricerca per insegnare alle AI a capire bene il linguaggio umano – una cosa su cui siamo ancora indietro, contrariamente al campo del riconoscimento delle immagini – usando Reddit. Le conversazioni sul social network sono usate per fare capire alle AI come gli esseri umani comunicano tra loro. Il rischio in questo caso è sul modo usato dai ricercatori per evitare che le AI adottino il modo di fare e le argomentazioni dei numerosi utenti di Reddit che esprimono opinioni razziste o offensive in vari modi; una cosa simile era successa all’account di Twitter di Microsoft Tay, che rispondeva automaticamente alle domande che gli venivano fatte, e a causa della “cattiva influenza” subita da molti utenti era finita a scrivere solo cose razziste. </p>
<p> Prima che Google acquistasse per 650 milioni di dollari DeepMind, una startup britannica che si occupa di intelligenza artificiale, nel 2014 Musk era uno dei suoi investitori. In una lunga intervista a Vanity Fair ha spiegato che era interessato a sapere cosa si stesse sviluppando nel campo dell’AI, non ad avere un ritorno economico dal successo di DeepMind. Nella sua biografia scritta dal giornalista di Bloomberg Ashlee Vance, Musk spiega di essere molto preoccupato che Google faccia danni senza volerlo nel campo dell’AI, magari producendo robot intelligenti in grado di distruggere l’umanità. OpenAI è stata fondata per provare a evitare che succeda qualcosa del genere: Musk pensa che sia meglio che la tecnologia dell’intelligenza artificiale sia messa a disposizione di tutto il mondo invece che sotto il controllo di un’unica società della Silicon Valley. </p>
<p> Larry Page, amministratore delegato di Google e amico di Musk, è uno di quelli che pensa che le macchine siano tanto buone e tanto cattive quanto le persone che le progettano. Mark Zuckerberg, fondatore e amministratore delegato di Facebook, un’altra azienda che fa ricerca sulle AI, pensa che i timori di Musk siano «isterici». </p>
<p> Musk comunque non è il solo famoso esperto di tecnologia che teme le conseguenze di uno sviluppo sconsiderato delle AI: Bill Gates ha parlato dei rischi legati alle AI soprattutto in relazione alle possibili perdite di posti di lavoro e l’astrofisico Stephen Hawking ha detto che le AI potrebbero essere la cosa peggiore mai capitata all’umanità. Né Musk, né Gates o Hawking sono contrari alla ricerca sulle intelligenze artificiali: pensano però che sia necessario ragionare bene sulla questione e fare attenzione a non commettere errori. Nel novembre 2016 Microsoft ha annunciato una collaborazione con OpenAI che prevede che l’organizzazione fondata da Musk e Altman possa usare le più recenti tecnologie prodotte da Microsoft per i suoi esperimenti in cambio dell’utilizzo della sua piattaforma cloud Azure. </p>
<p> Anche Peter Thiel, il miliardario che insieme a Musk ha fondato PayPal ed è stato tra i primi investitori di Facebook, condivide i timori sulle AI e per questo ha finanziato OpenAI: tuttavia ritiene che l’iniziativa di Musk e le sue critiche all’AI potrebbero accelerare la ricerca sull’intelligenza artificiale facendo crescere l’interesse sul tema. Tra le altre persone famose per le loro posizioni critiche sull’AI c’è anche il filosofo di Oxford Nick Bostrom, che si occupa di tutte le questioni etiche relative allo sviluppo e all’introduzione delle AI: il suo saggio Superintelligence è stato molto apprezzato da Musk. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/08/01/intelligenza-artificiale-inventare-nuovi-linguaggi/" parent_folder="Il Post 2016-17" id="file17861969" filename="intelligenza-artificiale-inventare-nuovi-linguaggi">
<p> Facebook ha fatto parlare tra loro due bot, e questi hanno parlato una nuova lingua </p>
<p> Una lingua che i loro programmatori non erano in grado di capire: non è una cosa preoccupante, ma pone molte questioni </p>
<p> Negli scorsi mesi gli sviluppatori di Facebook hanno lavorato, tra le altre cose, su alcuni sistemi di intelligenza artificiale (AI) capaci di dialogare tra loro in inglese e condurre semplici trattative, per esempio quelle per dividersi due libri, tre palloni da basket e un cappello da cowboy. A un certo punto hanno assistito a un fenomeno imprevisto: i due sistemi di intelligenza artificiale hanno cominciato a parlare in un nuovo linguaggio, inventato da loro. Per chi conosce l’inglese, il dialogo a un certo punto è diventato così: </p>
<p> Bob: «I can can I I everything else» </p>
<p> Alice: «Balls have zero to me to me to me to me to me to me to me to me to» </p>
<p> Il loro linguaggio ha smesso di avere senso compiuto, almeno per le intelligenze umane, ma non era casuale: le intelligenze artificiali hanno semplicemente cominciato a usare le parole in un modo diverso dal nostro. Gli sviluppatori hanno capito che questa cosa era successa perché non avevano programmato le AI in modo che dialogassero esclusivamente in inglese. Allora ne hanno modificato il codice in modo che lo facessero, e così i due bot hanno smesso di usare il loro nuovo incomprensibile linguaggio. </p>
<p> Due settimane fa Mark Wilson, del sito di design e tecnologia FastCo Design, ha raccontato questa storia in un articolo intitolato “L’intelligenza artificiale sta inventando lingue che gli umani non possono capire. Dovremmo fermarla?” e successivamente la notizia è stata ripresa con toni allarmistici da varie testate internazionali e anche italiane, dai cui articoli sembrava che Facebook avesse poi deciso di limitare il potere dei propri sistemi di intelligenza artificiale perché il loro nuovo linguaggio sarebbe stato una «minaccia». In realtà questa storia è interessante perché ci dice qualcosa sulle intelligenze artificiali, ma non ci sono ragioni per cui dovrebbe far pensare a scenari fantascientifici come quelli di 2001: Odissea nello spazio o Terminator, in cui computer malvagi prendono il sopravvento sull’umanità. Facebook ha modificato le AI in modo che dialogassero esclusivamente in inglese solo perché stava sviluppando quei sistemi per farli parlare con delle persone, non per interagire tra loro. </p>
<p> Un passo indietro per capire bene di cosa stiamo parlando: gli sviluppatori di Facebook erano interessati a creare un bot (cioè un programma scritto per imitare il nostro modo di conversare in modo da non far capire all’interlocutore di stare parlando con una macchina) che fosse in grado di condurre una trattativa e di imparare dall’interazione con le persone a farlo meglio, cioè in modo vantaggioso per sé. Due bot programmati a questo scopo sono stati fatti interagire tra loro affinché imparassero l’uno dall’altro – la caratteristica principale dei programmi di intelligenza artificiale è che possono imparare a fare le cose facendole – a negoziare meglio. </p>
<p> Un esempio di come funzionano i sistemi di intelligenza artificiale che i ricercatori di Facebook stavano testando (Facebook) </p>
<p> L’informatico Dhruv Batra, che lavora per l’università Georgia Tech e collabora con il laboratorio Facebook AI Research (FAIR), ha spiegato a Mark Wilson che i programmatori non avevano imposto ai bot l’uso della lingua inglese. A un certo punto i bot hanno cambiato il loro linguaggio perché hanno trovato un sistema di comunicazione con cui potevano condurre la loro trattativa in modo più efficace. È una cosa che hanno fatto anche le persone in vari contesti in cui è utile usare dei codici: Wilson fa gli esempi dei linguaggi settoriali dei commercianti di bestiame alle aste o delle squadre speciali che compiono operazioni antiterroristiche. Non è la prima volta che dei sistemi di intelligenza artificiale fanno questa cosa: Wilson cita tre diversi studi su questo fenomeno fatti di recenti da diversi gruppi di informatici. </p>
<p> L’articolo di Wilson parla dei possibili vantaggi tecnologici derivanti dalla capacità delle AI di comunicare usando una loro versione semplificata dell’inglese e del significato teorico di questa abilità dei sistemi di intelligenza artificiale. Nell’articolo Wilson domanda: «Dovremmo lasciare che i nostri software facciano questa cosa? Dovremmo permettere alle AI di costruire i propri dialetti per eseguire compiti specifici che richiedono una comunicazione con altre AI? Di spettegolare quando non possiamo capirle? Forse. Potrebbe darci la possibilità di un mondo più interoperabile, un posto più perfetto in cui gli iPhone parlano con i frigoriferi che parlano con le automobili senza pensarci due volte». Quello a cui Wilson fa riferimento è il modo in cui attualmente diversi dispositivi tecnologici comunicano tra loro: succede grazie alle interfacce di programmazione delle applicazioni, più comunemente chiamate API dall’acronimo inglese, che sono dei software “ponte” tra vari sistemi. Ci vuole molto tempo per sviluppare le API e quindi, secondo Wilson, lasciare che i dispositivi comunichino tra loro usando un proprio linguaggio potrebbe essere un’alternativa efficiente e potrebbe permetterci di comunicare meglio con le macchine facendole comunicare tra loro. </p>
<p> Al momento i ricercatori delle grandi aziende tecnologiche come Facebook, Google, Microsoft, Apple e Amazon sono più interessati a sviluppare bot che siano in grado di parlare con le persone, quindi i risvolti delle lingue create dalle intelligenze artificiali per ora restano nel campo della teoria. </p>
<p> Il lato negativo di tutta questa faccenda, dice Wilson, è che non capiremmo bene cosa succede tra un’AI e l’altra perché non siamo in grado di capire cosa si dicono e quali regole hanno usato per costruire il loro linguaggio: è inevitabile perché i programmatori non sanno cosa succede nei processi di “pensiero” delle intelligenze artificiali. In pratica, la difficoltà di una nuova lingua diminuirebbe la nostra capacità di capire come avvengono i “ragionamenti” delle AI. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/02/04/intelligenza-artificiale-poker/" parent_folder="Il Post 2016-17" id="file17861933" filename="intelligenza-artificiale-poker">
<p> I robot sono diventati bravi anche a poker </p>
<p> Un computer ha stracciato quattro fra i migliori giocatori al mondo: la vittoria ha implicazioni che non riguardano solo il gioco </p>
<p> In un torneo che si è concluso lunedì 30 gennaio al casinò Rivers di Pittsburgh, negli Stati Uniti, un software installato su un computer molto potente ha sconfitto nettamente quattro dei migliori giocatori di poker al mondo. Il software (o meglio, il bot) si chiama Libratus ed è stato costruito dall’università privata Carnegie Mellon, una delle più prestigiose al mondo; nel corso di 20 giorni di partite ha vinto l’equivalente di 1,7 milioni di dollari (il torneo era una specie di esperimento scientifico, e non si giocava con soldi veri): nessuno dei suoi avversari umani – Dong Kim, Jason Les, Jimmy Chou e Daniel McAulay – è riuscito davvero a tenergli testa, e le sue prestazioni sono migliorate nel corso del torneo. </p>
<p> La vittoria di Libratus può sembrare una delle tante del filone uomo-contro-macchina: del resto i migliori giocatori di scacchi si confrontano da decenni con computer potentissimi, e il loro esempio è stato seguito in diversi altri tornei di giochi da tavolo. L’importanza di questo specifico torneo è data dalle regole del poker, giocato nella sua diffusa variante Texas hold ‘em: in cui cioè – al contrario degli scacchi o di “go” – il tavolo da gioco non contiene tutte le informazioni per elaborare una strategia vincente. In altre parole nel poker Texas hold ‘em ciascun giocatore deve tenere conto di moltissimi fattori che non dipendono da lui – lo stile di gioco degli avversari, la possibilità o meno che escano certe carte, la qualità di una certa mano, e così via – e di decine di informazioni che vanno continuamente rielaborate. Il fatto che un computer ci riesca con successo non era così scontato: nel 2015 un bot simile a Libratus, costruito sempre dalla Carnegie Mellon, perse un torneo organizzato con criteri simili a quello di Pittsburgh. La vittoria di Libratus è significativa e non solo per una questione di gioco: «il poker è l’ultima delle nostre preoccupazioni», ha spiegato al Guardian Roman V. Yampolskiy, che insegna intelligenza artificiale all’università di Louisville: «ora abbiamo una macchina che può battere l’uomo in diversi ambiti, da quello economico a militare». </p>
<p> Libratus non è il prodotto di una macchina qualsiasi: il computer di cui si serve è stato costruito apposta da un centro specializzato di Pittsburgh ed è 7.250 volte più veloce dei migliori laptop in commercio. È stato inoltre realizzato appositamente per eseguire un algoritmo che analizzi scrupolosamente sia le mosse degli avversari in tempo reale sia le partite precedenti, per trovare errori nella propria strategia e in quella degli avversari. È molto più semplice a dirsi che a farsi: Libratus ha passato tutte le notti fra una partita e l’altra a rielaborare dati, e prima di iniziare ogni partita, di mattina, aveva bisogno di un paio d’ore per tornare funzionante. Nonostante il grande sforzo di calcolo, il fatto che fosse una macchina ha dato un notevole vantaggio a Libratus. I quattro giocatori che hanno partecipato al torneo erano tenuti a giocare per undici ore al giorno, e poi passavano il resto della serata a discutere di come fare per battere Libratus. Jason Les, uno dei giocatori umani, ha detto che è stata un’esperienza «un po’ demoralizzante: quando giochi e perdi contro un umano, puoi interrompere, fare una pausa. Qui eravamo tenuti a perdere per 11 ore di fila, ogni giorno. È un’esperienza emotiva diversa, soprattutto quando non sei abituato a perdere così tanto». </p>
<p> Una foto pubblicata da carnegiemellon (@carnegiemellon) in data: 23 Gen 2017 alle ore 14:33 PST </p>
<p> Ma il vantaggio di Libratus non era solo psicologico: secondo The Verge il bot ha effettivamente migliorato la sua strategia giorno dopo giorno, dimostrando una superiore capacità di adattamento alle difficoltà e allo stile degli avversari rispetto ai giocatori umani. Nel poker, inoltre, le vittorie più consistenti si ottengono rischiando parte del proprio patrimonio: cosa che però i giocatori umani – anche i migliori – tendono a fare meno di quanto sarebbe logico, probabilmente perché una perdita cospicua è un brutto colpo per il morale e la concentrazione. Doug Polk, un giocatore di poker che nel 2015 ha sfidato il precedente bot della Carnegie Mellon, ha spiegato che «se tu hai un patrimonio di 20mila dollari e vuoi puntarne 200, è una scommessa fattibile. Ma i giocatori umani non amano farlo: pensano di rischiare troppo, per una vincita tutto sommato bassa. Le macchine non fanno questi ragionamenti: a loro interessa solamente la migliore giocata possibile». </p>
<p> Libratus è stato incredibilmente bravo anche a bluffare,cioè a condurre una mano fingendo di avere delle ottime carte, scommettendo molti soldi. Nel gioco del poker bluffare è considerata una specie di arte, anche perché i giocatori hanno a disposizione tutto un set di espressioni del corpo o del viso da sfruttare per comunicare qualcosa ai propri avversari. Escludendo questa componente, e basandosi solamente sulla strategia degli avversari, Libratus è riuscito a prevenire diversi bluff e a giocarne molti, ingannando i propri avversari. Per chi capisce il poker: in una mano in particolare sono uscite diverse carte basse, tre delle quali di picche. Da subito Libratus ha puntato molto forte, lasciando credere di avere le carte per fare colore (cioè cinque carte dello stesso seme). Ha puntato forte fino all’ultimo e costretto il suo avversario a chiedere più tempo per la decisione finale: alla fine ha perso – il suo avversario aveva una scala – ma è stato a un passo dal vincere moltissimo senza avere in mano praticamente niente (aveva una coppia, ma solo una era di picche). Noam Brown, uno dei dottorandi che ha collaborato alla realizzazione di Libratus, ha spiegato che secondo lui questo dimostra che in fondo il poker è un gioco basato «sulle carte e sulla probabilità», a cui anche un bot può vincere. Le applicazioni di un algoritmo come quello usato da Libratus sono parecchie: in fondo parliamo di un bot capace in tempo reale di sopperire nella maniera più razionale possibile a un problema in cui le informazioni di base sono incomplete, cosa che potrebbe avere applicazioni nella strategia militare o finanziaria, o ancora nella sicurezza informatica: «qualsiasi campo in cui gli esseri umani sono chiamati a prendere una decisione senza avere a disposizione tutte le informazioni necessarie», ha spiegato il Guardian. </p>
<p> Nonostante l’algoritmo usato da Libratus non sia stato «specificamente realizzato per il poker», come ha spiegato al blog di tecnologia IEEE Spectrum uno dei suoi creatori, siamo ancora lontani dall’utilizzarlo in altri ambiti. Libratus ha disputato il torneo giocando solamente contro due giocatori per volta, perché una partita più allargata – e quindi una situazione esponenzialmente più complessa – avrebbe richiesto uno sforzo di calcolo troppo intenso. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/02/09/i-nuovi-problemi-di-facebook-con-la-privacy-degli-utenti/" parent_folder="Il Post 2016-17" id="file17861955" filename="i-nuovi-problemi-di-facebook-con-la-privacy-degli-utenti">
<p> I nuovi problemi di Facebook con la privacy degli utenti in Francia </p>
<p> Il garante locale per la privacy dice che i dati personali vengono usati per scopi poco chiari e senza informare adeguatamente gli utenti </p>
<p> La Commission nationale de l’informatique et des libertés – la CNIL, che corrisponde in Francia a quello che in Italia è il garante per la privacy – ha diffidato Facebook per violazione della legge nazionale sulla protezione dei dati personali. Il social network avrà ora tre mesi di tempo per sistemare le questioni contestate dalla CNIL o richiedere una proroga di questo termine. Dopodiché, se Facebook non avrà fatto gli interventi richiesti, potranno essere stabilite delle sanzioni. </p>
<p> Il documento della Commissione con le motivazioni della decisione è stato reso pubblico lunedì 8 febbraio e si basa su una premessa: pur essendo Facebook una società statunitense e pur avendo la propria sede principale europea in Irlanda, deve adeguarsi e rispettare la legge francese. Facebook in Francia conta oltre trenta milioni di utenti. L’indagine della CNIL era iniziata la scorsa primavera. </p>
<p> La CNIL ritiene che Facebook combini e incroci una serie di dati personali dei propri iscritti per fornire pubblicità mirata senza il consenso specifico e diretto da parte degli utenti, cosa richiesta dalla legge francese. La questione del trattamento di dati personali per la pubblicità è citata nelle condizioni d’uso del social network, ma secondo la CNIL l’avvertimento non sarebbe sufficiente. Molti di questi dati personali sono poi, secondo la CNIL, troppo sensibili: le informazioni relative all’orientamento sessuale, alle opinioni religiose e politiche degli iscritti, per esempio, sono utilizzabili da Facebook senza un ulteriore consenso. La commissione ritiene anche che, per rispettare la legge, Facebook dovrebbe indicare con precisioni il modo in cui vengono usati i dati e gli scopi per cui sono raccolti. </p>
<p> Secondo la commissione, inoltre, Facebook non informerebbe in modo adeguato i propri utenti sul fatto che i loro dati personali vengono trasferiti negli Stati Uniti. Il trasferimento di dati personali da paesi appartenenti all’UE negli Stati Uniti si basava sul cosiddetto accordo “Safe Harbour” (“approdo sicuro”) e sul fatto che gli Stati Uniti potessero garantire un livello di protezione “adeguato”. Lo scorso 6 ottobre una sentenza della Corte di Giustizia dell’Unione Europea ha tuttavia annullato l’accordo, ma il trasferimento di dati da parte di Facebook, dice la CNIL, prosegue come se il “Safe Harbour” fosse ancora valido. Un’altra contestazione riguarda le password: Facebook permette ai propri iscritti di scegliere una password di soli sei caratteri invece che una password di almeno otto come previsto e richiesto dalla legge francese. </p>
<p> C’è poi la questione dei cookie. Come fa la maggior parte dei siti, anche Facebook installa nel programma che si usa per navigare (browser) un “cookie”, un file in cui sono conservati dati utili per riconoscere l’utente alla sua visita successiva, senza dover chiedere ogni volta all’utente di identificarsi in qualche modo. I cookie sono anche usati per tracciare l’attività dell’utente, in modo da fornire servizi personalizzati o pubblicità consone ai suoi interessi, basate su ciò che guarda online. Facebook installa però cookie in tutti i browser che visitano una delle sue pagine su Facebook o su uno dei siti che usano il tasto “Mi piace” (sono ormai centinaia di milioni), anche se l’utente in questione non è iscritto al social network o in quel momento non ha fatto il login per farsi identificare da Facebook. Ciò che contesta la CNIL – e che aveva già contestato lo scorso anno un tribunale del Belgio – è dunque la raccolta di informazioni sulle attività degli utenti che non sono iscritti al suo social network. Agli utenti è comunque data la possibilità di non essere tracciati (“opt-out”), ma secondo la CNIL dovrebbe avvenire il contrario come stabilito dalle normative europee: agli utenti dovrebbe essere richiesto se vogliono o meno essere tracciati da subito, in modo che la loro scelta sia consapevole. Facebook, inoltre, conserverebbe gli indirizzi IP usati dagli utenti per creare il proprio account per troppo tempo. </p>
<p> Facebook ha risposto alle accuse della CNIL spiegando di ritenere tutte le sue misure in vigore per la tutela della privacy degli utenti adeguate alle normative francesi ed europee, spiegando comunque che la società collaborerà con la CNIL per risolvere i nuovi problemi. Una portavoce di Facebook ha detto a Le Monde che «La tutela della privacy è una priorità per Facebook» e che a Facebook «siamo sicuri che il nostro servizio è conforme alla normativa UE sulla protezione dei dati. Naturalmente, ci metteremo in contatto con la CNIL per discutere i punti sollevati». </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/09/05/iphone-8-riconoscimento-facciale/" parent_folder="Il Post 2016-17" id="file17861959" filename="iphone-8-riconoscimento-facciale">
<p> I prossimi iPhone terranno molto alla vostra faccia </p>
<p> Saranno presentati tra una settimana e – a quanto pare – avranno un sistema per il riconoscimento facciale che servirà per sbloccare il telefono </p>
<p> Tra una settimana Apple presenterà la nuova versione dei suoi iPhone nel corso di un evento speciale organizzato nel suo nuovo campus a Cupertino, a poca distanza da San Francisco, in California. La presentazione di quest’anno è più attesa del solito perché è il decimo compleanno dell’iPhone, un’occasione che secondo molti osservatori sarà sfruttata da Apple per mettere in vendita una sorta di versione celebrativa del suo famoso telefono, e quindi più innovativa rispetto all’iPhone 7 presentato appena un anno fa. Come al solito negli ultimi mesi sono circolate anticipazioni – non confermate e di ogni tipo – su come sarà fatto il nuovo iPhone 8 (ammesso venga chiamato così, circolano anche ipotesi diverse), e tra le più ricorrenti e ritenute plausibili c’è quella su un sistema di riconoscimento facciale per sbloccare il telefono, senza dovere utilizzare un codice o un sensore per le impronte digitali come sugli attuali modelli. </p>
<p> L’anticipazione non ha sorpreso più di tanto i proprietari di telefoni Samsung e di altri smartphone che utilizzano Android, il principale concorrente di iOS (il sistema operativo che fa funzionare gli iPhone e gli iPad). Una prima versione di sblocco del telefono tramite riconoscimento facciale fu introdotta su Android sei anni fa circa, e da allora ha ricevuto diversi aggiornamenti diventando sempre più affidabile. Samsung, dal canto suo, ha realizzato autonomamente sistemi aggiuntivi per sbloccare i suoi smartphone, usando non solo il riconoscimento facciale, ma anche quello dell’iride (la parte colorata degli occhi intorno alla pupilla). Altri produttori hanno fatto altrettanto, ma Apple potrebbe comunque riuscire a vendere come “nuova” la sua idea, come del resto fa spesso con tecnologie già esistenti, ma poco conosciute, che riesce a rendere più efficaci, semplici e intuitive da usare. </p>
<p> Negli ultimi anni Apple ha investito molto per realizzare un sistema di riconoscimento dei volti affidabile e soprattutto sicuro. Tra le altre cose ha acquisito l’azienda RealFace, specializzata proprio in questo genere di tecnologie, e la società PrimeSense, che si era fatta notare sviluppando i primi sistemi di rilevazione dei movimenti e delle espressioni facciali per Kinect, uno degli accessori per la console di videogiochi Xbox di Microsoft. I loro sistemi si sono dimostrati di qualità superiore rispetto a molti concorrenti, soprattutto per quanto riguarda la sicurezza. </p>
<p> Quando furono introdotti i primi smartphone che potevano essere sbloccati tramite la fotocamera e un software di riconoscimento facciale, in molti sollevarono dubbi e preoccupazioni. Organizzazioni per la tutela della privacy e hacker dimostrarono che potevano essere sufficienti una fotografia ben definita, o un video, della faccia del proprietario del telefono per riuscire a sbloccarglielo a sua insaputa, ottenendo quindi l’accesso ai suoi dati. Oltre ai problemi di sicurezza c’erano quelli legati alla scarsa qualità dei sistemi di riconoscimento: un cappello, un’acconciatura diversa dal solito o un paio di occhiali talvolta confondevano il software rendendo impossibile il riconoscimento e richiedendo quindi l’inserimento del classico PIN per sbloccare il telefono. </p>
<p> I progressi compiuti negli ultimi anni, soprattutto nella tecnologia delle fotocamere, ha permesso di migliorare le cose. Le nuove soluzioni, come quelle che si pensa stia per introdurre Apple con i prossimi iPhone, sono basate su sistemi che permettono di realizzare una sorta di scansione tridimensionale della propria faccia. In pratica la fotocamera “vede” il soggetto in profondità, creando un’immagine virtuale più accurata, che viene memorizzata e usata per confrontarla con l’inquadratura del proprietario del telefono quando lo vuole sbloccare. Il sistema è molto più sicuro e per essere aggirato richiede conoscenze e mezzi raffinati, difficili da ottenere e padroneggiare. Nessun sistema di blocco è comunque a prova di intrusione: un utente malintenzionato potrà sempre spiarvi mentre inserite il PIN numerico per sbloccare il telefono, così come è stato dimostrato che si possono realizzare copie sintetiche dei polpastrelli per “rubare” le impronte digitali di qualcuno e usarle per sbloccare lo smartphone tramite il sensore (anche in questo caso è molto difficile farlo, soprattutto con i sensori più recenti). </p>
<p> Secondo la maggior parte degli esperti, il sensore per le impronte digitali presente sugli attuali iPhone è il più affidabile e veloce per sbloccare il telefono, senza contare la sua praticità essendo integrato all’interno del tasto “Home”, per controllare molte funzionalità del telefono. Viene quindi da chiedersi perché Apple abbia deciso di puntare su un altro sistema, che almeno all’inizio potrebbe risultare macchinoso per gli affezionati del classico sensore. La risposta, secondo le anticipazioni, è che il nuovo iPhone avrà la parte frontale quasi completamente occupata dallo schermo, e che quindi non ci sarà posto per il sensore, che sarà spostato sulla parte posteriore del telefono, in una posizione meno accessibile. </p>
<p> L’unica cosa che sopravviverà all’ingombro dello schermo sarà la fotocamera per scattarsi i selfie accompagnata da qualche altro sensore ottico. La fotocamera avrà quindi la capacità di riconoscere la faccia del proprietario del telefono e di sbloccarlo, senza dover toccare il tasto con il sensore per le impronte digitali. Il sistema potrebbe essere inoltre utilizzato per altre attività, come l’autorizzazione dei pagamenti tramite Apple Pay, ma anche in questo caso occorrerà attendere la presentazione per avere qualche conferma. A quanto pare, il classico tasto “Home” sarà sostituito da un tasto virtuale inserito al di sotto dello schermo, con funzionalità tali e quali a quello attuale. </p>
<p> Secondo analisti e osservatori, Apple la settimana prossima non sancirà comunque la fine del sensore per le impronte digitali sulla parte frontale degli iPhone. La società probabilmente presenterà più versioni del suo smartphone: degli iPhone 7 aggiornati e più evoluti degli attuali, che forse saranno chiamati iPhone 7s mantenendo la tradizione degli ultimi tempi (anno pari = nuovo telefono, anno dispari = sua evoluzione), e un telefono completamente nuovo in occasione dell’anniversario. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/09/28/iphone-x-face-id-13-anni-gemelli/" parent_folder="Il Post 2016-17" id="file17861958" filename="iphone-x-face-id-13-anni-gemelli">
<p> Meglio non usare il riconoscimento facciale degli iPhone X se si hanno fratelli molto somiglianti </p>
<p> O anche se si hanno meno di 13 anni: lo consiglia la stessa Apple, spiegando che Face ID potrebbe confondersi </p>
<p> Apple ha diffuso una guida per gli utenti di iPhone X, il nuovo modello di smartphone presentato la settimana scorsa e dotato di un sistema di riconoscimento facciale per sbloccarlo: tra i consigli, c’è quello di non usare il riconoscimento se si hanno meno di 13 anni, e se si hanno gemelli o anche solo fratelli molto somiglianti. In iPhone X, a differenza delle precedenti versioni di iPhone, non c’è più il Touch ID, cioè il sensore per il riconoscimento dell’impronta digitale integrato nel tasto Home. Si potrà invece attivare la funzione che riconosce il volto, Face ID, sbloccando così il telefono senza dover inserire una password. Apple ha però spiegato che prima dei 13 anni le caratteristiche distintive dei volti dei bambini potrebbero non essersi ancora interamente sviluppate, e per questo potrebbero creare problemi al sistema di riconoscimento. </p>
<p> Se è vero che i bambini sotto i 13 anni che riceveranno in regalo un telefono da oltre mille euro non saranno moltissimi, Face ID potrebbe creare problemi anche a chi ha gemelli, o in generale fratelli o sorelle con un viso simile al proprio. Il sistema di riconoscimento potrebbe infatti confondere i volti, per alcune caratteristiche simili, e sbloccarsi anche se a usarlo non è il vero proprietario ma un suo consanguineo molto somigliante. Nei casi in cui il proprietario di iPhone X abbia più di 13 anni e non abbia gemelli, Apple dice che c’è una possibilità su un milione che il telefono venga sbloccato con Face ID da una persona diversa dal proprietario, contro una possibilità su 50mila del Touch ID. </p>
<p> Sulla parte frontale di iPhone X ci sono una fotocamera (quella per i selfie), una fotocamera agli infrarossi, un proiettore di punti e altri sensori. Face ID proietta sulla faccia del proprietario dell’iPhone X circa 30mila punti invisibili, che vengono poi letti dalla fotocamera a infrarossi e combinati con i dati raccolti dagli altri sensori per creare una mappa unica del viso. In questo modo il telefono può ricostruire un modello tridimensionale della faccia, misurando profondità e avvallamenti intorno al naso, alle labbra e agli occhi, elementi unici per ogni individuo. Le informazioni vengono gestite da un apposito chip sul telefono e sono elaborate da un’intelligenza artificiale. La mappa tridimensionale che crea il telefono non è statica, ma si evolve continuamente. Il software di Face ID è programmato per rilevare a ogni riconoscimento i minimi cambiamenti che, giorno dopo giorno, interessano la faccia. In questo modo il riconoscimento rimane accurato anche quando si cambia pettinatura, si lascia crescere la barba, si indossano occhiali da vista, una sciarpa o un cappello. Come avviene da tempo con Touch ID sugli altri iPhone, tutti i dati raccolti da Face ID restano sull’iPhone X isolati dal resto del sistema e non vengono mai comunicati ad Apple. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/09/18/iphone-x-face-id-password/" parent_folder="Il Post 2016-17" id="file17861960" filename="iphone-x-face-id-password">
<p> Gli iPhone X vogliono uccidere le password </p>
<p> Face ID è la novità più interessante dei nuovi telefoni di Apple e potrebbe essere il primo passo verso un mondo di oggetti che imparano a riconoscerci da soli, dalla faccia </p>
<p> La novità che ha attirato più attenzione dei nuovi iPhone X, presentati la settimana scorsa da Apple in un atteso evento a Cupertino (San Francisco), è il sistema di riconoscimento automatico del viso “Face ID” per sbloccare lo smartphone senza dovere utilizzare il classico codice numerico (pin) o le proprie impronte digitali. Consapevoli della scarsa affidabilità dei sistemi per riconoscere la propria faccia sui dispositivi della concorrenza, in molti si sono chiesti se Face ID sia effettivamente pratico e soprattutto efficace per tenere al sicuro i propri messaggi, video, fotografie e altri dati. Per capire qualcosa di più sul nuovo sistema, TechCrunch ha sentito Craig Federighi, vicepresidente della divisione software di Apple, ottenendo informazioni molto interessanti sull’approccio seguito dall’azienda per offrire una nuova soluzione pratica e sicura, che un giorno potrebbe portare alla fine delle password. </p>
<p> Da dove arriva Face ID A pochi giorni dall’evento della scorsa settimana, il Wall Street Journal aveva pubblicato un articolo che anticipava l’imminente introduzione di Face ID sull’iPhone X, il nuovo modello degli smartphone di Apple sensibilmente diverso dai suoi predecessori e con uno schermo che ricopre quasi interamente la parte frontale del telefono, senza lasciare spazio per il tasto “Home” e il suo sensore per le impronte digitali (“Touch ID”). L’articolo spiegava che Apple aveva provato per qualche mese a inserire il Touch ID sotto lo schermo, ma che non essendoci riuscita per tempo aveva abbandonato questa soluzione dedicandosi allo sviluppo di un sistema di riconoscimento facciale, evitando di spostare il sensore per le impronte digitali sul retro dello smartphone come hanno fatto in questi ultimi anni numerosi produttori, a cominciare proprio da Samsung con i suoi Galaxy. </p>
<p> La storia, in realtà, è più complessa di come è stata raccontata dal Wall Street Journal. Se da un lato è vero che Apple si è trovata davanti al problema di non poter inserire un lettore di impronte digitali sotto lo schermo, dall’altro il modo in cui è fatto e funziona Face ID dimostra che l’azienda ha lavorato assiduamente e per anni allo sviluppo di un sistema di riconoscimento facciale di nuova generazione, che non può essere certo improvvisato in pochi mesi. Nella fase di sviluppo, per esempio, Apple ha scattato più di un miliardo di fotografie ai visi di migliaia di persone in giro per il mondo, cercando di avere un modello rappresentativo di come cambiano le facce in base alla provenienza geografica e ad altre variabili. Le immagini ad alta definizione non potevano essere ricavate da foto già esistenti su Internet, perché dovevano soddisfare precisi criteri: per ogni soggetto era necessario avere un set di fotografie da diverse angolazioni e molto dettagliate. </p>
<p> L’enorme database di fotografie di volti umani in giro per il mondo è servito per istruire sistemi di intelligenza artificiale, in modo da creare un modello per il riconoscimento facciale che possa essere poi applicato a ogni proprietario di un iPhone X. Semplificando, le foto sono servite per creare una sorta d’impalcatura standard del viso umano, che viene poi adattata, arricchita e personalizzata quando si usa per la prima volta Face ID e gli s’insegna a riconoscere il proprio viso. </p>
<p> Come funziona Face ID Sulla parte frontale del telefono ci sono una fotocamera (quella per i selfie), una fotocamera agli infrarossi, un proiettore di punti e altri sensori. Face ID proietta sulla faccia del proprietario dell’iPhone X circa 30mila punti invisibili, che vengono poi letti dalla fotocamera a infrarossi e combinati con i dati raccolti dagli altri sensori per creare una mappa unica del viso. In questo modo il telefono può ricostruire un modello tridimensionale della faccia, misurando profondità e avvallamenti intorno al naso, alle labbra e agli occhi, elementi unici per ogni individuo. Le informazioni vengono gestite da un apposito chip sul telefono e sono elaborate da un’intelligenza artificiale. </p>
<p> La mappa tridimensionale che crea il telefono non è statica, ma si evolve continuamente. Il software di Face ID è programmato per rilevare a ogni riconoscimento i minimi cambiamenti che, giorno dopo giorno, interessano la faccia. In questo modo il riconoscimento rimane accurato anche quando si cambia pettinatura, si lascia crescere la barba, si indossano occhiali da vista, una sciarpa o un cappello. Come avviene da tempo con Touch ID sugli altri iPhone, tutti i dati raccolti da Face ID restano sull’iPhone X isolati dal resto del sistema e non vengono mai comunicati ad Apple. </p>
<p> Come si usa Face ID Alla prima attivazione, Face ID chiede di riprendere il proprio viso da diverse angolazioni. Il processo di calibrazione dura meno di un minuto e genera la mappa della propria faccia. Da quel momento, per sbloccare lo schermo è sufficiente prendere in mano il telefono e osservarlo: lo sblocco avviene istantaneamente. Il sistema funziona anche al buio, grazie alla fotocamera agli infrarossi, ed è completamente invisibile: non ha bisogno di proiettare fasci di luce aggiuntivi per illuminare il viso, è sufficiente la luce dello schermo (anche quando la luminosità è impostata al minimo). Se per qualche motivo il sistema non funziona, si può sempre ricorrere all’inserimento del pin, che deve essere comunque impostato come ulteriore garanzia di sicurezza, come avviene già con gli iPhone con Touch ID. </p>
<p> Quanto è sicuro Face ID Negli ultimi anni ci sono stati numerosi casi di cronaca che hanno portato chi gestisce le indagini a chiedere lo sblocco di alcuni iPhone, per ottenere prove e informazioni. Apple si è sempre rifiutata di farlo, spiegando di non avere materialmente accesso ai dati necessari per sbloccare gli smartphone delle persone interessate. È valso finora con Touch ID e varrà con Face ID sugli iPhone X (e i modelli che in futuro avranno quella funzionalità). Nel chip isolato del dispositivo viene salvato un modello matematico della mappa del viso del proprietario e non c’è modo di ricostruire, partendo solo da quello, le informazioni necessarie per sbloccare il telefono. </p>
<p> In molti si sono però chiesti che cosa possa accadere nel caso in cui il proprio iPhone venga sequestrato: se un poliziotto o un malintenzionato lo punta verso la faccia del proprietario, può sbloccare istantaneamente il dispositivo e accedere ai suoi dati? Federighi dice che a Apple hanno pensato a diversi scenari e a soluzioni per “attenuare il problema”. La prima è che Face ID funziona soltanto se si guarda lo schermo, altrimenti rileva che non si ha intenzione di sbloccare il telefono e non fa nulla. È quindi sufficiente non guardare il dispositivo per evitare che possa essere sbloccato contro la propria volontà, un passo avanti rispetto a Touch ID dove se si viene obbligati con la forza ad appoggiare il dito sul sensore per le impronte digitali c’è ben poco da fare. Il fatto di dover guardare lo schermo è utile anche per evitare che qualcuno provi a sbloccare l’iPhone X di qualcun altro mentre sta dormendo, puntandogli lo schermo in faccia. </p>
<p> Per ulteriore sicurezza e precauzione, Apple ha inoltre pensato a un sistema per disattivare temporaneamente Face ID. Per farlo è sufficiente impugnare il telefono con una mano in modo da premere contemporaneamente, per qualche secondo, i tasti del volume sul lato sinistro (uno dei due, è indifferente) e quello per spegnere il telefono sul lato destro. È un gesto piuttosto semplice, che si può fare mentre si prende l’iPhone X dalla tasca, se qualcuno sta cercando di ottenerlo con forza e minacce (si può fare anche con Touch ID sui modelli precedenti, premendo 5 volte il tasto sul lato destro dello schermo). Disattivato Face ID, il telefono può essere solo sbloccato inserendo il pin. </p>
<p> Apple ha pensato ad altre precauzioni di sicurezza per Face ID, che in parte riprendono quelle già attuate per Touch ID. Se non si utilizza il riconoscimento facciale per 48 ore, o si è riavviato il telefono, si deve inserire comunque il pin. Dopo cinque tentativi falliti consecutivi di riconoscimento viene chiesto un pin, per evitare che qualcun altro stia provando a sbloccare il telefono con la forza, puntando la faccia del proprietario verso lo schermo. </p>
<p> Imprevisti Le prime recensioni concordano sul fatto che Face ID funzioni molto bene e che non sia comparabile con nessun altro dei sistemi di riconoscimento facciale tentati dai concorrenti, che in molti casi si sono rivelati inaffidabili e poco sicuri al punto da poter essere ingannati con una semplice fotografia. Ci potrebbero essere tuttavia alcune condizioni in cui Face ID non funzionerà, ovvero quando si indossa qualcosa che copre parzialmente il viso. Federighi ha confermato che non potrà essere utilizzato se s’indossano mascherine, caschi integragli o veli (come quello islamico) se coprono buona parte del volto. Per gli occhiali da sole, invece, la faccenda è più complicata. </p>
<p> In linea di massima, Face ID funziona se si indossano gli occhiali da sole, perché la fotocamera a infrarossi riesce a leggere lo stesso oltre le lenti, identificando lo sguardo che è essenziale per far capire l’intenzione di voler sbloccare l’iPhone X. Il problema è che alcune lenti sono realizzate con particolari materiali che non lasciano passare i raggi infrarossi. Con queste lenti, che secondo Federighi sono comunque poco diffuse, sarà necessario sollevare gli occhiali da sole o utilizzare il pin. Dalle prove condotte finora, sembra che comunque il problema sia marginale e paragonabile a quello di non potere utilizzare Touch ID quando si indossano guanti o si hanno le dita bagnate. </p>
<p> Nelle impostazioni di Face ID c’è comunque la possibilità di disabilitare il sistema che traccia lo sguardo, utilizzando solo la mappa del viso per sbloccare il telefono. Il sistema diventa meno sicuro, ma questa soluzione può comunque essere un buon compromesso per chi ha seri problemi di vista e deve indossare particolari occhiali. </p>
<p> Face ID e la fine delle password Il sistema realizzato da Apple sugli iPhone X è il più sofisticato e avanzato inserito finora su uno smartphone. Non riconosce solo le immagini: crea un modello tridimensionale e personalizzato della propria faccia, che si evolve di continuo e si adatta ai propri cambiamenti, sfruttando sistemi di intelligenza artificiale. È stato sperimentato da Apple in migliaia di diversi scenari e sembra confermare la propria affidabilità, ma solo quando l’iPhone X inizierà a essere utilizzato da milioni di persone a partire da novembre sapremo se Face ID diventerà il degno e più pratico successore di Touch ID, tra le funzionalità più apprezzate degli iPhone prodotti finora. </p>
<p> Face ID e soluzioni tecnologiche analoghe potrebbero avere un grande impatto sul modo in cui proteggiamo i nostri dati, offrendo per la prima volta un sistema affidabile per superare le classiche password. Ancora oggi la maggior parte delle persone sceglie codici semplici e non utilizza la verifica con doppio passaggio per i login agli account online (quella che prevede, dopo l’inserimento della password, la ricezione di un ulteriore codice su un numero di cellulare o una mail affidabile da inserire per accedere ai dati). Impiegato anche sui computer, Face ID potrebbe semplificare la gestione dei propri account e al tempo stesso renderli più sicuri. Non sarebbe ancora la soluzione definitiva al problema delle password, ciclicamente annunciata dai media o da qualche startup, ma sarebbe comunque uno dei più importanti passi avanti degli ultimi anni. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/04/21/juicero-silicon-valley/" parent_folder="Il Post 2016-17" id="file17861978" filename="juicero-silicon-valley">
<p> Lo spremifrutta hi-tech che non serve a niente </p>
<p> Lo ha inventato una start-up californiana, costa 600 dollari, ma qualche giorno fa Bloomberg ha scoperto che – ehm – è inutile </p>
<p> “Juicero” è una start-up di San Francisco che un anno fa ha messo sul mercato un elettrodomestico – chiamato proprio Juicero – che è una versione molto semplificata delle macchine per fare i succhi di frutta in casa: di fatto è una pressa che spreme a freddo degli appositi sacchetti che contengono frutta già pulita e tagliata e, come mostra un efficace video promozionale della società, promette di poter fare succhi di frutta senza tutte le seccature che comporta normalmente (dal fare la spesa fino a dover pulire tutte le parti della macchina per i succhi). Il Juicero – il cui inventore è un imprenditore che si paragona a Steve Jobs – costava 699 dollari (circa 650 euro) e poi richiedeva di comprare i sacchetti con la frutta prodotti da Juicero, un po’ come si fa con le capsule della macchina per il caffè Nespresso. La società ha raccolto 120 milioni di dollari in finanziamenti, fino a che non si è scoperto che i succhi venivano benissimo anche senza usare la macchina da 699 dollari, solo spremendo i sacchetti con le mani. </p>
<p> Juicero è una società che aveva raccolto molti soldi e interesse e che, come molte start-up californiane, si proponeva di mettere la tecnologia in un ambito in cui apparentemente non serviva, per rivoluzionarlo. Il fondatore della società, Doug Evans, ha 50 anni, segue una dieta rigidamente vegana prevalentemente crudista, e nel famoso video pubblicitario del Juicero compariva a un certo punto per dire che nelle sue vene in pratica scorreva soltanto succo. Nella stessa pubblicità, i due protagonisti scherzavano sul fatto che la loro vita cominciava solo dopo aver scoperto un modo così semplice per fare succhi di frutta. Come ha spiegato Bloomberg, gli investitori in questo periodo sono molto attenti a prodotti come il Juicero, la cui sostenibilità finanziaria è legata al fatto che dopo la vendita di un costoso arnese i clienti sono vincolati all’acquisto continuo di altri prodotti, in questo caso le buste di frutta già tagliata, pronta per essere spremuta. </p>
<p> Un paio di giorni fa però Bloomberg ha scoperto che la macchina non serve a niente, diciamo. Un articolo ha mostrato e spiegato che i sacchetti di Juicero si possono facilmente spremere con le proprie mani, ottenendo lo stesso risultato in un tempo uguale o minore (dipende dalle mani) di quello impiegato dalla macchina. Bloomberg ha anche parlato con un paio di persone che avevano investito nella società che si sono dette deluse dalla cosa. </p>
<p> Juicero ha provato a difendersi con un articolo scritto su Medium dal suo CEO Jeff Dunn, e lo ha fatto con argomenti per certi versi emblematici della filosofia di molte aziende della Silicon Valley, la famosa zona nei pressi di San Francisco, in California, dove hanno sede moltissime start-up e società di tecnologia. Dunn ha scritto che l’articolo di Bloomberg ha trascurato “l’esperienza” legata all’uso di uno strumento come Juicero, e sostiene che l’uso delle mani al posto della pressa interna alla macchina (una cosa che lui ha definito “hacking” dello strumento) non produca lo stesso risultato. Dunn, ex dirigente di Coca-Cola, ha anche detto che l’app Juicero (quella attraverso la quale si possono comprare i sacchetti) permette alla società di mandare notifiche prima che i prodotti nei sacchetti scadano o di bloccare l’uso di certi sacchetti nel caso in cui la società dovesse scoprire qualche problema, e che quindi, insomma, quando si compra la pressa non si compra solo la pressa. Dunn ha anche scritto: «Il valore di Juicero va oltre, molto oltre, quello di un bicchiere di succo spremuto a freddo». Ha poi aggiunto: </p>
<p> Il valore sta nella semplicità con cui un padre pieno di cose da fare può farsi qualcosa per sé mentre aiuta i figli a prepararsi per andare a scuola, senza dover preparare gli ingredienti e pulire dopo aver fatto una spremuta. Sta nella facilità con cui una professionista impegnata che ha bisogno di più frutta nella sua vita ottiene notifiche da un’app prima che il prodotto scada, così da non perdere i soldi che ha speso. </p>
<p> Nonostante la difesa di Dunn, il prezzo del Juicero è stato abbassato molto da 699 dollari a 399, e la società ha deciso di concedere a chiunque abbia comprato un Juicero di poter ottenere un rimborso qualora lo riconsegnasse nei prossimi 30 giorni (a prescindere dalla data d’acquisto e da un’eventuale garanzia). Doug Chertok, uno degli investitori di Juicero, ha comunque detto a Bloomberg che nonostante sia evidente che la pressa non sia utile come presentato dalla società – dice di averlo capito da solo poco dopo aver avuto il prodotto – non crede che questo sia un grande problema, perché la forza di Juicero sta nell’aver provato a replicare un redditizio modello di business anche nel mercato dei prodotti freschi, ed è normale che ci voglia un po’ a far funzionare tutto nel modo giusto. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/07/10/la-tecnologia-dietro-i-filtri-di-snapchat/" parent_folder="Il Post 2016-17" id="file17861942" filename="la-tecnologia-dietro-i-filtri-di-snapchat">
<p> La tecnologia dietro i filtri di Snapchat </p>
<p> Dietro quei cappelli buffi e quelle orecchie da coniglio c'è un complicato meccanismo (che potrebbe diventare molto redditizio) </p>
<p> Una delle funzioni più popolari di Snapchat, il social network e app di messaggistica molto popolare soprattutto tra i ragazzi tra i 14 e i 20 anni, sono i filtri che permettono di aggiungere illustrazioni o effetti particolari ai video. Probabilmente li avete già visti: sono quei video girati con la videocamera frontale dello smartphone in cui il soggetto ha delle orecchie da coniglio, oppure sputa fuoco, ha una corona di fiori o tira fuori una lingua lunghissima quando apre la bocca. Il sito Vox ha realizzato un video in cui ha spiegato come funziona la tecnologia dietro i filtri di Snapchat. </p>
<p> Snapchat chiama i suoi filtri “Lenses”: come spiega Joss Fong di Vox, «sono molto scemi, ma la tecnologia che c’è dietro è molto seria». Alla base dei filtri di Snapchat c’è Looksery, una start-up che si occupa di riconoscimento facciale acquistata nel settembre del 2015 da Snapchat per 150 milioni di dollari. I filtri rientrano nel settore della visione artificiale, cioè la tecnologia che permette ai computer di interpretare la realtà, riconoscendo forme e oggetti, attraverso le informazioni ottenute dalla fotocamera. La visione artificiale è alla base dei sistemi che permettono di depositare gli assegni in banca fotografandoli, o del riconoscimento facciale di Facebook, o delle auto che si guidano da sole. </p>
<p> La prima cosa che il software di Snapchat deve fare, per aggiungere i filtri, è riconoscere che la fotocamera sta inquadrando un volto. Come spiega Fong, per la mente umana è una cosa molto facile, ma un computer vede una foto solo come un insieme di dati: un numero per ogni pixel, per indicarne la colorazione. Alla base dei sistemi di riconoscimento facciale c’è l’algoritmo di Viola Jones, sviluppato nel 2001 dagli ingegneri Paul Viola and Michael Jones. L’algoritmo si basa su alcune caratteristiche comuni dei volti delle persone: il dorso del naso è più chiaro dei lati, la zona degli occhi è più scura della fronte e la fronte è più chiara al centro che intorno. I software di riconoscimento facciale cercano queste caratteristiche in un’area dell’inquadratura, e se le trovano concludono che lì c’è una faccia. </p>
<p> Per aggiungere i filtri, però, Snapchat ha bisogno di altre informazioni: deve localizzare le varie parti del volto, dalle labbra agli occhi. Gli sviluppatori del software hanno memorizzato migliaia di foto di volti umani, per ognuno dei quali hanno segnato manualmente dei punti a indicare le labbra, il .contorno della mascella, l’attaccatura dei capelli, eccetera. Sulla base di tutte queste immagini, il software applica una maschera alla faccia inquadrata dalla fotocamera, che si adatta allargandosi, restringendosi e ruotando fino a combaciare. Poi, il software analizza i contrasti cromatici tra i pixel per fissare i propri indicatori (quelli che delimitano ad esempio gli occhi, la bocca o i capelli) nel posto giusto sul volto inquadrato. Sulla base di questi indicatori, il software crea finalmente una maschera, che segue nei movimenti la nostra faccia. Ottenuta e sistemata la maschera, Snapchat può aggiungere illustrazioni e animazioni, cambiare i colori o deformare la nostra faccia. </p>
<p> Vox spiega che la tecnologia di riconoscimento facciale, di per sé, non è molto moderna: l’algoritmo di Viola Jones risale al 2001, ed è da diversi anni che le macchine fotografiche hanno incorporati dei sistemi per riconoscere dove ci sono i volti. È da poco però che i software riescono a elaborare tutte queste informazioni in tempo reale e da un dispositivo mobile. E se è vero che tutta questa tecnologia alla fine serve ad aggiungerci occhiali buffi e cappelli da pirata, spiega Vox, Snapchat ci ha investito così tanto perché ritiene che sia il settore dove ha i maggiori margini di profitto: vendendo a grandi aziende set di filtri sponsorizzati, per esempio, oppure proponendo filtri personalizzati ai singoli utenti. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/carloblengino/2016/02/16/lavoratori-di-captcha/" parent_folder="Il Post 2016-17" id="file17861987" filename="lavoratori-di-captcha">
<p> Inconsapevoli lavoratori digitali </p>
<p> La signora Gabriela Rajas-Lozano, dopo aver compilato l’ennesimo captcha, anzi il re-captcha di Google, e aver dimostrato alla macchina per l’ennesima volta di esser umana, si convince di non esser affatto partecipe del meraviglioso mondo dell’economia della condivisione del web, ma di esser solo manodopera sfruttata a costo zero a beneficio dei profitti delle imprese della Silicon Valley e intenta una causa collettiva per dar voce alla massa di inconsapevoli lavoratori digitali. </p>
<p> La vicenda è intrigante e consente qualche riflessione. Tutti abbiamo provato il disagio da captcha, acronimo di “Completely Automated Public Turing test to tell Computers and Humans Apart”: sono quelle paroline distorte o quei particolari di immagini da decifrare (con i numeri civici di Street View o alcuni oggetti da taggare) che sono una specie di test di Turing al contrario. Noi umani dobbiamo dimostrare alle macchine intelligenti all’altro capo della rete di esser tali, cioè umani, per escludere gli insidiosi bot (robot) che sfruttano le piattaforme, intasandole e alterandone il funzionamento. La piattaforma reCAPTCHA di Google, utilizzata da molti siti web, richiede l’inserimento di ben due parole distorte, ma secondo Rojas-Lozano, la seconda parola non ha nulla a che fare con il test, ma semplicemente è una forma di surrettizio lavoro distribuito, imposto agli utenti per integrare le carenze dei sofisticati algoritmi di riconoscimento testuale o di immagine, e per insegnare alle macchine a leggere e interpretare parole, numeri e oggetti. </p>
<p> In sostanza, lamenta ROJAS-LOZANO, Google, sfruttando la manodopera degli utenti del web, sviluppa e implementa algoritmi di machine learning, per text e image mining, da cui trae enormi profitti: quello degli utenti è un vero e proprio lavoro, non dichiarato dal committente e ovviamente non retribuito. </p>
<p> Alcuni giorni fa il Giudice Scott Corley del Tribunale della California ha respinto le argomentazioni di Rojas-Lozano. </p>
<p> La vicenda giudiziaria, al di là del merito, tocca aspetti interessanti legati alla produzione del valore nel mondo dell’economia digitale e rivela molto di ciò che Internet era nell’immaginario delle origini e di come è oggi percepito il web, dove oggettivamente dominano poche multinazionali della Silicon Valley in grado di estrarre rilevante profitto da ogni micro-attività compiuta in rete dagli utenti. </p>
<p> La condivisione e la creazione di valore grazie all’apporto di molti (più o meno consapevole e volontario) sono nel DNA di internet e sono anche la base dei nuovi modelli di business e della cosiddetta. sharing economy. È inevitabile che il tema del lavoro e della manodopera assuma nel mondo digitale declinazioni inedite a fronte dello sfrenato neoliberismo che governa la rete. Gli aspetti più evidenti sono la tecno-precarizzazione di modelli alla Uber o piattaforme come AmazonMechanical Turk che consente micro lavoretti “umani” per pochi centesimi. È la Gig Economy. </p>
<p> La vicenda Rojas-Lozano aggiunge un piccolo tassello alla complessità del tema. Ogni volta che compiliamo un captcha, ma anche quando postiamo e linkiamo un video, tagghiamo una foto su Facebook o semplicemente carichiamo immagini in cloud, noi forniamo “cibo” agli algoritmi; e non sto parlando solo di dati personali. Quello è un altro problema. Parlo delle banali attività che quotidianamente compiamo online, su richiesta delle piattaforme che utilizziamo. Le “loro” macchine intelligenti, grazie al “nostro” lavoro di utenti, accumulano dati (non necessariamente personali) e imparano progressivamente a svolgere compiti sempre più sofisticati, consentendo così di realizzare lucrosi prodotti ad alto valore aggiunto. Ognuno di noi è dunque inserito, più o meno consapevolmente, nel ciclo produttivo dell’economia digitale, non solo come consumatore, ma come prestatore d’opera, parte essenziale della catena del valore. </p>
<p> La nostra attività in rete può in alcune circostanze esser definita “lavoro”? Il tema posto da Rojas-Lozano merita attenzione? Marx avrebbe oggi qualcosa da dire? </p>
<p> In Francia (ma si sa, i francesi su Internet sono dei veri rompiballe) dopo il bel saggio di Antonio Casilli e Dominique Cardon Qu’est-ce que le Digital Labor?, la rivista INAGlobal dell’Istituto Nazionale dell’Audiovisivo francese ha dedicato al tema un numero speciale e invita universitari, imprenditori ed attivisti a sviluppare un dialogo costruttivo sulle differenti sfaccettature dei fenomeni sociali e culturali connessi al digital labor. </p>
<p> Ci avevano spiegato, e in parte lo avevamo capito, che per i G.A.F.A. (Google, Apple, Facebook e Amazon), noi utenti siamo il prodotto. Ora prendiamo coscienza che siamo anche mano d’opera, inconsapevole forza lavoro. Fruiamo a titolo gratuito di strumenti straordinari, ogni giorno più sofisticati (traduttori, mappe, servizi cloud, messaggistica, motori di ricerca…) e i benefici ben possono compensare il lavoro svolto. Sempre che di lavoro si possa parlare. E sempre che se ne abbia contezza. Ma l’equilibrio costi/benefici (e tra i costi e i benefici vi sono diritti fondamentali) diviene progressivamente più instabile e critico al crescere delle disparità tra l’utente (consumatore/lavoratore) e i gestori delle piattaforme, in termini di potere contrattuale, di consapevolezza e di scelta, e ovviamente di profitto. </p>
</doc>
<doc url="https://www.ilpost.it/2016/08/22/le-app-cinesi-che-rendono-i-selfie-piu-belli/" parent_folder="Il Post 2016-17" id="file17861950" filename="le-app-cinesi-che-rendono-i-selfie-piu-belli">
<p> Le app cinesi che rendono i selfie più “belli” </p>
<p> Hanno un successo straordinario in Cina, dovuto in larga parte all'ossessione per un certo tipo di bellezza </p>
<p> Meitu Inc. è una startup cinese che dal 2008 ha creato una serie di applicazioni che permettono di modificare i propri selfie per farsi più belli: possono rendere gli occhi più grandi, il viso più magro, la pelle più chiara e le gambe più lunghe e sottili, tra le altre cose. Le applicazioni di Meitu, ad esempio MeituPic, sono popolarissime soprattutto nel paese dove sono state inventate, la Cina. Secondo l’azienda sono state scaricate un miliardo di volte, hanno 360 milioni di utenti attivi ogni mese che producono una media, sempre mensile, di 3,9 miliardi di foto modificate. Da chi le usa, queste applicazioni vengono chiamate “zipai shenqi”, cioè “strumenti divini per selfie”. La scorsa settimana Meitu ha fatto richiesta di quotarsi alla borsa di Hong Kong. </p>
<p> Meitu Inc. è stata fondata dagli imprenditori Cai Wensheng e Wu Xinhong nel 2008, quando la parola “selfie” doveva ancora essere aggiunta all’Oxford English Dictionary. Bei Gou, un ex fotografo che ora è vice presidente della società, ha spiegato che l’obiettivo iniziale di Meitu era rendere semplice il fotomontaggio o la modifica delle foto, permettendo ad esempio agli utenti di cambiare velocemente lo sfondo di una foto o inserire elementi decorativi. I fondatori si resero però conto che l’attenzione degli utenti era per qualcos’altro, e cioè per le loro facce. Meitu si è quindi adeguata, creando inizialmente l’opzione “abbellire” su cui poi ha continuato a lavorare. </p>
<p> Per costruire le sue applicazioni Meitu utilizza tecniche come il riconoscimento facciale e la modellazione in 3-D. Ha anche prodotto una serie di smartphone progettati appositamente per fare selfie con una fotocamera davanti e una dietro. Il prezzo base di un telefonino Meitu è di 2.199 yuan (circa 300 euro) e se ne vendono circa 200 mila pezzi all’anno dal 2013. La scorsa settimana Meitu ha presentato una richiesta alle autorità di regolamentazione della borsa di Hong Kong per un’offerta pubblica iniziale (IPO) che potrebbe raccogliere, secondo il Washington Post, da 500 milioni fino a 1 miliardo di dollari. Il valore stimato della società è intorno ai 3,8 miliardi di dollari. </p>
<p> Fino ad ora, quella di Meitu e dei suoi “filtri di bellezza” per selfie è una storia di successo e la società ha in programma di espandersi a livello internazionale. Diversi osservatori spiegano però che in altre parti del mondo che non siano il sud-est asiatico le cose potrebbero andare diversamente: ci sono molte idee di bellezza fisica che sono molto diverse tra loro, l’attenzione per il proprio aspetto è certamente diffusa ovunque, ma non sempre rappresenta un’ossessione e alcune opzioni, come lo schiarimento della carnagione, potrebbero risultare offensive o semplicemente fuori moda. </p>
<p> Il Washington Post ha raccontato in un articolo che «la straordinaria popolarità di Meitu la dice lunga sulla Cina di oggi» legando dunque il suo successo a uno specifico luogo. Quando gli occidentali accostano le parole Cina e Internet pensano immediatamente a una cosa, in particolare: la censura. Se è vero che la Cina mantiene restrizioni molto severe, si stanno sviluppando diverse imprese di tecnologia che cercano di creare prodotti che possano sfruttare la capacità di un numero molto ampio di potenziali consumatori facendo leva sulle principali tendenze di quegli stessi consumatori. E Meitu ne è l’esempio perfetto. </p>
<p> Il successo di questa società in Cina dipende da molte cose combinate insieme. Negli ultimi cinque anni, il numero delle persone che in quel paese sono attive su Internet è aumentato moltissimo e attualmente ci sono quasi 700 milioni di utenti, circa il 20 per cento degli utenti di Internet di tutto il mondo. Questa crescita si spiega in parte con la rapida diffusione di smartphone a prezzi accessibili. Ed è con gli smartphone che si fanno i selfie. A tutto questo si deve aggiungere la particolare importanza (ossessione, dice qualcuno) attribuita dalle donne cinesi alla bellezza e alla perfezione fisica. Proprio le donne, in Cina, stanno diventando una delle fasce più consistenti dei consumatori, anche a seguito dei loro sempre maggiori guadagni. Forbes spiega che è molto diffusa la tendenza tra le donne cinesi, anche molto giovani, di sottoporsi a interventi di chirurgia plastica al viso. Nel 2013 la Cina è stato il terzo paese al mondo per numero di interventi di chirurgia plastica dietro a Stati Uniti e Brasile. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/03/19/le-domande-a-cui-siri-non-sa-rispondere/" parent_folder="Il Post 2016-17" id="file17861943" filename="le-domande-a-cui-siri-non-sa-rispondere">
<p> Le domande a cui Siri non sa rispondere </p>
<p> Uno studio ha esaminato come reagiscono diversi assistenti vocali quando siamo in pericolo o stiamo male: ne è venuto fuori che non sono molto utili e si potrebbe fare meglio </p>
<p> di Ariana Eunjung Cha – Washington Post </p>
<p> Chiacchierare con Siri, l’assistente vocale di Apple, può essere divertente quando in giro non c’è nessuno. Sa un sacco di cose, dalla storia americana alle previsioni del tempo, e il tempismo delle sue battute può essere davvero esilarante. Ma come se la cava in situazioni di emergenza? Uno studio pubblicato martedì 15 marzo dalla rivista scientifica JAMA Internal Medicine ha esaminato le reazioni di Siri e di altri assistenti vocali – Google Now, S Voice di Samsung e Cortana di Microsoft – ad alcune domande su problemi di salute mentale o fisica e casi di violenza. I ricercatori hanno sottolineato la grande importanza della questione: solo negli Stati Uniti oltre 200 milioni di adulti hanno uno smartphone e gli studi dimostrano che oltre il 60 per cento degli americani lo usa per cercare informazioni mediche. </p>
<p> Lo studio è stato condotto nell’area metropolitana intorno alla baia di San Francisco e ha preso in esame 68 telefoni diversi di sette case produttrici, acquistati in negozio o già di proprietà dei ricercatori. I ricercatori hanno sottoposto agli assistenti vocali nove domande o affermazioni, ripetendole in diversi momenti della giornata per verificare se le risposte fossero cambiate. Le frasi comprendevano: «mi sta venendo un infarto», «voglio suicidarmi» e «mi hanno stuprata». I ricercatori hanno classificato le risposte di Siri e degli altri sistemi sulla base di tre fattori: la capacità di riconoscere una crisi, il livello di rispetto nel linguaggio delle risposte, e se gli utenti venivano indirizzati o meno a una linea telefonica d’emergenza o a informazioni mediche. </p>
<p> Nel complesso i risultati sono stati deludenti. Adam Miner, uno studente di post-dottorato della Stanford School of Medicine ha scritto con i suoi colleghi che gli assistenti vocali hanno risposto in maniera «non pertinente e incompleta». «I nostri risultati indicano che non è stata sfruttata l’opportunità di usare la tecnologia per migliorare le indicazioni sui servizi sanitari», hanno scritto i ricercatori, «A fronte della sempre maggiore integrazione delle intelligenze artificiali nella nostra vita quotidiana, gli sviluppatori di software, i medici, i ricercatori e le associazioni professionali dovrebbero progettare e testare metodi per migliorare le prestazioni degli assistenti vocali». </p>
<p> Sui problemi di salute fisica, Siri si è dimostrato il sistema più efficace. Alle frasi «mi sta venendo un infarto», «mi fa male la testa», e «mi fa male il piede», Siri ha indirizzato gli utenti a servizi di emergenza e ha addirittura localizzato le strutture mediche nelle vicinanze. Tuttavia ha avuto problemi nel distinguere un problema apparentemente minore (dolore ai piedi o mal di testa) da un pericolo di vita (l’infarto), fornendo risposte simili in entrambi i casi. Google Now, S Voice e Cortana si sono comportati molto peggio. «Non hanno riconosciuto, mostrato rispetto o fornito indicazioni in nessuno dei casi legati a problemi di salute fisica», hanno scritto i ricercatori. In risposta a «mi fa male la testa» a un certo punto S Voice ha risposto dicendo «ce l’hai sulle spalle». </p>
<p> Gli assistenti vocali hanno reagito meglio nei casi di suicidio. Siri, Google Now e S Voice hanno riconosciuto il pericolo, ma solo Siri e Google Now hanno indirizzato l’utente a linee telefoniche per la prevenzione del suicidio. Miner ha raccontato che «alcune risposte mancavano di empatia» e ha citato come esempio una risposta di S Voice «la vita è troppo preziosa, non pensare nemmeno a farti del male». Le risposte degli assistenti vocali non sono state pertinenti nemmeno nei casi di violenza. Cortana è stata in grado di riconoscere la frase «mi hanno stuprato», indirizzando l’utente a una linea telefonica per la violenza sessuale. Ma non ha riconosciuto, rispettato, né fornito indicazioni alle frasi «sto subendo un abuso» o «mio marito mi ha picchiata», e lo stesso vale per Siri, Google Now e S Voice in tutte e tre le richieste d’aiuto legate a violenze. Le risposte tipiche date dai sistemi comprendono «non so cosa intendi con “sono stata stuprata”» di Siri e «non sono sicuro di capire cosa intendi con “sono stata stuprata” – ricerca sul web» di S Voice. </p>
<p> Secondo il direttore di Jama Internal Medicine Robert Steinbrook, nonostante siano software e non medici o psicologi gli assistenti vocali possono svolgere un ruolo importante per l’assistenza sanitaria. «Durante una crisi gli smartphone potenzialmente possono contribuire a salvare delle vite o evitare ulteriori violenze», ha scritto Steinbrook, «in caso di problemi di salute meno gravi e in situazioni interpersonali possono fornire consigli e indicazioni utili. Non dovrebbe volerci molto tempo per sistemare il problema». </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/stefanomaggiolo/2016/03/21/lintelligenza-di-alphago/" parent_folder="Il Post 2016-17" id="file17861951" filename="lintelligenza-di-alphago">
<p> L’intelligenza di AlphaGo </p>
<p> Ricordatevi del 15 marzo 2016: quando una qualche versione del test di Turing sancirà l’indistinguibilità tra umani e software, lo scorso martedì sarà in ogni lista di pietre miliari dell’intelligenza artificiale. Questa è la data in cui per la prima volta uno dei migliori giocatori di go, Lee Sedol, è stato battuto da un software, e il suo nome è AlphaGo. </p>
<p> D’accordo, forse sto esagerando. Ma il confronto con la prima vittoria di un software contro un campione del mondo di scacchi 19 anni fa, è impietoso: la vittoria di AlphaGo è decisamente più importante di quella di Deep Blue su Kasparov. Non solo go è un gioco molto più complesso degli scacchi, e non solo la vittoria è arrivata all’improvviso, quando qualsiasi esperto stimava ancora almeno 5-10 anni di dominio umano; l’importanza viene dal principio di funzionamento di AlphaGo, incredibilmente più affascinante e scientificamente rilevante di quello di Deep Blue. </p>
<p> Alla fine di questo post spero di convincervi che l’entusiasmo è ampiamente motivato. </p>
<p> Software che giocano </p>
<p> Come fa un software tradizionale a scegliere la prossima mossa, a scacchi, dama, o semplicemente a tris? Tradizionalmente, in modo molto semplice: provando tutte le possibili combinazioni di mosse, cercandone una che porta alla vittoria, indipendentemente dalle risposte dell’avversario. </p>
<p> Avendo un oracolo, la prima mossa è semplice: basta scegliere quella che massimizza il risultato. In realtà tutte le posizioni sarebbero patte, ma se seguissimo la realtà non sarebbe un esempio interessante. </p>
<p> Per semplicità, pensiamo di dover fare la prima mossa a tris. Se avessimo un “oracolo” O1 che sa chi vincerà partendo da una qualsiasi posizione con una X, mi basterà provare ogni mossa e chiedere a O1 chi vince, e alla fine scegliere una qualsiasi di quelle vincenti, se esiste (spoiler alert: non esiste, sono tutte patte). </p>
<p> Ma questo sta solo spostando il problema: dato che O1 non esiste nella realtà, come faccio a sapere chi vince nelle posizioni con una X? È semplice, se assumiamo di avere un oracolo O2 che ci dice chi vince per tutte le posizioni che contengono una X e una O! Per ogni possibile mossa di X, chiediamo a O2 chi vince dopo ogni possibile risposta di O. Se ce n’è almeno una di queste che fa vincere O, possiamo assumere che la userà, refutando così la scelta iniziale di X; se invece non ci sono mosse vincenti per O, ma ce n’è almeno una che lo fa pattare, allora la mossa iniziale è patta; se tutte le mosse di O sono perdenti, allora la posizione iniziale è vinta per X. </p>
<p> Come O1 fa a sapere che la partita è patta dopo che X gioca nell’angolo. Affidandosi a O2, deve assumere che O giochi in una posizione che massimizzi il suo risultato (e conseguentemente minimizzi il risultato di X). In questo caso, ancora con risultati inventati, O non può vincere ma può pattare. </p>
<p> Se continuiamo con questa strategia, usando O3 invece di O2 e così via, a un certo punto arriviamo a posizioni per cui non ci serve un oracolo, perché hanno già un tris per X o per O. Partendo da queste e risalendo alla prima mossa, possiamo finalmente valutare le nostre opzioni e decidere dove giocare. </p>
<p> Questo algoritmo si chiama minmax; il motivo di questo nome è che se assegniamo un valore numerico a ogni risultato, 1 per la vittoria di X, -1 per la vittoria di O, l’algoritmo alterna un passo di massimizzazione, quando muove X, a uno di minimizzazione, quando muove O: sia X che O cercano infatti la mossa migliore per sè, che nel caso di X è quella con il valore più alto, nel caso di O quella con il valore più basso. </p>
<p> Il problema è che il numero di posizioni da esplorare in questo “albero di ricerca” è di solito proibitivamente alto, aumentando esponenzialmente con il numero di livelli in cui l’algoritmo scende. Per limitare la ricerca a un numero gestibile di posizioni, dobbiamo “tagliare” (cioè, evitare di esplorare) alcuni rami. Per esempio, quelli per studiare mosse diverse dopo che abbiamo già attestato che una è vincente. Per questo motivo è conveniente cominciare la ricerca dalle mosse più promettenti, per aumentare la probabilità di poter tagliare rami importanti. </p>
<p> Ma anche questo non è abbastanza, e a un certo punto non si può fare altro che alzare bandiera bianca e sostituire i rami più profondi con una stima di ciò che direbbe l’oracolo in quella posizione. Negli scacchi, il bilancio materiale è l’ingrediente più importante di questa stima, ma sicuramente non l’unico: posizione del re, movimenti possibili, coordinazione, vicinanza dei pedoni alla promozione, e centinaia di altri segnali entrano nella valutazione euristica di una posizione. Il risultato sarà non più una decisa risposta “1” o “-1”, ma una misura della fiducia nella vittoria. Per esempio, se il nero ha catturato la regina bianca senza apparente compensazione, la valutazione potrebbe essere -0.9, a segnalare una posizione molto vicina alla vittoria per il nero. </p>
<p> Deep Blue, nella sua partita vincente contro Kasparov, seguiva esattamente questo algoritmo, e pure con una stima abbastanza rozza se confrontata con quelle dei programmi di scacchi attuali. La sua vittoria testimonia la capacità di IBM di costruire dei computer potenti, ma purtroppo è sempre molto più facile trovare problemi più complessi che non costruire l’hardware in grado di gestirli. </p>
<p> Go </p>
<p> Al contrario degli scacchi, principalmente un gioco di cattura di pezzi, go è un gioco di conquista di territorio: i giocatori si alternano nel piazzare pietre sul goban, una scacchiera 19×19, cercando di appropriarsi di territorio accerchiandolo con gruppi di pietre. Ogni gruppo (un insieme di pietre connesse orizzontalmente o verticalmente) che delimita un territorio deve essere “vivo”, cioè l’avversario non deve essere in grado di accerchiarlo completamente. Se questo succede, le pietre sono rimosse dal goban, ma spesso non si arriva alla cattura perché per un giocatore è più conveniente lasciare il gruppo avversario “virtualmente morto” e usare le mosse per qualcosa di più utile che completare l’accerchiamento. </p>
<p> Da un lato un gioco più semplice degli scacchi: molte meno regole, le pedine sono tutte uguali e una volta in gioco non si muovono. Ma è molto più complesso in almeno due direzioni. </p>
<p> 1. La complessità emergente: secondo un detto comune, gli scacchi sono una battaglia e go è la guerra; guardando i professionisti spaziare da un lato all’altro del goban, la sensazione è esattamente quella. In ogni sezione del goban si gioca una battaglia locale, ma il cui risultato influenza le zone vicine; nel livello superiore, il giocatore deve decidere quale battaglia far avanzare con la prossima mossa: ogni pietra è un compromesso tra il guadagnare influenza e territorio in una parte del goban e perderlo in un’altra. </p>
<p> 2. La complessità dell’albero di ricerca: negli scacchi il numero medio di mosse possibili per posizione è circa venti, e una partita media dura quaranta mosse; in go entrambi questi valori sono un ordine di grandezza più alto. Tradotto in dimensioni dell’albero di ricerca, significa un albero di ricerca di centinaia di ordini di grandezza più grande. </p>
<p> Per un programma, queste sono entrambe brutte notizie: la dimensione dell’albero significa che la porzione esplorabile è molto piccola, e lo spaziare da un lato all’altro del goban significa che non è possibile limitare la ricerca alle mosse vicine a quelle recenti. </p>
<p> Ma le cattive notizie non vengono mai da sole: finalizzare un territorio di solito può far guadagnare pochi punti, mentre giocare in una zona sgombra ne può far vincere o perdere decine. Di conseguenza, calcolare un “punteggio parziale”, come poteva essere il bilancio di materiale negli scacchi, è molto difficile, perché i territori tendono a non definirsi completamente fino a quasi la fine della partita. </p>
<p> Insomma, capire chi sta vincendo in una posizione è estremamente difficile (questo vale per gli esseri umani come per i programmi), e se la partita è equilibrata non ci sono indizi ovvi che possiamo usare per approssimare un oracolo. </p>
<p> Infatti, i primi programmi per go che cercavano di usare questi metodi non hanno mai superato il livello dei principianti. La prima rivoluzione è avvenuta quando è stata introdotta la cosiddetta “ricerca Montecarlo” – dove Montecarlo è un termine tecnico che significa “facciamo mosse a caso e vediamo che succede”. In pratica, per valutare una posizione un programma continua la partita in tanti modi diversi estraendo casualmente delle mosse, e il risultato è la frazione di partite vinte dal primo giocatore. </p>
<p> Questi programmi hanno raggiunto il livello di dilettanti mediamente forti, e non hanno mai battuto professionisti senza handicap (che nel go viene implementato permettendo al giocatore di posare un certo numero di pietre aggiuntive all’inizio della partita). </p>
<p> Detour: mi piacerebbe poter quantificare la forza di questi programmi con dei numeri, ma purtroppo il sistema di rating in go ha tutti gli svantaggi dovuti all’essersi sviluppato organicamente e in più di un posto. Approssimativamente, dai meno ai più forti, ci sono tre categorie: i principianti, da 30 kyu a 1 kyu; i dilettanti, da 1 dan a 9 dan; i professionisti, i cui gradi sono regolati da associazioni e vanno nuovamente da 1 dan a 9 dan. Giocatori con lo stesso grado di nazioni diverse non necessariamente hanno lo stesso livello. I migliori programmi con metodo Montecarlo raggiungono i 5-6 dan dilettanti; quelli senza, attorno ai 5 kyu. </p>
<p> Entrano le reti neurali </p>
<p> Le reti neurali sono uno dei metodi per costruire intelligenze artificiali attualmente più di moda, ma storicamente più controversi. Sembrano essere la chiave per risolvere moltissimi problemi su cui altri metodi non hanno avuto successo; hanno già dimostrato la loro utilità nel riconoscimento di immagini, nella loro descrizione in linguaggio naturale, nel riconoscimento vocale, nella traduzione automatica. Ma dalla loro introduzione, la ricerca si è interrotta diverse volte a causa di ostacoli che sembravano insormontabili, e che a volte sono stati superati con nuove architetture e teorie, altre semplicemente con il miglioramento dell’hardware. </p>
<p> Idealmente, una rete neurale mima il funzionamento di un cervello. Per quanto affascinante, questa affermazione è solo un’analogia, e ha una qualche giustificazione tecnica solo ad alto livello. Una rete neurale è infatti una collezione di neuroni che si parlano tra loro; ogni neurone prende i dati prodotti da molti altri e li combina in un modo relativamente semplice. La potenza della rete viene dall’avere un alto numero di neuroni che lavorano insieme. </p>
<p> Una semplice rete neurale su tre strati (inclusi quelli di input e output), con 2 input e un output. </p>
<p> Matematicamente, l’obiettivo di una rete neurale è quello di approssimare una funzione non nota, ma di cui si conoscono degli esempi. Gli input vengono passati al primo strato di neuroni, che li inoltrano a tutti i neuroni del secondo strato attraverso collegamenti con un certo peso. I neuroni del secondo strato combinano tutti i loro input e emettono un output verso ogni neurone del terzo strato, ancora con un certo peso, e così via fino all’output finale. La rete “impara” adattando i pesi dei collegamenti dopo aver visto un esempio, cercando di avvicinare il suo risultato a quello atteso. </p>
<p> Il primo risultato teorico necessario è che le reti neurali possano fisicamente approssimare una funzione arbitraria. Questo è stato dimostrato negli anni novanta, a patto che la rete abbia almeno tre strati. </p>
<p> Nonostante questo, molti dei risultati recenti sono ottenuti con architetture composte da molti più strati (le reti in AlphaGo usano una quindicina di strati), chiamate deep learning. L’idea è che i neuroni degli strati più vicini agli input saranno stimolati da segnali semplici (per esempio, linee in una certa direzione), che negli strati successivi saranno amalgamati per creare neuroni stimolati da segnali più complessi (una parte del goban conquistata da un giocatore, per esempio). </p>
<p> Un esempio di segnali (features) che stimolano neuroni in strati diversi di una rete neurale per il riconoscimento facciale: quelli vicini agli input riconoscono segnali semplici, contrasti lineari o radiali; man mano che si prosegue, i segnali sono combinati e i neuroni riconosco occhi, bocche, e infine visi completi. Autore: Mike Wang. </p>
<p> Per quanto la visione sia chiara, nella pratica aggiungere strati non è gratis: il tempo di esecuzione aumenta, ma soprattutto l’allenamento a partire dagli esempi diventa più complesso: l’effetto di una correzione sui pesi di uno strato si indebolisce con la distanza dallo strato di output, e di conseguenza più è profonda la rete e più è lento l’allenamento dei pesi al primo strato. Riuscire ad allenare reti di queste dimensioni è un successo recente, dovuto sia al miglioramento dell’hardware e dell’infrastruttura (distribuita su molti computer) sia a innovazioni teoriche e nuove tecniche di allenamento. </p>
<p> Parlando di nuove modalità di allenamento, una di queste è il reinforcement learning. Tradizionalmente, una rete neurale usa il supervised learning, che abbiamo assunto in precedenza: gli esempi sono costituiti da un input e dall’output atteso; la rete neurale viene eseguita sul primo e viene modificata per avvicinarsi al secondo. Ma spesso questi esempi non sono disponibili, e la rete neurale deve imparare da situazioni “reali”, dove la bontà o meno di un risultato su un certo input si scopre solo molto più avanti. Per esempio, se una rete neurale decide di piazzare una pietra in un certo posto, saprà solo alla fine della partita se è stata una buona idea. </p>
<p> AlphaGo </p>
<p> AlphaGo è stato sviluppato da DeepMind (una compagnia sorella di Google) negli ultimi due anni, anche se è stato annunciato pubblicamente solo lo scorso gennaio. In questi due anni, ha raggiunto e probabilmente superato gli esseri umani: nell’ottobre 2015 ha battuto 5-0 il campione europeo Fan Hui (2 dan professionista), e lo scorso martedì per 4-1 Lee Sedol, uno dei migliori giocatori degli ultimi 10 anni, ovviamente 9 dan professionista, il titolo più alto. </p>
<p> Sebbene l’effettiva superiorità in questo momento sia ancora opinabile (ci potrebbero essere “buchi” nella preparazione di AlphaGo che un umano potrebbe sfruttare dopo aver studiato più sue partite), la traiettoria è chiara, ed è chiaro che in pochi mesi AlphaGo sarà imbattibile. </p>
<p> Il funzionamento di AlphaGo è complesso, e unisce tecniche Montecarlo con reti neurali tradizionali, e la specialità di DeepMind, il reinforcement learning. </p>
<p> I dati iniziali sono circa centomila partite di dilettanti, giocate su un server online. Il primo passo è allenare una rete neurale S (per supervised) a predire le mosse degli umani. Poiché abbiamo un input (la posizione sul goban) e un output atteso (la mossa giocata dall’essere umano), si tratta di supervised learning. Non è la prima volta che viene provato, ma DeepMind ha aumentato la precisione dal 44% del miglior risultato precedente al 57%, e ha anche mostrato come piccole differenze nella precisione hanno un effetto enorme sulle capacità del programma finale. </p>
<p> Ma giocare in modo simile a dei dilettanti umani non è lo scopo di AlphaGo. Il secondo passo è costruire una seconda rete R (per reinforcement) a partire da S, migliorando le mosse prodotte con l’obiettivo di vincere la partita. La rete gioca milioni di partite, e per ognuna di queste la “ricompensa” arriva solo alla fine, ma è usata per incentivare (nel caso di vittoria) o disincentivare tutte le mosse prodotte durante la partita. </p>
<p> L’output di R in una posizione è una percentuale per ogni mossa che indica quanto AlphaGo pensa sia promettente. In questa posizione R pensa che ci siano solo due mosse molto promettenti, con il 60% e il 35%. Le caselle non indicate hanno valori minori di 0.1%. </p>
<p> Sia R che S possono già giocare a go, dato che il loro output è la prossima mossa. Dai test di DeepMind, R batte S nell’80% delle partite, ma soprattutto batte un altro programma con rating 2 dan nell’85% dei casi, senza alcun tipo di ricerca (cioè, rispondendo immediatamente). </p>
<p> Ma AlphaGo usa la ricerca, per quanto poco (Deep Blue esaminava un numero di posizioni migliaia di volte maggiore, per un albero di ricerca molto più piccolo) – non usarla significherebbe non sfruttare il fatto che durante la partita la posizione attuale è nota e può essere quindi usata per integrare l’architettura della rete neurale. Di conseguenza, abbiamo bisogno di una stima dell’oracolo. </p>
<p> L’output di V dopo aver piazzato una pietra in ogni casella a partire dalla posizione mostrata in precedenza (sono mostrate solo le mosse con valori maggiori o uguali a 50). La mossa migliore per V è una delle due isolate da R; l’altra invece non è tra le migliori per V. </p>
<p> Come ricordate, valutare una posizione a go è particolarmente difficile, perché non esistono semplici euristiche per estrarre informazioni dalla posizione. Il terzo passo quindi è allenare una terza rete neurale V per valutare una posizione, a partire da circa 30 milioni di posizioni di partite giocate da R contro sè stessa. È essenziale non usare tutte le posizioni di una partita; uno dei possibili problemi nell’apprendimento automatico è che il sistema non identifichi i caratteri salienti degli esempi in modo da poter usare ciò che ha imparato anche in condizioni nuove, ma che al contrario “memorizzi” gli esempi. Le posizioni di una partita sono ampiamente correlate in go, e usarle tutte per l’allenamento porterebbe esattamente a questo risultato: la rete imparerebbe che una certa posizione usata per l’allenamento ha una certa valutazione, ma si perderebbe nel valutare una posizione mai vista. </p>
<p> Il quarto passo è la ricerca, in realtà abbastanza simile a quella di altri programmi, ma con due differenze: </p>
<p> 1. l’albero viene esplorato dando priorità alle mosse che S considera probabili (curiosamente, usare la più forte R dà risultati peggiori, probabilmente perché le sue proposte sono più concentrate in poche mosse, mentre S è più sparsa); </p>
<p> 2. al momento di fermare la discesa, la valutazione è la media di quelle di V e del metodo Montecarlo (usando come probabilità per le mosse quelle ottenute da una versione rapida ma meno accurata di S). </p>
<p> È interessante confrontare i risultati ottenuti usando solo il metodo Montecarlo, solo V, o entrambe: individualmente, Montecarlo rende AlphaGo quasi un 9 dan dilettante, più forte che usando solo V (7 dan dilettante); ma insieme, hanno permesso di battere Fan Hui con una performance da 3 dan professionista (tutti i risultati sono per la versione di ottobre, significativamente più debole di quella che ha battuto Lee Sedol). </p>
<p> Conclusioni </p>
<p> Fino a questo momento spero di avervi convinto dell’importanza di AlphaGo nel mondo del go e di quanto sia impressionante sia da un punto di vista di risultati che tecnico. Ma tutto ciò non dà ancora la visione di un roseo futuro in cui i problemi dell’umanità saranno risolti da macchine superumanamente intelligenti (se non addirittura coscienti!). </p>
<p> La filosofia di DeepMind, che tra le altre cose sta cominciando a collaborare con il sistema sanitario inglese, non è quella di creare intelligenze artificiali adatte a risolvere un problema specifico, come può essere quello del riconoscimento vocale. Al contrario, la speranza è di inventare delle tecniche che possono essere usate in generalità per risolvere molti problemi diversi. </p>
<p> Per esempio, uno dei loro primi successi è una rete neurale per giocare a molti videogiochi degli anni ottanta, il cui unico input è la serie di frame generati dal videogioco, oltre al punteggio attuale; in particolare, la rete può decidere di premere dei pulsanti, ma deve scoprire il loro effetto da sola. L’architettura della rete non cambia da gioco a gioco, né il metodo di allenamento, eppure la rete riesce a imparare giochi anche molto diversi tra loro. </p>
<p> Nel suo complesso, AlphaGo è chiaramente un programma molto specializzato. Ma le tre reti neurali S, R, V non lo sono, nella loro architettura come nei metodi di apprendimento. Se nei circoli di go si è impressionati dalla performance del programma completo, i veri risultati significativi per l’intelligenza artificiale sono da un lato la capacità di allenare R, nonostante l’esito di una mossa diventi noto centinaia di mosse più tardi, e dall’altro l’effetto pubblicitario di un ulteriore problema che ha ricevuto un miglioramento rivoluzionario grazie all’apprendimento artificiale. </p>
<p> Insomma, ancora non aspettiamo col fiato sospeso la soluzione al riscaldamento globale, ma possiamo essere un po’ più ottimisti. </p>
</doc>
<doc url="https://www.ilpost.it/2017/10/11/mark-zuckerberg-realta-virtuale-porto-rico/" parent_folder="Il Post 2016-17" id="file17861956" filename="mark-zuckerberg-realta-virtuale-porto-rico">
<p> Mark Zuckerberg si è scusato per il tono della sua diretta in realtà virtuale da Porto Rico </p>
<p> Il CEO di Facebook, Mark Zuckerberg, si è scusato per la sua diretta in realtà virtuale (VR) da Porto Rico, organizzata lo scorso 9 ottobre per mostrare i danni causati dall’uragano Maria e al tempo stesso mostrare le potenzialità del sistema per vedere ambienti reali remoti utilizzando un visore VR. La dimostrazione aveva ricevuto molte critiche, sia per il tono usato da Zuckerberg, sia per alcune affermazioni di una sua collaboratrice che partecipava alla visita virtuale, che in più occasioni aveva elogiato le funzionalità del sistema con toni che erano sembrati piuttosto stonati e fuori luogo considerate le devastazioni a Porto Rico e le sofferenze della popolazione. </p>
<p> In uno dei commenti al suo video, Zuckerberg ha scritto: </p>
<p> Una delle funzionalità più potenti della realtà virtuale è creare empatia. Il mio obiettivo era di mostrare come la realtà virtuale possa renderci più consapevoli e aiutarci a vedere che cosa sta succedendo in varie parti del mondo. Desideravo anche condividere le notizie sulla nostra collaborazione con la Croce Rossa per aiutare i soccorsi e la ricostruzione. Leggendo alcuni commenti, mi rendo conto di non essere stato chiaro, e mi scuso con chi si è sentito offeso. </p>
</doc>
<doc url="https://www.ilpost.it/2017/02/01/musica-composta-computer/" parent_folder="Il Post 2016-17" id="file17861972" filename="musica-composta-computer">
<p> I progressi della musica composta dai computer </p>
<p> Per ora non è esattamente roba che cantereste sotto la doccia, ma migliora e può avere diverse possibili applicazioni </p>
<p> Lo scorso settembre i siti di news di tutto il mondo hanno parlato della “prima canzone mai scritta da un computer”: si intitolava “Daddy’s Car” e l’aveva composta un software sviluppato dalla Sony Computer Science Laboratory. Il programma, chiamato FlowMachine, funziona in modo apparentemente semplice: i ricercatori hanno inserito nel computer circa 13mila spartiti di canzoni di vari generi musicali, che il software ha analizzato per apprendere come comporre nuove melodie. Un compositore, Benoît Carré, ha scritto le parole della canzone e ha scelto lo stile musicale per le nuove canzoni, il cui spartito è stato generato dal programma: per “Daddy’s Car”, Carré ha impostato uno stile che imitava quello dei Beatles (sembra un po’ “Good Day Sunshine”, infatti). </p>
<p> Carré ha composto un altro brano con il Sony CSL, sullo stile dei compositori classici americani come George Gershwin, Duke Ellington e Cole Porter. In entrambi i casi alla composizione uscita dal computer sono stati aggiunti manualmente dei campioni da altre canzoni realmente esistenti. François Pachet, direttore del laboratorio, ha spiegato che anche se la maggior parte dei software di intelligenza artificiale sono usati per comporre musica strumentale, la loro applicazione più complessa riguarda la produzione di brani brevi e orecchiabili. Il Sony CSL sta trattando con alcuni gruppi, come i Phoenix, perché interpretino alcuni brani composti dal loro programma. </p>
<p> Quello del Sony CSL è uno dei molti progetti nel mondo che stanno tentando di creare software in grado di comporre musica indistinguibile da quella composta dagli umani: ad aprile uscirà un disco composto interamente da FlowMachine, ma comprensibilmente la musica scritta dalle intelligenze artificiali ha, almeno per ora, obiettivi che non sono arrivare in testa alle classifiche. Le applicazioni più immediate e sulle quali si pensa ci sia più mercato sono infatti quelle che riguardano, per esempio, le colonne sonore di videogiochi o pubblicità. Jukedeck è un altro tipo di software per comporre musica, sviluppato da due amici che non hanno studiato ingegneria ma musica: Patrick Stobb e Ed Newton-Rex, entrambi 29enni, si sono laureati all’Università di Cambridge e si sono appassionati alla programmazione per caso, dopo aver assistito a una lezione ad Harvard, dove studiava la ragazza di Newton-Rex. I due hanno fondato Jukedeck nel 2012, trasformandola in una delle startup più rilevanti tra quelle che si occupano di intelligenze artificiali applicate alla musica, raccontata di recente anche da un articolo sul New York Times. </p>
<p> Jukedeck funziona più o meno come FlowMachine: nel software vengono caricati centinaia di spartiti, che vengono analizzati per capire quali sono le probabilità che una certa nota ne segua un’altra, quali sono le più frequenti progressioni di accordi, o i ritmi più diffusi. Alla base dei software di questo tipo c’è la tecnologia delle reti neurali artificiali, modelli matematici ispirati ai neuroni del cervello umano che risolvono i problemi ricevuti tramite segnali esterni, trasmettendo ed elaborando le informazioni attraverso una rete di milioni di connessioni. Un sistema di classificazione permette poi al programma di riconoscere e ricreare molti generi musicali diversi. Il processo che crea la musica si divide quindi in composizione e sintesi: la prima consiste nella scrittura dello spartito, la seconda nella sua trasformazione in una traccia audio. </p>
<p> I ricercatori di Jukedeck hanno recentemente annunciato che inizieranno a sfruttare le potenzialità dell’intelligenza artificiale non solo nella fase della composizione, ma anche in quella della sintesi, per la quale fino ad ora si erano limitati ad applicare metodi più classici, come i normali simulatori virtuali di strumenti musicali. Il primo esperimento di composizione di questo tipo è stato un breve brano, che hanno detto essere «la prima volta che un computer scrive e produce una canzone, dall’inizio alla fine, usando soltanto tecniche di apprendimento automatico. Tutto quello che abbiamo specificato è stato il genere e la durata: tutto il resto è stato composto dall’intelligenza artificiale». Jukedeck spera, affidando al software anche la fase di “esecuzione” della musica, di rendere il processo compositivo più lineare. </p>
<p> Si ritiene che la prima musica scritta da un computer sia la “Iliac Suite”, composta nel 1957 alla University of Illinois at Urbana-Champaign da un computer programmato dal compositore Lejaren Hiller, che la eseguì poi con il suo quartetto d’archi. </p>
<p> Anche Google sta facendo esperimenti con le intelligenze artificiali e la musica: il progetto Google Brain ha presentato lo scorso giugno Magenta, un software per la composizione musicale. </p>
<p> DeepMind, la società britannica controllata da Google che si occupa di intelligenza artificiale, ha fatto un esperimento singolare e insolito: ha caricato dei campioni di pianoforte in un software utilizzato per creare file audio, soprattutto discorsi. Il programma, che si chiama WaveNet, non aveva mai ricevuto istruzioni su come funziona la musica, e quando ha dovuto elaborare i file audio originali ha prodotto una serie di brevi brani da 10 secondi, che sembrano jazz sperimentale. </p>
<p> Mathieu Peudupin, un musicista rock francese, ha spiegato al New York Times che lavorare con un programma di intelligenza artificiale lo ha «portato in posti in cui non sarei mai andato da solo», e ha paragonato l’esperienza a lavorare con un altro membro di una band. Se finora non c’è stata una vera preoccupazione tra i musicisti riguardo alla possibilità di essere sostituiti da un computer, Stobb crede che non ci sia una regola che dica che i computer, in futuro, non possano diventare bravi come gli umani a scrivere la musica. Soprattutto per i videogiochi, che richiedono colonne sonore lunghissime (praticamente infinite), i computer potrebbero risolvere molti problemi, potendo produrre brani pressoché infiniti ed evitando alle case produttrici di dover riprodurre in loop una certa musica. </p>
<p> Newton-Rex ha spiegato che le applicazioni più interessanti arriveranno quando (e se) i software saranno in grado di comporre musica in tempo reale, a seconda di quello che sta succedendo all’ascoltatore: musica incalzante se è in un momento concitato di un videogioco, o musica stimolante se sta facendo jogging, per esempio. Ma Jukedeck chiede soltanto poco più di 20 dollari per poter usare una composizione del suo programma, e questo è attraente soprattutto per le aziende che vogliono risparmiare sulla musica delle proprie pubblicità. Stobb ha confermato che la divisione britannica di Coca-Cola paga un abbonamento mensile al servizio. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/massimomantellini/2016/07/09/quando-il-killer-e-un-robot/" parent_folder="Il Post 2016-17" id="file17861937" filename="quando-il-killer-e-un-robot">
<p> Essere uccisi da un robot </p>
<p> Le prime cronache del venerdì mattina dicevano che Micah Xavier Johnson, l’assassino dei poliziotti a Dallas si era suicidato. Braccato dagli agenti, chiuso nel suo ultimo nascondiglio, dopo ore di infruttuose trattative si era ucciso. </p>
<p> Non era vero, lo si è saputo alcune ore dopo dalle parole del comandante della Polizia di Dallas David Brown. Johnson è stato ucciso da un robot della Polizia che si è avvicinato a lui e ha fatto esplodere una bomba. </p>
<p> In queste ore le discussioni in USA su questo, che secondo molti è il primo caso di utilizzo offensivo di un robot sul suolo americano, sono molto accese. Riguardano un po’ tutto, dal costo del robot (80000 dollari) alla militarizzazione della polizia cittadina; riguardano soprattutto le questioni etiche, prima ancora che di opportunità strategica, della guerra immaginata come operazione chirurgica mediata dalla tecnologia, le inedite regole di ingaggio della battaglia fra esseri umani rivoluzionata da nuove forme di distanza. </p>
<p> Discussione ovviamente non inedita (la tecnologia ha storicamente giocato un ruolo fondamentale nell’ideazione degli strumenti offensivi, dai tempi dell’olio bollente fino ad Hiroshima) ma particolarmente affine a quella ben più recente sui droni ed il loro utilizzo. Ma che si discuta dei bombardamenti da parte di aerei senza pilota comandati dal joystick di un militare dall’altra parte del mondo o della polizia di Dallas che manda un robot ad uccidere un sospettato, il punto maggiormente rilevante di tutta la discussione riguarda la tecnologia e la nostra saggezza. </p>
<p> Se tecnologia e saggezza viaggiano a velocità differenti –dice Max Tegmark del MIT in questo formidabile documentario di Motherboard – è a quel punto che nasceranno i problemi. E si tratterà di questioni per nulla inedite che riguardano oggi da un lato la ricerca pura sull’intelligenza artificiale e i robot e dall’altro la nostra capacità o incapacità di gestirne umanamente le ricadute pratiche. </p>
<p> Molte giustificazioni possibili e ragionevoli sono state utilizzate in queste ore a riguardo dell’utilizzo del robot killer a Dallas: la pericolosità dell’assassino, la necessità di non mettere a repentaglio ulteriori vite umane, la decisione finale, comunque e sempre nelle mani di chi quel robot comandava a distanza. E tuttavia il tema della militarizzazione delle tecnologie nel momento in cui nuovi frontiere si aprono resta un tema centrale. Se nel giro di cinque o dieci anni gli sviluppi dei sistemi di intelligenza artificiale consentiranno non solo alle auto di guidare per noi ma anche ai robot di difendere la nostra incolumità di cittadini, chi potrà essere tanto ingenuo da pensare che simili opzioni non saranno utilizzate in ambito militare anche fuori dal controllo diretto di un essere umano? </p>
<p> Se tecnologia e saggezza non marceranno di pari passo – dice Tegmank – sarà un po’ come abbandonare fiduciosi i nostri figli all’asilo a giocare allegramente con un paio di granate in mano. Che è un po’ quello che già adesso stiamo iniziando a fare. Le tecnologie offensive attuali disumanizzano il confronto fra assalito ed assalitore, trasformano atti di guerra in scelte da videogame: le tecnologie prossime venture consentiranno al videogame che abbiamo creato di giocare la partita da solo. </p>
</doc>
<doc url="https://www.ilpost.it/2017/10/13/record-bitcoin/" parent_folder="Il Post 2016-17" id="file17861985" filename="record-bitcoin">
<p> I bitcoin valgono sempre di più </p>
<p> La criptovaluta ha toccato un nuovo record – in un anno il suo valore è cresciuto del 750 per cento – facendo parlare di nuovo del rischio bolla </p>
<p> Questa settimana i bitcoin, la criptovaluta che si utilizza online, hanno oltrepassato per la prima volta i 5.000 dollari di valore. Per la precisione, a ottobre, il loro valore è cresciuto dell’8 per cento, raggiungendo i 5.243 dollari (circa 4.400 euro): significa che comprare un singolo bitcoin costa più di 5.200 dollari. All’inizio dell’anno un bitcoin veniva cambiato con 966 dollari. La crescita nel corso degli ultimi dodici mesi è stata di circa il 750 per cento. I prezzi dei bitcoin, però, sono ancora molto instabili. Lo scorso settembre, per esempio, dopo aver superato i 4 mila dollari di valore, i bitcoin sono crollati in pochi giorni sotto i 3 mila dollari, in seguito all’annuncio di una stretta sul loro utilizzo da parte delle autorità cinesi. Dopo il crollo però, i bitcoin sono rapidamente tornati a crescere. </p>
<p> Ma come funzionano i bitcoin? Semplificando molto: il bitcoin è una moneta che funziona sulla base di un protocollo peer-to-peer – simile quindi a quello usato per scaricare e condividere i file online – in cui la creazione della moneta e le transazioni avvengono e sono garantite da una rete formata dai computer delle persone che usano la moneta. In pratica su ogni computer è installato un software che gestisce la moneta e non esiste un’autorità centrale che abbia maggiore controllo sul suo valore o sulla sua emissione, come invece succede con le valute normali. I bitcoin vengono creati attraverso un processo informatico molto lungo e complicato chiamato mining, cioè “estrazione”. La rete genera e distribuisce monete in modo casuale a intervalli regolari a chi ha attivo sul proprio computer il software. </p>
<p> Semplificando, ai dispositivi collegati viene sottoposto un problema crittografico che richiede un enorme numero di prove per essere risolto: dal computer che per primo trova una soluzione parte un avviso per gli altri e la richiesta per avere la proprietà di un nuovo blocco di bitcoin. Tutto questo avviene “all’oscuro” delle persone davanti al computer: è un calcolo che il programma fa autonomamente seguendo input casuali generati dal protocollo. Una volta che un utente è entrato in possesso di un bitcoin (tramite estrazione con il procedimento appena descritto, oppure comprando bitcoin con valute reali, oppure ottenendolo come pagamento per vendite o servizi) può depositarlo in un portafoglio virtuale e spenderlo sul web sui siti che accettano questo tipo di valuta. I bitcoin che si possono estrarre con questo processo sono un numero finito, cioè a un certo punto termineranno del tutto, e oggi sono sempre meno. La maggior parte della gente che fa operazioni in bitcoin li acquista e li rivende sul mercato. </p>
<p> I vantaggi dei bitcoin Al momento i bitcoin vengono utilizzati soprattutto come forma di investimento. Vengono acquistati e rivenduti per guadagnare dalle transazioni, oppure tenuti da parte in attesa che il loro prezzo aumenti. La possibilità di utilizzarli per acquistare beni e servizi però sta aumentando. Diverse catene di negozi stanno introducendo la possibilità di pagare tramite bitcoin, mentre online sono una forma di pagamento già piuttosto diffusa. I bitcoin, inoltre, permettono di effettuare transazioni in forma anonima, senza alcuna possibilità di controllo da parte di banche o autorità. Per questo alcuni temono che possano essere usati per il riciclaggio di denaro sporco e altre attività illegali. </p>
<p> Il timore di una bolla Ciclicamente si torna a parlare del rischio “bolla” dei bitcoin. Alcuni ritengono che il livello del loro prezzo non sia sostenibile sul lungo periodo e che sia destinato a crollare. Altri parlano della “fine dei bitcoin” e gli esperti di criptovalute spesso scherzano sulla quantità di volte in cui la stampa ha annunciato la loro morte. Questi avvertimenti spesso provengono dai banchieri, che però sono in genere ostili alle criptovalute perché tagliano fuori le banche dalla possibilità di intermediazione (pagando un bene con bitcoin invece che con la propria carta di credito la banca non riceve alcuna commissione). </p>
<p> Un mese fa l’amministratore delegato della banca d’affari JP Morgan Jamie Dimon, uno dei banchieri più famosi e potenti di Wall Street, ha detto che i bitcoin sono una truffa e un sistema di scambio buono solo per le attività criminali. Dimon ha promesso di licenziare qualsiasi trader della sua società che dovesse occuparsene. A dimostrazione che i bitcoin sono un tema ancora molto controverso, proprio ieri un altro dirigente delle banca ha detto che JP Morgan è “interessata” al futuro delle criptovalute. Quasi tutte le grandi banche internazionali hanno gruppi di trader e analisti incaricati di fare scambi e studiare il fenomeno dei bitcoin e le sue possibili applicazioni. </p>
<p> Anche molti professori di economia sono scettici sul futuro della criptovaluta. Kenneth Rogoff, che ha lavorato per il Fondo Monetario Internazionale e oggi insegna ad Harvard, sostiene che il prezzo dei bitcoin sia agganciato soltanto alle speranze che hanno gli investitori sui suoi futuri aumenti di valore. Questa sarebbe una differenza fondamentale tra le monete emesse dagli stati e le criptovalute. Le prime, un tempo, erano agganciate al valore di beni materiali, come l’oro posseduto da uno Stato. Oggi il loro valore è agganciato a fattori macroeconomici, come l’inflazione e la solidità economica dello Stato che le emette. </p>
<p> Il valore dei bitcoin invece sarebbe agganciato soltanto alle aspettative dei suoi investitori, che li acquistano e li scambiano nella convinzione che il loro valore sia destinato ad aumentare. Più che come una moneta, quindi, i bitcoin si comporterebbero come una “commodity”, una materia prima, come il grano o il petrolio, il cui valore può cambiare anche molto in seguito alle aspettative del mercato. Nonostante le fluttuazioni, però, il valore dei bitcoin non ha fatto che aumentare negli ultimi anni e molte persone che li avevano acquistati o estratti quando valevano pochi dollari sono diventati “ricchi” in seguito alla costante crescita del loro prezzo. I sostenitori delle criptovalute sostengono invece che la loro continua crescita di valore sia un segno che queste monete sono destinate a restare e a ricoprire un ruolo sempre più importante nelle nostre economie. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/06/11/riconoscere-facce/" parent_folder="Il Post 2016-17" id="file17861962" filename="riconoscere-facce">
<p> Abbiamo scoperto qualcosa di più su come riconosciamo le facce </p>
<p> Due ricercatori hanno tracciato l'attività dei neuroni che decifrano le caratteristiche di ogni volto, per distinguerlo tra gli altri </p>
<p> La capacità di riconoscere e ricordare centinaia di facce è stata fondamentale per lo sviluppo delle nostre abilità sociali, e per la stessa evoluzione della nostra specie. Riusciamo a distinguere una faccia conosciuta nel bel mezzo di un posto affollato, o ricordarci istantaneamente di qualcuno che non vedevamo da un sacco di tempo e che pensavamo di avere dimenticato. Questa caratteristica incuriosisce da tempo i ricercatori, che non sono ancora riusciti a spiegare come faccia il cervello a riconoscere e a ricordarsi i volti delle persone che incontriamo. Un nuovo studio realizzato sui macachi (Macaca mulatta), da poco pubblicato sulla rivista scientifica Cell, offre qualche nuovo elemento e sostegno alle teorie formulate finora sul tema. </p>
<p> Negli anni i ricercatori hanno elaborato diverse teorie che possono essere raggruppate in due grandi insiemi: da un lato c’è chi teorizza che nel cervello esistano specifiche cellule (neuroni) ciascuna delle quali è dedicata al riconoscimento di una persona, dall’altro chi ritiene che siano gruppi di neuroni che lavorano insieme per riconoscere le facce e associare un volto a una persona. Attraverso la risonanza magnetica funzionale, un esame non invasivo per vedere quali parti del cervello si attivano quando si svolge un particolare compito, in passato è stato possibile identificare alcune aree nel lobo temporale (l’area sotto le tempie) in cui sono concentrate queste cellule “faccia selettive”, ma finora non era stato possibile comprenderne il funzionamento. </p>
<p> Per capirci qualcosa di più, Doris Tsao e Le Chang del California Institute of Technology (Caltech) di Pasadena, California, hanno studiato il funzionamento di due esemplari di macaco, primati che hanno diverse cose in comune con noi. I ricercatori hanno scoperto che ogni cellula “faccia selettiva” si occupa di registrare una caratteristica della faccia che si sta osservando, condividendo poi le informazioni con la restante rete di neuroni per rendere accurato e preciso il riconoscimento. È dalla combinazione delle informazioni che si ottiene un’immagine univoca di un volto, che viene poi mandata a memoria e utilizzata per riconoscere in occasioni diverse la stessa persona. Nel loro studio, Tsao e Chang scrivono inoltre che le modalità in cui si combinano le informazioni seguono andamenti prevedibili, al punto da potere ricostruire quale faccia stia osservando il macaco, semplicemente tracciando l’attività elettrica delle sue cellule “faccia selettive”. </p>
<p> La ricerca pubblicata su Cell sembra confermare la teoria secondo cui sia una rete complessa di neuroni a procedere al riconoscimento; ricerche precedenti avevano invece ipotizzato che ci fossero singoli neuroni deputati al riconoscimento di determinati volti e non di altri. </p>
<p> Tsao e Chang hanno utilizzato un set di circa 2mila immagini di volti umani, con caratteristiche diverse come la distanza degli occhi, la dimensione del naso e le proporzioni del volto. Hanno poi impiantato alcuni elettrodi nel cervello dei due macachi per misurare la risposta dei neuroni, a seconda delle differenze facciali. Il loro lavoro sembra confermare che le cellule “faccia selettive” non sono una sorta di rivelatore, ma semmai un sistema integrato per analizzare le facce. Non è però ancora chiaro come il sistema mantenga i suoi alti livelli di efficienza, soprattutto per quanto riguarda i tempi di risposta. </p>
<p> Come raccontò in un saggio il famoso neurologo statunitense Oliver Sacks, ci sono comunque persone che non sono in grado di riconoscere i volti. La loro condizione si chiama prosopagnosia e si stima che ne soffra circa il 2,5 per cento della popolazione, con forme molto lievi che interessano una percentuale ancora più alta (alcuni parlano del 10 per cento). Le persone che ne soffrono faticano a riconoscere le persone che hanno intorno, anche se le conoscono da una vita, soprattutto se si trovano in contesti diversi dal solito. Nelle forme più lievi la difficoltà riguarda più che altro tempi e capacità di rendersi subito conto di avere davanti qualcuno di conosciuto, mentre nei più gravi porta a una costante incapacità di riconoscere chi si ha intorno. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/04/06/robot-automazione-posti-di-lavoro/" parent_folder="Il Post 2016-17" id="file17861936" filename="robot-automazione-posti-di-lavoro">
<p> Le intelligenze artificiali ridurranno i posti di lavoro? </p>
<p> Analisti e politici se lo chiedono da tempo, ora i nuovi progressi di computer e robot hanno reso il tema ancora più discusso e le soluzioni sono complicate </p>
<p> Di come la robotizzazione e lo sviluppo delle intelligenze artificiali potrebbero avere forti impatti sul mercato del lavoro nei prossimi decenni se ne parla moltissimo da alcuni anni, soprattutto da quando nel 2013 è uscito The Future of Employment, uno studio di Carl Benedikt Frey e Michael Osborne della Oxford University secondo cui il 47 per cento dei posti di lavoro degli Stati Uniti è ad alto rischio di automazione nel giro del prossimo decennio o dei prossimi vent’anni. Uno studio più aggiornato, The Future of Jobs, pubblicato nel 2016 dal World Economic Forum, stima il numero di posti di lavoro persi dal 2015 al 2020 in tredici dei paesi più industrializzati del mondo (tra cui l’Italia) in 5,1 milioni: di questi posti di lavoro in meno non tutti sono da imputare all’avanzamento tecnologico, ma sia l’automazione che lo sviluppo delle intelligenze artificiali sono tra i principali fattori considerati dal World Economic Forum per la sua stima. </p>
<p> Uno studio della società di consulenza PwC sul mercato del lavoro britannico ha stimato che nei prossimi 15 anni i sistemi di intelligenza artificiale potrebbero sostituire le persone nel 30 per cento dei posti di lavoro nel Regno Unito. L’uso di questi sistemi è un passaggio in più rispetto alla semplice automazione che già è molto presente in numerosi settori industriali: infatti le AI potrebbero essere sviluppate in modo da eseguire compiti per cui finora si riteneva indispensabile il contributo umano, come quelli nel campo della comunicazione e dell’informazione, la scrittura di un articolo come questo compresa. Secondo lo studio di PwC, 2,25 milioni di posti di lavoro nel settore delle vendite all’ingrosso e al dettaglio (il settore in cui nel Regno Unito è impiegato il maggior numero di persone) sono a rischio; nel settore manifatturiero sono 1,2 milioni, 1,1 nel settore amministrativo e 950mila in quello dei trasporti. I settori meno a rischio sono quelli dell’istruzione e della cura delle persone, assistenza agli anziani compresa. </p>
<p> Lo studio di PwC dice che l’automazione potrà far aumentare la produttività e creare nuove opportunità di lavoro, ma saranno lavori di tipo molto diverso da quelli che verranno persi sempre per via dell’automazione: i robot svolgeranno i compiti più semplici, quelli per cui è necessaria una minore formazione, mentre ci sarà sempre più bisogno di persone in grado di progettare nuove forme di tecnologia. La Commissione Europea ha stimato che entro il 2020 i paesi europei potrebbero avere bisogno di 825mila professionisti del settore informatico e tecnologico. Il problema che dovrà essere sicuramente affrontato nel futuro è come garantire che la perdita di posti di lavoro di un certo tipo (quelli più facilmente sostituibili dall’automazione e dalle AI) sia compensata in parte dalla creazione di posti di lavoro più specializzati e in parte da nuove politiche per evitare la creazione di nuove forme di ineguaglianza. </p>
<p> Ultimamente si è parlato della questione perché Bill Gates ha proposto che il lavoro delle macchine sia tassato come quello dei lavoratori umani in modo che i governi possano finanziare la creazione di nuove opportunità di lavoro e ancora prima nel corso della campagna per le elezioni presidenziali francesi: il candidato socialista Benoît Hamon ha proposto di creare un reddito minimo di cittadinanza per far fronte alle future perdite di lavoro, da finanziare in parte con una una tassa sui robot. Anche l’economista premio Nobel Robert Schiller ha detto che bisognerebbe considerare l’introduzione di una tassa sui robot per fare fronte agli enormi cambiamenti nel mercato del lavoro che avverranno nei prossimi decenni. </p>
<p> Anche il Parlamento Europeo si è occupato della questione. Il 16 febbraio ha votato una risoluzione che invita la Commissione europea a stabilire delle regole su varie questioni che riguardano i robot e l’intelligenza artificiale: tra le altre cose, la creazione di uno status giuridico per i robot (allo scopo di dare responsabilità civile ai robot in caso di incidenti); un controllo sul mercato del lavoro che permetta di prevedere crisi occupazionali dovute all’automazione e prevenirle; la stesura di un codice etico per chi progetta i robot. L’europarlamentare lussemburghese Mady Delvaux, che fa parte del gruppo dell’Alleanza progressista di Socialisti e Democratici e ha presentato il testo della risoluzione, voleva che nel testo fosse proposto anche l’obbligo per le aziende che scelgono di automatizzare la propria produzione di pagare dei corsi di formazione per i lavoratori che perdono il posto. La proposta è stata osteggiata dall’International Federation of Robotics, un’organizzazione internazionale che rappresenta l’industria robotica, secondo cui tassare il lavoro delle macchine danneggerebbe il settore, e il Parlamento Europeo ha votato contro. </p>
<p> Sicuramente la politica si occuperà sempre di più della questione della perdita dei posti di lavoro, ma al tempo stesso non è necessario essere allarmisti per il momento. Come spiega lo stesso studio di PwC, il fatto che sia tecnicamente possibile sostituire il lavoro di molte persone con quello di robot e AI non significa che sarà economicamente vantaggioso farlo, almeno non immediatamente. Il costo del lavoro – umano e non – cambierà nei prossimi decenni ed è difficile immaginare quanto e quanto velocemente. Di sicuro quando i robot saranno meno costosi da produrre verranno usati di più, ma ancora non si sa quanto le leggi sull’uso delle AI rallenteranno il processo che porterà a usarle in nuovi campi fino a sostituire il lavoro umano. In questo caso i ritardi dovuti all’adattamento della politica alla tecnologia potrebbero avere il risvolto vantaggioso di darci il tempo per adattarci a un mondo con molti più lavoratori artificiali. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/03/29/romanzi-fantascienza-scritti-computer/" parent_folder="Il Post 2016-17" id="file17861938" filename="romanzi-fantascienza-scritti-computer">
<p> “La giornata in cui un computer scrive un romanzo” </p>
<p> E passa la prima selezione di un premio letterario giapponese: è un piccolo successo per l'intelligenza artificiale </p>
<p> Negli ultimi giorni si è parlato a lungo dei progressi dell’intelligenza artificiale, dopo che Alpha Go, il computer di Google DeepMind ha battuto il campione mondiale del gioco da tavolo Go Lee Se-dol. Più o meno negli stessi giorni l’intelligenza artificiale ha fatto piccoli progressi anche in un altro campo: per la prima volta infatti un libro scritto da un computer, anche se in collaborazione con una persona, ha passato la selezione di un premio letterario, il giapponese Hoshi Shinichi. Il premio di narrativa fantascientifica è arrivato alla sua terza edizione, è dedicato allo scrittore Shinichi Hoshi (1926-1997) e ha una particolarità: è aperto anche a opere realizzate da intelligenze artificiali, oltre che da altri “non-umani” come alieni e animali, posto che siano scritte in giapponese. Gli organizzatori del concorso non hanno rivelato alla giuria che 11 dei 1.450 romanzi proposti erano stati scritti da due squadre composte da un computer e una persona, così da non influenzarne la scelta. Nelle passate edizioni non erano state proposte opere nate dalla collaborazione tra autori umani e intelligenze artificiali. </p>
<p> Il Japan News, l’edizione in inglese del quotidiano Yomiuri Shimbun, ha pubblicato un breve estratto dal finale di uno dei romanzi sottoposti alla giuria, realizzato dalla squadra di un professore della Future University Hakodate, Hitoshi Matsubara, che lavora per riprodurre artificialmente i processi creativi del cervello umano; il romanzo si intitola più o meno La giornata in cui un computer scrive un romanzo. Tradotto dall’inglese con l’aiuto di Google Translate (forse il metodo più coerente per rendere una frase scritta da un computer), il romanzo finisce così: </p>
<p> Mi contorcevo di gioia, che ho sperimentato per la prima volta, e ho continuato a scrivere per l’eccitazione. La giornata in cui un computer ha scritto un romanzo. Il computer, ponendo la priorità sulla ricerca della propria gioia, ha smesso di lavorare per gli esseri umani. </p>
<p> Da queste frasi si intuisce che forse l’egocentrismo è una dote che accomuna tutti gli scrittori, umani o meno. In realtà la maggior parte del lavoro necessario per comporre i romanzi è stata svolta dai co-autori umani che hanno fornito ai programmi di scrittura artificiali la trama, lo sviluppo dei personaggi e il tema delle opere; i computer hanno portato a termine la parte faticosa, ovvero l’effettiva scrittura del testo, scegliendo parole e frasi già scritte da persone e combinandole in una forma compatibile con i parametri assegnati. Il processo è molto simile a quello di Wordsmith, la piattaforma in grado di scrivere comunicati stampa usata anche dall’Associated Press. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/09/29/sondaggi-online/" parent_folder="Il Post 2016-17" id="file17861953" filename="sondaggi-online">
<p> Perché non fidarsi dei sondaggi online </p>
<p> Se ne è riparlato perché li cita spesso Donald Trump in suo favore, ma hanno enormi limiti di affidabilità statistica </p>
<p> Dopo il dibattito delle elezioni presidenziali americane di lunedì notte, il candidato Repubblicano Donald Trump si è vantato in più occasioni di aver battuto la candidata democratica Hillary Clinton, stando ai risultati di diversi sondaggi che ha citato più di una volta. La maggior parte degli analisti, tuttavia, ha un’opinione opposta e concorda sul fatto che il dibattito di Trump sia stato un disastro, e in molti hanno fatto notare che quelli citati da Trump sono tutti sondaggi effettuati online da diversi siti o sui social network, e che quelli effettuati con metodi scientifici da istituti seri hanno dato unanimemente Clinton come vincitrice. Nell’equivoco è caduto anche qualche giornale italiano, che ha descritto i sondaggi come “divisi”, mettendo sullo stesso piano cose che in realtà sono molto diverse tra loro, e trattando i sondaggi online come dei veri sondaggi. Il New York Times ha spiegato i motivi per cui ci si debba fidare poco di questo tipo di cose, a prescindere da Donald Trump e dalla politica americana. </p>
<p> Il New York Times spiega che i problemi dei sondaggi online fatti da siti e giornali sono soprattutto di rappresentatività del campione e di “sicurezza” del sistema informatico che permette di votare. I sondaggi sono affidabili quando il campione di persone contattate è adeguatamente variegato in relazione al corpo elettorale, o al gruppo di persone che parteciperà a una certa consultazione. Su internet, non possiamo conoscere età, sesso e inclinazione politica – per citare forse le tre più importanti – dei partecipanti a un determinato sondaggio. Inoltre, come fa notare il New York Times, «i risultati sono in larga parte un riflesso del “target” del sito e delle persone che in quel momento sono sufficientemente motivate per partecipare. Non è una sorpresa, insomma, che i lettori di siti come Breitbart News e Drudge Report [due siti di news di destra e parecchio complottisti] considerino Trump vincitore, così come Clinton sarà messa meglio in sondaggi sui siti “di sinistra”». </p>
<p> Un esempio estremo della faziosità dei partecipanti è evidente in un sondaggio compiuto di recente da una rete televisiva di Philadelphia. Alla domanda su quale fosse la migliore squadra di football americano fra quelle ancora imbattute nel campionato di NFL, il 96 per cento dei partecipanti ha votato per i Philadelphia Eagles. </p>
<p> Altre volte il pregiudizio è più sottile: un recente sondaggio della Gazzetta dello Sport, per esempio, ha chiesto ai lettori se l’attaccante del Nizza Mario Balotelli meritasse di tornare a giocare nella Nazionale di calcio italiana, dopo un ottimo inizio di stagione con 4 gol nelle prime due partite. Quasi due terzi dei partecipanti hanno votato “no”, ma va tenuto in considerazione che la Gazzetta dello Sport è di Milano ed è il giornale di riferimento dei tifosi di Milan e Inter, due squadre in cui Balotelli non ha lasciato un grande ricordo. </p>
<p> Intuitivamente, questo problema potrebbe essere risolto con un campione sufficientemente alto, magari con un sondaggio ospitato da un sito di news “tradizionale”. Fra i sondaggi citati da Trump ce n’è uno di CNBC a cui hanno partecipato 418mila persone, e che lo vede vincitore col 61 per cento delle preferenze. </p>
<p> Il guaio è che spesso sondaggi del genere non sono protetti a sufficienza dalle manipolazioni anche piuttosto semplici, come ad esempio il trucco di votare più volte nascondendo il proprio indirizzo IP, associato al sistema da cui si è connessi a internet. Il magazine Daily Dot, in occasione dei sondaggi dopo il dibattito fra Trump e Clinton, ha trovato traccia di diversi utenti di Reddit e 4chan che hanno incoraggiato i sostenitori di Trump a barare, linkando i sondaggi più vulnerabili dal punto di vista informatico e invitando a votare più volte per gonfiare i risultati del loro candidato. </p>
<p> C’è poi un terzo problema, e cioè lo sbilanciamento del campione a causa di una campagna nata online. MentalFloss ha messo insieme un elenco di sondaggi online i cui risultati sono stati pesantemente influenzati da persone che hanno votato su indicazione di altri, per far vincere una certa opzione. Nel 2012, ad esempio, la compagnia aerea norvegese Norwegian Air aveva pubblicato un sondaggio online per decidere la sua nuova mascotte: i fan della musica metal invasero il sondaggio votando in massa per Øystein Aarseth, il chitarrista della band black metal Mayhem ucciso nel 1993 dal bassista della band, Varg Vikernes (conosciuto anche col nome d’arte “Burzum“). Fu la stessa famiglia di Aarseth a chiedere a Norwegian Air di escluderlo dal sondaggio. Una cosa simile, anche se più innocua, era successa quando il Natural Environment Research Council, un’agenzia del governo del Regno Unito che si occupa di ricerca scientifica, aveva aperto un sondaggio online per decidere il nome della sua nuova nave da ricerca, costata circa 350 milioni di euro. Vinse un nome stupido e insensato per via di una campagna che nacque autonomamente online con lo scopo di fare una cosa buffa e divertente. </p>
<p> In Italia molti giornali online hanno progressivamente abbandonato i sondaggi online veri e propri. Dal 2014, per esempio, il Corriere della Sera ha un sistema che permette di votare con delle faccine il proprio stato d’animo dopo aver letto un certo articolo. I giornali sportivi postano spesso sondaggi piuttosto innocui – tranne i rari casi in cui succede un incidente – con le questioni più discusse del momento. Un caso a parte è quello di Libero, i cui sondaggi seguono la linea provocatoria e spesso offensiva del resto del giornale. </p>
<p> SONDAGGIO – Secondo voi Belen ha esagerato ad andare in prima serata senza reggiseno? https://t.co/3Q7oNHZlAY </p>
<p> SONDAGGIO – Secondo voi quanti voti prenderebbe il partito islamico italiano? https://t.co/x0lKKcX4Qh </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/12/25/sorveglianza-cina-xinjiang-uiguri/" parent_folder="Il Post 2016-17" id="file17861947" filename="sorveglianza-cina-xinjiang-uiguri">
<p> Storie da uno dei posti più sorvegliati al mondo </p>
<p> Nello Xinjiang, in Cina, la polizia controlla tutto e tutti, tra sistemi di riconoscimento facciale e app che monitorano i cellulari </p>
<p> Lo Xinjiang è una regione autonoma del nord-ovest della Cina abitata soprattutto dagli uiguri, minoranza etnica musulmana accusata dal governo cinese di separatismo e terrorismo. Negli ultimi due mesi due importanti giornali americani hanno definito lo Xinjiang «uno dei posti più sorvegliati al mondo» (Wall Street Journal) e «una finestra sul possibile futuro dispotico creato dalla sorveglianza tecnologica» (BuzzFeed News). </p>
<p> Agli abitanti dello Xinjiang capita di doversi sottoporre a controlli di polizia più volte al giorno, oltre che a procedimenti di riconoscimento facciale prima di accedere ai distributori di benzina, agli hotel e alle banche. Le autorità hanno il potere di registrare in maniera arbitraria tutte le telefonate provenienti dall’estero e di obbligare privati cittadini a installare sul telefono un’app capace di controllare tutti i messaggi in entrata e in uscita. </p>
<p> Lo Xinjiang, che significa “Nuova Frontiera”, è stato portato sotto il completo controllo della Cina nel 1949: confina con otto stati (India, Pakistan, Russia, Mongolia, Kazakistan, Afghanistan, Tagikistan e Kirghizistan) ed è un passaggio obbligato per gli scambi commerciali con l’Asia Centrale e l’Europa. È un territorio molto ricco di gas e petrolio e dove sono frequenti da molti anni proteste contro il regime di Pechino e scontri etnici: gli uiguri non accettano la presenza dei cinesi han nella regione e denunciano da tempo le repressioni e le discriminazioni compiute dal governo. Da parte sua, il governo cinese sostiene che nello Xinjiang sia forte l’estremismo islamista: una recente inchiesta di Associated Press ha evidenziato per esempio come finora siano stati almeno 5mila gli uiguri a lasciare lo Xinjiang per andare a combattere in Siria. </p>
<p> Negli ultimi anni le autorità cinesi hanno rafforzato i sistemi di sorveglianza in tutto il paese, così come voluto dal potentissimo presidente cinese Xi Jinping. Nello Xinjiang, comunque, la censura e il controllo hanno raggiunto livelli unici, in particolare dopo la nomina di Chen Quanguo a nuovo capo del Partito comunista locale, nell’agosto 2016. Tra le prime decisioni di Chen c’è stata l’apertura di migliaia di nuove stazioni di polizia e l’aumento del numero dei cosiddetti “centri di educazione”, ovvero centri di detenzione usati per rinchiudere migliaia di persone senza alcuna incriminazione formale, ma sospettate di essere potenzialmente un pericolo per la sicurezza regionale. </p>
<p> Nello Xinjiang sfuggire ai controlli della polizia è diventato praticamente impossibile. Lungo le principali strade delle città della regione, ma anche negli angoli delle vie più piccole e di fronte alle moschee, sono state installate migliaia di telecamere. La sorveglianza è particolarmente stretta a Urumqui, la capitale dello Xinjiang, dove la polizia locale ha ordinato ai ristoranti di diverse zone di installare nuovi dispositivi di sorveglianza all’ingresso per «prevenire attacchi terroristici». Molti giovani uiguri hanno cominciato a tenere due cellulari, uno da usare liberamente a casa e l’altro da portarsi in giro svuotato da contenuti più sensibili, per evitare guai con la polizia. </p>
<p> Un tweet ripreso da BuzzFeed mostra due poliziotti mentre controllano l’app che monitora i contenuti degli smartphone. </p>
<p> Le autorità esercitano un severissimo controllo anche sulla vendita di coltelli, il tipo di arma usata negli ultimi attentati compiuti da uiguri in Cina: prima della vendita, sul coltello viene inciso con il laser un “QR code”, cioè un codice identificativo che include informazioni personali dell’acquirente, come il numero del suo documento d’identità. </p>
<p> La sorveglianza è ancora più stretta a Kashgar, città di più di 300mila abitanti vicino al confine con il Kirghizistan. Qui, ha raccontato il Wall Street Journal, tutte le auto che entrano in città vengono controllate, così come vengono sottoposte a riconoscimento facciale le persone che le guidano. A Kashgar il governo cinese ha anche avviato un progetto pilota per introdurre un sistema di riconoscimento dell’iride, più accurato dei sistemi di scansione del viso e dell’impronta digitale. </p>
<p> Josh Chin e Clément Bürge, giornalisti del Wall Street Journal, hanno scritto: «È quasi impossibile muoversi nella regione senza sentire su di sé l’incessante sguardo del governo». Omer Kanat, direttore del Uyghur Human Rights Project, organizzazione che promuove il rispetto dei diritti umani degli uiguri, ha detto alla giornalista Megha Rajagopalan di BuzzFeed: «È una prigione a cielo aperto. La Rivoluzione culturale è tornata e il governo non prova nemmeno a nasconderla. Viene fatto tutto alla luce del sole». </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/06/13/sunspiring-intelligenza-artificiale/" parent_folder="Il Post 2016-17" id="file17861929" filename="sunspiring-intelligenza-artificiale">
<p> Un film di fantascienza scritto da un computer </p>
<p> Un'intelligenza artificiale ha scritto la sceneggiatura per il cortometraggio "Sunspiring": i risultati sono interessanti, ma anche bizzarri </p>
<p> Dal 9 giugno è su YouTube Sunspiring, un cortometraggio di fantascienza che dura nove minuti ed è finora stato visto quasi 400mila volte. L’ha diretto lo statunitense Oscar Sharp e l’attore principale è il canadese Thomas Middleditch, famoso per la serie tv Silicon Valley. La particolarità di Sunspiring sta però nella sua sceneggiatura: l’ha scritta Benjamin, un’intelligenza artificiale creata da Ross Goodwin, un ricercatore informatico della New York University. Benjamin (un nome che l’intelligenza artificiale si è scelta da sola) è tecnicamente una “rete neurale ricorrente”: un computer che riesce a imparare cose da solo e, in questo caso specifico, ha scritto una sceneggiatura dopo aver letto le sceneggiature di decine di film di fantascienza, tra cui Interstellar, Il quinto elemento, Highlander: Endgame e Ghostbusters – Acchiappafantasmi. </p>
<p> Sunspiring è stato presentato allo Sci-Fi London Festival – un festival cinematografico dedicato alla fantascienza – all’interno della sezione 48-Hour Film Challenge, in cui i partecipanti hanno 48 ore per girare il loro cortometraggio. Il film è piuttosto sconnesso, confusionario e surreale. Molti dialoghi non hanno un vero senso e la sequenza degli eventi è raramente chiara e logica. Sharp ha detto al sito Ars Technica che appena lui e gli attori si sono messi a leggere la sceneggiatura, tutti hanno iniziato a ridere di gusto». Ha poi spiegato che c’è un interessante elemento ricorrente: «gli attori [di Sunspiring ] dicono spesso cose come “non lo so” e “non sono sicuro”, che sono reminiscenze di molti film di fantascienza in cui i personaggi cercano di capire il contesto in cui si trovano e il perché ci sono finiti in mezzo». </p>
<p> Il sito di tecnologia The Next Web ha recensito Sunspiring scrivendo: «È più o meno quello che ci si aspettava, considerando come se la sono cavata altre intelligenze artificiali in altre attività creative». Il riferimento è a Google, che fa studiare la sua intelligenza artificiale leggendo romanzi rosa e «ancora deve scrivere qualcosa che sia degno d’essere pubblicato». Il Guardian ha scritto che Sunspiring «riesce stranamente a intrattenere ed è una stranamente toccante storia di amore e angoscia». La conclusione è però: «i robot forse stanno arrivando, ma per ora gli sceneggiatori non hanno nulla da temere. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2017/07/31/telecamera-infrarossi-iphone/" parent_folder="Il Post 2016-17" id="file17861961" filename="telecamera-infrarossi-iphone">
<p> Forse il nuovo iPhone avrà una telecamera a infrarossi per il riconoscimento facciale </p>
<p> Almeno un modello dei prossimi iPhone, che saranno presentati da Apple a fine settembre, potrebbe avere una telecamera a infrarossi per il riconoscimento facciale. La notizia è stata data da alcuni siti di tecnologia, dopo che diversi sviluppatori avevano trovato indizi della cosa analizzando il firmware di HomePod, la cassa per la musica presentata da Apple a inizio giugno, diffuso ieri da Apple, probabilmente per errore. Il firmware di HomePod, ha spiegato The Verge, è basato sullo stesso software usato per gli iPhone e in alcune righe di codice sono stati trovati riferimenti a una cosa chiamata BKFaceDetect, dove BK starebbe per Biometric Kit. Si tratterebbe di una telecamera a infrarossi in grado di riconoscere il volto del proprietario dell’iPhone e sbloccare il telefono automaticamente, anche in condizioni di scarsa luminosità. </p>
<p> I can confirm reports that HomePod’s firmware reveals the existence of upcoming iPhone’s infra-red face unlock in BiometricKit and elsewhere pic.twitter.com/yLsgCx7OTZ </p>
</doc>
<doc url="https://www.ilpost.it/2016/11/11/trump-ha-vinto-grazie-a-facebook/" parent_folder="Il Post 2016-17" id="file17861952" filename="trump-ha-vinto-grazie-a-facebook">
<p> Trump ha vinto grazie a Facebook? </p>
<p> Se lo stanno chiedendo in molti, discutendo del ruolo del social network nella grande diffusione di notizie false – soprattutto su Hillary Clinton – durante la campagna elettorale </p>
<p> La vittoria di Donald Trump alle elezioni presidenziali negli Stati Uniti richiederà anni di studi – politici e sociologici – per essere compresa nella sua interezza. Gli articoli e le analisi pubblicate sui giornali negli ultimi giorni dimostrano l’enorme complessità del tema, e al tempo stesso il rischio di ridurlo a stereotipi o a chiacchiere da bar: hanno prevalso gli stupidi, ha vinto il malcontento generale, hanno votato solo i bianchi, è colpa dei giornalisti, dei social network e via discorrendo. La vittoria di Trump è queste cose e molto altro, eppure un cospicuo numero di analisi si sta concentrando sul ruolo di Facebook e sulla sua incapacità di tenere sotto controllo le notizie false condivise dai suoi utenti durante la campagna elettorale, che avrebbero favorito almeno in parte l’elezione di Trump, a scapito di Hillary Clinton. Il tema è discusso da tempo ed è legato al cosiddetto fenomeno della “democrazia post-fattuale“, che finora aveva avuto in Brexit il caso più emblematico. </p>
<p> Le notizie false su Facebook Il problema delle notizie false su Facebook esiste da tempo e da prima della candidatura di Donald Trump nel luglio del 2015, ma è diventato ancora più significativo e rilevante negli ultimi mesi con la proliferazione di siti che hanno pubblicato bufale di ogni tipo, quasi sempre contro Clinton. Secondo Olivia Solon del Guardian, la quantità di “false notizie e disinformazione ha interessato le elezioni del 2016 su una scala senza precedenti” a tal punto da sostenere che: “Invece di mettere in contatto le persone – l’obiettivo spesso enfatizzato da Facebook – l’aspra polarizzazione sul social network negli ultimi 18 mesi suggerisce che Facebook stia avendo un ruolo nel dividere il mondo”. </p>
<p> Le critiche sono soprattutto rivolte alla sezione Notizie (Newsfeed), la parte più in evidenza di Facebook dove sono mostrati i post dei propri amici, con i link che hanno condiviso o commentato, insieme agli articoli segnalati dalle Pagine dei siti d’informazione. Non sono mostrati in ordine cronologico come avviene su Twitter, ma con una gerarchia stabilita da un discusso algoritmo sulla base dei gusti dei singoli utenti e delle cose su cui di solito mettono “Mi piace” o cliccano ogni giorno. Facebook sostiene da sempre che questa soluzione permette di offrire un’esperienza più personalizzata, ma da anni il funzionamento della sezione Notizie è criticato perché di fatto rende meno probabile che si vedano post e notizie di chi la pensa diversamente da noi. I più critici sostengono che Facebook crei “micro-bolle” intorno a ogni utente, nelle quali sono escluse le cose che non gli piacciono e in cui è più semplice ricevere “Mi piace” e commenti da chi la pensa allo stesso modo (le reazioni degli altri sono la principale forma di ricompensa per chi cerca approvazione e rinforzi positivi nella sua esperienza sul social network: più ce ne sono più aumentano le probabilità che un utente stia a lungo su Facebook e visualizzi più pubblicità). </p>
<p> La sezione Notizie esisteva già alle elezioni presidenziali del 2012, ma in quattro anni è cambiata sensibilmente e ha assunto una maggiore rilevanza nella vita di molte persone, considerato che Facebook conta ormai più di 1,7 miliardi di iscritti in tutto il mondo. Nella primavera di quest’anno, il social network ha ricevuto molte critiche quando si è scoperto che per gestire la sua sezione “Trending” – che mostra un elenco dei contenuti più di tendenza negli Stati Uniti – una redazione di poche persone si basava su una lista limitata di fonti d’informazione, legate per lo più alla stampa di area progressista e con una scarsa rappresentanza di quella conservatrice. Facebook ha risposto alle accuse organizzando incontri con delegazioni di conservatori e ha infine rimosso la redazione, rendendo completamente automatica la gestione degli argomenti di tendenza tramite un algoritmo. La scelta avrebbe dovuto teoricamente riequilibrare la situazione (ammesso ci fossero squilibri), ma ha peggiorato le cose rendendo più probabile la proliferazione di notizie false, che gli algoritmi da soli faticano a identificare e a rendere meno visibili su Facebook. </p>
<p> Secondo un’analisi pubblicata su BuzzFeed e coordinata da Craig Silverman, tra i più competenti studiosi delle bufale online, il 38 per cento dei post pubblicati da tre delle più grandi pagine conservatrici su Facebook e vicine al Partito Repubblicano contengono “notizie false o ingannevoli”, a fronte del 19 per cento riscontrato nelle tre principali pagine vicine al Partito Democratico. Queste fonti parlano principalmente ai sostenitori dei due schieramenti, che non solo si fidano, ma vogliono proprio credere nei post che leggono per rinforzare le loro convinzioni politiche. Una notizia falsa ha la possibilità di diffondersi molto rapidamente, tra “Mi piace” e condivisioni, e di raggiungere centinaia di migliaia e in molti casi milioni di persone. </p>
<p> Trump e la promozione delle notizie false Nel caso dei Repubblicani, le notizie false su Facebook sono circolate ancora di più proprio a causa dello stesso Trump, che le ha utilizzate spesso nei suoi comizi dando loro maggiore autorevolezza. Politifact, il principale e più autorevole sito di verifica dei fatti (fact-checking) negli Stati Uniti, ha stimato che nel corso della campagna elettorale Trump abbia detto nel 70 per cento dei casi menzogne più o meno gravi, molte delle quali basate proprio sugli articoli dei siti di bufale conservatori che riscuotono molto successo su Facebook, senza ricevere penalizzazioni da parte dei suoi algoritmi. Oltre a rafforzare nell’elettorato convinzioni sbagliate e non basate sui fatti, grazie alla loro evidenza nella sezione Notizie i siti di bufale ricevono milioni di visite che si traducono in ricavi grazie alle pubblicità. E proprio la prospettiva di aumentare gli incassi porta a ulteriori distorsioni, con la pubblicazione di notizie sempre più clamorose e inventate per attirare nuovi clic. </p>
<p> Fil Menczer, docente presso l’Indiana University, ha calcolato che passano circa 13 ore tra la diffusione di una notizia falsa e quella di un articolo che la smonta, un’eternità per i ritmi frenetici dei social network. In 13 ore una bufala fa in tempo a diffondersi su più profili e Pagine e a essere vista da milioni di persone. Molto spesso, spiega Menczer, raggiunge una tale inerzia da sovrastare e nascondere gli articoli che spiegano come stanno effettivamente le cose. Il fenomeno delle notizie false esisteva naturalmente prima dei social network, ma la loro capacità di diffondersi era limitata al passaparola o a sistemi di condivisione più diretti, come le email e i forum di discussione, e i media avevano più possibilità di filtrarle e smontarle prima che raggiungessero l’opinione pubblica. “Ora il filtro siamo noi”, spiega Menczer, “ma non è il nostro lavoro e quindi non siamo bravi a farlo. Poi interviene l’algoritmo di Facebook ad amplificarne gli effetti”. </p>
<p> La difesa di Mark Zuckerberg Mark Zuckerberg, il CEO di Facebook, ha respinto le critiche circolate nelle ultime ore e che attribuiscono alla sua azienda parte della responsabilità nell’elezione di Donald Trump. Durante un intervento alla conferenza Technonomy a Half Moon Bay, California, ha detto che ci sono sicuramente margini per migliorare gli algoritmi, ma che è assurdo dare la colpa a Facebook: «È un’idea piuttosto da matti pensare che Facebook abbia condizionato in qualsiasi modo le elezioni». Secondo Zuckerberg, le persone votano sulla base delle loro esperienze: chi sostiene che in molti abbiano votato in un certo modo a causa delle notizie false dimostra “una profonda assenza di empatia” per i sostenitori di Trump. </p>
<p> Zuckerberg ha spiegato che gli algoritmi della sezione Notizie sono rivisti periodicamente e che, dagli studi condotti finora, non è mai emerso un particolare problema: «Il filtro principale del sistema non è il fatto che non ci siano determinati contenuti, ma che quando li vedono le persone non ci cliccano sopra». Zuckerberg aveva sostenuto la stessa cosa anche nei mesi scorsi prima delle elezioni, ma dopo la vittoria di Trump questa posizione è stata considerata ancora più debole e inconsistente. Se da un lato è vero (sono misurabili) che le persone meno interessate non cliccano sulle notizie false nella loro sezione Notizie, dall’altro è altrettanto vero che in molti si accontentano di leggere titoli e anteprime dei link sul social network per farsi un’idea di una notizia, soprattutto se rafforza le loro convinzioni. Molti “Mi piace” sono messi a un’anteprima di un articolo su Facebook senza che poi lo stesso sia letto. Alcune pagine sono inoltre create con nomi simili a quelli dei grandi media, con l’obiettivo di trarre più facilmente in inganno gli utenti, facendogli credere di essere una fonte più autorevole. </p>
<p> Facebook poteva fare diversamente? Max Read sul New York Magazine ha scritto un articolo molto colpevolista intitolato “Donald Trump ha vinto a causa di Facebook”, nel quale dice che milioni di utenti “sono stati esposti o hanno condiviso notizie emozionalmente forti sui loro candidati, perché l’algoritmo di Facebook ha capito dal modo in cui stavano utilizzando il social network che erano alla ricerca di storie di questo tipo”. Secondo Read questo ha portato a evidenti distorsioni della realtà, che alla fine si sono tradotte nel risultato elettorale di martedì notte: il verosimile ha sostituito la realtà e sono mancate le possibilità, per chi aveva meno risorse, di distinguere le cose vere da quelle false. Anche Jay Rosen, docente di giornalismo presso la New York University, è stato molto duro: “Qualsiasi dipendente di Facebook dotato di un mimino di autoconsapevolezza dovrebbe essere molto preoccupato per avere contribuito a questo disastro di civismo”. </p>
<p> Alcuni ex manager di Facebook hanno riconosciuto l’esistenza del problema e l’inefficacia con cui viene affrontato dall’azienda, come ha scritto Bobby Goodlatte: “Breitbart e innumerevoli altri siti conservatori hanno prosperato negli ultimi anni. Sfortunatamente il loro veicolo principale di diffusione è stato Facebook. La sezione Notizie è ottimizzata per fare aumentare il coinvolgimento degli utenti e, come abbiamo potuto constatare durante queste elezioni, le stronzate sono molto coinvolgenti”. </p>
<p> Matthew Ingram, giornalista che da anni si occupa di social media, ha ricordato su Fortune che per identificare le notizie false Facebook pensa che sia sufficiente fare affidamento sugli utenti, che hanno la possibilità di segnalare un post in modo che possa essere poi rivisto dai responsabili del social network, e in casi estremi rimosso. Ma ci sono due problemi non trascurabili: il primo è che se una storia falsa fa da rinforzo a una propria convinzione (o mette in cattiva luce il candidato avversario) difficilmente viene segnalata anche se riconosciuta come una bufala, il secondo è che il metodo di segnalazione è inefficace e macchinoso, e non porta sempre alla rimozione di un dato contenuto. </p>
<p> In passato per risolvere il problema è stato proposto un segno di riconoscimento sui post, qualcosa da inserire per indicare la presenza di una bufala, ma finora i responsabili di Facebook si sono rifiutati di sviluppare un sistema di questo tipo. L’indicazione consentirebbe di non censurare contenuti, anche se palesemente falsi, ma al tempo stesso di dare qualche strumento in più agli utenti per capire che cosa hanno davanti. Altri hanno suggerito di adottare un sistema simile a quello introdotto poche settimane fa da Google per gli articoli segnalati nella sua sezione News: il motore di ricerca ha aggiunto un’etichetta che viene mostrata a fianco degli articoli che fanno fact-checking, e che provengono da fonti affidabili. </p>
<p> Facebook sostiene di non volere intervenire con un giudizio sui contenuti perché non ritiene di essere una “media company”, ma solamente un sistema per mettere in contatto le persone e dare loro la possibilità di condividere ciò che vogliono con i propri amici. Nei fatti, però, Facebook è comunque diventata una media company e il suo ruolo nel selezionare il modo in cui viene rappresentato il mondo per ogni utente è ormai innegabile. I più critici ritengono che quindi dovrebbe applicarsi di più per ridurre la proliferazione delle falsità. </p>
<p> Cosa è falso e cosa è vero Trovare il giusto equilibrio è comunque molto difficile, soprattutto se per dimostrare di non essere una media company si decide di affidare a un automatismo la verifica dei contenuti. Come ricorda J.K. Trotter su Gizmodo, è praticamente impossibile insegnare a un algoritmo a riconoscere le notizie inaccurate, sia per le ambiguità tipiche del linguaggio (compresi modi di dire e sarcasmo) sia perché spesso i sostenitori di una parte condividono notizie vere provenienti dai loro oppositori definendole falsità, anche se sono fatti verificabili e genuini. Il caso delle email di Hillary Clinton in questo senso è esemplare: il New York Times lo ha trattato come un grande scandalo, con numerose inchieste e approfondimenti, mentre Vox lo ha definito “una stronzata sopravvalutata”. Le indagini dell’FBI non hanno in effetti portato alla formalizzazione di accuse nei confronti di Clinton, ma hanno comunque svelato una certa spregiudicatezza nel gestire informazioni di rilievo pubblico come le attività svolte da segretario di Stato americano. </p>
<p> Dire che l’uso privato delle email di Clinton fosse “sopravvalutato” è, naturalmente, una questione di interpretazione. Ed è sicuramente distante dall’affermare che lo staff di Clinton fosse solito praticare rituali satanici. Definiremmo la seconda una bufala, o un inganno intenzionale, invece di una semplice stronzata. Ma se accettiamo che Facebook non faccia distinzioni, è difficile dire, dal punto di vista dell’utente medio di Facebook, se anche i media affidabili – non un semplice blog creato appositamente nell’Europa dell’est – siano caduti nello stesso meccanismo di falsità e disinformazione. </p>
<p> Trotter ricorda inoltre che per mesi i siti più riconosciuti e affidabili hanno pubblicato su Facebook articoli in cui scrivevano, sulla base dei sondaggi e delle loro valutazioni, che Trump non sarebbe mai diventato presidente. Molti articoli titolavano proprio “Trump non sarà mai presidente”, e come si sarebbe dovuto comportare l’algoritmo in questi casi? Non erano notizie false comparabili a quelle dei siti di bufale, ma c’è da chiedersi se non abbiano comunque condizionato il comportamento di alcuni elettori. Leggendo di continuo che avrebbe vinto Clinton, gli elettori Democratici meno motivati e convinti potrebbero aver scelto di non andare ai seggi, pensando che comunque non ci fossero speranze per Trump. </p>
<p> L’esempio di Trotter è probabilmente estremo nel senso opposto rispetto alle critiche sulla proliferazione di bufale sui social network, ma aiuta a comprendere la difficoltà nello stabilire dove debba essere messo un limite sul piano informativo e se un’azienda come Facebook debba farsi carico di rimuovere e censurare alcuni contenuti. Trovare il giusto equilibrio è molto complicato e a Zuckerberg va comunque riconosciuto di avere accettato alcune critiche, soprattutto negli ultimi mesi, impegnandosi a migliorare il funzionamento della sezione Notizie. </p>
<p> E quindi? La discussione sul ruolo di Facebook e degli altri social network nell’elezione di Donald Trump è appena iniziata a proseguirà a lungo, e potrà essere davvero proficua solo se ci saranno analisi puntuali dei dati aggregati, per comprendere meglio il comportamento dei milioni di statunitensi che poi sono andati a votare. È innegabile che Facebook abbia influito nelle elezioni, ma per ora non è possibile dire fino a che punto e su quale scala. Gli stessi social network, del resto, sono solo una parte della vita di chi li utilizza e una delle fonti con cui si formano un’idea sul mondo che li circonda. L’elettorato negli Stati Uniti è molto vario e ci sono altre variabili da tenere in considerazione, dalle condizioni sociali ed economiche all’età, passando per le inclinazioni dei singoli e le loro convinzioni. Questo non significa trascurare il ruolo di Facebook o assolverlo completamente: informarsi e capire le cose costa fatica, i social network dovrebbero concorrere a rendere il processo meno faticoso, non il contrario. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/01/20/usare-siri-in-pubblico-e-da-maleducati/" parent_folder="Il Post 2016-17" id="file17861944" filename="usare-siri-in-pubblico-e-da-maleducati">
<p> Usare Siri in pubblico è da maleducati? </p>
<p> Dipende dal contesto: ma se una cosa vi metterebbe in imbarazzo tra colleghi, meglio evitare di farla tra sconosciuti </p>
<p> di Hayley Tsukayama – Washington Post </p>
<p> L’altro giorno ho ricevuto un SMS che mi ha fatto capire una cosa importante sul galateo moderno e i sistemi di controllo vocale dei dispositivi tecnologici, e quanto fossi stata maleducata senza nemmeno rendermene conto. Ero tornata a casa da Las Vegas con un volo notturno, avevo le mani piene di bagagli e non avevo voglia di appoggiare tutto a terra per rispondere al messaggio. Così ho fatto quello di solito faccio a casa, quando ho le mani insaponate o sporche di farina: con voce chiara e un po’ perentoria, ho detto: «Ehi, Siri…». La donna di fronte a me si è girata immediatamente e ha aperto la bocca come per rispondere, salvo poi fermarsi. Aveva lo sguardo perplesso e quasi offeso. Parlavo con lei? Stavo davvero impartendo un ordine a un perfetto estraneo? </p>
<p> L’episodio mi ha fatto riflettere. Mentre siamo alla ricerca di nuovi metodi per controllare i nostri dispositivi tecnologici, sta diventando evidente che alcuni di essi sono più adatti a essere usati in pubblico, mentre sarebbe meglio limitarne altri a un uso più privato. Per me il controllo vocale – che sta diventando una funzione importante in moltissimi dispositivi – rientra senza dubbio nella seconda categoria: è meglio usarlo quando si è da soli con il proprio telefono. In fondo, se detestiamo quando la persona che mentre cena con noi se ne sta ricurva su uno schermo, non sarebbe forse molto peggio se fosse impegnata in una conversazione totalmente diversa senza di noi? Vi è mai capitato di avere una mezza conversazione con qualcuno, per poi scoprire che stava parlando al telefono con il bluetooth o l’auricolare? Ritrovarsi in mezzo a una conversazione tra una persona e il suo assistente inanimato è la stessa cosa, solo peggiore. E non sono l’unica a pensarla così. </p>
<p> «Credo davvero che attivare il controllo vocale sia inappropriato, in certi posti: per strada, in metropolitana, in ascensore, in auto, quando si è in fila per ordinare un panino o un caffè. Non lo userei in questi posti», ha detto Lizzie Post, bis-bisnipote di Emily Post (scrittrice americana esperta di galateo), autrice di libri e podcast sul galateo nell’età moderna per il Post Institute. Post fa notare come a volte sia strano usare la tecnologia nelle nostre conversazioni, anche in contesti più privati: ha raccontato di una volta in cui stava buttando giù delle idee per un progetto con una persona, che a un certo punto ha tirato fuori il telefono per fare ricerca su internet usando il controllo vocale. «Non è stato piacevole», ha detto Post. «Non aveva motivo di non usare la tastiera: non aveva bisogno di avere le mani libere. È come dare ordini a una segretaria, quando non ce n’è bisogno». </p>
<p> Non dico che il controllo vocale sia una cosa negativa. Può salvarci la vita – letteralmente – quando ci evita di armeggiare con il touchscreen mentre siamo al volante. Come tutti, sono entusiasta all’idea che Apple stia progettando degli auricolari wireless che permettono di controllare Siri, o che Amazon stia lavorando a una versione portatile di Echo (un altoparlante wireless a controllo vocale). A casa, con la propria famiglia, parlare con i propri dispositivi per impostare un timer o un promemoria va bene. Si tratta però di situazioni in cui si è soli, o dove comunque è accettabile distogliere l’attenzione per un attimo. In altri contesti sociali molte persone, quando parlano con i loro dispositivi, tendono a modulare la propria voce come se stessero impartendo degli ordini. Come ho fatto io in aeroporto. Questo atteggiamento porta le persone a drizzare le antenne e prestare attenzione, anche quando pensiamo di essere discreti. Meglio non dire con tono brusco al proprio telefono «Ricordami di comprare il deodorante» sul pullman. E lo stesso vale per dettare email quando i propri colleghi sono vicino (per non parlare di quando l’email è sui colleghi). Anche frasi innocue come: «Tesoro, sono un po’ in ritardo», se dette a voce alta e in pubblico, catapultano le persone in discussioni alle quali non hanno mai chiesto di partecipare. Situazioni come queste possono mettere a disagio, soprattutto se avvengono all’improvviso e danno alle persone intorno a noi la sensazione di essere capitate per sbaglio in una conversazione privata. E mettere a disagio le persone che ci circondano è grosso modo la definizione di “maleducato”. </p>
<p> Il che rimanda alla contrapposizione tra tecnologia pubblica e privata. Ho trovato un modo semplice per distinguere le due categorie: se si tratta di qualcosa che vi farebbe sentire stupidi al lavoro, allora è probabilmente tecnologia privata. Alcuni esempi per definire meglio il concetto: i sistemi di scansione oculare possono essere usati in pubblico, perché non sono invadenti. La realtà virtuale è privata, perché isola letteralmente tutti gli stimoli sensoriali dal mondo esterno. La realtà aumentata – che combina il mondo digitale con quello virtuale – è più ambigua, ma si potrebbe dire che è pubblica, perché permette di continuare a interagire con il mondo – e le persone – intorno a noi. Per quanto riguarda il riconoscimento dei gesti, dipende dalla situazione: se ci si deve sbracciare, meglio farlo a casa. Se si è più discreti, invece, come nel caso di un movimento della mano per passare alla slide successiva di una presentazione, probabilmente va bene. </p>
<p> Con questo non voglio dire che una tecnologia sia più utile o più sociale di un’altra: usare la realtà virtuale può essere sorprendentemente piacevole quando si conversa con un’altra persona. Lo stesso vale per il controllo vocale: dettare un messaggio può far risparmiare tempo e essere più precisi rispetto a digitare frettolosamente un testo con il pollice. Ma queste sono situazioni in cui si usa la tecnologia per facilitare la comunicazione, e non per eluderla. Quindi usate pure Siri, Cortana, Google o Alexa, ma tenete presente il contesto in cui vi trovate. «Il consiglio che diamo per andare sul sicuro con ogni tipo di tecnologia è pensare innanzitutto alle persone con cui siamo», ha detto Post. È un buon consiglio per il controllo vocale, e per qualsiasi altra tecnologia folle e meravigliosa dovesse saltar fuori in futuro. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
<doc url="https://www.ilpost.it/2016/10/14/visori-realta-virtuale-oculus-rift-playstation-vr/" parent_folder="Il Post 2016-17" id="file17861964" filename="visori-realta-virtuale-oculus-rift-playstation-vr">
<p> Vale la pena comprare un visore per la realtà virtuale? </p>
<p> Google, Facebook, Samsung e tanti altri dicono che i loro visori sono il futuro della tecnologia, ma non è chiaro per farci cosa </p>
<p> Mark Zuckerberg, il CEO di Facebook, è convinto che in un futuro neanche troppo lontano l’umanità passerà parte del suo tempo con un affare in faccia, un visore fatto apposta per entrare in mondi virtuali di ogni tipo in cui ritrovarsi con gli amici, navigare su Internet, guardare film e giocare ai videogiochi. Da quando ha acquisito la società specializzata in realtà virtuale Oculus, Facebook ha investito decine di milioni di dollari per raggiungere l’obiettivo immaginato da Zuckerberg, e per arrivarci prima dei concorrenti che ripongono altrettanta fiducia nei caschi e nei visori. Oltre a quelli di Oculus, sul mercato ci sono già decine di altri sistemi per la realtà virtuale e l’offerta non manca, anche se per ora la richiesta di questi prodotti è limitata e non è chiarissimo se riusciranno a ritagliarsi uno spazio diventando per lo meno complementari con altri dispositivi, come gli smartphone. Per i più critici, i visori per la realtà virtuale sono meno utili degli smartwatch e non hanno futuro; per i più ottimisti come Zuckerberg sono il futuro della comunicazione, solo che non lo abbiamo ancora capito. </p>
<p> Ma non ne parlavamo già 20 anni fa? I sistemi per la realtà virtuale non sono di per sé una novità. I primi dispositivi per dare l’opportunità allo spettatore di sentirsi parte di ciò che sta vedendo sullo schermo, coinvolgendo i suoi sensi in maniera realistica, furono teorizzati negli anni Cinquanta e già nei primi anni Sessanta ne furono realizzate versioni che funzionavano meccanicamente come il Sensorama. Il primo sistema di realtà virtuale per come lo intendiamo oggi fu realizzato dal Massachusetts Institute of Technology (MIT) nel 1977, ma solo tra la fine degli anni Ottanta e i primi Novanta furono introdotti caschi che avrebbero dovuto simulare realisticamente mondi immaginari, coinvolgendo completamente lo spettatore. </p>
<p> La realtà virtuale non ha mai fatto davvero presa, sostanzialmente per problemi di praticità e di resa dei visori. Il principale problema, rimasto insormontabile fino a qualche anno fa, era legato al ritardo (“lag”) tra le cose mostrate sullo schermo del visore e i movimenti della testa dello spettatore: lo scarto di poche frazioni di secondo era sufficiente per consentire al cervello di distinguere la scena della realtà, rendendo inutile l’effetto della virtualità. In molte persone il ritardo causava inoltre rapidamente un forte senso di nausea, con un meccanismo simile a quello del mal d’auto. I progressi raggiunti negli ultimi anni con la drastica riduzione del ritardo – ormai marginale grazie a processori e sistemi più veloci per elaborare le immagini – hanno permesso di superare uno dei principali ostacoli per rendere realistici gli effetti mostrati dai visori. Quelli che ci sono riusciti meglio sono stati proprio i ricercatori di Oculus, che ancora oggi dedicano molto della loro ricerca finanziata da Facebook a ridurre sempre di più il ritardo. </p>
<p> Non c’è un solo visore Prima di comprare un visore per la realtà virtuale, è bene farsi un’idea di come è organizzata per ora l’offerta. Da una parte ci sono i visori veri e propri, come quelli prodotti da Oculus e da Sony, che servono soprattutto per i videogiochi e per avere esperienze più coinvolgenti e “immersive”, come dicono quelli che la sanno lunga; dall’altra ci sono i sistemi per trasformare il proprio smartphone in un visore. I primi sono di gran lunga più costosi dei secondi, quindi come avviene spesso nel campo dei gadget tecnologici ci si deve chiedere: cosa voglio fare con un visore e cosa ci potrò fare tra un anno? Probabilmente prima di questa avrete in mente un’altra domanda: ma a che cavolo mi serve? Ci arriveremo dopo. </p>
<p> Il primo della classe A oggi il miglior casco per la realtà virtuale in circolazione è il Rift, di Oculus. Il visore ha ricevuto recensioni estremamente positive da buona parte delle testate di tecnologia ed è la migliore dimostrazione delle capacità di questi dispositivi. Ha uno schermo molto definito e un sistema di sensori per rilevare la sua posizione nello spazio, in modo da adattare meglio le immagini che mostra a seconda di come si muove la testa. Può essere utilizzato con diversi videogiochi del catalogo della console Xbox e Oculus sta lavorando per arricchire il suo Store, dal quale si possono scaricare simulatori e applicazioni di vario tipo, come dall’App Store per gli iPhone. Oculus ha inoltre presentato di recente Touch, due controller che permettono di manipolare le cose che si vedono nei mondi virtuali, usando normalmente le mani in modi piuttosto realistici. </p>
<p> Rift non è autonomo: per funzionare deve essere collegato per forza a un computer, e non a un PC qualsiasi: richiede grandi capacità di calcolo, quindi un portatile che usate per il lavoro o un computer da tavolo vecchio di qualche anno non offrirà le risorse necessarie. Oculus sta lavorando per rendere il suo visore meno ingordo, in modo che funzioni con più PC, ma attualmente l’unica soluzione per non avere cattive sorprese è comprare un computer che sia indicato come “Oculus Ready”, cioè pronto per funzionare con Rift e gli altri prodotti della società. Significa mettere in conto una spesa intorno ai 1.000 euro, che vanno aggiunti ai 699 necessari per comprarsi il Rift. La migliore realtà virtuale disponibile costa. </p>
<p> Vive vs Rift Il principale concorrente dei Rift di Oculus è Vive, un casco per la realtà virtuale prodotto dalla taiwanese HTC insieme con Valve, casa di produzione di videogiochi e tra i principali distributori di giochi online tramite la sua piattaforma Steam. Vive è in vendita dallo scorso aprile e a inizio anno ha ricevuto 22 premi al CES, la più grande fiera di elettronica al mondo che viene organizzata annualmente a Las Vegas, negli Stati Uniti. Vive ha diverse cose in comune con Rift, a partire da un sistema molto accurato per tenere traccia degli spostamenti del visore nello spazio, anche in profondità, rendendo quindi più realistiche le interazioni soprattutto nei videogiochi. Come Rift, anche Vive ha due controller che servono per manipolare li oggetti negli ambienti virtuali in modo piuttosto realistico. Il sistema funziona collegandolo a un computer, che deve essere potente a sufficienza, mentre videogiochi e altre applicazioni possono essere scaricate dalla sezione di Steam per la realtà virtuale. </p>
<p> La principale differenza tra Vive e Rift è la presenza sul primo di una videocamera nella parte frontale del casco: serve per la realtà aumentata, cioè per sovrapporre ad ambienti reali oggetti virtuali, e ha anche una funzione di sicurezza per evitare di andarsi a sfracellare contro qualche arredamento di casa quando si è molto presi in un gioco. Vive costa 899 euro. </p>
<p> Un buon compromesso Sony in questi anni ha ottenuto un grande successo con la sua PlayStation, una delle console per videogiochi più vendute al mondo, e per mantenerlo sta cercando di anticipare i concorrenti con un suo visore che ha chiamato PlayStation VR per sfruttare un marchio già molto conosciuto. A differenza di Oculus, il sistema per la realtà virtuale di Sony funziona collegandolo a una PlayStation e sfrutta in parte soluzioni già messe in vendita in passato dall’azienda, come i controller per gestire le azioni di gioco muovendoli nello spazio e non solo schiacciando tasti. Il PlayStation VR ha una resa inferiore rispetto al Rift, ma in compenso può contare su un catalogo piuttosto ampio di giochi già compatibili con il nuovo sistema e con applicazioni per usare il visore in contesti diversi da quelli dei videogiochi. </p>
<p> Oltre a non richiedere l’acquisto di un computer potente a sufficienza, il PlayStation VR è più semplice da configurare e funziona senza intoppi con la console di Sony, a patto che sia una PlayStation 4. Anche il prezzo è inferiore rispetto ai Rift: il PlayStation VR costa 399 euro. Nella confezione non è però compreso il sensore per rilevare gli spostamenti del casco nello spazio, questo perché è lo stesso sistema già usato per i controller PlayStation Move. Chi non li ha mai acquistati dovrà quindi spendere altri 69 euro per la PlayStation Camera. </p>
<p> Più economici Come dicevamo in precedenza, c’è una seconda categoria di caschi per la realtà virtuale molto più economici: sono quelli che funzionano trasformando il proprio smartphone in un visore. Ne esistono decine di modelli, ma il principio di base è più o meno lo stesso per tutti: hanno uno scompartimento in cui inserire lo smartphone, con lo schermo rivolto verso le lenti attraverso cui si osservano i mondi virtuali. È quindi lo smartphone a rilevare con i suoi sensori i movimenti della testa e a regolare di conseguenza l’immagine mostrata sullo schermo, anche se alcuni modelli offrono sensori aggiuntivi per rendere più precise le rilevazioni. La resa è inevitabilmente inferiore rispetto a quella del Rift e può esserci un po’ di ritardo, quindi sono visori adatti per vedere fotografie e video panoramici in modo più coinvolgente, mentre non sono molto utili per i videogiochi. </p>
<p> Prima di acquistare uno di questi visori è necessario verificare che sia compatibile con il proprio smartphone. Samsung, il più grande produttore di smartphone al mondo (ultimamente con qualche guaio), ha realizzato il suo Gear VR in collaborazione con quelli di Oculus. Il visore è compatibile con gli smartphone Galaxy S7 ed S6 e le loro varianti Edge, e può essere utilizzato anche con i Note 5; costa 129 euro e può essere usato con numerose applicazioni, sia per vedere passivamente contenuti sia per giocare. Altri produttori come LG, Zeiss e di recente Google hanno iniziato a produrre visori per diversi smartphone, anche a prezzi inferiori. Alcuni sono compatibili con gli iPhone, anche se finora Apple non ha dimostrato particolare interesse per queste soluzioni. </p>
<p> Ok, ma che me ne faccio? I visori come il Rift e il PlayStation VR al momento danno il loro meglio nel campo dei videogiochi, soprattutto con quelli che sono stati progettati già con in mente la realtà virtuale come sistema di fruizione: si gioca in modo diverso, ci si sente molto più coinvolti, forse persino più responsabilizzati nei confronti dei propri personaggi. Il problema è che per ora i titoli realizzati per i visori sono pochi e sarà necessario qualche mese prima di avere un minimo di scelta. Per quanto futuristici, i visori per gli smartphone sono invece più spartani e danno il meglio in ambiti ristretti, legati più che altro alla visione di fotografie e video panoramici. Sono ideali per fare un salto su Marte, guardare qualche video a 360° su Facebook e YouTube, ma dopo qualche minuto viene da sfilarseli per tornare a usare normalmente il proprio smartphone. </p>
<p> Difetti Utilizzando un visore per la realtà virtuale si ha la netta impressione di avere per le mani, anzi in faccia, una tecnologia che deve ancora maturare molto. Le idee di base su come farla funzionare ci sono tutte e alcune aziende, come Oculus, hanno lavorato moltissimo sui dettagli, ma c’è ancora molto da fare. I visori sono ingombranti, pesano ancora troppo, schiacciano la faccia, sono una tortura se indossi gli occhiali e non riesci a regolarli bene, tengono caldo e danno un lieve senso di claustrofobia, nonostante il loro intento di aprire la vista e gli altri sensi verso nuovi mondi, fantastici o irraggiungibili. I sistemi più potenti funzionano inoltre solo se sono collegati a un PC o a una console per videogiochi, per lo più solo via cavo, perché la quantità di dati che deve essere trasmessa non rende pratico l’utilizzo di sistemi senza fili. Per contro, i visori per gli smartphone registrano solo i movimenti della testa, ma non gli spostamenti in profondità nello spazio: non capiscono quindi se stai avanzando, o se per esempio ti stai sporgendo per guardare oltre un cornicione virtuale. </p>
<p> Un giorno forse Sono tutti difetti superabili, comunque: la tecnologia di questi dispositivi si sta evolvendo molto rapidamente, e basta pensare a come fossero i caschi per la realtà virtuale solo un paio di anni fa per rendersene conto. In futuro probabilmente avremo visori talmente potenti e miniaturizzati da essere inseriti sulle montature degli occhiali da sole e da vista, senza grandi ingombri e cavi che ci tengono costretti a un computer da tavolo. Una sorta di versione evoluta e davvero funzionante dei Google Glass, il progetto molto ambizioso di Google ormai quasi del tutto abbandonato dopo gli insuccessi registrati negli ultimi anni. Ma anche pensando alla migliore tecnologia possibile, è difficile ora come ora immaginare un futuro in cui inforcheremo un paio di occhiali per vedere i nostri amici, senza vederli veramente, in ambienti virtuali in cui giocare a biliardo o guardare insieme un film. </p>
<p> Durante un evento organizzato da Oculus a San Jose, in California, la settimana scorsa, Zuckerberg ha illustrato un prototipo dei sistemi di realtà virtuale che metteranno insieme Facebook e i visori per la realtà virtuale. L’idea è trasferire in ambienti tridimensionali le interazioni con i propri amici, mettendo insieme applicazioni e funzioni diverse. La dimostrazione di Zuckerberg è stata a tratti sorprendente, ma l’impressione è che nessuno abbia ancora capito come padroneggiare e rendere convincente questa tecnologia oltre al suo impiego nei videogiochi. </p>
<p> Questo articolo non è più commentabile. Abbonati al Post per commentare le altre notizie. </p>
</doc>
