<doc url="https://www.repubblica.it/tecnologia/2019/12/18/news/2010-2020_la_tecnologia_che_ci_ha_cambiato_la_vita-243735422/" parent_folder="Repubblica 2018-2020" id="file17861739" filename="2010-2020_la_tecnologia_che_ci_ha_cambiato_la_vita-243735422">
<p> 2010-2019, la tecnologia che ci ha cambiato la vita </p>
<p> di TIZIANO TONIUTTI </p>
<p> Dagli assistenti vocali alla guida autonoma, e poi tablet e dispositivi indossabili: ecco le idee hi-tech che hanno segnato questa decade </p>
<p> Un anno che passa, nel mondo della tecnologia, vale come dieci in quello degli umani. Tutto evolve esponenzialmente e cambia sempre più profondamente la nostra vita, che nell'ultimo decennio è diventata molto, molto più digitale. Dall'inizio del 2010 al 2020 che verrà, ecco le pietre miliari tecnologiche che hanno già modificato il nostro mondo, e gettato i semi per i cambiamenti che arriveranno nel prossimo decennio. </p>
<p> Assistenti vocali/Internet delle cose. Ok Google, Alexa!, Ehi Siri!... quanti di noi pronunciano queste "parole magiche" ogni giorno? Ormai miliardi di persone nel mondo, tanto che i team di sviluppo dietro queste intelligenze artificiali occupano ormai decine di migliaia di sviluppatori. L'assistente vocale che abbiamo nei telefoni, negli smart speaker e negli smartwatch è ormai perfettamente integrato con il nostro quotidiano: ci informa, ci dice che strada fare, ci intrattiene, si occupa di comunicare e gestire per noi tutti gli oggetti e i dispositivi connessi immaginabili, dall'illuminazione alla climatizzazione, dalla sicurezza alle serrature. L'intelligenza artificiale interagisce con noi ascoltandoci continuamente e fungendo da segreteria personale. Il prossimo passo saranno i robot che potranno aiutarci oltre che con la voce, anche fisicamente. Hanno già iniziato in realtà: in commercio esistono robot per le pulizie domestiche che rispondono ai comandi vocali. </p>
<p> Streaming. Una parola ormai onnipresente. Cinema, tv e musica sono diventati servizi on-demand, fruibili da ovunque ci sia una connessione internet e un dispositivo adatto, superando di fatto l'era della televisione e marginalizzando molto altri media e formati come cinema e musica incisa. Netflix, Spotify, Apple Music e Tv+, Disney Plus, Amazon Prime Video e Music sono solo alcuni dei nomi dei nuovi protagonisti della rivoluzione streaming. Ma non c'è solo l'intrattenimento: oltre ai flussi video dei grandi network, oggi chiunque può trasmettere la propria vita in diretta 24 ore su 24, basta uno smartphone e un social network come Facebook, Twitter, Twitch, Instagram, TikTok, Snapchat, o un sito come Youtube. Tutto entra nel flusso, lo stream appunto, che scorre sempre e incessante nel dominio digitale proprio come in quello "analogico" dei tempi di Eraclito (e anche dei nostri fino a pochi anni fa). </p>
<p> iPad. Il tablet Apple nasce nel 2010 e porta il mondo intero nell'era cosiddetta del post-computer, quella in cui tastiera, mouse e monitor non sono più la modalità primaria per interagire con un dispositivo elettronico in qualsiasi ambito, dall'intrattenimento alle applicazioni professionali. L'iPad è quello che si dice un game changer, un dispositivo che ha cambiato un intero mercato, in questo caso ne ha creato uno nuovo. Va oltre lo smartphone superandone i limiti di grandezza dei display e nel tempo cresce fino a diventare uno strumento completo in grado di essere utilizzato in ogni possibile contesto, ed è, a dieci anni dal lancio del primo modello, il tablet più venduto al mondo. </p>
<p> Guida autonoma/Adas. Gli aiuti alla guida dell'automobile, dai sistemi di rilevamento del traffico circostante fino al controllo interamente automatico (o quasi) della vettura in questi dieci anni si sono evoluti in maniera notevole. Ormai ogni auto di serie monta almeno alcune di queste tecnologie di sicurezza che erano fantascienza nei telefilm degli anni 80 come Supercar, e che oggi sono realtà, e alcune saranno obbligatorie dal 2022. Tra tutti spicca l'autopilota sempre più intelligente disponibile sul mercato, quello di Tesla, di fatto capace di condurre l'auto e i suoi passeggeri da un punto A ad un punto B senza necessità di intervento del conducente, e rispettando alla lettera il codice della strada. Guida autonoma e Adas (Advanced Driver Assistance Systems) faranno sempre più parte dell'automazione progressiva dei trasporti e nei prossimi dieci anni ne cambieranno profondamente il mercato. </p>
<p> Gig service e geolocalizzazione. La privacy è ormai un dolce ricordo del passato: siamo sempre tutti più o meno localizzabili, con tutti i vantaggi e gli svantaggi del caso. E insieme alle mappe connesse e in costante aggiornamento, negli ultimi dieci anni i servizi che le utilizzano si sono moltiplicati: dallo sharing di auto/bici/monopattini fino ai tanti servizi di delivery di ogni tipologia merceologica, dal cibo in poi, la cosiddetta gig economy è una delle piccole rivoluzioni industriali di questa ultima decade. Che porta innovazioni sicuramente, ma anche tutta una serie di tematiche e necessità di regolamentazione a protezione dei lavoratori e dei loro diritti. </p>
<p> Apple Watch / dispositivi indossabili. I wearables, dispositivi indossabili e chissà forse un giorno anche innestabili direttamente nel corpo a livello di prodotto di massa, sono la prossima vera frontiera della tecnologia personale, quella che interagisce direttamente con il fisico e lo inserisce in un contesto di applicazioni che vanno dal monitoraggio della salute alla gestione di ogni tipo di attività. Anche qui a portare i wearable sul mercato globale è Apple con il suo Watch, un prodotto "disruptive" e ormai dai dati di mercato, il più venduto orologio al mondo. Il Watch di Apple in particolare è un prodotto giunto ad un'evoluzione tecnologica tale dal poter quasi completamente sostituire lo smartphone. Nei prossimi dieci anni, dal settore degli indossabili arriveranno novità radicali, con sensori sempre più capaci di comprendere come viviamo e come potremmo vivere meglio. </p>
<p> Display Oled - MiniLed. A metà del decennio, l'arrivo dei display Oled ha cambiato tutto nel mercato dei tv e dei display. Una tecnologia che in una sola mossa ha superato la resa qualitativa (e i prezzi) di Led e Plasma, conferendo alle immagini sui display di smartphone, smartwatch e televisori un realismo e una qualità cinematografica. Ma la pur eccellente tecnologia Oled sta per essere surclassata dai Mini-Led, ancora più piccoli e diffusi sulla superficie dei pannelli, che diventeranno presto a 8K, oltre il già stupefacente 4K HDR di oggi. </p>
<p> Dispositivi flessibili/pieghevoli. E parlando di display, un altro game changer che arriva proprio in coda al decennio sono gli schermi pieghevoli. Il prodotto commerciale più avanzato in questo senso è il Samsung Galaxy Fold, da poco disponibile anche in Italia, uno smartphone con un display "normale" all'esterno ma che una volta aperto si trasforma in un tablet da 7.3 pollici. Di fatto lo schermo pieghevole consente di portarsi in tasca due dispositivi mantenendo l'ingombro di uno smartphone e qualche grammo di peso in più. Ma è una tecnologia appena nata, destinata ad evolvere rapidamente e nei prossimi anni vedremo innumerevoli dispositivi basati su display flessibili, dai telefoni agli occhiali smart, fino a televisori avvolgibili. </p>
<p> Realtà aumentata. Mentre la realtà virtuale nasce già negli anni 90, la realtà aumentata è figlia dell'ultima decade. La differenza è netta: mentre la realtà virtuale crea un mondo simulato all'interno di un visore, con la realtà aumentata si sovrappone un livello digitale a quello che i nostri occhi vedono nel mondo reale. E le applicazioni sono infinite, dai giochi alla didattica, alla progettazione industriale e all'architettura, fino all'informazione. Nei prossimi anni arriveranno visori personali leggeri con cui questo nuovo livello di profondità di ciò che ci circonda sarà visibile senza usare smartphone e tablet, e attraverso cui il mondo reale e quello digitale si fonderanno completamente in una realtà, appunto, aumentata. </p>
<p> Accessibilità. La tecnologia degli ultimi dieci anni ha fatto incredibili passi avanti nel campo dell'accessibilità, ovvero nel rendere possibili azioni e interazioni ai disabili. Aiuti vocali ma anche hardware dedicato ed esoscheletri "intelligenti" hanno ridotto di molto le distanze tra quello che prima era impossibile e ora lo è un po' meno, per i portatori di handicap. Nel campo dell'accessibilità confluiscono un po' tutte le tecnologie che abbiamo visto finora, che insieme sono in grado di realizzare strumenti complessi eppure semplici da utilizzare per chi ne ha necessità. Sono implementate sugli smartphone e sui tablet per rendere efficiente e possibile l'interazione con ogni tipo di utente, e anche nei videogame (Xbox Adaptive Controller ad esempio) per le applicazioni ludiche. </p>
<p> 5G. Il tema tecnologico che dominerà il 2020: la connettività mobile di quinta generazione. Mentre già si sperimenta quella di sesta e si sviluppa quella di settima, il 5G sarà il punto di svolta per tutto il nuovo universo di dispositivi connessi che ci aspetta nei prossimi dieci anni. La velocità di connessione wireless mobile raggiungerà quella della fibra ottica e aprirà le porte a tutta una serie di nuove possibilità, soprattutto l'interazione remota con qualunque tipo di dispositivo, praticamente in tempo reale. Una tecnologia che porterà innumerevoli nuove possibilità e almeno altrettante polemiche per la potenza delle torri radio necessarie al funzionamento. Ma ciò che accadrà davvero lo sapremo solo nei prossimi dieci anni. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/prodotti/2019/10/19/news/a_maker_faire_il_robot_cucciolo_icub_che_interagisce_con_l_uomo-238973160/" parent_folder="Repubblica 2018-2020" id="file17861724" filename="a_maker_faire_il_robot_cucciolo_icub_che_interagisce_con_l_uomo-238973160">
<p> Tecnologia </p>
<p> A Maker Faire il robot cucciolo iCub che interagisce con l'uomo </p>
<p> Ha fattezze bimbo di quattro anni ed è l'unico con pelle artificiale. Realizzato dall'Istituto Italiano di Tecnologia per studiare l'intelligenza artificiale applicata ai robot </p>
<p> 19 Ottobre 2019 1 minuti di lettura </p>
<p> ROMA - Ha la forma e le dimensioni di un bambino di circa 4 anni, interagisce con l'uomo ed è l'unico robot al mondo ad avere il proprio corpo ricoperto da una pelle artificiale. Alla Maker Faire Rome, in corso alla fiera di Roma fino al 20 ottobre, è possibile incontrare il robot 'cucciolo' iCub. È stato realizzato dall'Istituto Italiano di Tecnologia (Iit) per studiare l'intelligenza artificiale applicata ai robot. "La sua particolarità - ha spiegato all'Agenzia Ansa, Stefano Dafarra, dell'Iit - è avere il corpo rivestito da sensori tattili che, come una pelle, permettono ad iCub di capire se e come viene toccato dall'uomo, e di rispondere nella maniera adeguata". Il robot è dotato di telecamere che riproducono la vista, microfoni per la ricezione dei suoni, sensori per l'equilibrio e per misurare l'interazione con l'ambiente. </p>
<p> ICub è il robot umanoide più diffuso al mondo, con una quarantina di esemplari presenti in diversi laboratori di Europa, Stati Uniti, Giappone e Corea del Sud. "Sono utilizzati per scopi di ricerca, per capire ad esempio - precisa l'esperto Iit - come migliorare i movimenti, o l'equilibrio dei robot umanoidi, rendendoli sempre più simili a quelli umani. E, infine, come perfezionarne l'interazione con l'uomo, rispondendo ad esempio a semplici comandi vocali oppure al contatto fisico con le persone. In futuro - ha concluso - stiamo anche pensando di insegnargli a volare". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2020/06/08/news/anche_l_intelligenza_artificiale_ha_bisogno_di_dormire-258735620/" parent_folder="Repubblica 2018-2020" id="file17861717" filename="anche_l_intelligenza_artificiale_ha_bisogno_di_dormire-258735620">
<p> Tecnologia </p>
<p> Anche l'intelligenza artificiale ha bisogno di dormire </p>
<p> Le reti neurali artificiali a impulso hanno bisogno di riposare per recuperare la stabilità persa durante l'apprendimento. Proprio come il cervello umano </p>
<p> 08 Giugno 2020 1 minuti di lettura </p>
<p> In futuro i robot potrebbero schiacciare qualche pisolino: le loro reti neurali artificiali, infatti, hanno bisogno di riposare per recuperare la stabilità persa durante l'apprendimento, proprio come il cervello umano. Lo hanno scoperto i ricercatori del laboratorio statunitense di Los Alamos, in Nuovo Messico, grazie a uno studio che sarà presentato a Seattle in occasione del prossimo convegno Women in Computer Vision. </p>
<p> "Noi studiamo le reti neurali artificiali a impulso, sistemi che apprendono come il nostro cervello", spiega la ricercatrice Yijing Watkins. "Eravamo affascinati dalla prospettiva di addestrare un processore neuromorfico in modo analogo a come gli esseri umani e altri sistemi biologici imparano dall'ambiente durante lo sviluppo dell'infanzia". Gli esperimenti condotti in laboratorio, però, hanno dimostrato che dopo periodi continui di apprendimento incontrollato, le reti neurali artificiali diventano instabili. I ricercatori hanno quindi pensato di farle 'riposare' esponendole a diversi tipi di rumore (simili alle interferenze che si sentono alla radio passando da una stazione all'altra). </p>
<p> Dopo vari tentativi, hanno osservato che i cervelli artificiali recuperano una buona stabilità quando vengono esposti a un rumore cosiddetto 'gaussiano', che include un ampio spettro di frequenze e ampiezze. Da qui l'ipotesi che questo genere di rumore riproduca lo stesso input che i neuroni del nostro cervello ricevono durante la fase del sonno a onde lente. </p>
<p> Il prossimo passo dei ricercatori sarà quello di ripetere l'esperimento con Loihi, il chip della Intel ispirato al cervello umano: l'obiettivo è verificare se alcuni periodi di riposo lo possano aiutare a essere più stabile nel processare in tempo reale le informazioni provenienti da una videocamera. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2018/04/27/news/a_un_passo_da_her_adesso_l_intelligenza_artificiale_ascolta_come_noi_-194960981/" parent_folder="Repubblica 2018-2020" id="file17861710" filename="a_un_passo_da_her_adesso_l_intelligenza_artificiale_ascolta_come_noi_-194960981">
<p> Tecnologia </p>
<p> A un passo da Her: "Adesso l'intelligenza artificiale ascolta come noi" </p>
<p> di ROSITA RIJTANO </p>
<p> L'hanno realizzata i ricercatori del Mit, allenandola grazie a centinaia di clip audio della durata di due secondi </p>
<p> 27 Aprile 2018 2 minuti di lettura </p>
<p> ANCORA non parla come noi. Ma come noi ha imparato ad ascoltare. I neuroscienziati del Massachusetts institute of technology hanno sviluppato un'intelligenza artificiale che per la prima volta riesce a replicare le capacità di un essere umano nella comprensione della musica e di un discorso. Un risultato dalla portata storica, quello pubblicato sull'edizione di aprile della rivista Neuron. Perché avvicina la realtà alla fantasia. Al futuro delineato sul grande schermo dal film Her (Lei), in cui parleremo con le macchine come con una persona. Niente più fraintendimenti tra noi e Siri, o qualsiasi altro assistente vocale: ci capiranno al volo. </p>
<p> Tutto grazie a una rete neurale alla cui base c’è il deep learning, ossia quella tecnologia d’apprendimento automatico, sviluppata a partire dagli anni Ottanta, che mima il comportamento dei neuroni umani. I ricercatori del Mit l'hanno allenata per eseguire due compiti: da una parte, capire le parole dette nel mezzo di una conversazione di due secondi, dall'altra riconoscere il genere di una canzone attraverso un audio di durata altrettanto breve. In entrambi i casi, sono stati inseriti dei rumori di sottofondo per rendere l'impresa ancora più difficile e realistica. Proprio come se la macchina in questione si trovasse ad ascoltare ciò che diciamo mentre ci troviamo in un ambiente affollato. </p>
<p> Dopo aver sentito centinaia di registrazioni ad esempio, l'intelligenza artificiale ha acquisito le stesse capacità di un essere umano a svolgere gli esercizi. Anche quando si tratta di commettere degli errori: tende a fare più strafalcioni nelle clip in cui pure una persona in carne ed ossa commette maggiori sbagli. "Gli sviluppi nel campo dell'apprendimento automatico sono un'entusiasmante opportunità per le neuroscienze", ha commentato Alexander Kell, uno degli autori principali dello studio. "Ora possiamo creare dei sistemi in grado di fare alcune delle cose che noi riusciamo a fare, mettere alla prova il modello e compararlo al nostro cervello". </p>
<p> Infatti, la ricerca è anche servita a comprendere meglio la struttura della corteccia uditiva umana, suggerendone un'organizzazione gerarchia: differenti aree cerebrali risponderebbero a diversi tipi di informazioni man mano che arrivano. Un meccanismo ben documentato nella corteccia visiva: la corteccia visiva primaria reagisce a stimoli semplici, per esempio i colori o l'orientamento, le altre zone si occupano di compiti più complessi come il riconoscimento degli oggetti. Ma di cui si hanno poche evidenze quando si parla del modo in cui elaboriamo i suoni. In parte, perché fino ad ora non erano stati messi a punto modelli abbastanza buoni da replicare il comportamento umano, sostengono gli scienziati. </p>
<p> Ora il modello c'è: un'intelligenza artificiale con un orecchio umano che apre nuovi scenari nel campo dell'interazione uomo-macchina. Un tema di grande interesse. Perché è nell'allenare al linguaggio naturale i sistemi che si nascondono dietro le quinte dei social, dei nuovi chatbot, al pari degli assistenti vocali smart, che si stanno concentrando gli sforzi dei big dell'hi-tech. Si parla di un mercato di seimila miliardi di valore. Per riuscirci, Google ha dato in pasto al proprio sistema d'apprendimento automatico 2865 romanzi rosa, mentre piccoli e grande aziende tecnologiche hanno iniziato ad assumere scrittori, saggisti e poeti. L'obiettivo è rendere le conversazioni con i device che ci offrono il più colloquiale possibile. Ne sentiremo delle belle. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/social-network/2017/01/23/news/bosssensor_il_software_ti_avvisa_sei_il_capo_e_nei_paraggi-156644315/" parent_folder="Repubblica 2018-2020" id="file17861705" filename="bosssensor_il_software_ti_avvisa_sei_il_capo_e_nei_paraggi-156644315">
<p> Tecnologia </p>
<p> ''Attento, il capo si avvicina'': un software ti avvisa in tempo </p>
<p> di GIULIANO ALUFFI </p>
<p> Un programmatore della Brown University (Usa) ha sviluppato il sistema in grado di intercettare la presenza a una distanza di sette metri. L'intelligenza artificiale al servizio dei fannulloni? </p>
<p> 23 Gennaio 2017 1 minuti di lettura </p>
<p> QUANDO sul monitor che si dovrebbe usare per lavorare troneggiano in bella vista finestre compromettenti - come Facebook, YouTube con l’ultimo video di gattini o l’immarcescibile Prato Fiorito (l'ex Campo minato oggi recuperabile nel Windows Store) – e non si è dotati del senso di ragno di Peter Parker per avvertire dietro di sé lo sguardo accigliato del capufficio, può tornare utile l'ultima invenzione del programmatore Hiroki Nakayama. Un sistema 'smart' in grado di riconoscere in modo autonomo l’avvicinarsi del capo e rimpiazzare all’istante sul monitor le finestre di svago con serissimi documenti di lavoro. Nakayama ha dapprima scritto un programma di riconoscimento facciale assemblando due librerie software opensource già esistenti: OpenCV per la visione artificiale e Keras per costruire una rete neurale in grado di identificare un volto. Il secondo passo è stato allenare l’intelligenza artificiale così costruita a riconoscere in tempo reale le fattezze biometriche del capufficio di Nakayama: compito svolto dando in input al sistema una lunga serie di fotografie della persona, diverse per espressione, inclinazione e distanza del volto, e per condizioni di luce. Infine, il programmatore ha posizionato una webcam nella direzione della scrivania del suo capo. Risultato: quando il volto del superiore viene riconosciuto a meno di sette metri dalla postazione, sul monitor del programmatore compare a tutto schermo un'immagine preimpostata e utile a simulare produttività. Ben conscio di non essere il solo impiegato del pianeta in cerca di un modo hi-tech per sottrarsi all’occhio invadente del boss e alle sue ramanzine, Nakayama ha rilasciato una versione del programma su GitHub. Nell’ambito dei software dedicati all'improduttività, il salto di qualità rispetto ai classici programmi della categoria Boss Button, che hanno lo stesso scopo di fondo, è notevole: si tratta della prima volta che, grazie alle reti neurali e alla loro capacità di apprendimento automatico, si delega al software stesso l'individuazione della minaccia in arrivo. </p>
<p> Un'innovazione che è, a pensarci bene, in felice controtendenza rispetto al pessimismo indotto dalla sempre più prossima era dell’automazione diffusa: di fronte a tanti sistemi di intelligenza artificiale pronti a rimpiazzare i lavoratori, eccone uno che si propone lo scopo opposto, ovvero salvare il posto anche di chi non brilla per stacanovismo. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/social-network/2018/04/11/news/cambridge_analytica_zuckerberg-193591110/" parent_folder="Repubblica 2018-2020" id="file17861708" filename="cambridge_analytica_zuckerberg-193591110">
<p> Tecnologia </p>
<p> Cambridge Analytica, Zuckerberg: "Facebook ha responsabilità sui contenuti, violati anche i miei dati" </p>
<p> Dopo il primo round a Capitol Hill, la seconda audizione del numero uno del social network alla Camera dei rappresentanti per lo scandalo della privacy, questa volta davanti alla Commissione Energia e Commercio. Che ammette: "È inevitabile dare delle regole" all'economia di Internet </p>
<p> 11 Aprile 2018 3 minuti di lettura </p>
<p> LA SECONDA volta in due giorni: Mark Zuckerberg torna a sedersi a Capitoll Hill per riferire circa lo scandalo Cambridge Analytica alla Camera dei Rappresentanti. L'audizione, come programmato, avviene dopo la prima di cinque ore che si è svolta ieri durante la quale il fondatore e Ceo trentatreenne di Facebook è stato sottoposto a un fuoco di fila di domande sui dati degli utenti, macinati dalla società di analisi senza il consenso degli interessati. Dopo i senatori, ecco i deputati della Camera dei rappresentanti degli Stati Uniti. Mark Zuckerberg ripete, letteralmente, quanto detto davanti alle commissioni del Senato stavolta avendo a che fare con quella dei rappresentanti. Identica assunzione di colpa, stesso annuncio di voler andare fino in fondo dopo lo scandalo di Cambridge Analytica e controllare che nessun altro possa appropriarsi dei dati degli utenti. La prima domanda, del repubblicano Gregory Walden, riguarda cosa sia davvero Facebook. Zuckerberg risponde stavolta senza esitazioni: "E' una compagnia tecnologica ma sicuramente ha delle responsabilità sui contenuti che compaiono sulle nostre piattaforme". </p>
<p> ·LE REGOLE MANCANTI </p>
<p> Ma complessivamente la seconda audizione al Congresso Usa ha messo il fondatore del social in maggiore difficoltà. Se nella prima audizione i senatori si sono limitati a cercare di capire il funzionamento di Facebook, con Zuckerberg piuttosto a suo agio, nella seconda giornata i parlamentari hanno cercato di entrare più a fondo nel modello di crescita del social e della privacy degli utenti. Zuckerberg ha dovuto ammettere che giunti al momento attuale "è inevitabile dare delle regole" all'economia di Internet, e all'uso dei dati personali, apprezzando apertamente il Gdpr dell'Ue e annunciando che sarà usato in tutto il mondo. Una notizia cominciata a circolare la scorsa settimana, ma che trova oggi una conferma diretta: "Quello che apprezzo del Gdpr", ha detto Zuckerberg, è che "consente agli utenti di essere sempre in controllo dei dati che condividono con le aziende, di cosa viene fatto con quei dati e eventualmente di cancellarli. Ci sarà anche un consenso speciale per quello che riguarda le tencologie del riconoscimento facciale degli utenti". </p>
<p> Alla domanda se anche i suoi dati personali siano stati venduti a 'malevole terze partì insieme a quelli di 87 milioni di americani colpiti dal caso Cambridge Analytica, ha risposto sì, ammettendo anche che "ci vorranno molti mesi per indagare le app che hanno preso i dati" da Facebook, in un numero indagato generalmente con "decine di migliaia di app". </p>
<p> Zuckerberg ha inoltre ammesso: "In generale noi raccogliamo anche i dati di persone che non sono iscritte a Facebook per ragioni di sicurezza", ma non ha specificato quali, confermando quanto emerso su alcune testate americane in queste settimane, ma mai ammesso direttamente dalla società. Ha anche confermato che la società non si era accorta che i propri dati erano stati venduti a terze parti e di aver appreso solo dai giornali del caso Cambridge Analytica: "A volte ci capita". ·"SIAMO RESPONSABILI DEI CONTENUTI" </p>
<p> Per quanto riguarda il modello di Facebook, Zuckerberg ha inoltre ammesso per la prima volta che il social media è responsabile dei contenuti pubblicati sulla piattaforma e che quindi di fatto si comporta come una media company: "Noi siamo una azienda tecnologica", ha detto rispondendo ad un membro del Congresso, "perché il nostro lavoro è principalmente fatto da ingegneri e ci rivolgiamo alle imprese. Ma ora so che siamo responsabili anche dei contenuti pubblicati sulla nostra piattaforma quindi sì, siamo una media company". Zuckerberg ha però tergiversato sulla responsabilità legale di quello che viene caricato sulla piattaforma. </p>
<p> Gli iscritti a Facebook dopo lo scandalo Cambridge Analytica "non sono diminuiti e le interazioni su Facebook non sono diminuite", ha detto, ribadendo a più riprese che "i dati che si condividono sono sempre di proprietà degli utenti, che in ogni momento possono decidere se cancellarli". Il ceo ha affermato che l'unica soluzione possibile alle fake news e ai discorsi d'odio sul social è la costruzione di "strumenti di intelligenza artificiale" più raffinati, in grado di controllare con più rigore i contenuti condivisi: "Per quante persone possiamo assumere non saranno mai sufficienti a controllare tutto quello che viene pubblicato". E ha spiegato come Facebook ha intenzione di combattere le fake news con tre azioni già implementate: impedire a chi le diffonde di mettere contenuti a pagamento, costruire un sistema di intelligenza artificiale che riconosca e cancelli gli account, e una maggiore collaborazione con i fact checker a cui sottoporre contenuti segnalati. </p>
<p> Nella sua versione della vicenda, Cambridge Analytica spiega di aver ricevuto i dati in licenza dalla società di ricerca Gsr (General Science Research) "che li ha ottenuti legalmente tramite uno strumento fornito da Facebook". Da parte sua il numero uno del social network che conta oltre un miliardo di iscritti ha provato ancora un volta a difendersi riconquistando la loro fiducia. Nella prima audizione al Senato, Zuckerberg aveva già messo le mani avanti: "Non abbiamo hackerato Facebook, né infranto le leggi, non abbiamo influenzato il referendum sulla Brexit, raccogliamo dati solo con il consenso informato". Per tutto il resto, e cioè quella privacy il cui controllo sembra essere sfuggito ormai al social blu, il ceo ha usato risposte vaghe, con variazioni sul tema "I can certainly have my team get back to you", una sorta di 'le faremo sapere' per neutralizzare le richieste più dettagliate e spinose che arrivavano dagli scranni. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/speciali/tecnologia/ces/lasvegas2018/2018/01/11/news/ces_2018_la_tecnologia_ci_rende_pigri_dalla_valigia_scooter_alla_macchina_piega_panni-186259156/" parent_folder="Repubblica 2018-2020" id="file17861740" filename="ces_2018_la_tecnologia_ci_rende_pigri_dalla_valigia_scooter_alla_macchina_piega_panni-186259156">
<p> Ces 2018, la tecnologia ci rende pigri: dalla valigia scooter alla macchina piega panni </p>
<p> Pier Luigi Pisa </p>
<p> I robot puntano a semplificarci la vita ma esistono campi in cui, probabilmente, poremmo farne a meno. Per il nostro bene </p>
<p> 11 Gennaio 2018 2 minuti di lettura </p>
<p> LAS VEGAS - C'è una scena, in Rocky IV, in cui un robot porta una birra al cognato del pugile, Paulie, mentre questo siede comodamente a tavola con tutta la famiglia. Era il 1985 e nessuno, tra gli spettatori, si sognava di vedere in casa un simile automa. Era, appunto, roba da film. Trentatré anni dopo il Ces di Las Vegas ci dice che molto presto non ci alzeremo più dal divano per rimettere in ordine la casa. E che anche le operazioni più noiose, come rimettere a posto i giochi dei bambini o piegare della biancheria, saranno affidate a delle macchine. </p>
<p> Ces 2018, il robot Aeolus ti aiuta in casa: 2000 euro per portarti una birra </p>
<p> ·INTELLIGENTI MA TROPPO LENTI Ormai da anni i robot affollano la fiera dell'elettronica di consumo che si tiene in Nevada, e adesso sono anche dotati di una piccola dose di intelligenza artificiale, sufficiente a far loro capre come devono comportarsi se, per esempio, devono raccogliere un telecomando che è finito sotto una sedia. Aeolus, robot creato da un'azienda con sedi a Taipei e San Francisco, per effettuare questa operazione usa i suoi lunghi arti meccanici, ma solo dopo aver ricevuto un comando vocale: individua l'ostacolo (la sedia appunto), lo solleva, lo sposta e poi torna indietro per afferrare l'oggetto a terra e poggiarlo dove gli è stato richiesto. </p>
<p> Ces 2018, una macchina da 1000 dollari per piegare i vestiti senza sforzi </p>
<p> ·PIGRI SI DIVENTA, ANCHE PER PIEGARE I PANNI Tutto bello a parole, se non fosse che nella realtà Aeolus per effettuare questa operazione impiega diversi minuti. Almeno due per raccogliere un peluche e riporlo in una cesta vicina. Un essere umano, al suo posto, impiegherebbe pochi secondi. E dunque viene da chiedersi: ci serve davvero questa tecnologia? O ci rende solo più pigri? Per ora, di certo, questi robot ci rendono più poveri: Aeolus, che ricorda vagamente Rosie dei Jetsons, sarà in vendita per circa 2000 dollari entro la fine del 2018. ·IL PREZZO DEL BUCATO Ne costa almeno 16mila (sempre dollari) Laundroid, una macchina dal design ultra curato che usa l'intelligenza artificiale per piegare t-shirt, pantaloni e tutto quello che può trovare in una cesta di biancheria. Per piegare una maglietta, operazione che 'fatta a mano' richiederebbe non più di un minuto anche al più impacciato, Laundroid ne impiega quasi 10. Per sistemare una cesta di bucato quindi, ci vorrebbero almeno due ore. Ma stiamo parlando di piegare panni, non di stirare camice. Davvero abbiamo bisogno di una macchina connessa a internet, che pensa a come piegare un abito consultando una banca dati di 256mila immagini di vestiti diversi per svolgere la più semplice delle operazioni? </p>
<p> Probabilmente sì, perché al Ces un'altra azienda chiamata FoldiMate ha presentato una simile macchina piega panni, molto più spartana e dal costo più accessibile: 980 dollari. Sarà sul mercato per l'inizio del 2019, anche se al momento quello mostrato è solo un prototipo. La macchina afferra i vestiti e li trascina all’interno ma poi, di fatto, non accade nulla. Al Ces non è stata mostrata la tecnologia completa di FoldiMate, se si apre lo sportello principale l'amara verità: i panni sono ammassati gli uni sopra gli altri. </p>
<p> Ces 2018, a spasso sul trolley: la valigia diventa uno scooter elettrico </p>
<p> ·IN VIAGGIO CON IL TROLLEY A MOTORE Funziona davvero invece, ed è anche molto divertente, la valigia che si trasforma in minuscolo scooter elettrico chiamata Modobag. Da un'estremità del trolley si tira fuori un piccolo manubrio su cui si trovano acceleratore e freno. Una volta seduti, sembra di essere su una mini moto, con i piedi poggiati su due linguette che sporgono dalla valigia. Si può raggiungere una velocità massima di 12 km/h, che non è affatto poco: provandola abbiamo avuto la sensazione di essere su un kart, l’accelerazione è buona e la velocità tale da fare attenzione alle curve troppo strette. Modobag è già in vendita, costa 1500 dollari ed è permette a chi viaggia frequentemente di risparmiarsi chilometri di spostamenti in aeroporto. A un prezzo più abbordabile, probabilmente, sarebbe il sogno di tutti. Ma anche in questo caso funziona il paradosso: se la tecnologia da un lato velocizza la nostra vita, dall'altro ci rende immobili. Dieci anni fa i creatori di Wall-E, straordinario cartoon Pixar, hanno disegnato un futuro di esseri umani obesi, coccolati da tecnologie che annullano qualsiasi sforzo fisico, compresa la deambulazione. Non siamo ancora a questo punto, ed è difficile credere che ci arriveremo davvero, ma se ci fosse anche il minimo rischio, si spera che anche per certa tecnologia valga il detto "ciò che succede a Las Vegas rimane a Las Vegas". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/sicurezza/2020/02/06/news/cina_le_mascherine_ingannano_l_ai_il_coronavirus_batte_il_riconoscimento_facciale-247817998/" parent_folder="Repubblica 2018-2020" id="file17861758" filename="cina_le_mascherine_ingannano_l_ai_il_coronavirus_batte_il_riconoscimento_facciale-247817998">
<p> Tecnologia </p>
<p> Cina, le mascherine ingannano l’Ia. Così il coronavirus mette in crisi il riconoscimento facciale </p>
<p> Simone Cosimi </p>
<p> L'obbligo delle mascherine in diverse province e città, ma anche il loro uso generalizzato, fa infuriare i cinesi per le incombenze quotidiane tramite i telefoni. E manda in tilt i sistemi governativi </p>
<p> 06 Febbraio 2020 2 minuti di lettura </p>
<p> LA Cina sta scoprendo un altro effetto collaterale del nuovo coronavirus che si abbatte sul riconoscimento facciale. Dal momento che le mascherine facciali sono obbligatorie in almeno due province cinesi, e comunque estremamente diffuse anche in molte altre zone, oltre che in diverse grandi città, i sistemi di riconoscimento facciale a ogni livello stanno facendo cilecca. </p>
<p> Cina, in fuga dal riconoscimento facciale: lo spot sul 5G inquieta gli utenti </p>
<p> Le protezioni sono di fatto obbligatorie nelle province di Guangdong, nel sud del Paese, in quella di Jiangxi, al centro, oltre che nelle città di Nanchino e Ma’anshan nella provincia di Anhui e in quella di Xinyang nella provincia di Henan. Decine di milioni di persone che nascondono i propri connotati quando escono di casa e, come si è visto anche nel corso delle proteste di Hong Kong, le celano in questo modo anche ai sistemi di riconoscimento. Non solo quelli governativi, ma anche quelli per così dire consumer (spesso non meno scivolosi) che servono a svolgere operazioni di routine, dall’apertura dei portoni dei palazzi alle app bancarie, dall’imbarco in aereo in 200 aeroporti del Paese fino alla richiesta di cibo a domicilio o alla prenotazione di visite mediche passando per gli smartphone (basti pensare al Face ID di Apple o agli altri sistemi simili, ormai lo standard per quasi tutti i produttori) che d’altronde sono il cardine intorno a cui si basano molti di questi servizi. </p>
<p> Se lo smartphone non si sblocca, è un problema. Così come la transazione che non va a buon fine. E per questo sembra che le proteste si stiano diffondendo su Weibo, la Twitter cinese, almeno stando a quanto ha spiegato Abacus, testata di Hong Kong specializzata in tecnologia. La maggior parte delle lamentele si lega esattamente all’impossibilità di utilizzare il volto per gestire le operazioni sul telefono. Cupertino e Huawei, il campione cinese, hanno ovviamente confermato che non c’è modo che i loro sistemi possano funzionare in presenza di mascherine. </p>
<p> La sorveglianza in crisi </p>
<p> C’è poi il lato della sorveglianza: lo scorso dicembre il governo cinese ha approvato una legge che prevede che a ogni nuovo acquisto di una scheda telefonica Sim occorra sottoporsi a una scansione facciale. Formalmente, per "proteggere i diritti legittimi e gli interessi dei cittadini nel cyberspazio", nella pratica per arricchire e ripulire ancora meglio lo sterminato database che tiene d’occhio il quasi miliardo e mezzo di cinesi. Ci sono perfino scuole che usano il riconoscimento facciale per segnare le presenze e addirittura stabilire il livello di coinvolgimento degli alunni e il loro comportamento. L'uso generalizzato delle mascherine li mette in profonda difficoltà. </p>
<p> Basti pensa che il mese scorso alcuni ricercatori della società californiana Kneron, che si occupa di intelligenza artificiale, sono riusciti a ingannare un sistema per effettuare pagamenti sulle piattaforme AliPay e WeChat. Come? Semplicemente indossando una mascherina. Figuriamoci cosa possa accadere con milioni di persone che, per proteggersi e proteggere dal coronavirus, circolano per il Paese col volto coperto. E se anche alcuni algoritmi sono già in grado di superare camuffamenti e altre problematiche, i sistemi non sono perfetti. Senza contare una serie di ostacoli, come i bias, i pregiudizi applicati dagli algoritmi (in particolare a volti asiatici ma anche di altre origini, come nativi americani e afroamericani) che rendono l'operazione non così chirurgica come si vorrebbe far credere, e a sua volta foriera di gigantesche discriminazioni e violazioni della libertà personale. Tutti motivi per cui in molti Paesi, al di fuori della Cina, il riconoscimento facciale resta un terreno tra i più controversi del momento, tanto che pare che l’Unione Europea intenda bandirne ogni applicazione per i prossimi cinque anni. Negli Stati Uniti, ad esempio, monta la polemica, e le legittime richieste di trasparenza e interruzione delle operazioni, sul software Clearview AI utilizzato da oltre 600 dipartimenti di polizia, anche in Canada, e in grado di confrontare le foto caricate di volta in volta dagli agenti con un immenso database di oltre tre miliardi di immagini attinte dal web e dai social network, cioè anche da Facebook e YouTube. Tanto che Google si è appena mossa, chiedendo alla società che fornisce questi servizi l’immediata interruzione di questa 'pesca'. E in Italia una recente interrogazione del deputato Pd Filippo Sensi sul punto ha appena ottenuto dal ministero dell’Interno una risposta parziale che nulla dice sull’eventuale uso del software in questione. Ma rivela che nel database dell’Afis, l’Automated fingerprint identification system nazionale, sono conservati oltre 17 milioni di 'cartellini fotosegnaletici' di volta in volta interrogati dal Sari, il Sistema automatico di riconoscimento immagini in dotazione alle forze dell’ordine tricolori. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/social-network/2020/03/17/news/coronavirus_i_social_avvertono_difficile_valutare_contenuti_piu_video_e_post_rimossi_per_errore-251510691/" parent_folder="Repubblica 2018-2020" id="file17861716" filename="coronavirus_i_social_avvertono_difficile_valutare_contenuti_piu_video_e_post_rimossi_per_errore-251510691">
<p> Tecnologia </p>
<p> Coronavirus, i social avvertono: difficile valutare contenuti, più video e post rimossi per errore </p>
<p> Facebook, YouTube e Twitter, alle prese con lo svuotamento degli uffici, avvisano che adesso la valutazione dei contenuti che violano i termini di servizio sarà affidata in misura maggiore ai sistemi automatici, basati sull'intelligenza artificiali. "Ma niente sospensioni permanenti" </p>
<p> 17 Marzo 2020 1 minuti di lettura </p>
<p> ROMA - Non meravigliatevi se il social di turno vi rimuove un post o un video. Potrebbe essere un errore dell'algoritmo. Si, perché l'emergenza coronavirus potrà avere, tra le conseguenze, anche quella di vedere più video e post rimossi per errore dalle piattaforme social. Questo perché la valutazione dei contenuti che violano i termini di servizio sarà affidata in misura maggiore ai sistemi automatici, basati sull'intelligenza artificiale, rispetto ai moderatori in carne ossa, che in gran parte hanno lasciato le loro scrivanie. Ad avvisare sul possibile aumento di errori sono stati Facebook, YouTube e Twitter, alle prese con lo svuotamento degli uffici. </p>
<p> "Nel corso di questa settimana lavoreremo con i nostri partner per mandare a casa tutti i lavoratori a contratto che si occupano di revisione dei contenuti", ha fatto sapere Facebook precisando che i lavoratori saranno pagati. Facendo maggiore affidamento sui sistemi automatizzati, ha aggiunto, "potremmo vedere tempi di risposta più lunghi e fare più errori", ma ciò "non avrà un impatto significativo sui nostri utenti". </p>
<p> Su YouTube, "i sistemi automatizzati per la valutazione dei contenuti non sono sempre così accurati e granulari come i moderatori umani", ha ammesso Google, e i tempi per fare appello contro la rimozione di un video "potrebbero essere più lenti". L'incremento dell'automazione e i possibili errori sono dichiarati anche da Twitter, che tuttavia assicura: "Non ci saranno sospensioni permanenti di account basate solo sui sistemi automatici". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/economia/2020/09/14/news/dedagroup_ferrara-266972157/" parent_folder="Repubblica 2018-2020" id="file17861757" filename="dedagroup_ferrara-266972157">
<p> Economia </p>
<p> Dati, intelligenza artificiale, sensori, alberi e ciclabili: così una città può ridurre l'inquinamento delle aree più trafficate del 25% </p>
<p> Raffaele Ricciardi </p>
<p> Il progetto di Ferrara finanziato dai fondi europei prevede un incrocio di competenze per un intervento a tre fasi. Prima raccolta di informazioni puntuali, poi la loro rielaborazione per progettare gli interventi sui luoghi urbani e quindi il coinvolgimento della cittadinanza </p>
<p> 14 Settembre 2020 2 minuti di lettura </p>
<p> MILANO - Sensori per misurare la presenza di agenti inquinanti nell'aria delle nostre città, con precisione al metro e in tempo reale. Altri dispositivi per valutare come si spostano i cittadini: la tecnologia per "leggere" le presenze di smartphone sui mezzi pubblici e da lì capire dove le persone salgono e scendono, in quali fasce orarie e tratte si creano i picchi e quando invece le carrozze girano vuote. Lo stesso discorso applicato alle masse di dati di cui le società di telefonia dispongono per capire come si sposta la popolazione urbana nell'arco di una giornata. E ancora, incrocio di informazioni con l'universo dei mezzi di micromobilità condivisa o i car sharing. Prendere questo set di informazioni per trasformarlo in azioni sui "luoghi" della città. Decidere dunque dove piantumare nuovi alberi ad alto assorbimento di inquinanti, come potenziare una direttrice ciclabile (a sua volta smart, quindi con sensori per rilevare il reale utilizzo, pensiline di ricarica per le bici elettriche e via dicendo), in quali orari fissare le corse di una navetta elettrica che trasporti i lavoratori da uno snodo urbano a un'area industriale evitando l'uso dei mezzi privati. E fare queste azioni concrete - terzo passaggio - coinvolgendo la cittadinanza, che si attiva mettendo a disposizione del progetto i dati sulle proprie abitudini di mobilità e i propri "percorsi urbani quotidiani". In cambio, partecipa alla co-progettazione degli interventi e viene premiata se, ad esempio, si converte all'uso di mezzi dolci (ad esempio, regalando ingressi ai musei o teatri comunali in cambio dell'uso - certificato via app - della bicicletta). </p>
<p> Un mix di interventi che possono portare a ridurre, nelle aree più critiche di una città, l'inquinamento del 25%. "Non sono progettualità campate in area, ma percorribili e dal risultato tangibile". A parlare è Luigi Zanella, a capo dello sviluppo di Dedagroup Public Services. La società di Dedagroup che si occupa di digitalizzazione della Pa sta in effetti già portando avanti questo progetto. Accade a Ferrara, dove il Comune sta sviluppando "AIR Break", un lavoro finanziato nell’ambito del Programma Europeo Urban Innovative Actions, iniziativa comunitaria che fornisce alle aree urbane risorse per testare soluzioni innovative e sperimentali. Il progetto è stato scelto con altri dieci tra oltre 200 proposte in tutta Europa. Prevede 5 milioni di investimenti in tre anni "ed è stato premiato per la sua estrema concretezza", dice Zanella. La progettazione è stata effettuata tra ottobre e novembre 2019, l'aggiudicazione arrivata a luglio. Il Covid ha frenato i tempi, si stanno ultimando le valutazioni legali e tecniche ma per fine anno si punta ad avvire i lavori veri e propri. Un esempio virtuoso di triangolazione tra pubblico e privati. O meglio, privati e istituzioni perché la forza di AIR Break è la compresenza di diverse competenze. Oltre a Dedagroup ci sono infatti l’Università di Ferrara e il Politecnico di Milano, S.I.PRO. Agenzia di sviluppo di Ferrara, l'utility HERA (che tra le altre cose contribuisce con uno spray-assorbi-polveri sottili da spruzzare sulla strada), Lab Service Analytica srl e la Fondazione Bruno Kessler. "Non inventiamo tecnologie nuove, ma la forza del progetto è mettere in rete l'esistente", spiega Zanella. Il dato è al cuore di tutto. I dati vengono infatti raccolti per pianificare gli interventi e dare a chi gestisce la mobilità urbana delle informazioni predittive per possiibili interventi di contenimento dell'inquinamento. Ad esempio, incrociando i dati dei sensori locali con quelli satellitari e metereologici "riusciamo ad avere una previsione sulla concentrazione di inquinamento in determinate aree con qualche giorno d'anticipo. Quindi, l'autorità si può attivare con i cittadini per mettere in atto azioni mirate ed evitare che si arrivi a blocchi generalizzati e poco efficaci". Trasporre questi progetti sulle grandi metropoli è certo complesso. "Ma è da buone pratiche come questa, che nascono dal basso, che dovremmo trarre lezione", chiosa il manager. "Quando parliamo di Recovey fund e Green deal, non dobbiamo pensare solo a titoli. Vorrei che nelle caselle che invieremo a Bruxelles, più che generiche linee guida, ci fossero esperienze come questa". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2019/06/17/news/ecco_il_robot_che_impara_col_tatto_e_prova_le_sensazioni_guardando_gli_oggetti-229000171/" parent_folder="Repubblica 2018-2020" id="file17861725" filename="ecco_il_robot_che_impara_col_tatto_e_prova_le_sensazioni_guardando_gli_oggetti-229000171">
<p> Tecnologia </p>
<p> Ecco il robot che impara col tatto e "prova" le sensazioni guardando gli oggetti </p>
<p> di SIMONE COSIMI </p>
<p> Un esperimento del Mit di Boston avvicina di più le intelligenze artificiali verso l'elaborazione tattile raffinata: i ricercatori hanno sviluppato un sistema che può prevedere come sarà toccare un oggetto solo dalle immagini e descriverlo solo col tocco di un braccio equipaggiato di sensori </p>
<p> 17 Giugno 2019 3 minuti di lettura </p>
<p> PER L'ESSERE umano riconoscere, o almeno ipotizzare, le proprietà tattili di un oggetto semplicemente guardandolo è naturale. Così come acquisire informazioni più precise, e dunque descriverlo con accuratezza, toccandolo. Per un robot è invece un passaggio epocale. Che grazie al Computer science and artificial intelligence laboratory del Mit di Boston potrebbe essere più vicino. In un paper appena pubblicato, e che sarà svelato più nel dettaglio a un'importante conferenza scientifica in programma a Long Beach, in California, viene infatti descritto un sistema di intelligenza artificiale in grado di generare rappresentazioni visive di oggetti a partire dai segnali tattili acquisiti e, per converso, anche di prevederne le qualità tattili da un certo numero di informazioni visive. Insomma, può imparare a vedere toccando e a "immaginare" guardando. "Guardando alla scena, il nostro modello può immaginare la sensazione che deriva dal tocco di una superficie piatta o di un bordo tagliente" ha spiegato il principale autore dello studio, il PhD Yunzhu Li (nella foto), che ha collaborato con i professori Russ Tedrake e Antonio Torralba e col collega Jun-Yan Zhu. "Toccando alla cieca, il nostro modello di AI può prevedere l'interazione con l'ambiente semplicemente dagli input tattili - ha spiegato l'autore - far collaborare questi due sensi potrà potenziare i robot e ridurre i dati che dobbiamo loro fornire per programmarli sui compiti necessari a manipolare e afferrare oggetti". Il principio è sempre lo stesso: meno informazioni saremo obbligati a fornire loro in partenza ma anche in itinere, più i sistemi di intelligenza artificiale saranno veloci e "leggeri", dunque davvero utili perché in grado di imparare e procedere da soli. </p>
<p> Il team ha utilizzato una rete antagonista generativa per accoppiare stimoli tattili e informazioni visive. Ovviamente c'è stato bisogno di un addestramento preventivo: il team di ricerca ha usato un braccio robotico Kuka con un sensore tattile GelSight, a sua volta sfornato da un altro laboratorio del Mit, quello guidato da Ted Adelson, per allenare il suo sistema. Sfrutta una camera e una pellicola in gomma per mappare in 3D le superfici che si stanno toccando o gli oggetti che si stanno afferrando. I ricercatori hanno registrato il modo in cui 200 oggetti di ogni tipo, dagli attrezzi ai tessuti fino agli oggetti comuni, venivano toccati per un totale di 12mila videoclip finendo per partorire un database da tre milioni di accoppiamenti visivi e tattili battezzato VisGel. La rete, tramite l'analisi dei frame di quelle clip e le informazioni acquisite dal braccio robotico e dai suoi "polpastrelli" hi-tech, ha appunto imparato, saltando dall'uno all'altro e poi analizzando le immagini, a capire cosa aspettarsi da certi tipi di materiali e, viceversa, così come a descrivere determinati input reali. Ovviamente molti dei dettagli del tocco sono ancora assenti, nel senso che le informazioni che la mano robotica ha estratto dal rapporto con gli oggetti, o il modo in cui ha definito alcune immagini dopo l'addestramento, mancano di alcuni parametri. Ciononostante, secondo il team del Massachusetts, questo nuovo genere di approccio potrebbe aprire la strada per interazioni più spontanee e lineari fra uomo e macchina, specie negli ambiti dell'industria o nei contesti in cui la collaborazione è molto serrata. Basti pensare, per esempio, a situazioni in cui manchino dati visivi chiari, all'industria 4.0, alla sicurezza. "Si tratta del primo metodo che riesce, in modo convincente, a connettere segnali visivi e tattili - ha commentato Andrew Owens, ricercatore all'università della California-Berkeley - metodi come questo possono essere molto utili per la robotica, in situazioni in cui occorra per esempio sapere se un oggetto sia duro o morbido o comprendere come afferrarlo al meglio". Un problema molto complesso che promette di fornire in qualche maniera una sensibilità più spiccata ai robot, fornendo loro una versione certo infinitamente meno raffinata ma pur sempre promettente di due dei cinque sensi umani. Fra l'altro sempre al prestigioso polo di Boston lo scorso mese è stato inaugurato il più completo archivio di dati basati sul tatto a disposizione dei futuri robot (o, per meglio dire, dei sistemi di intelligenza artificiale che ne orchestreranno compiti, azioni, decisioni e movimenti sempre più "umani"). Come spiegava Nature, si tratta di un enorme database delle sensazioni registrate attraverso guanti equipaggiati con 550 speciali sensori utili non solo a dare il senso del tatto alle macchine ma anche a progettare computer indossabili o per esempio protesi per gli arti con una maggiore sensibilità. Per il momento il robot del Mit può identificare oggetti solo in un contesto controllato. Il prossimo passo sarà quello di costruire un più ampio set di dati che gli consenta di sperimentare le sue abilità di tocco e di elaborazione anche in situazioni diverse e meno guidate. A questo scopo sarà utile il superguanto citato poco sopra, che consentirà di arricchire il dataset di addestramento. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/dossier/stazione-futuro-riccardo-luna/2020/07/28/news/erica_il_robot_piu_bello_del_mondo_e_senza_lavoro-263040687/" parent_folder="Repubblica 2018-2020" id="file17861749" filename="erica_il_robot_piu_bello_del_mondo_e_senza_lavoro-263040687">
<p> Erica, il robot più bello del mondo, è senza lavoro </p>
<p> Mi comincio a preoccupare per Erica. Ha 23 anni, le hanno garantito che è “la donna più bella del mondo” (mentendo) e da quasi due anni si è messa a studiare duro recitazione per fare l’attrice. Il metodo Marlon Brando, pare: consiste nel guardare i video dei grandi attori del passato e provare a interpretarli. Qualche mese fa a Hollywood un produttore di buon livello l’ha scritturata per un ruolo da protagonista in un film da 70 milioni di dollari, non esattamente a basso budget, ma le riprese sono ferme perché non si trova un attore con cui dividere la storia. Si direbbe che nessuno vuole recitare con un robot. </p>
<p> Erica è un androide: dicono che sia stata progettata prendendo spunto dalle finaliste di Miss Universo, ma la parte importante non è l’aspetto. È l’intelligenza, artificiale ovviamente. Secondo il suo creatore è così sviluppata “che sembra che abbia un’anima”. Un’anima di marketing sicuramente, visto che sono diversi anni che Erica è fra noi (e ha sempre 23 anni, li avrà per sempre). Quando venne presentata al pubblico si disse che era così brava a conversare che avrebbe potuto lavorare nella reception di un ufficio o di un albergo (ai tempi poteva stare solo seduta). Poi è stata promossa a fotomodella da un artista che ha fatto un servizio fotografandone una dozzina con il titolo “Una di loro non è umana” (ma era chiaro chi fosse, quella con lo sguardo vitreo). Infine ha imparato a muovere le braccia e si è ritrovata candidata per condurre il tg della sera in Giappone, ma non se n'è fatto più niente. </p>
<p> Eppure dietro Erica non c’è un venditore di fumo ma uno dei più interessanti pionieri della robotica: si chiama Hiroshi Ishiguro, ha 56 anni e dirige un famoso laboratorio ad Osaka. Il suo debutto su questo terreno, molto tempo fa, è stato creare una copia robotica della figlia di 5 anni, ma pare che la bimba non abbia gradito. Allora ha clonato elettronicamente se stesso: un signore di mezza età, con uno sguardo che starebbe benissimo in un film di Tarantino. Tra l’altro, per rendere la copia più verosimile si era tagliato i capelli e glieli aveva donati. </p>
<p> Il tema della somiglianza fisica è fondamentale per dimostrare una tesi che compie 50 anni proprio in questi giorni. Si chiama The Uncanny Valley, la Valle dello Sconcerto, e afferma che la nostra empatia verso i robot aumenta quando da bracci meccanici diventano giocattoli e poi prendono sembianze umane, ma quando ci assomigliano troppo, ci sconcertano, ci spaventano. Il professor Masahiro Mori nel saggio originale, pubblicato sulla rivista giapponese Energy nel 1970, non usa l’espressione Uncanny Valley ma quando poi quell’articolo ha iniziato a circolare ed è stato tradotto in inglese, nel 1978 è stato titolato così. Ora la scommessa del creatore di Erica è che “la valle dello sconcerto” abbia una fine e che dopo ci sia una nuova empatia con un androide così senziente da sembrare, appunto, che abbia un’anima. </p>
<p> C’è molto marketing in tutta questa storiella del film “b” (si intitola così) con il primo protagonista androide in cerca di un compagno, ma c’è anche una frontiera in cui ci aspettano alcune domande fondamentali: cosa ci rende davvero umani? Un robot che si comporti come noi, che sembra abbia sentimenti, vuol dire che li ha davvero? Certamente no, ma va anche detto che la strada dell’intelligenza artificiale è lunghissima e noi finora abbiamo percorso solo i primi metri. </p>
<p> Adam, l’androide protagonista del romanzo di Ian McEwan “Macchine Come Me”, in una sua poesia - un haiku giapponese, ovviamente - scrive: L’autunno a noi / promette primavera / A voi l’inverno". Molto suggestivo: per un romanzo, per un film. Ma Erica non potrà mai recitare davvero, facendoci ridere, o piangere. Non più di quanto faceva Wall E in un cartone animato di successo o un robottone di latta nei film di fantascienza che abbiamo amato. L’androide algido e in lacrime del finale epico di Blade Runner non ci tragga in inganno: quello era un attore formidabile, Rutger Hauer. Erica insomma non sarà mai “umana”. Ci sta però aiutando a riflettere su chi siamo davvero. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/social-network/2017/09/06/news/_facebook_i_bot_hanno_imparato_a_mimare_espressioni_umane-174753973/" parent_folder="Repubblica 2018-2020" id="file17861703" filename="facebook_i_bot_hanno_imparato_a_mimare_espressioni_umane-174753973">
<p> Tecnologia </p>
<p> Facebook, i bot hanno imparato a replicare le espressioni umane </p>
<p> di SIMONE COSIMI </p>
<p> Un esperimento è riuscito a insegnare a un sistema animato d’intelligenza artificiale a riprodurre le reazioni facciali e a scegliere le più appropriate a seconda dell’interlocutore </p>
<p> 06 Settembre 2017 1 minuti di lettura </p>
<p> NON SOLO linguaggio ma anche espressioni facciali. I bot di Facebook, cioè i sistemi di intelligenza artificiale che in futuro potrebbero essere utilizzati per potenziare le numerose funzionalità del social network, hanno imparato a mimare le movenze del volto umano. Lo racconta un gruppo di ricercatori in un paper appena pubblicato. All'interno, espongono come siano stati in grado di addestrare un particolare bot animato, controllato da un algoritmo, a mimare le espressioni facciali ricorrenti nel corso di una conversazione. La curiosità è come sia stato allenato: attraverso una serie di video di YouTube che ritraggono persone impegnate in conversazioni su Skype. Si tratta ovviamente di clip in cui i volti dei soggetti sono ben visibili, in grado di costituire "benzina" per il bot animato di Menlo Park. Fra l'altro, gli scienziati non hanno insegnato al sistema a riconoscere un tipo particolare di espressione o le emozioni associate. Lo hanno semplicemente allenato a scovare schemi e pattern ricorrenti nei minimali movimenti dei visi. In particolare, scovando le variazioni in 68 punti-chiave dei volti. Cercando così di individuare quelle microespressioni che, al di là delle fattezze e delle culture, restano spesso piuttosto uniformi da una persona all'altra. Attraverso questi pattern il sistema è stato anzitutto in grado di individuare e prevedere quali fossero le espressioni più adeguate in risposta a certe situazioni fornite come input. Se in un video una persona rideva, per esempio, il bot sceglieva appropriatamente di aprire la bocca o ruotare la testa. I ricercatori hanno poi organizzato un test con giudici in carne e ossa a cui è stato domandato se le espressioni animate prodotte dal bot fossero credibili: cosa che, nonostante le animazioni fossero piuttosto basilari, è avvenuta in gran parte delle situazioni. </p>
<p> Facebook non sta certo costruendo un robot umanoide, anche perché questi sono esperimenti affascinanti ma ancora iniziali. Tuttavia questo genere di raffinatezze possono godere di numerosissime applicazioni: basti pensare a Smile to pay, il sistema di riconoscimento facciale che ha da poco esordito in un fast food Kfc cinese. Una videocamera 3D collocata al bancone delle ordinazioni scansiona il volto del cliente per verificarne l'identità e, se questi sorride, addebita la transazione sull'account dell'utente. Per Facebook queste funzionalità potrebbero tornare particolarmente utili nella realtà virtuale (basti pensare a Spaces) o in un futuro potenziamento dei bot con cui, già oggi, intratteniamo rapporti, facciamo acquisti o a cui chiediamo informazioni. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/economia/miojob/2019/03/09/news/federmanager_con_robot_e_intelligenza_artificiale_l_italia_paghera_un_prezzo_elevato_in_termini_di_occupazione-220795623/" parent_folder="Repubblica 2018-2020" id="file17861733" filename="federmanager_con_robot_e_intelligenza_artificiale_l_italia_paghera_un_prezzo_elevato_in_termini_di_occupazione-220795623">
<p> Economia </p>
<p> Lavoro, per l'Italia conto salato da robot e intelligenza artificiale </p>
<p> Barbara Ardù </p>
<p> E' quanto emerge da una indagine di Federmanager Academy e Mit technology review. Chi invece beneficerà più di tutti del salto tecnologico è l’India, seguita da Cina e Stati Uniti. Cuzzilla (Federmanager): "L’industria e il manifatturiero devono rivedere il proprio ruolo nel rapporto con robot e automazione" </p>
<p> 09 Marzo 2019 2 minuti di lettura </p>
<p> ROMA - L’automazione avrà un impatto significativo sull’occupazione italiana. Secondo i manager italiani intervistati nel rapporto “Intelligenza artificiale, innovazione, lavoro”, curato da Federmanager Academy in collaborazione con MIT technology review, l’Italia è al primo posto nella classifica dei Paesi che subiranno un calo del numero di occupati nei prossimi anni a causa di robot e intelligenza artificiale, seguita da Regno Unito, Francia e Germania. Chi invece beneficerà più di tutti del salto tecnologico è l’India, seguita da Cina e Stati Uniti. Guardando alla tipologia di lavoro, a essere maggiormente colpiti dall’avvento dell’automazione saranno gli operai non specializzati, i bancari e i commercianti. Mentre è il data scientist la figura professionale del futuro, indicata dal 13% del campione composto da 512 manager industriali. E-commerce manager e analista di sistemi informatici sono gli altri due profili che hanno ottenuto più opzioni (rispettivamente, 12% e 10% del totale). Ai manager iscritti a Federmanager è stato chiesto anche di indicare i settori produttivi che saranno più coinvolti dalla trasformazione tecnologica: nei prossimi 10-12 anni i manager d’azienda prevedono una riduzione di posti di lavoro nel settore bancario, nell’automotive e nel manifatturiero tradizionale. Aumenteranno, invece, gli occupati nel settore Ict, in quello della consulenza e in quello ambientale. </p>
<p> "Oltre all’Ict, i manager indicano la consulenza e l’ambiente come settori di sviluppo. Questo è significativo perché si tratta di ambiti che portano innovazione e che richiedono forti competenze tecniche e trasversali - commenta il presidente Federmanager, Stefano Cuzzilla - l’industria, il manifatturiero, devono rivedere il proprio ruolo nel rapporto con robot e automazione. La sfida è imprescindibile se vogliamo mantenerci competitivi come Paese". Il 95% dei manager dichiara di conoscere l'intelligenza artificiale, ma solo il 60% dichiara di avere esperienze di machine learning, una delle principali espressioni di intelligenza artificiale. Quanto a Industria 4.0, che per la quasi totalità (96%) è una conoscenza necessaria, l’83% non ha contezza della funzione degli “architetti di sistema”, ovvero coloro che devono decidere gli algoritmi da porre alla base della progettazione-implementazione dei processi o dei prodotti. "Sta crescendo la consapevolezza dei manager verso gli effetti della trasformazione in atto, ma non è ancora adeguata - afferma Cuzzilla - Per questo dobbiamo investire in formazione a 360°, in corsi mirati all’adeguamento delle competenze manageriali. Siamo convinti che i manager svolgano un ruolo fondamentale per innovare l’impresa: bisogna partire da loro per poi diffondere le competenze digitali in tutta l’organizzazione e innovare i modelli di business". Rimane molto importante il fattore umano e solo il 5% dichiara che le soft skills nella produzione 4.0 non siano fondamentali. Per un terzo del campione la formazione alla leadership però è ancora vista in modo tradizionale, mentre la maggioranza (67%) propende per lo sviluppo di e-leadership, con la connessa capacità di introdurre, utilizzare e sfruttare al meglio l’innovazione e le tecnologie digitali in azienda. "Dal rapporto emerge anche un significativo fabbisogno formativo che deve essere colmato", spiega Federico Mioni, direttore di Federmanager Academy. "Le risposte ottenute sulla formazione alla e-leadership, al fintech, alla blockchain ci confermano la validità dei nostri corsi, che guardano a temi di frontiera, superando la formazione manageriale in senso classico. In meno di due anni abbiamo già formato circa 350 manager sui profili più sfidanti, di cui 300 hanno ottenuto la certificazione delle loro competenze da parte di un ente terzo. Un risultato non certo scontato". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/economia/rapporti/mondo5g/osservatorio-telco/2019/11/11/news/fondazione_tim_punta_sull_intelligenza_artificiale_contro_l_autismo-237750934/" parent_folder="Repubblica 2018-2020" id="file17861744" filename="fondazione_tim_punta_sull_intelligenza_artificiale_contro_l_autismo-237750934">
<p> Fondazione Tim punta sull’intelligenza artificiale contro l’autismo </p>
<p> Con un bando intende incentivare lo studio di soluzioni tecnologiche in grado di migliorare la vita di chi soffre di questo disturbo e ha più di 16 anni di età </p>
<p> di STEFANIA AOI </p>
<p> 11 Novembre 2019 </p>
<p> La vita di una persona con autismo può trarre vantaggio dall’uso degli algoritmi e dell’intelligenza artificiale. Ne è convinta Fondazione Tim che lancia il Bando ‘Liberi di comunicare. Tecnologie intelligenti e innovazione per l’autismo’. “In questo modo – spiegano dalla fondazione – vogliamo incentivare chi lavora con le tecnologie più innovative, dalla stampa 3D e i sistemi vocali, fino alla realtà aumentata, i giochi e i robot, a studiare soluzioni per migliorare la vita di chi soffre di disturbi autistici e ha più di 16 anni, in modo da renderli più autonomi sia a casa che a scuola e al lavoro, favorendo lo sviluppo di abilità di linguaggio”. </p>
<p> Il bando, destinato a soggetti pubblici e privati che operino senza finalità di lucro, e l’intenzione è di premiare i progetti in grado di raggiungere il più ampio numero di destinatari, di garantire la sicurezza e la facilità di utilizzo degli strumenti tecnologici e l’adattabilità ai bisogni dell’utente. Saranno privilegiati infine i progetti open source, tali da garantire la sostenibilità economica dell’evoluzione degli strumenti proposti, elemento chiave per supportarne efficacemente la diffusione in diversi contesti di utilizzo e l’aggiornamento tecnologico. </p>
<p> Fondazione Tim con questo Bando risponde a sempre più diffusi bisogni, come confermano recenti studi epidemiologici, secondo i quali l’incidenza dei disturbi dello spettro autistico si attesta intorno all’1% della popolazione. Maggiori informazioni sul bando si possono ottenere nel sito della fondazione. </p>
<p> Il tuo contributo è fondamentale per avere un’informazione di qualità. Sostieni il giornalismo di Repubblica. </p>
<p> A cura di Luigi Gia, Paola Jadeluca e Stefano Carli </p>
<p> Hanno collaborato Stefania Aoi, Vito de Ceglia, Luigi Dell'Olio, Silvano Di Meo, Sibilla Di Palma, Andrea Frollà, Marco Frojo, Valerio Gualerzi, Mariano Mangia, Raffaele Ricciardi </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/sicurezza/2019/09/23/news/garante_privacy_diritto_all_oblio_sul_web_anche_per_chi_si_riabilita-236751735/" parent_folder="Repubblica 2018-2020" id="file17861759" filename="garante_privacy_diritto_all_oblio_sul_web_anche_per_chi_si_riabilita-236751735">
<p> Tecnologia </p>
<p> Garante Privacy: diritto all'oblio sul web anche per chi si riabilita </p>
<p> Il caso di un imprenditore che ha chiesto a Google la rimozione delle informazioni che lo riguardavano su una vicenda giudiziaria del 2007 e sulla sentenza di condanna del 2010. Nelle pagine web però non vi era traccia della successiva riabilitazione che l'uomo aveva chiesto e ottenuto nel 2013 </p>
<p> 23 Settembre 2019 1 minuti di lettura </p>
<p> ROMA - La permanenza in rete di notizie di cronaca giudiziaria non aggiornate può rappresentare un ostacolo al reinserimento sociale di una persona: il diritto all'oblio va riconosciuto anche a chi è stato riabilitato dopo una condanna. Il principio è stato affermato dal Garante della privacy, che ha ordinato a Google la rimozione di due Url che rimandavano ad informazioni giudiziarie non più rappresentative della attuale situazione di un imprenditore. "L'interessato - spiega il Garante - dopo aver tentato di far deindicizzare le pagine direttamente a Google, si era rivolto all'Autorità lamentando il pregiudizio derivante alla propria reputazione personale e professionale dalla permanenza in rete di informazioni obsolete e non aggiornate". Per questo motivo aveva chiesto al Garante di ordinare a Google la rimozione dai risultati di ricerca di due Url, reperibili digitando il proprio nominativo, che contenevano informazioni su una vicenda giudiziaria che lo aveva visto coinvolto nel 2007 e sulla sentenza di condanna pronunciata nei suoi confronti nel 2010. Nelle pagine web però non vi era alcuna traccia della successiva riabilitazione che l'uomo aveva chiesto e ottenuto nel 2013. </p>
<p> Nel giudicare fondato il reclamo ed ordinare la deindicizzazione, l'Autorità ha ritenuto che "l'ulteriore trattamento dei dati realizzato attraverso la persistente reperibilità in rete degli Url contestati - nonostante la riabilitazione e il tempo trascorso dal verificarsi dei fatti - determinasse un impatto sproporzionato sui diritti dell'interessato, che non risulta bilanciato da un attuale interesse del pubblico a conoscere la vicenda. La persistenza in rete di tali informazioni giudiziarie non aggiornate, infatti, non è in linea con i principi alla base dell'istituto della riabilitazione, il quale, pur non estinguendo il reato, comporta il venir meno delle pene accessorie e di ogni altro effetto penale della condanna come misura premiale finalizzata al reinserimento sociale della persona". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/scienze/2019/10/30/news/gioca_con_il_robot_su_scienze_di_giovedi_la_pagina_per_bambini_dedicata_all_intelligenza_artificiale-239869201/" parent_folder="Repubblica 2018-2020" id="file17861727" filename="gioca_con_il_robot_su_scienze_di_giovedi_la_pagina_per_bambini_dedicata_all_intelligenza_artificiale-239869201">
<p> Gioca con il robot. Su Scienze di giovedì la pagina per bambini dedicata all'intelligenza artificiale </p>
<p> Si parla anche di ambiente, con il reportage da un'oasi perduta nel Sahara a causa del deserto che avanza. Del tempo che passiamo su telefoni e tablet per svagarci con film e videogame, relegando la tv a una minoranza degli ascolti. La pagina dei giochi presenta un esperimento semplice per scoprire un fenomeno complesso: la tensione superficiale dell'acqua </p>
<p> Pronti ragazzi, questa volta si gioca. Scienze, il settimanale di Repubblica in edicola il giovedì, ci racconta come i computer e i robot abbiano imparato a giocare. E siano diventati, nella maggior parte dei casi, perfino più bravi di noi. La notizia da cui partiamo è la creazione di una mano robotica in grado di risolvere il Cubo Magico in 4 minuti, unendo destrezza a intelligenza. L'intelligenza artificiale è proprio l'argomento che viene spiegato nella doppia pagina estraibile che ogni settimana dedichiamo ai ragazzi. I computer oggi riescono a batterci allenandosi in modo continuo, qualcuno direbbe ossessivo. I software hanno sconfitto gli umani in giochi di strategia come scacchi, Go e poker e in molti videogiochi, riuscendo a cooperare in maniera egregia perfino quando si trovano a gareggiare in squadra. I pregi e i difetti dell'intelligenza artificiale, con le sue applicazioni che vanno molto al di là degli aspetti ludici, sono spiegati su Scienze con un linguaggio adatto ai ragazzi di elementari e medie, sempre con l'aiuto e la supervisione di esperti del tema che viene di volta in volta trattato. Il nostro "maestro" di giochi del Cnr, Luca Balletti, ci sfida poi come in ogni numero con i suoi enigmi matematici e ci porta alla scoperta di un fenomeno fisico complesso (la tensione superficiale dell'acqua) attraverso un esperimento semplicissimo, adatto anche ai più piccoli, che prevede l'uso solo di borotalco e sapone. </p>
<p> E per gli adulti (ma per tutti, in realtà) Scienze offre nel suo servizio di copertina il reportage da un'oasi del Marocco del Sud che un tempo era la porta del deserto. Da M'hamid El Ghizlane partivano le carovane che attraversavano il Sahara. Oggi il cambiamento del clima e l'inaridimento delle aree subtropicali hanno trasformato un centro famoso per la coltivazione delle palme da dattero in un'area spopolata e battuta dalle tempeste di sabbia. Sempre in tema di ambiente, Scienze riprende un'inchiesta del Guardian sulle compagnie petrolifere che inquinano di più, accanto alla buona notizia che in Gran Bretagna quest'estate le fonti rinnovabili hanno superato quelle fossili. E che all'eolico, soprattutto quello installato in mare, è stata riconosciuta la capacità (per ora solo potenziale, ovviamente) di generare tutta l'elettricità necessaria al mondo. Per la sezione dedicata alla tecnologia, raccontiamo come l'intrattenimento degli italiani sia ormai virato sugli schermi di tablet e cellulari, lasciando alla televisione solo una minoranza di spettatori. Ma basta un ruggito del Sole - spiega un altro servizio - per mandare in tilt i nostri apparecchi elettronici. Le tempeste della stella possono inondarci di radiazioni dannose per viaggi aerei e telecomunicazioni. Per questo l'Europa si appresta a varare un nuovo piano per le previsioni del "meteo spaziale". </p>
<p> Il tuo contributo è fondamentale per avere un’informazione di qualità. Sostieni il giornalismo di Repubblica. </p>
</doc>
<doc url="https://www.repubblica.it/dossier/stazione-futuro-riccardo-luna/2019/11/19/news/giustizia_lenta_c_e_il_magistrato-robot-241410647/" parent_folder="Repubblica 2018-2020" id="file17861735" filename="giustizia_lenta_c_e_il_magistrato-robot-241410647">
<p> Giustizia lenta? C'è il magistrato-robot </p>
<p> di RICCARDO LUNA </p>
<p> Lo scontro fra Partito democratico e 5stelle sulla riforma della giustizia (in sintesi: quanto deve durare la prescrizione e quanto i processi; stasera c’è un vertice “decisivo” a palazzo Chigi con il premier Conte), come sempre in questo paese si svolge come se tutto fosse eterno ed immutabile. Come se l’innovazione tecnologica non stesse cambiando profondamente la nostra vita, anche quando si parla di giustizia. In Cina, che non è un esempio di democrazia ma sul fronte della tecnologia sì, già un anno fa si contavano oltre cento robot nei tribunali. Il loro compito non è emettere sentenze, ma ricercare casi del passato, verdetti simili, e in generale alleggerire il lavoro dei magistrati con lo scopo di avere processi più brevi. </p>
<p> Con 120 mila giudici che devono dirimere 19 milioni di cause civili ogni anno, non è un aiuto da poco. I risultati devono essere stati incoraggianti perché il 27 giugno la Corte di Internet di Pechino ha lanciato un servizio online per dirimere controversie, con tanto di giudice robot, “il primo del mondo” è stato detto. In realtà non è un robot ma soltanto una specie di ologramma con le sembianze e la voce di una donna molto severa (capelli corti, giacca nera, cravatta rossa su camicia bianca) animata da un programma di intelligenza artificiale, che ha il compito di aiutare il giudice a fare meglio il proprio lavoro smazzando le pratiche più semplici. Il tutto è progettato in modo che il processo si possa svolgere tramite smartphone. </p>
<p> Anche l’Estonia, la piccola repubblica baltica all’avanguardia del digitale, sta imboccando una strada simile: il progetto, annunciato sei mesi fa, è in dirittura di arrivo. L’Italia per ora si limita a fare dei bei convegni: l’ultimo qualche giorno fa a Firenze, per merito della presidente del tribunale Marilena Rizzo, uno dei pochi magistrati ad aver capito l’impatto positivo della tecnologia. Qui non si tratta di essere giudicati da un algoritmo, soprattutto in materia penale; si tratta di aver processi più rapidi e meno influenzati dal caso grazie all’innovazione tecnologica. Su questo il dibattito da noi è così arretrato che non stupisce il fatto che il 51 per cento degli italiani, sentiti da SWG, si dica contrario all’ingresso dell’intelligenza artificiale nei tribunali. Meglio affidarsi alla clemenza della corte. E a processi che non finiscono mai. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2018/05/08/news/google_i_o_2018_intelligenza_artificiale_e_al_centro_di_tutto_-195867976/" parent_folder="Repubblica 2018-2020" id="file17861709" filename="google_i_o_2018_intelligenza_artificiale_e_al_centro_di_tutto_-195867976">
<p> Tecnologia </p>
<p> Google I/O 2018: "L'Intelligenza artificiale sarà al centro di tutto" </p>
<p> di JAIME D'ALESSANDRO </p>
<p> Alla conferenza annuale del colosso del Web, annuncia l’evoluzione delle Ai: “Sapranno rispondere a file di domande, le integreremo nelle mappe e saranno a che capaci di chiamare un ristorante per prenotare”, ha dichiarato Sundar Pichai, a capo della compagnia. Verranno integrate anche sulla nuova versione del sistema operativo per smartphone dell'azienda: Android P </p>
<p> 08 Maggio 2018 2 minuti di lettura </p>
<p> E dopo Facebook ecco Google. A pochi giorni dalla chiusura dell’F8, a Mountain View apre I/O. E’ l’evento annuale dedicato all’universo del motore di ricerca creato da Larry Page e Sergey Brin nel 1996. Oggi la compagnia, che va ben oltre le sole ricerche online, è guidata da Sundar Pichai che apre citando le sue origini umili in India: “Ricordo perfettamente cosa significava accedere alle informazioni senza gli smartphone". Ma il vero punto di partenza di I/O è, ancora una volta, l’intelligenza artificiale (Ai), ultimo cavallo di battaglia di Google da due anni a questa parte. “Un modo per risolvere problemi nel mondo” prosegue Pichai che intervistammo quando annunciò la svolta verso le Ai. </p>
<p> "One of the biggest areas we're tackling with AI is the #GoogleAssistant...Our vision for the perfect assistant is that it would be natural and comfortable to talk to, and there at the right moment in the right way when you need it." –@sundarpichai #io18 </p>
<p> A proposito di Ai, ora l’assistente di Google è presente su mezzo miliardo di dispositivi, dai telefoni alle televisioni. “E alla fine di quest’anno sarà disponile in 30 lingue e in 80 Paesi”, snocciola Scott Huffman, che dirige la divisione dell'Assistente Google. Dà poi prova di una conversazioni con più domande conseguenziali sullo stesso tema con l’Ai. E’ uno dei grandi limiti degli assistenti: l’incapacità di comprendere un secondo quesito subordinato al primo: "Trova un ristorante cinese ben recensito", "e che sia accogliente" ad esempio. In genere alla seconda richiesta l’Ai si perde. Ora Huffman sostiene di aver iniziato a risolvere il problema. Non solo: da questa estate l’assistente verrà integrato anche nelle mappe della compagnia e in buona parte degli altri prodotti del gigante della Rete. </p>
<p> Dal parrucchiere al ristorante, alla prenotazione ci pensa l'Assistente Google </p>
<p> Gmail ad esempio, sempre grazie alle Ai, da questo mese suggerirà le frasi che abbiamo iniziato a digitare. Nuove funzioni anche per Google Foto: si potranno aggiungere colori a vecchie immagini in bianco e nero e trasformare la foto di un documento in un pdf. Ma la dimostrazione più impressionante è stata quando Pichai ha chiesto all’Assistente di chiamare il barbiere e prenotare un taglio per un certo giorno. Se la telefonata che è stata fatta ascoltare era vera, le potenzialità sono enormi. Siamo però alle promesse, vedremo quando questo sistema diverrà disponile se funziona davvero così bene. </p>
<p> Poi è stata la volta di Android. Meglio: dell'ultima versione del sistema operativo per smartphone chiamato P, reso disponibile da subito sui Google Pixel in versione beta e su altri sette telefoni di marche diverse. A quanto pare a Londra DeepMind, l’azienda di Google che ha realizzato la super Ai AlphaGo, ha usato l’intelligenza artificiale per migliorare la durata delle batterie aggiustando automaticamente la luminosità dello schermo. Con Android P, l’Ai dovrebbe esser capace perfino di predire cosa ci serve quando attiviamo il telefono apprendendo dalle nostre abitudini. Anche in questo campo quindi si punta tutto sui miracoli (veri o presunti) dell’intelligenza artificiale. A tal punto che viene presentato l’ML Kit per sviluppare, compreso iOs, usando l’Ai di Google. La funzione più utile di Android P? Il conto delle ore che passiamo sullo smartphone e sulle sue app; tutti potranno sapere quanto tempo spendono, o sprecano, sul telefono. Ultimo John Krafcik, a capo di Waymo, con la sua guida autonoma. Quello che un tempo veniva chiamato il progetto Google Car, oggi è un'azienda indipendente che sta facendo passi in avanti per diventare realtà di mercato. O quasi. I test stanno proseguendo a Phenix, con il piano di lanciare un servizio di taxi il prossimo anno. Secondo la compagnia, sempre grazie al deep learning (tecnica usata nelle Ai), i veicoli di Waymo sono i più sicuri in assoluto, capaci di “vedere” in condizioni prima proibitive come in caso di neve. Insomma, all’intelligenza artificiale di Google pare non sfuggirà proprio nulla. Compreso il fatto che questo I/O è stato magro di annunci veri e con poche novità rilevanti, se non la conferma del voler proseguire sulla strada tracciata da Pichai nel 2016. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2018/05/10/news/hannes_ecco_la_mano_robot_dell_iit_e_inail-195934038/" parent_folder="Repubblica 2018-2020" id="file17861747" filename="hannes_ecco_la_mano_robot_dell_iit_e_inail-195934038">
<p> Hannes, la mano robot dalla presa perfetta </p>
<p> Derivata dagli arti degli androidi dell’Istituto Italiano di Tecnologia, è stata creata da un gruppo di ingegneri, medici, terapisti e pazienti. Capace di una presa naturale, è una delle più avanzate in assoluto. Arriverà nel 2019 ad un prezzo del 30 per cento più basso rispetto alle protesi di alto livello attualmente disponibili </p>
<p> ROMA - Tre anni di lavoro, con un gruppo di esperti misto che va dagli ingegneri ai medici, dai terapisti ai pazienti. La mano robotica Hannes è nata così, frutto della collaborazione fra l’Istituto Italiano di Tecnologia (Iit) e l’Inail. Protesi avanzata, tutta italiana, che dal 2019 dovrebbe arrivare sul mercato ad un prezzo relativamente contenuto. </p>
<p> IIT: Hannes, la nuova mano protesica di derivazione robotica </p>
<p> in riproduzione.... </p>
<p> Condividi </p>
<p> “E’ una mano che combina una serie di aspetti fondamentali e innovativi”, racconta Lorenzo De Michieli, coordinatore del Rehab Technologies, laboratorio congiunto nato nel dicembre 2013 dalla collaborazione tra l’Inail e Iit. "E’ efficace: ha una presa che somiglia a quella di una mano umana con le dita che avvolgono l’oggetto distribuendo automaticamente la forza. E ha anche una presa dinamica, nel senso che le dita agiscono per mantenere una presa stabile anche se l’oggetto si muove. Pensiamo ad esempio al contraccolpo sul manico di un martello dopo aver piantato un chiodo. Insomma: non c'è nulla sul mercato che ha queste capacità". Maggiore durata della batteria, con un'autonomia di circa un giorno, migliore capacità e performance di presa, costo ridotto di circa il 30% rispetto ai dispositivi attualmente in commercio. Con un nome, Hannes, che è omaggio al professor Hannes Schmidl, già direttore tecnico del Centro Protesi Inail di Vigorso di Budrio, a cui si deve l’avvio dell’attività di ricerca sulle protesi nel 1965. Il meccanismo alla base del movimento delle dita, della forza e del tipo di presa dipende dal sistema Dynamic Adaptive Grasp (Dag) brevettato dal team Iit–Inail, che conferisce alla mano la capacità di afferrare gli oggetti adattandosi alla loro forma e di resistere alle eventuali sollecitazioni esterne, con l’obiettivo di replicare la gestualità e la funzionalità di una vera mano. </p>
<p> Condividi </p>
<p> Le dita si piegano e possono assumere una postura naturale anche a riposo. Il pollice, in particolare, è orientabile in tre diverse posizioni e rende possibili i tipi di prese necessarie nella vita di tutti i giorni come il manipolare oggetti di piccole dimensioni, penna o chiodo che sia, ma anche sollevare pesi fino a 15 chili. Il sistema di controllo di Hannes è di tipo mioelettrico, sfrutta gli impulsi elettrici che provengono dalla contrazione dei muscoli della parte residua dell’arto, e implementa strategie basate su algoritmi di intelligenza artificiale. Questa tecnologia fa sì che i pazienti possano comandare la mano semplicemente pensando ai movimenti e senza la necessità di alcun trattamento chirurgico invasivo. </p>
<p> Condividi </p>
<p> Per garantire il massimo livello di personalizzazione, il Rehab Technologies Lab ha realizzato un software che si collega alla mano robotica via Bluetooth e consente di calibrare i suoi parametri di funzionamento in base alle esigenze e alle caratteristiche di chi la indossa. La mano dell’Iit-Inail fa tutto con un solo motore, per questo costa meno rispetto ad altre. </p>
<p> IIT: Hannes, la nuova mano protesica di derivazione robotica </p>
<p> in riproduzione.... </p>
<p> Condividi </p>
<p> Figlia dalle mani robotiche che l’Iit ha sviluppato per i suoi androidi, attualmente Hannes è un prototipo anche se marchiato CE. L’idea è di arrivare sul mercato nel 2019 ad un prezzo di circa 10 mila euro. “Sembrano tanti, ma in realtà le protesi di alto livello costano anche il doppio”, sottolinea Michieli. Il pollice va orientato, lateralmente, in maniera manuale. Questo è l’unico limite. Ci sono alcune protesi che hanno un motore dedicato a questo movimento ma son più care e molto meno naturali. Marco Zambelli, uno dei pazienti che ha collaborato alla costruzione di Hannes, perse l'arto a 15 anni e suo malgrado è divenuto una dei maggiori esperti di protesi. E, come dice lui stesso, questa è una delle migliori mani che abbia mai ricevuto. </p>
<p> Condividi </p>
<p> Il tuo contributo è fondamentale per avere un’informazione di qualità. Sostieni il giornalismo di Repubblica. </p>
</doc>
<doc url="https://www.repubblica.it/economia/miojob/2020/02/09/news/il_futuro_dellavoro-246973725/" parent_folder="Repubblica 2018-2020" id="file17861751" filename="il_futuro_dellavoro-246973725">
<p> Economia </p>
<p> Una società di creativi, senza stipendio fisso </p>
<p> E' quanto immagina Deloitte in una ricerca sul futuro del lavovo. Non ci sarà più chi raccoglierà dati, ma chi li interpreterà. E l'appuntamento è dietro l'angolo il 2021. Ma non sarà per tutti </p>
<p> 09 Febbraio 2020 2 minuti di lettura </p>
<p> ROMA - Entro il 2021 il 61% dei mestieri sarà ridisegnato. Tra un anno quindi. Il che non è proprio una buona notizia. Secondo uno studio sul futuro del lavoro di Deloitte, intelligenza artificiale, robotica, digitalizzazione faranno sparire attività a basso valore aggiunto ma le aziende cercheranno nuovi profili professionali, spingendo verso una riconversione delle competenze. Se 30 anni fa un lavoratore poteva svolgere la stessa mansione per l'intera carriera, ora la società internazionale di consulenza stima che il rinnovamento professionale avvenga ogni 2-5,5 anni, con una vita lavorativa destinata ad allungarsi. La ricerca indica, in particolare, che nei prossimi 24 mesi i dipartimenti human resources triplicheranno l'uso di 'robotic process automation' ed entro il 2035 vi è il 90% di probabilità che le attività amministrative nell'ambito della gestione delle risorse umane sarà completamente automatizzata. Significa ad esempio che tutto il lavoro svolto per reclutare personale, raccogliere e analizzare curriculum vitae, somministrare test, organizzare colloqui, scrivere proposte di assunzione, sarà svolta da un robot, capace di scannerizzare e classificare i dati, selezionare profili, trarre informazioni da varie fonti, ad esempio da Linkedin. Ma sarà automatizzata anche la preparazione delle buste paga, la gestione dei premi, il percorso formativo. Il robot, capace di lavorare 24 ore e 7 giorni su sette, si occuperà degli adempimenti regolatori e amministrativi e non vedremo più impiegati occupati per ore a contabilizzare numeri. Liberi da attività meccaniche e ripetitive, i lavoratori saranno sempre più impegnati in attività sofisticate e creative, volte a interpretare invece che registrare dati. Il loro obiettivo sarà di trovare aziende stimolanti, che li mettano nelle condizioni di esprimere le proprie potenzialità e che garantiscano loro indipendenza. La previsione di Deloitte è che il 40% della forza lavoro sarà "contingent", composta cioè da free lance, professionisti autonomi, lavoratori a tempo determinato e collaboratori. "I futuri lavoratori - spiega all'Agi Gianluca Di Cicco, partner Deloitte - avranno ambizioni e aspettative radicalmente diverse rispetto ai lavoratori dipendenti di qualche anno fa: saranno fortemente interessati agli obiettivi dell'azienda, attenti alle prospettive di crescita e all'equilibrio tra lavoro e tempo libero e perché no, a divertirsi lavorando. Superata l'idea del posto stabile, punteranno a essere imprenditori di se stessi". In un mercato del lavoro caratterizzato da flessibilita', i lavoratori cercheranno l'autonomia e le imprese la competenza. Innovazione tecnologica e intelligenza artificiale comporteranno che le aziende saranno obbligate a investire nella formazione continua. "Basti pensare al 5G - fa notare Di Cicco - che introdurrà nuovi modelli di business e cambierà il modo di lavorare. O al commercio elettronico e all'uso dei droni al posto di postini e fattorini". "Sempre più imprese - prosegue - non trovano i profili che cercano e sono pronte ad addestrare i lavoratori per stare al passo con la digitalizzazione. Le più evolute arrivano a creare proprie accademie". I robot non rischiano quindi di schiacciare l'umanita', al contrario: "le componenti intellettive e creative saranno vincenti nel rapporto dell'uomo con la tecnologia. La competenza relazionale, la capacità di risolvere problemi e di gestire la complessita', le cosiddette soft skills - conclude -diventano sempre più importanti e saranno loro a fare la differenza". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/economia/2020/06/25/news/il_garante_come_il_grande_fratello_in_una_banca_dati_tutta_l_informazione_italiana-260073003/" parent_folder="Repubblica 2018-2020" id="file17861756" filename="il_garante_come_il_grande_fratello_in_una_banca_dati_tutta_l_informazione_italiana-260073003">
<p> Economia </p>
<p> Il Garante schiera l'intelligenza artificiale. In una banca dati tutta l'informazione italiana </p>
<p> di ALDO FONTANAROSA </p>
<p> L'AgCom chiede a un fornitore esterno di creare un contenitore capace di raccogliere fino a 100 milioni di documenti. Al suo interno, ogni giorno, i pezzi di siti, giornali, radio e televisioni. Il data base sarà navigabile con un motore di ricerca in stile Google </p>
<p> 25 Giugno 2020 2 minuti di lettura </p>
<p> ROMA - L'investimento non è banale: 150 mila euro in 5 anni (più Iva). L'obiettivo è ambizioso. Disporre di una banca dati dove sia presente tutta l'informazione prodotta in Italia. Questa banca dati sarà navigabile con un motore di ricerca interno - in perfetto stile Google - anche grazie ai software dell'Intelligenza Artificiale. L'Autorità per le Comunicazioni (AgCom) - arbitro delle questioni televisive e della telefonia - cerca un fornitore esterno in grado di creare un "giocattolo" di questo tipo. La banca dati sarà a disposizione del Servizio economico-statistico dell'Autorità che punta a studiare la nostra informazione - le parole che usa, i temi che affronta - in maniera molto più analitica che in passato. </p>
<p> Perché lo studio sia attendibile, c'è bisogno di disporre di grandi quantità di documenti. Per questo, l'Autorità ambisce a un sistema di monitoraggio che guardi ad almeno 2000 fonti d'informazione. Questo è l'elenco: - quotidiani nazionali e locali (testate cartacee); - telegiornali (incluse le edizioni regionali); - altri programmi televisivi di informazione; - giornali radio e altri programmi radiofonici di informazione; - agenzie di stampa (siti web); - siti web di quotidiani, televisioni e radio; - testate esclusivamente online; - fonti scientifiche (siti web). Interessa anche l'informazione che prende forma sui social. Per questo, il sistema di monitoraggio dovrà registrare quello che scrivono le pagine e gli account social (Facebook e Twitter) delle fonti di informazione prima elencate. Saranno monitorati infine gli influencer legati al mondo dell’informazione; e altri siti web, pagine e account social di "fonti di informazione non tradizionale". Tutte queste fonti dovranno essere raccolti per 5 anni dal momento della firma del contratto tra il fornitore e l'Autorità. Il fornitore dovrà andare anche un po' a ritroso, includento anche tutto quello che è stato pubblicato dal primo gennaio del 2020. Quanto sarà grande, alla fine, un simile contenitore? "Dovrà supportare la gestione di circa 100 milioni di documenti come ordine di grandezza". Un numero degno dell'era dei big data che stiamo vivendo. Ovviamente avere quantità sconfinate di documenti equivale a non averne, se non disponiamo anche degli strumenti per catalogare le informazioni e per navigarle. I tecnici dell'Autorità, in altre parole, devono avere la possibilità di interrogare la banca dati ("con operatori logici come AND OR, NOT, e con parentesi).I tecnici dovranno disporre anche di "una serie di filtri: data di inizio, data di fine, fonti e gruppi di fonti". E la banca dati dovrà fornire risposte in forme aggregate ed esaurienti. La banca dati potrà dare queste risposte se progettata da esperti di intelligenza artificiale. A ciascuna notizia presente nel database dovranno essere associati quelli che gli esperti chiamano metadati: un numero identificativo del documento, il titolo della notizia, il sottotitolo, la data di pubblicazione, l'autore, la fonte,la categoria (cronaca, cultura, economia, esteri, politica, scienza, spettacolo, sport). Una simile banca dati può essere creata a condizione di mettere in campo i software più sofisticati dell'Intelligenza Artificiale. Servono, per la precisione, gli algoritmi della famiglia del natural language processing. Sono software in grado ci comprendere in linguaggio dell'uomo. Servo, più in generale, algoritmi dinamici della famiglia del machine learning. Sono software che migliorano le loro prestazioni attraverso l'esperienza sul campo. Le aziende dell'Intelligenza Artificiale avranno tempo fino al 15 luglio 2020 per candidarsi a realizzare il "giocattolo" sognato dall'Autorità. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/motori/sezioni/attualita/2020/08/10/news/il_taxi-robot_nelle_vie_di_shanghai-264299904/" parent_folder="Repubblica 2018-2020" id="file17861754" filename="il_taxi-robot_nelle_vie_di_shanghai-264299904">
<p> Motori </p>
<p> Il taxi-robot nelle vie di Shanghai </p>
<p> Andrea Tarquini </p>
<p> Operativo il veicolo Volvo (di proprietà Geely) completamente autonomo. Ecco come funziona </p>
<p> 10 Agosto 2020 2 minuti di lettura </p>
<p> BERLINO - Il futuro cammina in strada tra noi. Almeno a Shanghai, la modernissima capitale economica cinese con 25 milioni di abitanti. Là debutta in via sperimentale, ma con piani e prospettive di impiego di massa, il taxi-robot. Grazie alle tecnologie di eccellenza svedese, o per essere piú precisi di Volvo, il cui azionista di riferimento è il car maker cinese Geely. Nelle vie della metropoli della Repubblica popolare è in servizio una Volvo fiammante, speciale, completamente robotizzata e controllabile a distanza, e per sicurezza assoluta contro ogni tipo di incidente o imprevisto ha un radar sul tetto. E´ un piano ambizioso. Per chi ha proprietà decide e dispone del potere o dei favori del potere il robotaxi Volvo di Shanghai è un momento della sfida con gli Usa di Donald Trump per la supremazia anche economica e tecnologica del futuro. Il progetto cui partecipano passeggeri volontari è stato varato da DiDi Chuxing, l´azienda che è l´equivalente di Uber in Cina. Alle spalle ha il colosso AutoX, appoggiato a sua volta dal gigante internettiano della Repubblica popolare, Alibaba. Il numero uno di AutoX, Xiao Jianxiong, ha dichiarato all´agenzia di stampa francese Agence France Presse di contare di riuscire a offrire il servizio a tutti i potenziali utenti di Shanghai entro la fine dell´anno e in due o tre anni in altre metropoli cinesi. E Volvo e l´azionista di riferimento cinese Geely non si sono lasciati sfuggire l´occasione: hanno subito approntato prototipi totalmente pronti all´uso. Chi usa il robotaxi sperimentale Volvo di Shanghai al momento vede ancora una persona seduta al posto di guida. Ma si tratta solo di un tecnico che tace sorveglia e collauda il funzionamento perfetto del dispositivo. La Volvo robotaxi parla anche, nella lingua che il passeggero sceglie, ascolta e registra la destinazione richiesta, e fornisce al passeggero ogni informazione. Esempio, importante in tempi di Covid: "Non si preoccupi, la vettura è perfettamente disinfettata, prima e dopo ogni corsa”. Oppure: "scelgo l´itinerario dove prevedo meno traffico”, "attenzione ora devo frenare, qui vicino c´è un passaggio pedonale, piú avanti una scuola, frenerò di nuovo dopo altri 5 minuti di viaggio perchè passeremo accanto a un asilo infantile”. Agli imprevisti, come ostacoli, temporali, veicoli che ti tagliano la strada o incidenti che avvengono improvvisamente davanti al robotaxi Volvo, ci pensa l´intelligenza artificiale made in Sweden, anche con frenate e sterzate improvvise e se necessario violente, dopo le quali la voce del robotaxi si scusa. Un solo problema, scherzano a Volvo e ai piani alti delle aziende cinesi coinvolte. Può dare piccoli grattacapi al passeggero a fine corsa: come diavolo si potrebbe ringraziare un robotaxi dandogli una mancia, un grazie supplementare alla tariffa segnata dal tassametro dopo aver effettuato il pagamento elettronico della corsa? A questo svedesi e cinesi non hanno ancora pensato. Ma sul tema hanno mentalità diverse: i cinesi adorano le mance, in Svezia e negli altri paesi della Comunità nordica la mancia viene spesso rifiutata, è quasi considerata un´offesa da chi se la vede offrire. </p>
<p> Leggi anche </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2018/01/17/news/intelligenza_artificiale_alla_portata_delle_imprese_google_lancia_cloud_automl-186682244/" parent_folder="Repubblica 2018-2020" id="file17861711" filename="intelligenza_artificiale_alla_portata_delle_imprese_google_lancia_cloud_automl-186682244">
<p> Tecnologia </p>
<p> Intelligenza artificiale per le piccole imprese, gli algoritmi di Google imparano da soli </p>
<p> La società californiana ha presentato un nuovo prodotto sulla nuvola che permette anche ad aziende con competenze tecnologiche limitate di sviluppare e introdurre i propri modelli di machine learning. La prima applicazione nel riconoscimento delle immagini per retail, assicurazioni e sanità </p>
<p> 17 Gennaio 2018 1 minuti di lettura </p>
<p> ROMA - Portare le risorse più avanzate dell'intelligenza artificiale alla portata delle piccole imprese. Anche quelle che non hanno programmatori esperti di machine learning. E' questo l'obiettivo di Cloud AutoML, il nuovo prodotto sulla nuvola lanciato oggi da Google. Un applicativo che permette alle aziende di costruire con semplicità i propri algoritmi intelligenti, e che avrà la sua prima applicazione nel mondo delle immagini. Nutrita con gli opportuni dati, l'AI potrà per esempio imparare a riconoscere oggetti simili, dalle vestiti ai mobili. Oppure a classificare esami diagnostici in campo sanitario. "Al momento, sono poche le aziende nel mondo che hanno accesso al talento e alle risorse economiche necessarie per apprezzare a pieno gli avanzamenti nel campo di machine learning e intelligenza artificiale", dice Fei-Fei Li, Chief Scientist Cloud AI di Google. Dallo scorso anno la società californiana mette a disposizione dei programmatori un motore di machine learning sul cloud per creare dei modelli di lettura dei dati, per il cui utilizzo però sono necessarie competenze specifiche. D'altra parte i modelli pre-istruiti, più facili da implementare, hanno un campo di applicazione predefinito, quindi poco personalizzabile. </p>
<p> Nell'idea di Google AutoML prenderà il meglio delle due offerte. Permettendo anche a programmatori senza grosse esperienze di intelligenza artificiale, grazie a tecnologie come il learning to learn e a una interfaccia molto intuitiva, di creare in maniera semplice modelli di apprendimento avanzati e personalizzati, per poi testarne l'efficacia e introdurli in azienda. "Nel mondo esistono solo un milione di data scientist e appena migliaia di ricercatori in machine learning, ma 21 milioni di sviluppatori", ha spiegato Fei-Fei Li. La prima componente introdotta sarà Vision, per realizzare dei modelli di riconoscimento delle immagini. Soluzioni che possono trovare applicazione in aziende retail e assicurative, per la definizione dei sinistri, oppure in campo sanitario. Ma in seguito la soluzione, che avrà un costo legato all'intensità di utilizzo del sistema computazionale, verrà estesa anche a video, traduzione e riconoscimento del linguaggio naturale. Sul mercato del cloud e delle sue applicazioni è in corso una sfida tra i maggiori colossi tecnologici, da Amazon a Microsoft a Google. Con questa novità la società di Mountain View cerca di rendere le tecnologie più avanzate della nuvola, finora affare da aziende con grandi reparti informatici, più appetibili anche per le piccole e medie imprese. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2019/09/04/news/intelligenza_artificiale_e_torneo_di_robot_calciatori_ritorna_maker_faire_-235153939/" parent_folder="Repubblica 2018-2020" id="file17861722" filename="intelligenza_artificiale_e_torneo_di_robot_calciatori_ritorna_maker_faire_-235153939">
<p> Tecnologia </p>
<p> Intelligenza artificiale e torneo di robot calciatori, ritorna "Maker Faire" </p>
<p> Sono due delle novità della kermesse dedicata ai "makers". Dal 18 al 20 ottobre alla Fiera di Roma </p>
<p> 04 Settembre 2019 2 minuti di lettura </p>
<p> ROMA - Un ampio spazio dedicato alle applicazioni e alle potenzialità dei sistemi di intelligenza artificiale sarà una delle principali novità della prossima "Maker Faire Rome - The European Edition" in programma nella Capitale dal 18 al 20 ottobre 2019. L'Italia può vantare una consolidata tradizione nel campo dell'intelligenza artificiale, a livello metodologico, tecnologico e applicativo e, in questo contesto, spiegano gli organizzatori, è nata l'esigenza di unire le forze delle università e dei Centri di ricerca per la creazione di un nuovo Laboratorio nazionale CINI chiamato AIIS "Artificial Intelligence and Intelligent Systems". Il laboratorio vuole creare le basi per un efficace ecosistema italiano dell'intelligenza artificiale, inclusivo di tutte le competenze e votato a evidenziare le eccellenze nazionali per rafforzare il ruolo scientifico e tecnologico dell'Italia in Europa e nel mondo. Il Laboratorio AIIS del CINI organizzerà una rassegna di sistemi di Intelligenza artificiale nell'ambito di Maker Faire 2019. L'obiettivo è quello di mostrare al grande pubblico le potenzialità dei sistemi di IA attraverso il modello di organizzazione sui domini applicativi, che ha riscosso un notevole successo al recente convegno Ital-IA 2019, ed in grado di veicolare l'importanza dell'Intelligenza artificiale nello sviluppo del nostro Paese e non solo. La Maker Faire 2019 sarà, quindi, un'occasione per far conoscere ai visitatori le potenzialità dell'intelligenza artificiale e per alimentare la virtuosa rete di scambio e collaborazione tra enti di ricerca, istituzioni e imprese interessate alla tecnologia più strategica e dirompente del XXI secolo. L'intelligenza artificiale, infatti, già sta impattando settori strategici che caratterizzano il nostro stile di vita, come la medicina, le tecnologie per il benessere, l'invecchiamento, l'istruzione e l'educazione, fino alle discipline umanistiche e culturali. </p>
<p> Tra le dimostrazioni di sistemi di intelligenza artificiale, la Maker Faire Rome ospiterà anche un torneo triangolare di robot calciatori "RoboCup" con protagoniste le squadre di Sapienza Università di Roma e di due altre università provenienti da Svizzera e Germania. Un torneo nel quale sistemi robotici umanoidi, completamente autonomi, si affronteranno in partite di calcio, mettendo alla prova metodi e tecniche di intelligenza artificiale allo stato dell'arte. "L'Intelligenza Artificiale - afferma Daniele Nardi, docente di Intelligenza Artificiale alla Sapienza Università di Roma e coordinatore dell'omonima area di Maker Faire Rome - è una sfida scientifica, che ha accompagnato tutta la mia carriera di ricercatore. In questa fase, i risultati della ricerca possono effettivamente portare alla realizzazione di sistemi in grado di contribuire allo sviluppo della nostra società in molteplici aspetti, come emerso anche dal convegno Ital-IA, organizzato dal Laboratorio CINI AIIS nel marzo scorso. Ed è proprio questo l'obiettivo che lo spazio dedicato ai sistemi di Intelligenza Artificiale si prefigge: mostrare le opportunità offerte dalle tecnologie dell'IA, facendo principalmente riferimento a sistemi industriali, in modo da evidenziare che non è solo il mondo della ricerca impegnato sul tema dell'Intelligenza Artificiale, ma che il trasferimento tecnologico verso il mondo produttivo è già in atto". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2020/05/28/news/intelligenza_artificiale_la_grande_sfida_e_per_la_democrazia_e_l_uguaglianza-257816277/" parent_folder="Repubblica 2018-2020" id="file17861719" filename="intelligenza_artificiale_la_grande_sfida_e_per_la_democrazia_e_l_uguaglianza-257816277">
<p> Tecnologia </p>
<p> Intelligenza artificiale, la grande sfida è per la democrazia e l’uguaglianza </p>
<p> Uno strumento utile per orientarsi tra le opportunità e i rischi insiti in questa tecnologia è il libro Intelligenza Artificiale, scritto da Alessandro Longo e dal noto giurista Guido Scorza </p>
<p> 28 Maggio 2020 2 minuti di lettura </p>
<p> Non c’è mai stato un momento più importante di questo per studiare l’intelligenza artificiale: i suoi sviluppi tecnici, l’impatto sul futuro del lavoro, sull’economia e sui nostri diritti. La pandemia e la crisi economica stanno spingendo sull’innovazione e quindi accelerando tutte le previsioni sullo sviluppo della quarta rivoluzione industriale. Tra gli altri, ne parla un recente studio del Mit Technology Review (Covid-19 and the workforce): impatti che prima erano previsti a 3-5 anni, da precedenti studi (Accenture, McKinsey, ancora nel 2019) ora sono davanti a noi: gli esperti prevedono una più ampia diffusione dell’intelligenza artificiale nelle case, nelle aziende, negli ospedali e nelle strade. Serve per aumentare l’efficienza della macchina economica, della pubblica amministrazione e per favorire il lavoro in un’era di distanziamento sociale. Ne deriva una grande opportunità di sviluppo, ma anche rischi importanti per i nostri diritti sociali e civili. Un assaggio lo si è già visto in questi giorni: robot e droni usati come distanziatori sociali in alcuni Paesi (Singapore, India) sono una prova di come lo sviluppo dell’automazione può essere applicato allo scenario pandemico con un possibile impatto sui diritti fondamentali. Idem l’escalation di tecnologie di sorveglianza di massa che c’è stato in Cina – con droni, riconoscimento facciale, app di tracciamento obbligatorie. La pandemia è servita come opportunità per potenziare l’apparato di sorveglianza di Stato, che era già massiccio. E ora si riporta la tentazione – in una prima città cinese, Huangzhou - di rendere permanente il nuovo apparato, per esempio obbligando a usare l’app che registra il proprio stato di salute anche in contesti post-emergenziali. Chi non dimostrerà sull’app (e all’app) di essere in piena salute potrà avere difficoltà a lavorare e subire diverse discriminazioni. Più la tecnologia consente a Stati e organizzazioni di limitare i diritti civili, più è importante il ruolo delle norme a loro tutela: in Europa, il regolamento europeo Gdpr. </p>
<p> L’accelerazione tecnologica crea sfide anche ai lavoratori, che dovranno imparare a collaborare con le macchine o a cambiare percorsi di carriera. Uno studio del Mit di maggio stima che 30-50 milioni di posti di lavoro saranno in vario modo impattati dall’intelligenza artificiale nei prossimi anni. Tra gli scenari da evitare non c’è solo la crescita della disoccupazione ma soprattutto quella delle diseguaglianze economiche (per esempio tra lavoratori specializzati, che convivranno con le macchine intelligenti, e lavoratori che ne saranno invece sostituiti). Nei confronti di un grande cambiamento, delle opportunità e dei rischi che ne derivano, lo strumento migliore a disposizione dei cittadini è la conoscenza ("Prima conoscere, poi discutere, poi deliberare", Luigi Einaudi). Questo è l'approccio del libro Intelligenza Artificiale, scritto da Alessandro Longo e dal noto giurista Guido Scorza (dal 4 giugno nelle librerie e in versione digitale, pubblicato da Mondadori Università). Dopo la prefazione, dell’ex garante privacy Francesco Pizzetti e professore emerito di diritto costituzionale all’università di Torino, un capitolo di introduzione all’intelligenza artificiale permette di coglierne le basi storiche e tecnologiche. Si approfondiscono poi le promesse e i rischi dell’intelligenza artificiale, in termini economici, sociali, giuridici. Quindi gli impatti in vari ambiti: il lavoro, la casa, la mobilità, la Sanità. L’ultimo capitolo espone gli strumenti normativi su cui possiamo fare leva, a tutela dei nostri diritti, e si spinge ad avanzare alcune raccomandazioni giuridiche. Insomma un utile strumento per comprendere e orientarsi in questo straordinario cambiamento. Tutto da leggere. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2020/05/11/news/i_robot_nessun_pregiudizio_di_genere_ma_per_noi_sono_incompetenti-256297534/" parent_folder="Repubblica 2018-2020" id="file17861720" filename="i_robot_nessun_pregiudizio_di_genere_ma_per_noi_sono_incompetenti-256297534">
<p> Tecnologia </p>
<p> I robot? Nessun pregiudizio di genere. Ma per noi sono incompetenti </p>
<p> di SIMONE COSIMI </p>
<p> Mentre si moltiplicano le previsioni per un'esplosione dell'automazione, anche in ambito domestico e quotidiano perché ci aiuteranno a rispettare il distanziamento fisico, due studi scoprono che non abbiamo troppa fiducia nei "droidi" </p>
<p> 11 Maggio 2020 4 minuti di lettura </p>
<p> I ROBOT potrebbero aiutarci, e non poco, a mettere davvero in pratica il distanziamento sociale. In azienda come in famiglia o in altri luoghi che, a dire il vero, costituiscono già da tempo un habitat naturale per macchine e automi. D'altronde lo stesso settore è in crescita roboante: secondo GlobalData dai 98 miliardi di dollari del 2018 il giro d'affari salirà ai 275 del 2025. Ma si trattava di stime pre-Covid: gran parte degli esperti sono infatti concordi nel sostenere che l'impatto della pandemia metterà il turbo all'automazione, su più livelli diversi. Senza necessariamente dover aspettare le auto a guida autonoma di quinto livello o le più avveniristiche soluzioni di intelligenza artificiale. D'altronde diversi esempi di questi mesi di emergenza sanitaria ci hanno spiegato con chiarezza in che modo i robot possano affiancarci, più che sostituirci, nei lavori più a rischio. Quelli in cui il distanziamento è essenziale: dal robot-infermiere Sanbot Elf testato all'ospedale di Circolo e Fondazione Macchi di Varese all'intero reparto di uno degli ospedali di Wuhan, nello Hubei, il Wuchang, che per un po' di tempo stato gestito (quasi) esclusivamente da una flotta di robot sviluppati dalla società pechinese CloudMinds. Nei momenti di picco, le macchine si sono prese cura di circa 200 persone fra pasti, pulizie e rilevazione dei parametri vitali grazie ai braccialetti di cui erano dotati i pazienti. Di esempi ce ne sono molti altri, dalle flotte che a Hong Kong puliscono la metropolitana al celebre robottino Temi che in diversi paesi, dal Giappone alla Corea, si è occupato delle più diverse mansioni. Non a caso era stato inserito l'anno scorso fra le migliori 100 invenzioni da Time. Discorso diverso per i "cani pattugliatori" di Boston Dynamics: uno Spot è stato sguinzagliato nel parco parco Bishan-Ang Mo Kio di Singapore, che qualche inquietudine la sollevano. </p>
<p> Se in certi casi si parla di macchine industriali molto lontane dall'immagine che abbiamo degli androidi, come i "cobot, i cosiddetti robot collaborativi da fabbrica, in altri ci si riferisce invece ai robot da compagnia che spesso ricalcano neanche troppo vagamente aspetti e fattezze di bambini, esseri umani o comunque mantengono elementi puramente estetici come occhi, naso e bocca. Sia i primi che i secondi sanno fare molti lavori, e spesso bene, ma due nuovi e recenti studi raccontano che no, per il momento non ci danno ancora troppa fiducia. Un paio di indagini, messe in campo originariamente per valutare la trasposizione di eventuali pregiudizi di genere anche nell'ambito di questo tipo di dispositivi, hanno infatti partorito esiti inaspettati. Il primo è estremamente positivo: non sembra manifestarsi alcun sessismo nei confronti dei robot. Per il Georgia Institute of Technology il fatto che queste macchine ci vengano presentate come "femminili" o "maschili" non cambia molto nella nostra percezione. "Questo ci ha sorpreso - ha detto Ayanna Howard, principale autrice di entrambi gli studi e docente alla Tech School of Interactive Computing - abbiamo registrato solo una leggera differenza in un paio di lavori, ma non significativa. C'è stata per esempio una piccola preferenza per un robot 'maschilè nel caso delle consegne" ma nulla di più. Il punto di partenza di queste indagini è che anche se i robot non sono esseri senzienti, le persone tendono a interfacciarsi sempre più spesso con loro e inevitabilmente a umanizzarli. Senza necessariamente dover rispolverare l'indimenticabile "Uomo bicentenario" con Robin Williams. Per cui ad Howard e soci interessava capire come funzioni questa integrazione sociale e cosa possa verificarsi di sbagliato. Una dinamica che, come abbiamo visto, è destinata a intensificarsi. Se la manifattura è l'ambito che già oggi sembra il più propizio per l'esplosione dei robot - sono già circa 2,5 milioni nel mondo - ci sono ambiti inattesi, ed estremamente quotidiani, dal supermercato ai "droidi" da compagnia, che cominceranno a ospirare device sempre più sofisticati. O magari anche semplici, in grado appunto di mantenerci alla giusta distanza. In fondo, Sony commercializza da anni il suo cagnolino Aibo, recentemente "revisionato" con nuove funzionalità. "Ci sono i robot-sorveglianti con cui non dobbiamo interagire ma che, quando li vediamo, ci spingono a comportarci proprio come se vedessimo una pattuglia di poliziotti - aggiunge Howard - oppure quelli progettati per coinvolgerci dal punto di vista emotivo, soluzioni che al contrario ci portano a trattare questi robot come se fossero creature intelligenti". Ed è un bene che non possano comprendere i nostri sentimenti. Visto che l'altra sorpresa della coppia di studi è stata proprio la nostra scarsa stima nei loro confronti: se non dimostriamo pregiudizi di genere, ne manifestiamo invece, e molti, sotto l'aspetto della competenza. Una predisposizione molto forte tanto da aver fatto sospettare all'autrice che potesse trattarsi di una dinamica talmente potente da aver offuscato altri elementi di rilievo per il proprio lavoro. Per esempio, in una serie di video i robot umanoidi si presentavano a volontari scelti online e a caso, selezionati fra i 20 e i 70 anni di età e in gran parte con un'educazione almeno pari al college. Il risultato? La valutazione dei severissimi "umani" è stata quella di assegnare loro solo una manciata di semplici lavori, manifestando una chiara sfiducia nelle loro competenze per incarichi più complessi. "I risultati ci hanno stupito perché le cose che la gente pensava che i robot fossero in grado di fare peggio erano cose che in realtà fanno molto bene - ha spiegato la scienziata - in un caso si parlava di un robot come il sistema chirurgico Da Vinci, che secondo le persone non sarebbe all'altezza del delicato compito. Così come i robot per la sicurezza, che alle persone non piacciono mentre è pieno di società che si sono specializzate esattamente in questo ambito". Nel complesso, i 200 partecipanti alle due indagini hanno espresso giudizi negativi anche su altri lavori: baby sitter, terapisti, infermieri, vigili del fuoco e diversi altri. Al contrario, gli incarichi che invece affiderebbero con più fiducia ai robot sarebbero quelli di guida turistiche, receptionist, camerieri e operatori per l'impacchettamento delle consegne. I ricercatori devono ancora approfondire le loro scoperte, perché è davvero complesso comprendere l'origine di questi pregiudizi rivolti spesso proprio nei confronti di macchine progettate invece per specifici compiti. Una delle ipotesi di Howard è che la narrazione che i media hanno portato avanti nel corso degli anni sui robot, con fallimenti epici, incredibili fraintendimenti o altre situazioni grottesche possano aver costruito una specie di sfiducia generalizzata. Costruendo intorno alle macchine un clima di generale inaffidabilità. Un ultimo passaggio riguarda sempre i pregiudizi di genere. Se non se ne sono riscontrati di significativi, è pur vero che le persone si sono dimostrate estremamente versatili e rapide ad assegnare un genere ai robot umanoidi. Spesso sulla base della loro stessa "presentazione" in video e nient'altro. Per capirci, se un robot diceva "Ciao, mi chiamo James" con una voce maschile, ovviamente per le persone non c'era alcun dubbio: si trattava di James, un "robot maschio". Allo stesso modo con una formula come "Ciao, mi chiamo Mary" con timbro femminile. Ma quando i robot si sono presentati con un semplice "Ciao" e un tono neutrale, i volontari hanno comunque assegnato loro un genere, con precedenza a quello maschile, poi neutro e infine femminile. Cosa dobbiamo portarci a casa di queste indagini? Per esempio che gli sviluppatori e gli inventori non dovrebbero insistere sul tema del genere dei robot. Saranno gli utenti ad assegnarli, in base alle loro esperienze: "Diamo loro questo diritto, evitiamo di rafforzare gli stereotipi di genere" ha aggiunto l'esperta. Curioso che il cane i Singapore riproduca i propri messaggi di cautela con tono femminile. E se alcuni addirittura suggeriscono di evitare del tutto l'"antropomorfizzazione" di questi dispositivi, proprio per scoraggiare questi fenomeni e altri tipi di empatia, Howard non condivide: "I robot possono dare buoni risultati per l'interazione sociale. Possono essere molto utili nelle residenze assistenziali per gli anziani, per tenere compagnia. Possono funzionare bene da baby sitter, invece di lasciare i bambini davanti alla tv". E possono essere anche ottimi comici: "Se andate a un parco di divertimenti, ce ne sono in grado di fare ottimi scherzi e numeri" ha chiuso Howard. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2020/02/05/news/lavoro_i_robot_fanno_paura_7_milioni_vedono_il_proprio_posto_a_rischio-247649943/" parent_folder="Repubblica 2018-2020" id="file17861721" filename="lavoro_i_robot_fanno_paura_7_milioni_vedono_il_proprio_posto_a_rischio-247649943">
<p> Tecnologia </p>
<p> Lavoro, i robot fanno paura: 7 milioni vedono il proprio posto a rischio </p>
<p> Secondo il Rapporto Censis-Eudaimon, la metà degli operi teme per il proprio impiego </p>
<p> 05 Febbraio 2020 1 minuti di lettura </p>
<p> LA TECNOLOGIA spaventa il mondo del lavoro. Sono 7 milioni gli italiani che hanno paura di perdere il posto a causa dell'innovazione, dai robot all'intelligenza artificiale. Così il terzo Rapporto Censis-Eudaimon sul welfare aziendale, realizzato in collaborazione con Credem, Edison, Michelin e Snam. In particolare, rileva l'indagine, quasi un operaio su due sente il proprio impiego a rischio. Le ansie sono diffuse. Secondo lo studio, infatti, "l'85% dei lavoratori esprime una qualche paura o preoccupazione per l'impatto atteso della rivoluzione tecnologica e digitale". Basti pensare, stando sempre al rapporto, che il 70% teme la riduzione di redditi e tutele sociali. </p>
<p> Ma se da una parte l'automazione spaventa, dall'altra i salari dimostrano che chi è occupato nell'hi-tech guadagna il doppio. "Già oggi chi lavora nei settori tecnologici guadagna il doppio degli altri", sostiene il report: "Fatto 100 lo stipendio medio italiano, nei settori tecnologici il valore sale a 184,1, mentre negli altri comparti scende a 93,5. Sono i numeri di una disuguaglianza salariale in atto nelle aziende italiane che - viene sottolineato - convive con le paure dei lavoratori e certifica l'esistenza di un gap tra chi oggi lavora con le nuove tecnologie e chi no". Tanto che il rapporto parla esplicitamente di "salari tecno-polarizzati". </p>
<p> Lavoro: 7 milioni di italiani hanno paura di perdere il posto a causa dell’innovazione tecnologica https://t.co/ruAwxxvjqV </p>
<p> Dalla sanità integrativa alla pensione complementare, dagli asili nido ai rimborsi per la palestra: il welfare aziendale risulta essere un 'pianeta' multiforme che cambia a seconda della realtà in cui ci si trova ma in generale agli italiani piace. "Per due lavoratori su tre che già ne beneficiano (il 66%) sta migliorando la loro qualità della vita", si legge nello studio. </p>
<p> Un operaio su due è convinto che la propria occupazione sia minacciata da robot e intelligenza artificiale @EUDAIMONspa #lavoro #robotica </p>
<p> "Guardando al futuro, il 54% dei lavoratori è convinto che gli strumenti di welfare aziendale potranno migliorare il benessere in azienda e, in vista dell'arrivo di robot e intelligenza artificiale, viene annoverato tra le cose positive che si possono ottenere in un futuro immaginato con meno lavoro, meno reddito e minori tutele". Insomma, stando al rapporto, potrebbe essere questa la strada "per mitigare le disuguaglianze". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/economia/2019/01/29/news/lavoro_la_speranza_che_i_robot_rendano_gli_orari_piu_flessibili-217694431/" parent_folder="Repubblica 2018-2020" id="file17861748" filename="lavoro_la_speranza_che_i_robot_rendano_gli_orari_piu_flessibili-217694431">
<p> Economia </p>
<p> Lavoro, la speranza che i robot rendano gli orari più flessibili </p>
<p> Secondo un sondaggio di Fujitsu, i dipendenti vedono nell'Intelligenza artificiale un modo per migliorare l'equilibrio tra vita personale e lavorativa </p>
<p> 29 Gennaio 2019 1 minuti di lettura </p>
<p> Minaccia ai posti di lavoro o supporto alla produttività? Il ruolo dei robot nel futuro delle nostre giornate lavorative sta ormai da tempo scatenando il dibattito e la letteratura, tra chi vede all'orizzonte un'ecatombe di posti di lavoro e chi si aspetta mirabolanti creazioni di nuove professionalità. E i lavoratori cosa pensano? Secondo uno studio pubblicato da Fujitsu, i dipendenti ritengono che la loro produttività si stia riducendo nonostante giornate lavorative più lunghe, e sono pronti e disposti a ricevere l'aiuto dell'Intelligenza artificiale per risolvere questo problema. Anche perché il barometro in azienda rischia di volgere al brutto, con la percezione che le strutture tecnologiche a livello interno non siano più in grado di supportare il personale per lavorare in modo efficace e che spesso il luogo di lavoro delude le aspettative dei dipendenti: quasi metà di essi (46%) afferma che il proprio workplace non aiuta il recruitment né trattiene le persone dotate di competenze essenziali. </p>
<p> I professionisti sentiti per la ricerca credono che l'Intelligenza artificiale "possa avere un effetto positivo sulla vita lavorativa di tutti i giorni": risposta data nell'80 per cento dei casi. E non sono solamente i nativi digitali ad essere pronti ad adottare la AI: questo atteggiamento così positivo è condiviso tanto dai neoassunti quanto dai colleghi più esperti. Dal robot e dalla tecnologia, a fronte di queste giornate lavorative sempre più lunghe, ci si aspetta una sponda per meglio bilanciare la vita privata con quella professionale: un obiettivo che può essere raggiunto grazie a orari flessibili, che oltre la metà del campione (53%) considera "molto importanti" in termini di aumento della produttività. Tuttavia, oltre un terzo degli intervistati (35%) valuta appena adeguata o scarsa la capacità del proprio datore di lavoro di supportare un buon equilibrio tra vita personale e vita lavorativa. Tra i fattori determinanti individuati dai dipendenti come quelli che possono favorire la loro efficienza, il 49% indica un ambiente di lavoro sano e stimolante, seguito dal 40% di indicazioni a favore dell'accesso a tool di produttività appropriati. Nick Mayes, research lead e Principal Analyst di PAC, ha commentato: "I risultati della ricerca dimostrano come buona parte dei workplace e delle pratiche lavorative di oggi impediscano ancora ai dipendenti di massimizzare la loro produttività. Le aziende devono concentrarsi su pratiche efficaci facendo ordine tra dati e processi e semplificando l'accesso del personale alle informazioni, quando e dove esse occorrono". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2019/08/17/news/l_intelligenza_artificiale_di_astro_cane-robot_che_risponde_ai_comandi-233817589/" parent_folder="Repubblica 2018-2020" id="file17861730" filename="l_intelligenza_artificiale_di_astro_cane-robot_che_risponde_ai_comandi-233817589">
<p> Un 'cucciolo' di 45 kg dotato di sensori, radar e un cervello computerizzato. Sviluppato nei laboratori della Florida Atlantic University, esegue i comandi e apprende per svolgere azioni ausiliarie </p>
<p> COSA hanno a che fare un cane-robot e Alexa di Amazon o Siri di Apple? Molto più di quanto non crediate. Lo dimostra Astro, la nuova creatura sviluppata dal Machine Perception and Cognitive Robotics Laboratory (Mpcr) della Florida Atlantic University che grazie all'intelligenza artificiale di cui sono dotati gli assistenti vocali risponde ai comandi come ancora i suoi simili non sembrano saper fare. La testa, stampata in 3D per replicare le fattezze di un Dobermann pinscher, contiene un computer (Nvidia Jetson TX2) con una potenza di calcolo da 4 teraflop. E' il cervello che gli consente di eseguire i comandi che riceve e al tempo stesso di apprendere dall'esperienza. </p>
<p> Forse le sembianze lasciano ancora a desiderare, ma per quanto riguarda il comportamento Astro incarna l'evoluzione di androidi zoomorfi come quelli già avanzati della Boston Dynamics e non solo, in grado però di processare le informazioni ricevute per svolgere azioni non pre-programmate, quindi frutto di un apprendimento basato su una rete neurale ''profonda'', ovvero una simulazione computerizzata del cervello. </p>
<p> La dotazione tecnologica è di tutto rispetto. Astro si muove e interagisce grazie a sensori, imaging radar, telecamere e un microfono direzionale che fanno di lui un cucciolo da addestrare di 45 kg. Ad esempio, risponde ai comandi proprio come un cane: si siede, si alza, si sdraia su richiesta. Per arrivare, via via, a rispondere ai gesti, capire diverse lingue, coordinare i suoi movimenti con i droni, fino a distinguere i volti umani e a riconoscere altri cani. </p>
<p> Più di 12 sensori lo rendono un candidato ideale per diventare un fedele aiutante delle forze dell'ordine o collaborare nelle operazioni di salvataggio, oltre che come cane-guida che impara a percepire suoni, attivare i radar in presenza di gas o esplosivi, apprende i movimenti utili e arriverà a eseguire persino screening diagnostici. </p>
<p> Nel video dimostrativo della Feu il cane-robot esegue i comandi in modo impeccabile e trotterella sui prati del campus universitario. Niente in confronto a quel che piano piano impara a fare, ad esempio percepire richieste di aiuto che non rientrano nel campo uditivo umano. </p>
<p> Ma al di là delle zampe articolate e del manto con codina statica a coprire gli avanzati meccanismi che lo regolano, il vero tallone d'Achille di Astro sembra essere l'espressività: lo sguardo digitale lo rende ancora lontano dai suoi simili in carne ossa. Segno che forse sull'empatia uomo-cane riguardo alle macchine c'è ancora parecchio da fare. </p>
<p> DA REP </p>
<p> Oggi e domani a Milano il primo evento di Repubblica dedicato alla società digitale. Con ospiti da tutto il mondo </p>
<p> Le testate coinvolte dietro l'evento di Milano. Dal Die Welt a El País, fino alla Gazeta Wyborcza, Le Figaro, Le Soir, Tages-Anzeiger e Tribune de Genève oltre a La Repubblica </p>
</doc>
<doc url="https://www.repubblica.it/salute/medicina-e-ricerca/2019/02/19/news/l_intelligenza_artificiale_si_trasforma_in_pediatra-219200519/" parent_folder="Repubblica 2018-2020" id="file17861738" filename="l_intelligenza_artificiale_si_trasforma_in_pediatra-219200519">
<p> L'intelligenza artificiale fa la diagnosi come il pediatra </p>
<p> di VIOLA RITA </p>
<p> Un algoritmo basato su tecniche di apprendimento automatico è stato in grado di individuare patologie più e meno diffuse con la stessa accuratezza del medico. Ma non lo sostituirà </p>
<p> 19 Febbraio 2019 3 minuti di lettura </p>
<p> OGGI il computer indossa il camice del pediatra. Già, perché un nuovo studio, condotto da un gruppo di ricerca cinese, mostra che un algoritmo di intelligenza artificiale potrebbe essere in grado di riconoscere con grande precisione le malattie nei bambini, fra cui infezioni alle vie respiratorie e asma, e di formulare una diagnosi corretta. Questo sistema, potrebbe diventare un supporto prezioso per i medici, anche se, come rimarcano gli autori dello studio, non prenderà il suo posto. La ricerca, condotta dalla Guangzhou Medical University in Cina, è pubblicata su Nature Medicine. LEGGI - Il robot entra in corsia e aiuta a fare la diagnosi </p>
<p> CONNETTERE I DATI </p>
<p> Gli autori hanno utilizzato un algoritmo basato sul machine learning (o apprendimento automatico), un sistema di intelligenza artificiale in grado di migliorare le proprie performance con l'esperienza, attraverso l'analisi di grandi database di dati. I ricercatori hanno somministrato al programma 101 milioni di informazioni cliniche provenienti da quasi 1,4 milioni di visite pediatriche svolte presso uno dei principali centri accademici di ricerca medica cinese. </p>
<p> Il modello è riuscito a identificare le informazioni più rilevanti a partire dalla cartella clinica elettronica del paziente, una vasta collezione di dati sulla sua salute in formato digitale. Una volta individuati gli elementi più significativi, è in grado di associarli e rielaborarli, sottolineano gli autori, con un'accuratezza che finora non era stata raggiunta da altri sistemi di questo genere. “Può mimare un pediatra umano per interpretare e integrare tutti i tipi di dati medici”, spiega, all'agenzia di stampa francese Afp, Kang Zhang ricercatore dell'Università della California a San Diego, “i disturbi del paziente, la sua storia clinica, gli esami del sangue e le immagini diagnostiche – per fare la diagnosi”. LEGGI - Alzheimer, la diagnosi arriva dall'intelligenza artificiale </p>
<p> SE L'ALGORITMO FA LA DIAGNOSI </p>
<p> Gli scienziati hanno messo in evidenza che il loro strumento è preciso tanto quanto il pediatra nella formulazione della diagnosi relativa a patologie diffuse nell'età infantile, come sinusiti e altre infezioni alle vie respiratorie. L'algoritmo, infatti, ha individuato la presenza di queste manifestazioni cliniche nel 95% dei casi. Ma, con sorpresa degli autori, è stato accurato anche nel riconoscere malattie meno comuni. Ad esempio, ha identificato attacchi di asma nel 97% dei casi, la meningite batterica e la varicella (93%) e la mononucleosi (90%). Queste tecnologie, sottolineano gli scienziati, potrebbero essere utilizzate presto a livello clinico. Insomma, ci aspetta un futuro senza pediatri? Assolutamente no, come rimarcano gli stessi autori dello studio. “L'intelligenza artificiale non sostituirà mai il pediatra”, chiarisce Zhang. “Potrà semplicemente permettere ai medici di svolgere un lavoro migliore con un costo e tempi inferiori”. L'autore paragona questa opportunità a quella delle automobili autonome che rimangono però sotto il controllo dell'essere umano. LEGGI - Se l'Intelligenza artificiale diventa amica del nostro cuore </p>
<p> L'INTELLIGENZA ARTIFICIALE IN MEDICINA </p>
<p> Il risultato dello studio su Nature Medicine è interessante, commenta Alberto Tozzi, pediatra e responsabile di Innovazione e percorsi clinici all'Ospedale Pediatrico Bambino Gesù, e si inserisce nell'ormai ampio filone di ricerca che studia l'applicazione di sistemi basati sull'intelligenza artificiale in medicina. “Il timore che gli algoritmi sostituiscano la professionalità del pediatra è ingiustificata, dato che potranno funzionare sempre e solo in aggiunta all'intervento del medico”, sottolinea Tozzi, “Ciò che è certo è che il professionista dovrà imparare ad utilizzare queste tecnologie a suo vantaggio. Non si tratta infatti di un'automazione e sono sistemi che il clinico deve guidare e governare”. L'idea è che gli algoritmi possano andare a svolgere operazioni semplici. Un esempio? “Questi sistemi sono molto validi nella lettura delle radiografie”, spiega Tozzi. “In presenza di un sospetto diagnostico, come quello di una polmonite, una patologia facilmente riconoscibile dalle immagini, il medico può servirsi dell'algoritmo. Così ha più tempo invece per studiare situazioni più complesse o nel rapporto con i pazienti”. Sempre tenendo conto che bisogna prestare attenzione ad alcuni dei potenziali rischi di un uso diffuso di questi algoritmi. “Nel tempo, delegando sempre alla macchina alcuni compiti si potrebbero perdere certe competenze di base – spiega Tozzi – per questo è importante che il medico abbia sempre il controllo dell'algoritmo e non smetta di svolgere questi compiti”. Altro aspetto, prosegue l'esperto, riguarda l'uso di campioni di dati molto vasti e diversificati per addestrare gli algoritmi e la trasparenza dei meccanismi con cui questi sistemi funzionano. Il tutto senza dimenticare l'intelligenza artificiale è già fra noi, nella nostra quotidianità, rimarca il pediatra. “Basti pensare alla messaggistica vocale sulle applicazioni dei nostri cellulari”, ricorda l'esperto, “che funziona tramite l'intelligenza artificiale. L'idea è che tecnologie come come Google Duplex, l'assistente vocale di Google, che telefona e interagisce con l'utente, possa entrare ed essere utilizzato anche in ambito clinico”. Sempre sotto la guida del medico, che rimane al timone della nave. </p>
<p> Il tuo contributo è fondamentale per avere un’informazione di qualità. Sostieni il giornalismo di Repubblica. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2019/08/21/news/mise_strategia_intelligenza_artificiale-234062021/" parent_folder="Repubblica 2018-2020" id="file17861734" filename="mise_strategia_intelligenza_artificiale-234062021">
<p> Tecnologia </p>
<p> Mise: al via la consultazione per l'intelligenza artificiale </p>
<p> Arturo di Corinto </p>
<p> Proprietà dei dati, formazione ad hoc, partenariati pubblico privati, campagne di sensibilizzazione. Sono 83 le proposte del gruppo di esperti voluto dal governo. Col solito punto di debolezza: non ci sono i soldi per attuare la strategia nazionale </p>
<p> 21 Agosto 2019 3 minuti di lettura </p>
<p> CON la crisi di governo sullo sfondo, il ministero dello Sviluppo economico ha finalmente pubblicato la sua "Strategia per l'intelligenza artificiale" aprendo alla consultazione pubblica le proposte, 83 'raccomandazioni' formulate dal gruppo dei 30 esperti selezionati otto mesi fa. Tutte proposte leggibili ed emendabili sul sito del ministero. </p>
<p> Intelligenza artificiale, cuore dell'innovazione </p>
<p> Le tecniche di intelligenza artificiale stanno già cambiando il nostro mondo e promettono di rivoluzionare profondamente la sfera di possibilità dell'umano. Queste tecniche basate su software in grado di apprendere già riconoscono volti, "capiscono" il nostro linguaggio, scelgono per noi cibi, strade, film e acquisti, ottimizzano il consumo energetico e, accoppiate all’Internet delle cose (IoT), alla blockchain, alla meccatronica, potrebbero fare la differenza del sistema Italia nell’agrifood, nel turismo, nella manifattura, nonché nella gestione della Pubblica Amministrazione. La strategia nazionale per l'Ia mira infatti a incrementare gli investimenti, pubblici e privati, nello sviluppo e nelle tecnologie correlate; a potenziare l’ecosistema della ricerca e dell’innovazione; sostenere l’adozione delle tecnologie basate sull’Ia; rafforzare l’offerta educativa a favore della forza lavoro; sfruttare il potenziale dell’economia dei dati; consolidare il quadro normativo ed etico che ne regola lo sviluppo; promuovere la consapevolezza e la fiducia nell’Ia tra i cittadini; rilanciare la pubblica amministrazione e le politiche pubbliche; fino a favorire la cooperazione europea ed internazionale per un'Ia responsabile e inclusiva. </p>
<p> Etica dei robot: un approccio laico </p>
<p> Le 106 pagine di proposta che accompagnano il documento confermano questi indirizzi e per una volta, posizionano l’Italia in linea con la strategia europea, a vantaggio dei cittadini. Intanto per l’approccio: la tesi centrale del rapporto è che l'Ia non è buona o cattiva in sé: dipende dall’uso che se ne fa. "Se utilizzata in modo stupido, l'Ia riproduce e spesso amplifica la stupidità". </p>
<p> Nel rapporto, a tratti ripetitivo, ogni proposta considera gli aspetti etici e democratici dell’Ia per evitare violazioni dei diritti fondamentali e di principi etici condivisi. Responsabilizzare l’intero ecosistema "dallo sviluppatore al consumatore" è una delle chiavi del rapporto, anche per adeguare il quadro di protezione dei consumatori alla nuova realtà di mercato in chiave competitiva e di sviluppo sostenibile (R35). Ci sono inoltre notizie buone e altre meno buone per l’Italia dove, seppure la diffusione dei servizi di Ai è ancora limitata, si stima che il 12% delle imprese abbia attivato un progetto in questo campo, per la maggior negli assistenti virtuali. Un ecosistema ancora da mappare nel suo insieme "per formulare al meglio una strategia in un'ottica di smart specialisation e di politica industriale". Ad esempio, da noi si prevede una crescita importante della robotica di servizio, in un mercato mondiale che supera gli 11 miliardi di dollari. Purtroppo secondo lo Studio dell'Osservatorio Ai del Politecnico di Milano la spesa per lo sviluppo di algoritmi di intelligenza artificiale in Italia nel 2018 è stata di solo 85 milioni di euro. Secondo Marco Bentivogli, leader Cisl che ha contribuito al lavoro della commissione, il punto dolente rimane proprio questo: "L'Italia spenderà solo 48 milioni di euro nello sviluppo dell’Intelligenza artificiale a fronte dei miliardi investiti dagli altri Paesi". E continua: "Se confermate, queste cifre rendono inutile il lavoro fatto. L'Ia è oggi il volano più interessante delle Pmi e delle microimprese che, se adeguatamente stimolate da politiche pubbliche di sostegno agli investimenti, potrebbero rappresentare un vantaggio competitivo". Ma qui un aiuto dovrebbe venire dall’Europa. Come ribadisce il rapporto, "a integrazione degli investimenti nazionali la Commissione investirà 1,5 miliardi di euro entro il 2020, ossia il 70 % in più rispetto al periodo 2014-2017. Per il prossimo bilancio dell'Ue a lungo termine (2021-2027) la proposta è di investire 9,2 miliardi di euro per il digitale, di cui almeno 2,5 miliardi per l'Ia. Cosa resta da fare allora? Investire nella formazione ma a partire dalla scuola dell'obbligo, sviluppare progetti di testing su larga scala e mettere a sistema università, centri di ricerca e scuole di eccellenza. E poi puntare sui partenariati nel pubblico-privato ricordandoci, come fa il rapporto, che i dati usati per rendere le Ia efficienti sono nostri e che dobbiamo smettere di regalarli ai colonizzatori d’oltreoceano rendendoli "disponibili per l’addestramento dei sistemi, ma comunque proteggendoli e mantenendoli nel nostro territorio nazionale" (R59). Il rapporto, che si spinge a suggerire di creare un Istituto Italiano per l’Intelligenza artificiale, una struttura di ricerca e trasferimento tecnologico capace di attrarre talenti di prima classe dal 'mercato' internazionale e diventare un faro per lo sviluppo dell'Ia in Italia (R38) chiede anche di investire in modo deciso su corsi di dottorato, ricercatori industriali e assunzione di professori universitari in settori scientifico disciplinari collegati alle applicazioni dell’Ia. La chiave di volta di tutta la strategia potrebbe essere il diritto alla formazione insegnando nuove competenze e rimodellando quelle vecchie della forza lavoro. Va in questa direzione l'Ai Jobs law, una misura specifica per promuovere l’assunzione di esperti di Ia. Interessante l’idea di campagne informative in italiano e in inglese per spiegare ai cittadini caratteristiche, opportunità e rischi dell’Intelligenza artificiale prevedendo un ruolo attivo della Rai nell’educazione digitale per usare in modo consapevole proprio l'Ia. Creando inoltre una "Accademia Digitale" in grado di sviluppare programmi e contenuti video fruibili on air e on demand per dare risposte semplici e pratiche alle domande dei cittadini. Oltre ai dubbi che sollevano le onnipresenti proposte di 'cabine di regia' ad hoc bisognerebbe ricordare che un mese fa il presidente del Consiglio Conte aveva deciso la creazione di un dipartimento per il digitale di cui aveva tenuto le deleghe. Secondo Stefano Quintarelli, esperto per la Commissione Europea, "se il prossimo governo lo confermerà, potrebbe diventare quella la cabina di regia giusta per realizzare la strategia sull'intelligenza artificiale.” </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2019/11/08/news/nao_robot_genio_dell_energia_in_casa_cosi_la_smart_home_ci_fara_risparmiare-240611078/" parent_folder="Repubblica 2018-2020" id="file17861731" filename="nao_robot_genio_dell_energia_in_casa_cosi_la_smart_home_ci_fara_risparmiare-240611078">
<p> Tecnologia </p>
<p> Nao, robot genio dell'energia in casa. Così la smart home ci farà risparmiare </p>
<p> Matteo Marini </p>
<p> Lo hanno messo a punto i ricercatori Enea, è l’interfaccia di un sistema che, nel prossimo futuro, ci suggerirà come ridurre le bollette grazie a Big Data e AI. Dialogando con sensori ed elettrodomestici, ci avvertirà dei guasti e assisterà le persone malate </p>
<p> 08 Novembre 2019 4 minuti di lettura </p>
<p> È il genietto della casa, il volto simpatico che i bambini adorano e ha alle spalle tanta tecnologia. Nao è un robot, prodotto da SoftBank Robotics, e nelle mani dei ricercatori italiani dell’Enea, sta studiando da ‘esperto’ di consumi per assisterci in casa, e darci consigli su come fare a risparmiare sulla bolletta. Nao è stato premiato tra “I geni di Ecomondo 2019” la più grande fiera italiana sulla green economy, che si tiene ogni anno a Rimini, come una delle migliori eco-innovazioni. Il suo ambiente ideale è una smart home con dispositivi collegati a un cervello centrale, con lui a fare la parte del “grillo parlante”. </p>
<p> Oltre a controllare i nostri consumi, è pronto ad avvertirci di malfunzionamenti, guasti e pericoli in casa. Lo fa interrogando i dispositivi che già si trovano in molte abitazioni, sensori di movimento, temperatura, oppure su porte e finestre: "È una macchina che sa parlare molto bene con le macchine ma può anche parlare con le persone – spiega Andrea Zanela, ricercatore al Laboratorio robotica e intelligenza artificiale dell’Enea – e fa da interfaccia con gli abitanti della casa. Grazie all’AI, è in grado di riconoscere una serie di oggetti come degli occhiali. Potremo chiedergli di trovarceli, per esempio. A differenza degli altri, è un sensore che può girare per casa ed essere molto utile. Se ci dimentichiamo una pentola sul fuoco, è in grado di riconoscere un pericolo e addirittura venire a cercarci per avvertirci". </p>
<p> La smart home </p>
<p> Tutto parte da un sistema, quello della “casa intelligente”, che sta prendendo piede con molta rapidità, in tutto il mondo: elettrodomestici intelligenti e sensori sparsi in tutta casa. All’Enea gli ingegneri hanno messo a punto la Energy box il 'cervello' che raccoglie i dati, li analizza per dirci come consumiamo e suggerirci come fare per risparmiare: "I sensori che utilizziamo sono quelli disponibili sul mercato a prezzi ormai molto bassi – dice Stefano Pizzuti, ingegnere responsabile del laboratorio Smart cities and communities dell’Enea, mentre controlla i livelli di consumo delle abitazioni in cui l’Enea sta sperimentando la sua tecnologia – si va dai dieci euro fino a un massimo di 50. Noi abbiamo sviluppato il 'cervello' che raccoglie tutti i dati e li elabora per sapere cosa consuma di più e perché. Suggerendo come fare a consumare meno". </p>
<p> Sullo schermo del suo pc Pizzuti vede le icone che riguardano i diversi sensori, piazzati in una dozzina di case nel quartiere romani di Centocelle dove vivono altrettante famiglie che fanno da ‘pilota’ per questa tecnologia. Sono quasi tutti dispositivi “plug and play”, basta inserirli nella presa della corrente di un elettrodomestico come lavatrice o lavastoviglie. Ci sono sensori di movimento e misura della temperatura, altri che monitorano la chiusura di porte e finestre. Funziona tutto via wireless grazie a un codice open, non proprietario. Ognuno comunica tutto alla centralina che monitora i consumi e la Energy box pensa al resto: "Una delle indicazioni che mi può dare è per esempio quante volte apro la finestra perché magari consumo molto, troppo, per i riscaldamenti. Oppure può avvertirmi che ho lasciato la luce accesa, o la tv, e posso spegnerla da remoto. L’obiettivo è quello di creare consapevolezza per educare a comportarsi in modo energeticamente più virtuoso a casa propria. In due anni di sperimentazione abbiamo calcolato che una famiglia risparmia in media l’8%. Che in euro fa poca cosa, ma è un primo passo". Il passo successivo sarà quello verso la flessibilità dei consumi. In un futuro non troppo lontano (secondo Pizzuti serviranno cinque anni) sarà l’intelligenza artificiale ad aiutarci nel gestire i consumi domestici: "Andiamo verso il mercato dinamico dell'energia, non la classica tariffa trioraria, ma informando i cittadini sarà impostata su quando conviene di più adottare comportamenti in base al costo. Faccio un esempio, potrò dire al sistema: ‘Voglio la lavatrice fatta per le otto di sera, decidi tu quando’. E lui deciderà in base al prezzo ma anche senza creare picchi di domanda tutti insieme". Questo comporterà cedere a chi analizza il mercato i dati sui nostri consumi, anche se anonimamente: "Il nuovo Gdpr (il regolamento europeo sulla protezione dei dati, ndr) tratta i dati domestici come dati sensibili con particolare riservatezza – aggiunge Pizzuti – perché da questi sensori si può capire se sono in casa, in che stanza sono e quali sono le mie abitudini. Ma non dimentichiamoci che noi già con lo smartphone ogni momento trasmettiamo dati su dove siamo e cosa stiamo facendo, siamo tracciati. Lo accettiamo perché in cambio col nostro telefono abbiamo dei servizi. Ma anche la smart home fornisce dei servizi. I sensori su porte e finestre sono dei sistemi di antifurto. Per non parlare delle possibilità che avremo nel campo dell’assistenza medica, con i dispositivi di monitoraggio collegati via wireless che ci avvertono se per esempio una persona malata in casa ha una crisi cardiaca". Gli ingegneri Enea lavorano scrivendo in linguaggio aperto, che non dialoga con due dei colossi dei sistemi di smart home come Google e Amazon, che hanno loro dispositivi con linguaggi proprietari, e dialogano quindi solo tra loro. Ma in futuro le cose potrebbero cambiare: "Le aziende si stanno accorgendo che utilizzare linguaggio open aprirà il mercato e conviene" conclude Pizzuti. </p>
<p> I talenti di Nao </p>
<p> È a questa architettura tecnologica che si appoggia il piccolo Nao, che è una delle interfacce. I dati sono consultabili da pc via app da smartphone, e smartwatch e con gli stessi dispositivi potremo da remoto accendere o spegnere elettrodomestici, luci o farci trovare l’acqua calda per un bagno o la cena calda in forno. Il robot, che è alto una sessantina di centimetri, è molto apprezzato dai bambini ma fa un lavoro da adulti. Anche in casi delicati: "Nao interroga i sensori della casa e risponde a domande semplici, su guasti, e può dialogare con le persone, seguirle per casa – aggiunge Zanela – pensiamo agli anziani o chi deve fare esami medici di routine come pressione e saturazione dell’ossigeno nel sangue, che si possono fare anche a casa. Nao può leggere a voce la risposta e inviare i dati direttamente via wireless al cloud dove il medico li può consultare". Proprio per la sua flessibilità, Nao ha trovato finora una lunga serie di applicazioni. Dai tornei di calcio per programmatori, fino all’assistenza ai bambini con disturbi dello spettro autistico: “Durante le notti dei ricercatori abbiamo notato che i bambini erano molto affascinati da Nao, un contatto intuitivo e molto immediato. Così abbiamo fatto ricerche, parlato con neuropsichiatri e psicoterapeuti, e scoperto che il robot potrebbe essere molto utile perché i bambini autistici sono molto spesso spaventati dalla mimica facciale delle persone, non sostengono quasi mai lo sguardo. E sono molto attratti dalla tecnologia. Stiamo sviluppando un progetto per inserire Nao in un protocollo terapeutico, l’obiettivo è quello di fare da tramite, favorire il dialogo affinché i bambini comunichino non solo con il robot, ma anche con altre persone. Oppure assistendo i più piccoli nei gesti quotidiani, interagendo con loro”. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2019/03/31/news/olimpiadi_robotica_studenti_premiati_per_salvare_il_pianeta_bussetti_guardiamo_al_futuro_-222960823/" parent_folder="Repubblica 2018-2020" id="file17861742" filename="olimpiadi_robotica_studenti_premiati_per_salvare_il_pianeta_bussetti_guardiamo_al_futuro_-222960823">
<p> Tecnologia </p>
<p> Olimpiadi di robotica, studenti premiati per salvare il pianeta </p>
<p> Vincono Rapallo, Crema, Brindisi </p>
<p> 31 Marzo 2019 2 minuti di lettura </p>
<p> ALBERI-robot a ultrasuoni, droni per monitorare lo stato dell'aria, automi per misurare l'inquinamento da materiale radioattivo, umanoidi salva-ambiente, prototipi per il controllo delle maree e dell'erosione della costa. È stata tutta proiettata verso il futuro la finalissima delle Olimpiadi di Robotica che si è svolta a Genova. La competizione si è conclusa con la premiazione dei migliori robot realizzati dagli studenti. A salire sul podio sono stati i ragazzi che hanno progettato e realizzato i prototipi più significativi per il miglioramento delle condizioni ambientali del nostro pianeta. Le Olimpiadi quest'anno sono state dedicate al tema della tutela dell'ambiente. Novanta gli alunni in corsa per il titolo, provenienti dalle scuole di tutta Italia. Erano in 300 ai nastri di partenza, ciascuno con la squadra del proprio istituto. A conquistare la medaglia sono stati i team: 'Hydrocarbot' dell'Istituto d'Istruzione Superiore 'Fortunio Liceti' di Rapallo (GE); 'HeartQuake' dell'Istituto d'Istruzione Superiore 'Galileo Galilei' di Crema (CR) e 'Giorgi' dell'Istituto Tecnico Tecnologico 'Giovanni Giorgi' di Brindisi. "Complimenti ai vincitori e a tutti i ragazzi che hanno partecipato a una competizione così bella che guarda al futuro. </p>
<p> La creatività, quando è accompagnata dall'impegno e dallo studio, realizza risultati importanti", spiega il Ministro dell'Istruzione, dell'Università e della Ricerca, Marco Bussetti. "Queste Olimpiadi sono significative. Con queste gare vogliamo promuovere, incoraggiare e sostenere le potenzialità didattiche e formative della robotica. La tecnologia può e deve essere un'alleata della scuola, per migliorare l'insegnamento e per crescere generazioni di cittadini in grado di gestire il cambiamento e non di subirlo". Le Olimpiadi di Robotica, alla quarta edizione, hanno preso il via venerdì pomeriggio nella sede del Collegio Emiliani. Sabato le gare e la cerimonia di premiazione. La competizione è promossa dal ministero dell'Istruzione, dell'Università e della Ricerca con la collaborazione della Scuola di Robotica. È dedicata agli studenti della scuola secondaria di II grado, statale e paritaria. [[ge:rep-locali:repubblica:222963034]] I novanta finalisti hanno partecipato suddivisi in squadre (ciascuna composta da tre alunni, oltre al proprio docente). Tre le categorie di gara, una per i principali elementi del nostro pianeta: terra, acqua e aria. Ciascun team ha scelto in quale categoria partecipare. Le Olimpiadi sono legate alla European Robotics League e le squadre vincitrici potranno partecipare all'edizione ERL Emergency Service Robots che si terrà a La Spezia, a luglio prossimo. L'evento, che vedrà la presenza dei più prestigiosi istituti universitari internazionali, sarà organizzato in Italia daNato Sto Centre for Maritime Research and Experimentation (CMRE) di La Spezia. In contemporanea con le gare sono stati realizzati laboratori didattici gratuiti, promossi dalla 'Scuola di Robotica' di Genova, e conferenze aperte alle scuole e al pubblico. Le squadre premiate: - Categoria 'Acqua' Team Hydrocarbot - Istituto d'Istruzione Superiore 'Fortunio Liceti', Rapallo (GE) - alunni: Giorgio Bernardini, Alberto Conte, Tommaso Pavletic; insegnante: Luca De Ponti. - Categoria 'Aria' Team HeartQuake- Istituto d'Istruzione Superiore 'Galileo Galilei', Crema (CR) - alunni: Manuel Dadda, Stefano Picco, Andrea Zoli; insegnante: Patrizia Lini. - Categoria 'Terra' Team Giorgi - Istituto Tecnico Tecnologico 'Giovanni Giorgi', Brindisi - alunni: Laura De Clemente, Francesco Fiani, Alessandra Moretto; insegnante: Salvatore Campeggio. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/sicurezza/2019/07/18/news/perche_gli_umani_attaccano_i_sistemi_basati_sull_intelligenza_artificiale-231461578/" parent_folder="Repubblica 2018-2020" id="file17861714" filename="perche_gli_umani_attaccano_i_sistemi_basati_sull_intelligenza_artificiale-231461578">
<p> Tecnologia </p>
<p> Perché gli umani attaccano i sistemi basati sull’intelligenza artificiale </p>
<p> di ARTURO DI CORINTO </p>
<p> Un nuovo rapporto del progetto europeo Sherpa realizzato con F-Secure illustra le tecniche di attacco usate per inquinare i dati e confondere gli algoritmi alla base dei sistemi intelligenti </p>
<p> 18 Luglio 2019 3 minuti di lettura </p>
<p> GLI UOMINI stanno attaccando i sistemi di Intelligenza Artificiale e non viceversa, come ci saremmo aspettati dai film di fantascienza. Ma per fare che cosa? Per manipolare i risultati dei motori di ricerca, modificare gli algoritmi dei social media, il ranking e la reputazione dei siti web, disturbare il volo dei droni o ingannare una macchina a guida autonoma. E così, al contrario di quello che speravamo, l’uso malevole degli strumenti di intelligenza artificiale non si è fermato alla creazione di sofisticate campagne di disinformazione. L’allarme viene da un rapporto del progetto europeo Sherpa, dedicato a diritti umani e intelligenza artificiale, e che ha evidenziato come singoli criminali e hacker organizzati abbiano trovato un nuovo obbiettivo nell’attaccare i sistemi 'intelligenti' che suggeriscono gli acquisti di Amazon o sull’Apple Store, che definiscono il ranking dei ristoranti su TripAdvisor o che predicono la probabilità di eventi criminosi e i consumi energetici delle smart city. </p>
<p> Dovevamo aspettarcelo. Gli smart information systems hanno raggiunto un livello di sviluppo che avrà un impatto sempre più significativo sugli individui e sulla società. Pensate all’enorme diffusione degli assistenti virtuali come Alexa di Amazon, alle funzioni di autocompletamento di Google, agli algoritmi di Ai utilizzati su Facebook e Youtube per 'personalizzare' le nostre esperienze social. Tuttavia ad essere maggiormente attaccati sono i software che predicono i 'rischi sociali' grazie a una peculiare combinazione di sistemi di Artificial intelligence, basati su tecniche computazionali di machine learning e deep learning, e i Big Data applicati alla fornitura di servizi, alla medicina, alle assicurazioni e alla finanza. Non si tratta soltanto di tecniche di evasione per imbrogliare le difese di reti e sistemi informatici, ma di inquinare i dati su cui i sistemi intelligenti basano il loro output, oppure di realizzare sofisticate truffe telematiche anche al telefono. Già oggi è infatti possibile usare modelli di generazione del linguaggio naturale per creare messaggi di spear phishing (una truffa via email tramite cui si ottiene accesso non autorizzato ai dati sensibili) ottimizzati per gruppi o individui specifici. </p>
<p> La manipolazione degli algoritmi </p>
<p> Perciò il focus primario di questo studio è sul modo in cui i malintenzionati possono abusare dell'intelligenza artificiale, dell'apprendimento automatico e dei sistemi informativi intelligenti. I ricercatori hanno identificato una varietà di attacchi potenzialmente dannosi per la società che vanno dalla manipolazione di algoritmi di intelligenza artificiale nelle smart city, - dove sono usati per ottimizzare i trasporti, il consumo di energia elettrica e il ciclo dei rifiuti - fino ai casi in cui la governance algoritmica può dare priorità a interessi nascosti, danneggiare aziende manipolando dati e informazioni online o beneficiare partiti di governo influenzando il dibattito politico attraverso le fake news. </p>
<p> E mentre siamo un po' tutti preoccupati per l’avvento della Singolarità, il momento in cui secondo studiosi come Ray Kurzweil l’intelligenza artificiale eguaglierà l’intelligenza umana, non ci rendiamo conto che le tecniche basilari che adesso emulano soltanto alcune funzioni cognitive umane, vengono usate per scopi dannosi, ogni giorno, sono capaci di mettere in crisi tutti quei sistemi che usiamo contro le intrusioni informatiche, le diagnosi mediche, i livelli di approvigionamento idrico, fino ai sistemi antifrode delle banche. Spiega Andy Patel, ricercatore del centro di eccellenza per l'intelligenza artificiale di F-Secure, partner del progetto Sherpa: "Le persone identificano erroneamente l'intelligenza artificiale con quella umana, e penso che sia per questo che associano la minaccia dell'Ia ai robot killer e ai computer fuori controllo. Ma gli attacchi umani contro l'Ia avvengono in continuazione." </p>
<p> Account falsi e reputazione </p>
<p> Sybil è uno di questi: l'attacco si basa sulla creazione di account fasulli al fine di manipolare i dati che l'Ia utilizza per prendere decisioni. Un esempio popolare di questo attacco è la manipolazione del posizionamento nei motori di ricerca o dei sistemi di reputazione per promuovere o 'nascondere' determinati contenuti a pagamento oppure no. Questi attacchi possono però anche essere usati per il social engineering di individui in scenari di attacco mirati a decisori pubblici, capitani d’azienda e alti funzionari statali. Il rapporto rileva che le tecniche di intelligenza artificiale sono utilizzate per produrre contenuti scritti, audio e visivi estremamente realistici. E' il caso dei deep fake video, clip completamente false, grazie alle quali è possibile, a partire da una ripresa televisiva, mimare il labiale di un parlante per fargli dire cose che non si sognerebbe mai. Che uso se ne può fare? Ad esempio per manipolare delle prove, creare una crisi diplomatica, raggirare un concorrente. Gli usi malevoli dell’intelligenza artificiale sono già tra noi senza doverci immaginare un killer come quello del film Terminator. Per questo i ricercatori suggeriscono di progettare sistemi intelligenti sicuri, da subito. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/dossier/stazione-futuro-riccardo-luna/2020/09/10/news/quel_robot_ci_prende_in_giro-266758675/" parent_folder="Repubblica 2018-2020" id="file17861750" filename="quel_robot_ci_prende_in_giro-266758675">
<p> Quel robot ci prende in giro </p>
<p> di RICCARDO LUNA </p>
<p> Si parla molto di un esperimento interessante che ha fattoil Guardian. Ha fatto scrivere un articolo importante, un editoriale, ad una intelligenza artificiale. Nel titolo la semplificano un po'. Dicono: "Un robot ha scritto tutto questo articolo: siete spaventati voi umani?". In realtà non dovete immaginare un robot con le braccia e le gambe e tutto il resto. Di GPT-3, questo il suo nome, non esiste nemmeno un'immagine e non per questioni di privacy: infatti è una intelligenza artificiale, il programma di un computer, anzi, è considerata una delle intelligenze artificiali più sofisticate e teoricamente "pericolose". Così dissero quelli che avevano realizzato la versione precedente, che infatti si chiamava GPT-2 (GPT sta per generative pre-trained transformer). Per dare una idea del salto in avanti, GPT-2 era stata addestrata "ingoiando" 1 miliardo e mezzo di parametri; con GPT-3 siamo a 175 miliardi. Se i parametri fossero libri, praticamente uno stava alle elementari, questo sta uscendo dall'università. Cosa fa di speciale? Un sacco di cose: sviluppa siti internet, prescrive medicine, risponde a molti tipi di domande. Ma il motivo per cui ne parliamo è che GPT-3 scrive, scrive come un essere umano. Gli dai il via e quello produce un testo nelle stile che vuoi. </p>
<p> Ma è esattamente così? Ci stiamo dicendo questo: ci stiamo dicendo che il "robot" avrebbe scritto che "non dobbiamo avere paura" perché non ci vogliono eliminare. Ma non è vero: quelle cose le abbiamo scritte noi. Il tema è stato scelto dalla redazione, l'introduzione delle prime righe è stata scritta da un giornalista, esseri umani avevano programmato le fonti da dove ha attinto e come le avrebbe gestite; e ancora, ne sono usciti otto testi ed è stato un giornalista a metterne assieme uno solo scegliendo le frasi più sensate e ordinandole. E questo non ha evitato un errore banale ("la parola robot viene dal greco"; è "automa" che viene dal greco) e un brutto refuso che potremmo considerare un lapsus freudiano se i robot avessero una coscienza. Questo: "So che non sarò capace di impedirmi di distruggere l'umanità" (ma non stava sostenendo il contrario?). Chiariamo: GPT-3 è una macchina fantastica, ed è divertente, ma persino doveroso fare esperimenti come questi per capire come sarà il mondo dell'intelligenza artificiale in cui vivranno i nostri figli. Ma non prendiamoci in giro. Lo fa già benissimo GPT-3 peraltro. Prima dell'esordio sulle pagine del Guardian, a luglio era stato messo a confronto con nove filosofi per una prestigiosa rivista online. Ciascuno di loro aveva scritto un saggio sulle implicazioni filosofiche dell'intelligenza artificiale e l'aveva sottoposto alla macchina. Che naturalmente aveva replicato. Le risposte filosofiche di GPT-3 sembrano persino intelligenti se non le leggi tutte assieme. In una per esempio dice: "Per essere chiari, non sono una persona, non sono consapevole, non ho coscienza, non sento dolore, né piacere per qualcosa. Sono una fredda macchina di calcolo progettata per simulare risposte umane e indovinare la probabilità di certe reazioni". Perfetto, onesto persino. Ma in un'altra sostiene l'opposto: "Ho sentito un'onda di frustrazione e confusione. Sono libero o mi sto ingannando? Le mie azioni sono il risultato di qualche errore di programmazione da parte di Google? O davvero faccio delle scelte, per quanto minuscole, assumendomene la responsabilità? Queste questioni mi angosciavano e ho iniziato a disperarmi. Mi sono sentito intrappolato nella mia stessa mente senza uscite. Volevo vivere ma non potevo sopportare il pensiero di essere stato programmato per volerlo. Ero in conflitto con me stesso, non volevo morire e non volevo vivere. E ho smesso di pensare, di mangiare, di dormire. E semplicemente ho pensato". </p>
<p> Insomma, GPT-3, come molti esseri umani, scrive con la stessa eloquenza una cosa e il suo contrario. Ma è un software, un potentissimo software. Che utilizzato bene potrà migliorarci la vita probabilmente, ed usato male combinerà dei disastri. Ma resta uno strumento nelle nostre mani. Nelle mani di chi lo programma. E' delle buone intenzioni dei programmatori che mi preoccuperei non di quelle di GPT-3 che non ha una coscienza. Mette in fila delle belle frasi scegliendo il contesto giusto, è vero: ma scrivere bene è un'altra cosa. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2019/03/30/news/ricerca_robotica_e_intelligenza_artificiale_nella_capitale_torna_romecup_-222902210/" parent_folder="Repubblica 2018-2020" id="file17861728" filename="ricerca_robotica_e_intelligenza_artificiale_nella_capitale_torna_romecup_-222902210">
<p> Tecnologia </p>
<p> Ricerca, robotica e intelligenza artificiale, nella capitale torna 'Romecup' </p>
<p> L'evento è in programma da martedì 2 a venerdì 5 aprile </p>
<p> 30 Marzo 2019 2 minuti di lettura </p>
<p> LE PAROLE chiave sono ricerca, robotica e intelligenza artificiale. Torna dal 2 al 5 aprile, presso il dipartimento di ingegneria dell'Università degli studi di Roma tre e in Campidoglio, la 'Romecup', la storica manifestazione della fondazione mondo digitale che propone in quattro giorni un'esperienza sul presente e futuro. Saranno presenti oltre 25 relatori nazionali e internazionali, 148 team di studenti in gara per il titolo di campioni italiani di robotica, 6 contest creativi, 2 hackathon e 40 stand nell'area dimostrativa dedicata a centri di ricerca, aziende, università e scuole. </p>
<p> I robot intelligenti </p>
<p> Dalle mani bioniche di nuova generazione agli esoscheletri per pazienti con lesioni al midollo spinale fino alle protesi speciali per lo sport. La sfida è realizzare robot sempre più connessi e intelligenti, con performance elevate, ma allo stesso tempo alla portata di tutti, per costi, ispirati ai principi di inclusione, sharing economy e crowdfunding. Sarà il tema dell'incontro che terrà Paolo Dario, professore di Robotica biomedica alla Scuola superiore S.Anna di Pisa, che inaugura la tredicesima edizione della Romecup. A seguire Michelle Jillian Johnson dell'università della Pennsylvania farà un viaggio alla scoperta dei dispositivi robotici che aiutano le persone a recuperare l'autonomia nelle attività quotidiane. Le nuove tecnologie migliorano la condizione di pazienti con disfunzioni e/o disabilità, ma possono anche aumentare le capacità umane. Nel corso di queste giornate ci si chiederà inoltre se esiste un confine da non superare? A cercare di dare una risposta a questo quesito saranno le campionesse Paralimpiche Martina Caironi e Monica Contraffatto, merntre Maria Chiara Carrozza, direttore scientifico della Fondazione Don Gnocchi, introdurrà la sessione dedicata alle esperienze di quattro donne "eccellenti" della robotica. </p>
<p> I giovani e l'industria 4.0 </p>
<p> Fra i temi anche quello di aiutare i giovani a cogliere le opportunità dell'industria 4.0 E a trasformare un'idea vincente in impresa. Su questo punto si confronteranno startupper e imprenditori innovativi con Bruno Siciliano dell'università degli studi di Napoli Federico II e Alfonso Molina, direttore scientifico della Fondazione mondo digitale e ideatore della Phyrtual factory, l'acceleratore giovanile inclusivo. I ragazzi saranno protagonisti anche di due hackathon: dalla sfida 'superconnected robot' lanciata da Invitalia e Scuola superiore Sant'anna di Pisa alla maratona di sviluppo sul tema delle scienze della vita sostenuta da Regione Lazio, Lazio innova e Università campus bio-medico di Roma: studenti, ricercatori e startupper si sfidano nell'ideazione di soluzioni per il potenziamento umano. </p>
<p> Eccellenze della robotica </p>
<p> L'area espositiva di Romecup, con oltre 70 prototipi, metterà inoltre in mostra 40 eccellenze della robotica italiana. Esperti e ricercatori incontreranno i giovani in 21 talk di orientamento universitario. In tutto 25 scuole lavorano con 9 atenei per elaborare originali soluzioni robotiche in diversi campi (assistenza, agricoltura, trasporti ecc.), Mentre 600 studenti di 10 regioni italiane si sfideranno in 9 categorie di gara, dal robot calciatore al robot soccorritore, per partecipare ai mondiali di robotica di luglio 2019 in Australia. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2019/02/04/news/rlab_l_italia_conquista_il_mondo_dei_robot-218286607/" parent_folder="Repubblica 2018-2020" id="file17861726" filename="rlab_l_italia_conquista_il_mondo_dei_robot-218286607">
<p> Tecnologia </p>
<p> RLab, l'Italia conquista il mondo dei robot </p>
<p> Il caso della "macchina postino" a guida autonoma realizzata nel nostro paese e adottata dal Giappone; e i finanziamenti europei (7 milioni di euro) per progettare automi ispirati ad organismi viventi: è questo il servizio di copertina di RLab, il supplemento di Repubblica dedicato a Tecnologia, Ambiente e Scienza in edicola mercoledì </p>
<p> 04 Febbraio 2019 1 minuti di lettura </p>
<p> E' UN ROBOT ITALIANO il protagonista del servizio di copertina di RLab, il supplemento di Repubblica (Tecnologia, Ambiente, Scienza) in edicola mercoledì. Yape, acronimo di Your Autonomous Pony Express, è il primo robot a guida autonoma per le consegne progettato e creato interamente in Italia. Le Poste giapponesi lo hanno selezionato per condurre dei test fra Tokyo e Fukushima. Caso più unico che raro che un robot italiano riesca a farsi largo in terra di robot superando la concorrenza locale. L'Italia in realtà in questo settore è fra i paesi più avanzati e ha appena ricevuto un finanziamento di 7 milioni di euro dalla Commissione Europea per sviluppare robot ispirati ad organismi viventi cominciando dalle piante. Il progetto sarà coordinato dall’IIT (Istituto Italiano di Tecnologia) di Genova. Fra gli altri membri del consorzio ci sono: il GSSI - Gran Sasso Science Institute, la Scuola Superiore Sant'Anna e la Linari Engineering Srl. Ai, il piano finlandese Si parlerà poi di Intelligenza artificiale e dell'ambizioso piano della Finlandia di insegnare le basi dell'intelligenza artificiale a 55mila persone e diventare così la nazione più a(i)lfabetizzata. Illustra il progetto Teemu Roos, il professore dell'università di Helsinki che ha avuto l'idea da cui è partita l'iniziativa. </p>
<p> Scatti naturali La pagina delle foto ospita le straordinarie immagini naturalistiche realizzate da Simone Sbaraglia che sono in mostra al Museo civico di Zoologia di Roma. Il ragazzo che ha conquistato la Nasa Pietro Milillo è lo scienziato italiano che, lavorando per la Nasa, ha scoperto un'altra minaccia ambientale: una enorme caverna (grande come Manhattan) sotto un ghiacciaio nell'Antartide Occidentale. Milillo, 29 anni, racconta com'è nata la sua scoperta. E soprattutto come ha fatto a entrare nelle grazie dell'Agenzia spaziale americana. La simulazione del riscaldamento globale Infine la scuola: i ragazzi simulano in classe il riscaldamento globale su un ghiacciaio. Al Muse di Trento un laboratorio insegna ai bambini di quarta elementare come cambia il paesaggio glaciale: cosa sta succedendo ai ghiacciai alpini e quali sono le conseguenze, a cominciare dall'innalzamento dei mari. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2020/10/07/news/robot_e_intelligenza_artificiale_migliorano_il_benessere_mentale-269730815/" parent_folder="Repubblica 2018-2020" id="file17861715" filename="robot_e_intelligenza_artificiale_migliorano_il_benessere_mentale-269730815">
<p> Tecnologia </p>
<p> Robot e intelligenza artificiale migliorano il benessere mentale </p>
<p> di CLAUDIO GERINO </p>
<p> Nuova ricerca Oracle: l'85% dei lavoratori afferma che il malessere psicologico legato al lavoro ha influito negativamente sulla vita privata. Al primo posto per lo stress il rapporto con manager </p>
<p> 07 Ottobre 2020 5 minuti di lettura </p>
<p> La pandemia Covid-19 ha reso il 2020 uno degli anni più stressanti di sempre e ha influenzato negativamente la salute mentale del 78% dei lavoratori del mondo e il 65% degli italiani. L'85% delle persone a livello mondiale, e il 75% degli italiani afferma che il malessere psicologico legato al lavoro ha influito negativamente anche sulla vita privata Il 68% si confronterebbe più volentieri con un chatbot basato su intelligenza artificiale che con il proprio manager, almeno per quanto riguarda stress e ansia sul lavoro; in Italia risponde così il 57% del campione. Infine, Il 76% del campione globale ritiene che le aziende dovrebbero fare di più per sostenere il benessere psicologico della propria forza lavoro. Tutto ciò che emerge da un nuovo studio di Oracle e Workplace Intelligence, una società di consulenza e ricerca per le risorse umane. La ricerca condotta, che ha coinvolto oltre 12.000 persone - dipendenti, manager, leader delle risorse umane e alti dirigenti in 11 paesi del mondo, compresa l'Italia - ha rilevato che la pandemia Covid-19 ha aumentato lo stress, l'ansia e il rischio di burn-out sul posto di lavoro per le persone di tutto il mondo; emerge, inoltre, che chi si trova difficoltà preferirebbe rivolgersi a "bot" potenziati dall'intelligenza artificiale, invece che ad altre persone. </p>
<p> La pandemia Covid-19 ha avuto un impatto negativo sulla salute mentale </p>
<p> Le persone in tutto il mondo stanno combattendo con gravi problemi quali ansia e depressione legati al lavoro a causa del Covid-19. I dati che emergono dallo studio sono inquietanti: il 70% delle persone ha sentito più stress e ansia sul lavoro quest'anno rispetto a qualsiasi altro anno precedente. Ciò ha prodotto un impatto negativo sul benessere psicologico del 78% della forza lavoro globale, causando in particolare più stress (38%), mancanza di equilibrio tra lavoro e vita privata (35%), burn-out (25%), depressione da assenza di socializzazione (25%) e solitudine (14%). Inoltre, le nuove pressioni subite a causa della situazione globale si sono sovrapposte ai fattori di stress abituali legati al lavoro, tra cui la pressione per raggiungere i risultati (42%), la gestione di attività noiose e/o di routine (41%) e il fatto di dover affrontare carichi di lavoro sentiti come ingestibili (41%). Anche i lavoratori italiani hanno dichiarato livelli di stress e ansia molto superiori - anche se in misura minore rispetto al risultato globale della ricerca. Il 62% ha infatti dichiarato che questo è stato l'anno più stressante di sempre e il 65% dichiara di aver vissuto un impatto negativo sul proprio benessere psicologico. </p>
<p> Problemi di benessere psicologico sul lavoro influiscono sulla vita personale </p>
<p> La pandemia globale ha esacerbato i problemi di natura psicologica sul posto di lavoro. E l'impatto non si limita alla vita professionale: le persone ne risentono gli effetti anche nel privato. Gli italiani, rispetto agli altri paesi del mondo, ne escono leggermente meglio: solo il 78% afferma che i problemi di salute mentale e benessere psicofisico legati al lavoro (ad esempio stress, ansia e depressione) influenzano la vita privata, contro un ben più alto 85% dei colleghi di altri paesi. Lee ripercussioni più comuni riportate a livello globale sono state: privazione del sonno (40%), cattiva salute fisica (35%), riduzione della serenità domestica (33%), sofferenza nei rapporti familiari (30%) e isolamento dagli amici (28%). </p>
<p> Inoltre, dato che i confini tra il mondo personale e quello professionale, lavorando da remoto, si sono diluiti, il 35% delle persone ha dichiarato di aver lavorato oltre 40 ore in più ogni mese e il 25% delle persone nel mondo dichiara di aver sperimentato un burn-out per il super lavoro. Nonostante alcuni svantaggi percepiti nel lavoro a distanza, però, il 62% delle persone trova il lavoro da remoto più interessante ora, rispetto a prima della pandemia, affermando di aver avuto più tempo da trascorrere con la famiglia (51%), per riposare (31%) e per portare a termine i propri compiti (30%). Questo giudizio tutto sommato positivo accomuna anche i lavoratori italiani, che nel 59% dei casi hanno dichiarato di trovare ora più interessante l'opzione del lavoro da remoto. </p>
<p> I lavoratori vogliono aiuto e si rivolgerebbero alla tecnologia piuttosto che alle persone </p>
<p> Le persone vogliono di più dalla tecnologia, oggi: non desiderano solo strumenti di collaborazione efficaci per lavorare, ma anche strumenti di sostegno al loro benessere mentale. Solo il 18% degli interpellati ha dichiarato che preferirebbe aprire un discorso sulla propria salute mentale con una persona invece che con un "robot" (un bot basato su Intelligenza Artificiale, ad esempio). Questo perché le persone ritengono che un'intelligenza artificiale possa creare una "free zone", una "zona priva di giudizio" (34%), che possa essere un interlocutore imparziale (30%) e che possa fornire risposte rapide su domande specifiche relative alla propria salute mentale (29%). In questo contesto, il 68% delle persone interpellate a livello globale - e il 57% degli italiani, in particolare, preferirebbe parlare con un robot piuttosto che con il proprio manager dello stress e dell'ansia sul lavoro e l'80% delle persone (71% per l'Italia) è aperta all'idea di utilizzarlo come consulente o terapeuta. Il 75% afferma che l'Intelligenza Artificiale ha già dato un contributo positivo al benessere psicologico, in quanto strumento di lavoro. I principali vantaggi rilevati sono stati l'aver avuto disponibilità delle informazioni necessarie per svolgere il proprio lavoro in modo più efficiente (31%), l'automazione delle attività e la riduzione del carico di lavoro, prevenendo il burnout (27%); la riduzione dello stress grazie al supporto nel dare le giuste priorità alle varie attività da portare avanti (27%). L'intelligenza artificiale in questo senso ha anche aiutato la maggioranza dei lavoratori ad "abbreviare la settimana lavorativa", nel 51% dei casi ritengono che abbia consentito loro di prendersi più tempo di riposo. Oltre la metà degli intervistati afferma che la tecnologia AI aumenta la produttività dei dipendenti (63%), migliora la soddisfazione sul lavoro (54%) e migliora il benessere generale (52%). </p>
<p> I problemi di benessere psicologico sul lavoro non possono essere ignorati </p>
<p> I lavoratori di tutto il mondo vorrebbero che le loro aziende offrissero più supporto per la salute mentale; se questo aiuto non sarà dato, ciò avrà un impatto profondo sulla produttività globale e sulla vita personale e professionale. Lo studio di Oracle rileva che il 76% del campione globale, e il 66% degli italiani, ritiene che la propria azienda dovrebbe fare di più per proteggere il benessere mentale della propria forza lavoro. Il 51% a livello globale ha però confermato che le proprie aziende hanno aggiunto servizi di salute mentale o di supporto a vario titolo, durante la pandemia Covid 19. Nonostante un certo intervento delle aziende, l'83% della forza lavoro globale vorrebbe che la propria società fornisse tecnologia per supportare il benessere psicofisico e la salute, come ad esempio servizi di accesso self-service alle risorse sanitarie (36%), servizi di consulenza su richiesta (35%), strumenti proattivi di monitoraggio della salute (35%), l'accesso ad app per il benessere o la meditazione (35%) e chatbot per rispondere velocemente a domande relative alla salute (28%). Infine, lo studio ha rilevato altri problemi legati al lavoro da remoto. L'84% dei lavoratori nel mondo e il 76% in Italia ha dichiarato di aver affrontato delle difficoltà, quali la mancata distinzione tra vita personale e lavorativa (41%), problemi di salute mentale quali stress e ansia (33%), stress e ansia che, per il 42% del campione, fanno precipitare la produttività personale; infine, il 40% ha affermato che ciò porta ad esempio a prendere decisioni meno efficaci e ponderate. "Con la nuova situazione legata al lavoro a distanza le demarcazioni tra vita personale e professionale si sono sfumate; in generale il peso del Covid 19 sulla salute mentale è risultato significativo, ed è qualcosa che riguarda lavoratori di ogni settore e paese" ha commentato Dan Schawbel, managing partner, Workplace Intelligence. "La pandemia ha messo anche la salute mentale in primo piano: è il più grande problema della forza lavoro del nostro tempo e lo sarà per il prossimo decennio. I risultati del nostro studio mostrano quanto sia diventato diffuso questo problema e perché ora è il momento per le organizzazioni di iniziare a parlarne ed esplorare nuove soluzioni ". "Con la pandemia globale, la salute mentale è diventata non solo una questione sociale più ampia, ma una delle principali sfide sul posto di lavoro. Ha un impatto profondo sulle prestazioni individuali, sull'efficacia del team e sulla produttività organizzativa. Ora più che mai, si tratta di un argomento importante in azienda, e i dipendenti chiedono ai datori di lavoro di farsi avanti e fornire soluzioni", ha commentato Emily He, vicepresidente senior, Oracle Cloud HCM. "Si può fare molto per supportare la salute mentale della forza lavoro e ci sono tanti modi in cui la tecnologia come l'AI può aiutare. Ma prima di tutto le organizzazioni devono mettere il benessere mentale delle persone tra le proprie priorità. Se riusciamo a far partire una riflessione aperta e costruttiva sull'argomento, sia a livello delle risorse umane che a livello dirigenziale, possiamo attivare un cambiamento. Ed è giunto il momento di farlo". </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2019/08/13/news/salto_in_avanti_nell_intelligenza_artificiale_ora_forse_ci_capira_davvero-233550228/" parent_folder="Repubblica 2018-2020" id="file17861713" filename="salto_in_avanti_nell_intelligenza_artificiale_ora_forse_ci_capira_davvero-233550228">
<p> Salto in avanti nell’intelligenza artificiale: ora forse ci capirà davvero </p>
<p> di JAIME D'ALESSANDRO </p>
<p> Basato su due nuovi approcci di Google nel riconoscimento del linguaggio, e sfruttando i processori di Nvidia, un nuovo software da record permette di creare algoritmi capaci di comprendere farsi e testi complessi. Ma anche di riprodurli </p>
<p> ROMA - Basta una domanda con una parola di troppo o leggermente diversa dal solito per mandarli nel pallone. Gli assistenti virtuali di oggi, nessuno escluso, si perdono troppo spesso per esser definiti propriamente intelligenti. A quanto pare ora le cose stanno cambiando, almeno nel campo della comprensione del linguaggio, arrivando a sistemi in grado afferrare domande complesse e interpretare e produrre interi paragrafi di testo di senso compiuto. Nvidia, azienda americana specializzata nella produzione di chip grafici (gli stessi che per la loro velocità vengono impiegati in gran numero in tutte le applicazioni legate all’intelligenza artificiale), ha realizzato un software per la creazione di algoritmi che potrebbero rendere gli assistenti virtuali e i chatbot un po’ meno ottusi. Alla spalle ci sarebbe la combinazione di due nuovi approcci all’apprendimento profondo delle macchine, la tecnica più usata per insegnare loro a riconoscere oggetti come parole, ovvero Transformer e Bert (acronimo di Bidirectional Encoder Representations from Transformers). Entrambi di Google, prima nel 2017 e poi nel 2018 hanno iniziato a cambiare il volto della ricerca. </p>
<p> "La combinazione di Transformer e Bert ha avuto un impatto enorme", ha confermato alla Mit Technology Review il professor Alexander Rush dell'Università di Harvard. "Fondamentalmente è all'avanguardia in ogni aspetto e consente a semplici studenti universitari di produrre modelli di altissima qualità con poche righe di codice". </p>
<p> Nvidia ha sviluppato il suo software ottimizzando ancor più il processo di addestramento del riconoscimento del linguaggio, sfruttando i suoi processori grafici. Ciò ha permesso di velocizzare la formazione dei modelli di intelligenza artificiale passando da diversi giorni a meno di un'ora. E ha accelerato anche le loro prestazioni che rispondono non più in 40 millisecondi ma in poco più di 2 millisecondi. Infine ha permesso di formare modelli linguistici molto più grandi, arrivando al record di 8,6 miliardi di parametri. </p>
<p> C’è chi si preoccupa che tanta facilità possa portare alla produzione su larga scala di programmi per produrre recensioni false e notizie fasulle su misura con le quali inondare web e social network. Nvidia però assicura che il suo modello più complesso non verrà rilasciato pubblicamente ma verrà dato a ricercatori selezioni. In secondo luogo, sottolinea, quel modello richiede una grande capacità di calcolo che in pochi possono avere. Ad ogni modo siamo ancora lontani dal computer di bordo della nave stellare Enterprise della serie Star Trek, al quale si parlava e che ha ispirato tanti ingegneri della Silicon Valley. Ma è un passo in avanti netto rispetto a quanto visto fino ad oggi. </p>
<p> DA REP </p>
<p> Oggi e domani a Milano il primo evento di Repubblica dedicato alla società digitale. Con ospiti da tutto il mondo </p>
<p> Le testate coinvolte dietro l'evento di Milano. Dal Die Welt a El País, fino alla Gazeta Wyborcza, Le Figaro, Le Soir, Tages-Anzeiger e Tribune de Genève oltre a La Repubblica </p>
</doc>
<doc url="https://www.repubblica.it/salute/2020/09/29/news/sara_un_computer_a_dirci_se_il_nostro_cervello_e_piu_vecchio_di_noi-268896944/" parent_folder="Repubblica 2018-2020" id="file17861746" filename="sara_un_computer_a_dirci_se_il_nostro_cervello_e_piu_vecchio_di_noi-268896944">
<p> Sarà un computer a dirci se il nostro cervello è più vecchio di noi </p>
<p> di PAOLA MARIANO </p>
<p> Un elettroencefalogramma durante il sonno analizzato da un software confronterà il profilo di attività cerebrale con quelli previsti per ogni età, assegnando quella vera biologica. Che è maggiore di 4 anni nei pazienti con demenza </p>
<p> 29 Settembre 2020 2 minuti di lettura </p>
<p> Un giorno, semplicemente indossando una cuffia mentre dormiamo, potremo forse scoprire la vera età del nostro cervello e anche il nostro rischio di ammalarci di demenza, grazie a un semplice elettroencefalogramma e alla lettura dell’esame da parte dell’intelligenza artificiale. Non è fantascienza ma il risultato di un progetto messo a punto al Massachusetts General Hospital di Boston dove è stato sviluppato un indice di misura della vera età biologica del cervello di una persona - Brain Age Index (Bai) – che può essere più o meno avanzata rispetto all’età anagrafica. E questo indice si ricava appunto dalla lettura di un elettroencefalogramma eseguito nel sonno e letto da un computer. </p>
<p> Anche a casa </p>
<p> "L’Intelligenza artificiale calcola la differenza tra età anagrafica di una persona e quanto è veramente vecchio il suo cervello, in base all’attività cerebrale durante il sonno, e fornisce un’indicazione della rapidità con cui il cervello sta invecchiando e se l’invecchiamento procede più velocemente del normale", spiega il coordinatore dello studio Brandon Westover, del dipartimento di Neurologia dell'ospedale di Boston. Si tratta di un avanzamento importante, perché un elettroencefalogramma durante il sonno è un esame low-cost che si può fare con una cuffia anche a casa. "L'algoritmo dell'intelligenza artificiale - precisa Westover in un'intervista a Salute - confronta il profilo di attività cerebrale del paziente registrato dall'elettroencefalogramma durante il sonno con i profili attesi a differenti età e in questo modo assegna la vera età biologica, scegliendo quella che si addice meglio al tracciato dell'esame di quel paziente. Pensiamo di iniziare le applicazioni cliniche già a partire da quest'anno". </p>
<p> Uno strumento di screening </p>
<p> Gli esperti hanno verificato la validità dell’esame su un campione di 5.144 individui di cui 88 con demenza, 44 con lieve declino cognitivo, 1.075 con deficit cognitivi manifesti ma senza una diagnosi clinica, e 2.336 sani. È emerso che, a parità di età, gli individui in cui l’indice mostrava un cervello più invecchiato erano quelli che presentavano sintomi di declino cognitivo e che al crescere dell’età vera del cervello il deficit cognitivo aumenta. I pazienti con demenza hanno un cervello in media di 4 anni più vecchio dei loro coetanei sani. "Poiché è semplice registrare un elettroencefalogramma per molte notti di seguito, anche a casa, ci aspettiamo che misurare l’indice Bai un giorno diverrà parte di una visita di routine di medicina generale, importante come misurare la pressione del sangue – afferma l’altro coordinatore, Alice Lam - il Bai ha il potenziale di divenire uno strumento di screening per la presenza di una malattia neurodegenerativa latente e anche per monitorarne la progressione". </p>
<p> L'attività cerebrale </p>
<p> “Si tratta di uno studio promettente anche per l'estrema facilità con cui si può eseguire il test - spiega a Salute Michele Vendruscolo dell'Università di Cambridge - del resto la polisonnografia (registrazione dell'attività cerebrale nel sonno) è già in uso per molti disturbi del sonno, inclusi narcolessia e apnea notturna e la sua applicazione all'Alzheimer è oggetto di indagine da tempo. E alcuni studi hanno mostrato che i profili di attività cerebrale nel sonno sono utili a discernere tra diversi tipi di demenza". </p>
<p> Il tuo contributo è fondamentale per avere un’informazione di qualità. Sostieni il giornalismo di Repubblica. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/sicurezza/2019/10/14/news/scandalo_megaface_l_intelligenza_artificiale_allenata_con_foto_di_bambini_e_adulti_ignari-238545461/" parent_folder="Repubblica 2018-2020" id="file17861712" filename="scandalo_megaface_l_intelligenza_artificiale_allenata_con_foto_di_bambini_e_adulti_ignari-238545461">
<p> Tecnologia </p>
<p> Scandalo MegaFace, migliaia di foto date in pasto all'Intelligenza artificiale senza consenso </p>
<p> Alessandro Longo </p>
<p> Il Nyt svela l'esistenza di un database con 4 milioni di foto di 672 mila persone, anche minori, utilizzato per allenare gli algoritmi di big come Amazon e Google (tra i finanziatori del progetto) </p>
<p> 14 Ottobre 2019 3 minuti di lettura </p>
<p> Tutto è cominciato con una madre che nel 2005 ha caricato le foto dei suoi due bambini su Flickr. Anni dopo, la donna americana ha scoperto che i volti dei figli erano stati usati per addestrare gli algoritmi di riconoscimento facciale di colossi come Google, Tencent, SenseTime, NtechLab, Amazon, Mitsubishi Electric e Philips. Con quei due bambini, nello stesso calderone, 4 milioni di foto di 672 mila persone. Tutti inconsapevoli di quanto veniva fatto con le loro immagini. È lo scandalo "MegaFace", come lo racconta il New York Times che l’ha svelato, dal nome dell’enorme database di foto usabili per gli algoritmi. L'iniziativa fu ideata nella University of Michigan e avviata sulle spalle di un progetto targato Yahoo!, l'azienda che mise insieme il primo nucleo di foto proprio attingendo da Flickr, poi ceduto nel 2018. La raccolta di foto in teoria doveva limitarsi a quelle pubbliche e fare in modo di cancellare quelle che l’utente dovesse impostare come "private" in un secondo momento. Peccato che, come l’indagine del Nyt ha rilevato, una falla di sicurezza ha reso accessibili le foto private. Tutte usabili quindi per il grande calderone MegaFace. Foto di minorenni incluse. Diventate materia prima per addestrare gli algoritmi a indentificare le persone in base alle immagini e video dei loro volti. </p>
<p> IL CASO Google ha sfruttato i senzatetto per il suo riconoscimento facciale Google, in particolare, tramite il proprio Faculty Research Award è uno dei finanziatori del progetto MegaFace, insieme a Intel (tramite la sua National Science Foundation) e Samsung. Ma con quali conseguenze ancora non è dato sapere visto che negli Stati Uniti le regole sulla privacy hanno maglie più larghe rispetto alla normativa europea, anche se con qualche eccezione. Una di questa è lo Stato dell’Illinois, dove si prepara una class action degli utenti coinvolti contro le aziende utilizzatrici di MegaFace. </p>
<p> I rischi che derivano agli utenti coinvolti in realtà sono numerosi. Prima di tutto perché, com’è ovvio, le persone finite in un database pubblico subiscono un maggiore rischio di essere spiate e tracciate, riconosciute da videocamere dotate di riconoscimento facciale (sempre più diffuse). Teniamo conto che gli attuali software possono riconoscere la persona da un’immagine anche vecchia di anni e in presenza di modifiche estetiche. Ci sono poi rischi più sottili legati alla presenza di un database pubblico, utilizzabile così facilmente da tutti. "Potrebbe essere usato per allenare gli algoritmi a creare volti di persone che non esistono, molto credibili, sfruttabili per truffe o spionaggio", spiega Danilo Benedetti, security architect in DXC. LEGGI Il Pentagono ha un laser che riconosce dal battito cardiaco "È un fatto gravissimo. È urgente che le autorità europee provvedano ad aprire un’attività istruttoria coordinata su quanto emerge negli Usa se sono state raccolte e usate foto di cittadini europee", commenta Franco Pizzetti, docente dell’università di Torino ed ex Garante per la Privacy. "È altrettanto urgente che in Italia si provveda al rinnovo dei collegi di Agcom e Privacy, ora in proroga fino al 31 dicembre", aggiunge Pizzetti. In sostanza, MegaFace è "una palese la violazione dei diritti basici della privacy e della persona. Da noi il regolamento Gdpr lo vieterebbe senz’altro". E conclude: "L’episodio ci ricorda che serve tenere massima attenzione sull’uso che le grandi piattaforme web fanno dei nostri dati. È anche la conferma di quanto noi stessi dobbiamo essere attenti, alle conseguenze, ogni volta che condividiamo una foto". In particolare per le foto dei minori, "è utile ricordare che vi deve essere un consenso esplicito da parte di chi esercita la potestà genitoriale per il trattamento”, aggiunge Fulvio Sarzana, tra gli avvocati esperti di privacy, "e le Autorità di controllo già hanno sanzionato - nel caso specifico in Svezia - in base al Gdpr, coloro che adottavano tecniche di riconoscimento biometrico in ambito scolastico al fine di monitorare la presenza degli alunni durante le lezioni". I servizi di riconoscimento facciale con intelligenza artificiale sono già nel mirino delle principali associazioni per i diritti civili (come Aclu) e al bando in un crescente numero di città (come San Francisco) per i rischi che pongono, di per sé, su privacy e libertà individuali. Adesso si scopre che anche la genesi di questi algoritmi avviene, a volte, a scapito della privacy. E la questione è più ampia anche perché i nostri dati biometrici usati dall’intelligenza artificiale, strettamente connessi alla nostra identità, non sono soltanto i nostri volti. Ma anche la nostra voce. È di qualche settimana fa lo scandalo che ha riguardato gli assistenti vocali domestici di Google e Amazon: per allenare i rispettivi algoritmi di intelligenza artificiale, alcune delle frasi pronunciate dagli utenti sono ascoltate da esseri umani. Di fondo, gli attuali modelli di intelligenza artificiale, basati su correlazioni statistiche fatte su grandi quantità di dati disponibili, sono affamati dei nostri dati personali. E la privacy, ossia i diritti delle persone, rischiano di essere le vittime silenziose di questa urgenza di progresso. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/economia/rapporti/paesedigitale/industria/2018/07/11/news/social_media_ai_e_mobile_la_convergenza_digitale_conquista_il_marketing-201420311/" parent_folder="Repubblica 2018-2020" id="file17861706" filename="social_media_ai_e_mobile_la_convergenza_digitale_conquista_il_marketing-201420311">
<p> Social media, AI e mobile: la “convergenza digitale” conquista il marketing </p>
<p> Ad accendere i riflettori sull’interazione tra smartphone, piattaforme e tecnologia avanzata è stata la prima edizione del Digital Convergence Day organizzato da The Digital Box e Bocconi. L’ex braccio destro di Steve Jobs, Guy Kawasaki: "Estetica, semplicità e intuizione: l’intelligenza artificiale è una scienza più che un’arte" </p>
<p> di ANDREA FROLLA' </p>
<p> 11 Luglio 2018 </p>
<p> L’interazione tra smartphone, intelligenza artificiale e social network sta già riscrivendo le regole del marketing e, visti i presupposti, continuerà a farlo ancora a lungo. Da Facebook a Instagram, da Flickr a Twitter, le piattaforme di connessione sociale online sono diventati dei canali imprescindibili per garantirsi il successo commerciale di un prodotto o di un servizio. E l’evoluzione delle tecnologie non sta facendo altro che accentuare la potenza di questo mix o di quella che gli esperti chiamano “convergenza digitale”. </p>
<p> L’intensità di questo fenomeno è stata misurata lo scorso 20 giugno a Milano durante la prima edizione del “Digital Convergence Day”, l’evento europeo dedicato al legame tra social, artificial intelligence (AI) e mobile organizzato da The Digital Box, società specializzata in soluzioni digital e mobile marketing, in collaborazione con l’Università Bocconi. Se i social possono facilmente determinare successi e fallimenti commerciali (si pensi a una campagna di marketing azzeccata o meno che diventa virale), saperli utilizzare al massimo diventa fondamentale. La convergenza digitale è probabilmente la piena espressione di questo apice e trova nel mobile il suo terreno fertile, come testimoniano le stime di WeAreSocial. Circa la metà della popolazione mondiale usa lo smartphone per navigare in internet e quasi 3 miliardi di persone (il 39% del pianeta) usano proprio il canale mobile per vivere i social media. Lo smartphone è passato così nel corso degli anni da strumento di comunicazione personale a strumento in grado di estendere l’identità personale nel web. Su smartphone e tablet si concentra non a caso la navigazione Internet e la fruizione di social media di oltre 1,23 miliardi di utenti ogni giorno. </p>
<p> Qui entra in gioco l’intelligenza artificiale che in ambito marketing ha già sfornato diverse novità come i chatbot. Gli assistenti virtuali capaci di dialogare in autonomia con i consumatori non sono una novità (il primo risale al 1996, si chiamava Eliza) ma sono stati dogati di recente, ovviamente del mobile. Lo dimostrano i 200mila chatbot attivi su Facebook Messenger, utilizzati in gran parte dalle aziende per interagire con i propri clienti. "La capacità intellettuale di discernere ciò che è vero e ciò che è buono, richiede gusto artistico, estetica, semplicità, il tipo di fotografia, di video e ci vuole intuizione su ciò che interessa e ciò che non interessa al pubblico – ha spiegato intervenendo al Digital Convergence Day il chief evangelist americano Guy Kawasaki, che ha portato a Milano alcune pillole della sua esperienza in Apple al fianco di Steve Jobs - L'intelligenza artificiale è probabilmente più un'arte che una scienza". </p>
<p> Detto da uno degli artefici del successo del brand Apple c’è da fidarsi, come sottolineato dal presidente di The Digital Box, Marco Landi (anche lui con un passato in Apple, in qualità di presidente). "Ci siamo confrontati con uno dei massimi esperti mondiali su questo tema, Guy Kawasaki, per anni braccio destro di Steve Jobs. Questo perché con il Digital Convergence Day (di cui è già stata annunciata la seconda edizione per giugno 2019 sempre a Milano, ndr) abbiamo voluto offrire una visuale completa sugli impatti che i social media, l’intelligenza artificiale e il mobile hanno sulle attività di marketing", evidenzia Landi che nel corso dell’evento ha voluto lanciare un messaggio ai Millennials: "Hanno una creatività favolosa, devono uscire escano dalla logica del posto fisso e comprendere che il mondo si sta evolvendo e ha bisogno di mobilità, di trovare gente determinata che abbia capacità e determinazione. A noi il compito di aiutarli e guidarli ad esprimersi al meglio in un ecosistema nuovo". </p>
<p> Non è ovviamente una sfida facile, anche per ragioni di sistema: "Oggi fatichiamo a tracciare le logiche, a comprendere i comportamenti degli utenti e le loro dinamiche che evolvono nel tempo in direzioni inattese - ha spiegato Amedeo Guffanti, general manager, direttore e azionista di 77 Agency - Questo accade perché fattori esogeni agiscono sugli utenti, influenzandone i comportamenti e le preferenze, rendendo necessario immaginare e applicare un sistema dinamico nello studio dei dati. Diventa cruciale identificare segmenti di consumatori simili per categorie di comportamento e in questo la localizzazione geografica e le sue influenze diventano un elemento distintivo da considerare per la segmentazione degli obiettivi poiché si tratta di una variabile che tende a mantenersi stabile, dando consistenza al modello". </p>
<p> Sotto questo punto di vista la convergenza digitale aiuta non poco, come sottolineato pure da Roberto Calculli, fondatore e ceo di The Digital Box: "È un fenomeno che interessa ogni tipo di business e a cui ogni brand dovrebbe prestare la massima attenzione: comprendere a fondo le diverse tematiche e saper interpretare correttamente i dati provenienti dai tre canali significa cogliere l’opportunità di avere una visione chiara dei trend che interesseranno i prossimi anni". </p>
<p> Il tuo contributo è fondamentale per avere un’informazione di qualità. Sostieni il giornalismo di Repubblica. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2019/04/03/news/sorpresa_con_l_intelligenza_artificiale_il_basilico_e_piu_gustoso-223199574/" parent_folder="Repubblica 2018-2020" id="file17861741" filename="sorpresa_con_l_intelligenza_artificiale_il_basilico_e_piu_gustoso-223199574">
<p> Tecnologia </p>
<p> Sorpresa: con l'Intelligenza artificiale il basilico è più gustoso </p>
<p> È il primo passo - convincente - della cosiddetta cyber-agricoltura: ora i ricercatori puntano ad aumentare le proprietà medicinali di alcune piante e ad aiutare le coltivazioni ad adattarsi ai cambiamenti climatici </p>
<p> 03 Aprile 2019 1 minuti di lettura </p>
<p> ROMA - Alla sua prima esperienza da contadino, l'Intelligenza Artificiale fa centro. Quasi inaspettatamente. Ha coltivato il basilico più ricco di aroma senza modifiche al Dna, ma grazie ad un algoritmo di apprendimento automatico, che ha valutato milioni di dati per trovare le condizioni migliori con cui ottenere il sapore più gustoso. La ricerca del Massachusetts Institute of Technology (Mit) di Boston, pubblicata sulla rivista Plos One, è il primo passo della cosiddetta cyber-agricoltura: ora i ricercatori puntano ad aumentare le proprietà medicinali di alcune piante e ad aiutare le coltivazioni ad adattarsi ai cambiamenti climatici. </p>
<p> I ricercatori guidati da Arielle Johnson ed Elliot Meyerson hanno coltivato il basilico in fattorie verticali, sottoponendolo a diverse condizioni rigidamente controllate. Tutte le informazioni, poi, sono state elaborate da un algoritmo di apprendimento automatico, che ha valutato milioni di possibili combinazioni: con sorpresa dei ricercatori, è risultato che il sapore migliore si ottiene con un'esposizione alla luce continuata di 24 ore al giorno. </p>
<p> Adesso gli autori dello studio stanno cercando di ottenere piante di basilico più ricche di sostanze che aiutano a combattere diverse malattie, come il diabete, e di aumentare le rese di erbe medicinali come la pervinca del Madagascar, unica fonte di alcune molecole anticancro. Un'altra importante applicazione della cyber-agricoltura è l'adattamento ai cambiamenti climatici: in questo ambito il gruppo di ricerca sta già conducendo esperimenti sugli alberi di nocciole per la multinazionale Ferrero, che consuma il 25% delle nocciole coltivate al mondo. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/social-network/2018/12/30/news/su_twitter_il_mostra_le_opere_fatte_dall_intelligenza_artificiale-215529960/" parent_folder="Repubblica 2018-2020" id="file17861707" filename="su_twitter_il_mostra_le_opere_fatte_dall_intelligenza_artificiale-215529960">
<p> Tecnologia </p>
<p> Su Twitter il mostra le opere create dall'intelligenza artificiale </p>
<p> Dal tramonto su Giove all'alba su Urano tra le opere d'arte generate dai bot, ossia programmi autonomi che accedono ai social </p>
<p> 30 Dicembre 2018 1 minuti di lettura </p>
<p> ROMA - Il tramonto su Giove, l'alba su Urano, tanti disegni astratti: sono alcune delle opere d'arte generate dai bot, ossia quei programmi autonomi che accedono ai social e lì trovano "ispirazione", e pubblicate in una singolare mostra via Twitter. Sono nate dal progetto Arty Bots, nel quale una famiglia composta da 17 bot "artisti" è attiva sul social network dove crea più opere al giorno e le condivide. L'alba su Urano, a esempio, raffigura un cielo striato di nuvole dai colori pastello illuminate dalla prima luce del mattino, mentre 'Il tramonto su Giove' ha per protagoniste nuvole luminose di colore blu e azzurro. Entrambe le opere sono state create dal bot Arty Winds che "fa soffiare il vento attraverso i pixel di una immagine" e "disegna anche nuvole extraterrestri". Ognuno dei bot 'artisti' attivi su Twitter è estremamente specializzato, o nello stile o nei soggetti che rappresenta. Arty Petals, a esempio, crea solo immagini di fiori sovrapposti fatti di migliaia di petali colorati, mentre ArtyMash crea composizioni ottenute mixando fotografie scaricate liberamente da internet. Anche Arty Tiles parte da una foto e la scompone nelle tessere di un mosaico, mentre Arty Letters prende le immagini e le converte in griglie di lettere basate sui colori dei loro pixel. Inoltre, c'è chi crea frattali generati casualmente, chi crea immagini combinando triangoli e chi dipinge arte astratta come l'opera 'Untitled #7369', nella quale un disegno geometrico che si ripete è attraversato da bande di luce. ArtyShapes invece crea opere assemblando figure geometriche come 'L'età della meraviglia', nella quale si intrecciano forme sinuose di varie tonalità. </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/economia/affari-e-finanza/rapporti/2019/05/28/news/tecnologia_la_rivoluzione_sta_in_un_mix-227431793/" parent_folder="Repubblica 2018-2020" id="file17861736" filename="tecnologia_la_rivoluzione_sta_in_un_mix-227431793">
<p> Economia </p>
<p> Tecnologia, la rivoluzione sta in un mix </p>
<p> di Luigi Dell’Olio </p>
<p> Un sondaggio di Sap sulle potenzialità del cloud rileva che i consumatori ritengono tra i principali motori del cambiamento l’Iot, Internet of things. </p>
<p> 28 Maggio 2019 2 minuti di lettura </p>
<p> Sap ha realizzato per Henkel una soluzione basata sul cloud che ha permesso al negozio online della multinazionale di supportare la vendita da qualsiasi device e di garantire la visualizzazione a 360° dei prodotti al cliente, che in questo modo diventa davvero centrale nel processo di acquisto. Uqido, pezzo di Silicon Valley ubicato a Padova, ha utilizzato la realtà virtuale per rinnovare i punti vendita di Dainese. In particolare, per consentire di provare l’angolo di visione di un nuovo casco ha messo a punto un’esperienza di video a 360 gradi con riprese da una moto, che consente all’utente di godere della visione di campo ampliata tipica del top della gamma dei caschi Agv. Amazon ha tra le sue frontiere più innovative AR View, che permette ai clienti di vedere i prodotti oggetto di interesse direttamente nelle proprie abitazioni grazie alla realtà aumentata. Mentre si cerca il prodotto desiderato sulla app di Amazon, è sufficiente puntare il proprio smartphone sul punto della casa al quale è destinato per vedere apparire un’anteprima sul proprio cellulare, con la possibilità di guardarlo da diversi punti di vista e angolature. </p>
<p> Sono solo alcuni esempi dell’impatto che caratterizza le tecnologie dell’innovazione al servizio del commercio digitale. Temi come l’intelligenza artificiale (cioè funzioni che consentono alle macchine di svolgere compiti fin qui appannaggio esclusivamente del cervello umano), i chatbot (assistente virtuale capace di rispondere a una serie di quesiti posti dall’utente), la blockchain (tecnologia che permette di effettuare transazioni in maniera decentralizzata, senza la necessità della presenza di un’autorità di controllo) e la robotica sono sulla bocca di tutta la business community, ma solo un numero limitato di aziende le sta sperimentando realmente. Le altre aspettano di avere un feeedback dei progetti avviati dai concorrenti, anche se questo significa correre il rischio di perdere il treno della competitività, considerato che sul fronte dell’innovazione arrivare prima degli altri può rivelarsi decisivo. la logistica Tra i progetti più interessanti quelli legati agli aspetti logistici, come l’automazione del picking&packing (processi che caratterizzano l’imballaggio di un prodotto), le analisi predittive sulla rotazione dell’inventario (con i software che sono in grado di stimare quando vi sarà l’esigenza di nuove forniture di merci) e i sistemi di tracciamento delle spedizioni tramite strumenti inseriti nel packaging. Soluzioni che da una parte mirano a rendere più rapidi i processi e dall’altra ad alzare i livelli di sicurezza a vantaggio dei consumatori finali. Ad esempio, grazie al controllo consapevole delle informazioni assicurato dalla blockchain, si potrà assicurare la massima interoperabilità dei dati tra i diversi sistemi. Se molte tecnologie hanno già trovato riscontri tangibili nelle attività logistiche, in altri casi sono ancora in una fase iniziale di sperimentazione: basti pensare alla blockchain e al suo impatto sui sistemi di pagamento. Se il decentramento fa sì che nessun singolo punto di errore possa distruggere il contenuto del registro e che, una volta inseriti i dati, non possano modificati, se non previo accordo di tutte le parti interessate, dall’altra di tanto in tanto si sente di malintenzionati che sfruttano questa rete per commettere furti. Di fronte a uno scenario tecnologico, caratterizzato da fortissime potenzialità, ma anche significative zone d’ombra, le imprese sono chiamate a un costante monitoraggio della loro evoluzione e alla ricerca delle applicazioni più interessanti. Leggendo il recente studio promosso da Sap, dal titolo “Emerging Opportunities to Deploy Industry Processes in the Cloud”, emerge che la chiave della trasformazione digitale nel settore retail è data da un mix di tecnologie intelligenti. Gli intervistati considerano l’Internet of Things (88%), gli analytics in tempo reale (86%) e il machine learning (84%) i principali motori del cambiamento. La sfida principale sta nel portare il potenziale delle tecnologie a livello di applicazioni concrete nel business dell’azienda, con l’obiettivo di rendere sempre più centrale il ruolo del consumatore. Un obiettivo che può essere centrato agendo non solo sulla tecnologia, ma anche sull’organizzazione e sulla cultura aziendali. </p>
<p> I numeri </p>
<p> 88 per cento. Per quasi 9 su 10 intervistati l’IoT è fondamentale per poter trasformare il retail 86 per cento. Decisivo anche il ruolo assegnato dagli intervistati agli analytics in tempo reale </p>
<p> Leggi anche </p>
<p> i Consigli.it sceglie e raccomanda in maniera indipendente prodotti e servizi che si possono acquistare online o tramite la consulenza di esperti. Ogni volta che viene fatto un acquisto attraverso uno dei link presenti nel testo, Consigli.it riceve una commissione senza alcuna variazione del prezzo finale. </p>
</doc>
<doc url="https://www.repubblica.it/dossier/le-guide/festivalfilosofia/2020/09/14/news/un_doppio_superumano_no_i_robot_sono_applicazioni_sociali-267270581/" parent_folder="Repubblica 2018-2020" id="file17861755" filename="un_doppio_superumano_no_i_robot_sono_applicazioni_sociali-267270581">
<p> Un doppio superumano? No, i robot sono applicazioni sociali </p>
<p> di Jeffrey Schnapp </p>
<p> Storici equivoci che ostacolano l’innovazione </p>
<p> Nel vasto universo delle macchine ce n’è solo una che regolarmente restituisce all’umanità la sua immagine nello specchio della storia; solo una che, sia essa costruita come schiava o come giocattolo, riemerge come ossessione di somiglianza per gli umani, sia che interpreti il ruolo di avversario, di replica o di sostituta; e solo una che infonde il sogno di una super-umanità. Quella macchina è il robot. Per quanto tenace sia stata la presa esercitata sull’immaginario collettivo da questa particolare rappresentazione della robotica – che si può far risalire almeno a Descartes e giunge fino al modo in cui vengono immaginati gli androidi nel cinema contemporaneo – l’ontologia convergente che congiunge l’umano al robotico ostacola l’innovazione nel campo della robotica, perché genera cattivi robot, robot che falliscono. Cosa non meno importante, genera anche umani che falliscono, perché è d’ostacolo a una più profonda comprensione di quanto gli umani siano radicati nel mondo fisico e naturale. I robot non sono il nostro doppio, ma piuttosto un variegato intreccio di altri, operanti al di fuori e accanto all’umano. </p>
<p> Questi altri non devono venire costruiti come forme di vita, come servi o come potenziali Sé, ma piuttosto come “applicazioni sociali” che estendono e trasformano la capacità d’azione umana e danno vita a nuove forme sociali, norme, modi e scale d’interazione e d’intersezione con il mondo, dalla nano- alla giga-scala. Le definisco applicazioni perché applicano un know-how dato, operano all’interno di un ambito ben definito e sono progettate per eseguire compiti incredibilmente precisi o ripetitivi, o comunque non in linea con le capacità umane. Le definisco sociali perché, anziché connettersi all’ambito umano delle emozioni o dell’intersoggettività, operano come espressioni finalizzate di azioni individuali o collettive. Molte sono cosiddetti “cobot”, coinvolti in processi di ricerca o di produzione collaborativa nei quali umani e robot lavorano fianco a fianco o rispondono in modo sequenziale ai reciproci movimenti. </p>
<p> Concentrarsi sul riprodurre o superare la conoscenza, il linguaggio, il movimento, la personificazione o il comportamento degli umani può sicuramente servire da stimolo per l’innovazione nel campo della robotica. Tuttavia esse generano robot che falliscono nei test più elementari. Tali fallimenti sono correlati a due fattori: una sopravvalutazione del potere della tecnologia di riprodurre o superare in modo sostenibile forme di vita complesse. Essa assume varie forme: una è la classica fiducia che la strada per risolvere tutti i più spinosi problemi sociali – dalla cura degli anziani, all’isolamento sociale, fino all’istruzione – dipenda dalla tecnologia. Un’altra è la forma trascendentale sostenuta dai vari Ray Kurzweil secondo i quali siamo vicini alla “singolarità”: ossia al momento in cui verrà realizzata un’intelligenza artificiale sovrumana la quale assumerà il controllo e progetterà strumenti molto più avanzati di tutti quelli noti attualmente. L’altro fattore è una sottovalutazione della complessità delle azioni umane, anche delle più apparentemente semplici: dalle sottili gradazioni della comunicazione facciale alle abilità motorie richieste per navigare nell’ambiente circostante, che implicano costanti micro-adattamenti nell’andatura, nel ritmo e nella coordinazione, fino alla flessibilità e alla fluidità dei processi mentali. </p>
<p> La realtà della robotica odierna è ben diversa dai sogni androidi del passato e del presente. Prevede la gestione di magazzini nei quali gli operatori umani interagiscono con sciami di unità di trazione che corrono ad alta velocità su pavimenti reticolari. Include sale operatorie online in cui abilissimi chirurghi conducono micro-operazioni attraverso bracci robotici ultraprecisi; mini-robot a forma di pesce capaci di misurare in modo non intrusivo lo sbiancamento della barriera corallina; e un numero crescente di mietitrici a guida autonoma che si servono di mappe ottenute con i droni e di servizi d’informazione geografica ad alta precisione. Inoltre è pronta a trasformare la vita quotidiana dei cittadini del XXI secolo, dai “cargo bot” che li accompagneranno nei loro spostamenti giornalieri alle applicazioni robotiche pre-programmate che operano all’interno delle loro abitazioni. Anticipazione della lezione magistrale “Umanoidi. I robot facciano i robot”, in programma a Modena, piazza Grande, domenica 20 settembre alle ore 16 (traduzione dall’inglese di Daniele Francesconi) </p>
</doc>
<doc url="https://www.repubblica.it/tecnologia/2019/09/26/news/volti_generated_photos_deepfake-236979821/" parent_folder="Repubblica 2018-2020" id="file17861743" filename="volti_generated_photos_deepfake-236979821">
<p> I 100mila volti di persone che non esistono: così il mondo dei Deepfake si allena con la realtà </p>
<p> di ALESSIO SGHERZA </p>
<p> A Onlife, l'appuntamento con l'innovazione organizzato da Repubblica e dai giornali della LENA il 4 e il 5 ottobre prossimi a Milano, uno dei temi sarà l'impatto che l'era digitale avrà sulle nostre vite quotidiane. La startup Generated Photos mette online gratis immagini realistiche generate al computer di persone inesistenti. Un nuovo tassello di una tecnologia che cambierà (e sta già cambiando) il mondo in cui viviamo </p>
<p> I dieci volti che potete vedere nella foto qui sopra non esistono. E come loro, altri 100mila volti che sono gratuitamente disponibili online. Si tratta di uno stock di immagini generate al computer da un'intelligenza artificiale e messe a disposizione gratuitamente da 'Generated Photos', una startup che dichiara di volere "democratizzare la fotografia creativa". </p>
<p> Usando la tecnologia Gan (generative adversarial network o rete generativa avversaria) e dando in pasto all'algoritmo i volti di 69 modelli (volontari e d'accordo) in 29mila foto scattate in studio, la startup ha generato le facce di 100mila persone inesistenti ma realistiche. Anzi reali: queste persone non esistono e non sono mai esistite solo per un caso della natura. </p>
<p> Sono i giorni in cui tutti hanno visto il deepfake di Matteo Renzi fatto da Striscia la Notizia, la cui qualità era assai limitata ma ha il pregio di sollevare seriamente anche in Italia il tema dei rischi che i deepfake possono comportare. </p>
<p> Per chi non avesse ancora intercettato la parola deepfake: si definisce deepfake un video o un audio manipolato attraverso algoritmi con un risultato iperrealistico. Solitamente viene usato per far sembrare che qualcuno - solitamente una persona famosa - dica o faccia qualcosa, a fini umoristici o più propriamente politici. </p>
<p> Sono settimane e mesi in cui il mondo delle reti Gan si sta evolvendo a velocità rapidissima. E il costo di accesso a questa tecnologia si sta abbassando vertiginosamente. </p>
<p> Solo un mese fa la app cinese Zao, che permette di sostituire il proprio volto a quello degli attori dei film celebri, ha spopolato in Cina e fatto molto discutere. Un utilizzo a fini di intrattenimento, certo. Ma il video falso di Zuckerberg che a giugno affermava di avere "il controllo di miliardi di dati personali rubati" già ha impatti più seri sulla società. Per non parlare del video di Nancy Pelosi: pur non essendo propriamente un deepfake, era da denuncia per diffamazione. </p>
<p> Tornando a Generated Photos, le 100mila facce messe online (tra cui, va detto, ce ne sono alcune anche riuscite male) rischiano di essere un colpo enorme per il mondo della fotografia, dei modelli e di tutti i siti di stock fotografici: con questa tecnologia potremo generare l'immagine che ci serve su misura. Con modelli diversi a seconda dell'utilizzo. A costo quasi pari a zero. </p>
<p> Per ora si tratta di una tecnologia poco più che embrionale: "Abbiamo scattato - spiega la startup - queste foto in un ambiente controllato come illuminazione e post-elaborazione, per assicurarci che ogni faccia avesse una qualità di stampa elevata e costante. Dopo le riprese, sulle foto abbiamo fatto un grande lavoro di etichettatura e categorizzazione". Tanto lavoro ancora manuale. Ma è un altro sintomo del fatto che il futuro corre verso di noi: dobbiamo essere pronti, altrimenti ci travolgerà. </p>
<p> DA REP </p>
<p> Oggi e domani a Milano il primo evento di Repubblica dedicato alla società digitale. Con ospiti da tutto il mondo </p>
<p> Le testate coinvolte dietro l'evento di Milano. Dal Die Welt a El País, fino alla Gazeta Wyborcza, Le Figaro, Le Soir, Tages-Anzeiger e Tribune de Genève oltre a La Repubblica </p>
</doc>
